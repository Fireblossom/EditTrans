# qecGPT: decoding Quantum Error-correcting Codes with Generative Pre-trained Transformers 

Hanyan Cao, 1, 2 

Feng Pan, 1 

Yijia Wang, 1, 2 

and Pan Zhang 1, 3, 4, _ ∗_ 

1 _CAS Key Laboratory for Theoretical Physics, Institute of Theoretical Physics,_ _Chinese Academy of Sciences, Beijing 100190, China_ 2 _School of Physical Sciences, University of Chinese Academy of Sciences, Beijing 100049, China_ 3 _School of Fundamental Physics and Mathematical Sciences,_ _Hangzhou Institute for Advanced Study, UCAS, Hangzhou 310024, China_ 4 _International Centre for Theoretical Physics Asia-Pacific, Beijing/Hangzhou, China_ 

##### Abstract
We propose a general framework for decoding quantum error-correcting codes with generative modeling. The model utilizes autoregressive neural networks, specifically _ Transformers_ , to learn the joint probability of logical operators and syndromes. This training is in an unsupervised way, without the need for labeled training data, and is thus referred to as _ pre-training_ . After the pretraining, the model can efficiently compute the likelihood of logical operators for any given syndrome, using maximum likelihood decoding. It can directly generate the most-likely logical operators with computational complexity \(\mathcal{O}(2k)\)in the number of logical qubits \(k\), which is significantly better than the conventional maximum likelihood decoding algorithms that require \(\mathcal{O}(4^{k})\)computation. 

##### Abstract
Based on the pre-trained model, we further propose _ refinement_  to achieve more accurately the likelihood of logical operators for a given syndrome by directly sampling the stabilizer operators. We perform numerical experiments on stabilizer codes with small code distances, using both depolarizing error models and error models with correlated noise. The results show that our approach provides significantly better decoding accuracy than the minimum weight perfect matching and belief-propagation-based algorithms. Our framework is general and can be applied to any error model and quantum codes with different topologies such as surface codes and quantum LDPC codes. Furthermore, it leverages the parallelization capabilities of GPUs, enabling simultaneous decoding of a large number of syndromes. Our approach sheds light on the efficient and accurate decoding of quantum error-correcting codes using generative artificial intelligence and modern computational power. 

Quantum computers can potentially solve practical problems which are intractable for classical computers. However, the current implementation of quantum computers has an issue with noise, which limits its power. An essential step towards fault-tolerant quantum computing is quantum error correction (QEC), which now becomes one of the key research frontiers in both theoretical studies and hardware developments [ 1 ,  2 ] of quantum computation [ 3 ]. In QEC, logical states with \(k\) logical qubits are encoded using \(n\) physical qubits with redundancy. The effects of continuous errors can be digitalized into a finite set of discrete errors, which can be obtained by measuring the redundant ancilla qubits, giving an error syndrome. Then a decoding algorithm infers the information of errors based on the syndrome and determines an appropriate operation to correct the logical error. However, the decoding problem is a hard problem, for example, it \(\#\)P hard problem in the classical error-correcting codes. In quantum codes, decoding is considered to be more challenging than classical code, because the errors inherently degenerate, and the corresponding factor graph for the codes is more complex, for example, in CSS code the factor graph always contains loops with various sizes due to the commutation relations, so standard decoding algorithms such as belief propagation do not work as well as in classical low-density parity check (LDPC) codes. 

While a number of algorithms have been proposed for decoding quantum error-correcting codes, we lack general decoding algorithms that are efficient and accurate. The minimum weight perfect matching algorithm [ 4 ,  5 ] can decode surface code efficiently, however, as a minimumweight decoder ignores the degeneracy of quantum codes, in principle its performance usually has a gap to the theoretical limit. Moreover, it is less efficient in non-planar graphs and is challenging when applied to code on hypergraphs where the distances between two nodes are not well defined. As a prototype of the maximum likelihood decoder (MLD), tensor network methods (e.g. the boundary matrix product state method [ 6 ]) consider the degeneracies of quantum codes and work close to the theoretical limit in surface code. However, for general codes not defined on lattices with open boundaries, the tensor network contractions are difficult to apply due to the large treewidth of the graph. Another issue for existing maximum-likelihood decoders is computing probabilities for \(4^{k}\)logical operators for \(k\) logical qubits, which is intractable for a large \(k\). Moreover, the contraction of tensor networks for each syndrome consumes significantly more computational resources than the minimum-weight decoding algorithms and hence less efficient. Recently, a number of neural network decoders are proposed for leveraging fast inference in neural networks on modern GPUs [ 7 – 14 ]. These methods are based on supervised 