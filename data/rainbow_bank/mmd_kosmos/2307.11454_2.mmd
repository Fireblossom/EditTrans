<table>
<thead>
<tr>
<th style="text-align: center;">Configuration</th>
<th style="text-align: center;">Median F1</th>
<th style="text-align: center;">Median ROC AUC</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Baseline</td>
<td style="text-align: center;">27.29</td>
<td style="text-align: center;">0.696</td>
</tr>
<tr>
<td style="text-align: center;">Without SMOTE &amp; RL</td>
<td style="text-align: center;">21.45</td>
<td style="text-align: center;">0.730</td>
</tr>
<tr>
<td style="text-align: center;">Without AST edges</td>
<td style="text-align: center;">27.65</td>
<td style="text-align: center;">0.706</td>
</tr>
<tr>
<td style="text-align: center;">With pruning</td>
<td style="text-align: center;">30.83</td>
<td style="text-align: center;">0.724</td>
</tr>
<tr>
<td style="text-align: center;">Majority downsampling</td>
<td style="text-align: center;">26.61</td>
<td style="text-align: center;">0.678</td>
</tr>
</tbody>
</table>


**Table 1.**  Results of experiments for research question 1 

<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th colspan="2" style="text-align: center;">P1</th>
<th colspan="2" style="text-align: center;">P2</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">k</td>
<td style="text-align: center;">train</td>
<td style="text-align: center;">test</td>
<td style="text-align: center;">train</td>
<td style="text-align: center;">test</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">410 (205)</td>
<td style="text-align: center;">135 (68)</td>
<td style="text-align: center;">0 (0)</td>
<td style="text-align: center;">0 (0)</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">399 (200)</td>
<td style="text-align: center;">145 (73)</td>
<td style="text-align: center;">343 (171)</td>
<td style="text-align: center;">122 (61)</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">416 (208)</td>
<td style="text-align: center;">132 (66)</td>
<td style="text-align: center;">696 (347)</td>
<td style="text-align: center;">228 (113)</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">414 (207)</td>
<td style="text-align: center;">128 (65)</td>
<td style="text-align: center;">960 (479)</td>
<td style="text-align: center;">346 (172)</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">415 (210)</td>
<td style="text-align: center;">129 (64)</td>
<td style="text-align: center;">1159 (575)</td>
<td style="text-align: center;">433 (217)</td>
</tr>
<tr>
<td style="text-align: center;">6</td>
<td style="text-align: center;">414 (208)</td>
<td style="text-align: center;">131 (65)</td>
<td style="text-align: center;">1393 (692)</td>
<td style="text-align: center;">506 (254)</td>
</tr>
<tr>
<td style="text-align: center;">7</td>
<td style="text-align: center;">421 (212)</td>
<td style="text-align: center;">120 (60)</td>
<td style="text-align: center;">1583 (789)</td>
<td style="text-align: center;">596 (296)</td>
</tr>
<tr>
<td style="text-align: center;">8</td>
<td style="text-align: center;">394 (197)</td>
<td style="text-align: center;">151 (75)</td>
<td style="text-align: center;">1870 (938)</td>
<td style="text-align: center;">572 (284)</td>
</tr>
<tr>
<td style="text-align: center;">9</td>
<td style="text-align: center;">410 (207)</td>
<td style="text-align: center;">135 (67)</td>
<td style="text-align: center;">2027 (1012)</td>
<td style="text-align: center;">664 (330)</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: center;">411 (206)</td>
<td style="text-align: center;">131 (66)</td>
<td style="text-align: center;">2195 (1089)</td>
<td style="text-align: center;">632 (314)</td>
</tr>
<tr>
<td style="text-align: center;">11</td>
<td style="text-align: center;">399 (199)</td>
<td style="text-align: center;">150 (75)</td>
<td style="text-align: center;">2439 (1215)</td>
<td style="text-align: center;">708 (353)</td>
</tr>
<tr>
<td style="text-align: center;">12</td>
<td style="text-align: center;">400 (202)</td>
<td style="text-align: center;">144 (72)</td>
<td style="text-align: center;">2545 (1270)</td>
<td style="text-align: center;">769 (383)</td>
</tr>
<tr>
<td style="text-align: center;">13</td>
<td style="text-align: center;">397 (200)</td>
<td style="text-align: center;">143 (72)</td>
<td style="text-align: center;">2619 (1303)</td>
<td style="text-align: center;">872 (434)</td>
</tr>
<tr>
<td style="text-align: center;">14</td>
<td style="text-align: center;">409 (204)</td>
<td style="text-align: center;">136 (68)</td>
<td style="text-align: center;">2853 (1421)</td>
<td style="text-align: center;">845 (419)</td>
</tr>
</tbody>
</table>


**Table 2.**  Statistics of collected Java methods after stratifi- cation by \(k\)and cleaning. Each cell has the format \(N_{1}(N_{2})\), where \(N_{1}\) is the total number of methods and \(N_{2}\) is the num- ber of vulnerable ones. 

# Dissecting Code Vulnerabilities: Insights from C++ and Java Vulnerability Analysis with ReVeal Model 

\(200\), batch size \(128\), maximum number \(10000\), number of gradient accumulation steps \(8\), \(50\)for C++ data and \(20\)for Java data. 

## Experiments with C++ data 

To answer the first research question, we used the original C++ method-level vulnerability dataset from [ 1 ]. After parsing, we obtained the following statistics of the input graphs: 

11788 train graphs (956 vulnerable), 1667 validation graphs (133 vulnerable), 3385 test graphs (286 vulnerable) 

To test each dimension of RQ 1, we performed 10 trials of training the model. In each trial, the dataset was split into train, validation, and test parts anew. The results can be found in Table  1 . 

### Excluding SMOTE and RL 

The model without SMOTE and RL achieves the worst performance with respect to the F1 score and the best performance with respect the ROC AUC measure. 

### AST edges 

The model performs slightly better without including AST edges. This is likely due to including too much of fine-grained information or too many nodes. The model becomes more likely to overfit to irrelevant features in the input and fail to generalize. 

### Pruning 

The experiments also showed that the model performs better with pruning at operator nodes. Pruning makes a graph simpler and less entangled for the model to understand. 

### Downsampling 

Table  1  shows that the model performs worse with balancing the train set by downsampling non-vulnerable methods. We think that a rough balancing of the train part impacts the score negatively since it turns off SMOTE. 

## Experiments with Java data 

To answer the rest of research questions, we trained and tested the model on different parts of the Java dataset  ( 1 ) : \(P_{1}\), \(P_{2}\), and \(P_{3}\). In particular, we varied \(k\)\(1\)to \(14\). Then, we plotted the resulting ROC AUC scores against \(k\), and draw conclusions based on the observed dynamics. To make set \(P_{3}\) to be independent of \(k\), we fixed it to be the complement of \(P_{1}\). That is, \(P_{3}\) consisted of functions that remained unchanged in the commits where only one function was changed. Also, in order to balance different parts involved in training and testing, we restricted the size of \(P_{3}\): \[|P_{3}|=|P_{1}|+|P_{2}|\]  

During the data cleaning phase, we ensured that in each experiment, \(P_{3}\) did not contain functions that are contained in \(P_{1}\cup P_{2}\). Also, we removed any duplicate functions from each of the parts \(P_{1},P_{2}\), and \(P_{3}\), and removed methods contained in the training data from the test data. 

Table  2  shows the distribution of the collected Java methods after stratification by \(k\)and cleaning the data: 

### Research question 2 

In this research question, we investigate training on different combinations of sets \(P_{1}\), \(P_{2}\), and \(P_{3}\), and testing on \(P_{1}\cup P_{2}\cup P_{3}\)or \(P_{1}\cup P_{3}\), which is a stricter test. The results can be found in Figures  2  and  3 . 

Figures  2  and  3  allow us to conclude that if the test set includes part \(P_{3}\), then the inclusion of part \(P_{3}\) into training is critical to achieving a high performance. Overall, parts \(P_{2}\)and \(P_{3}\) contribute the most to the prediction, as seen by the red and blue lines on Figures  2  and  3 . 

Also, on Figure  3 , we see a slight degradation of performance corresponding to training on \(P_{2}\cup P_{3}\) (red line) as \(k\)increases. This might indicate the increasing amount of 