tion of the created entanglement was studied. A more refined study of the process was presented in [ 18 ]. 

When specifically addressing scattering problems, with either classical or quantum simulations, there is an additional conceptual complexity which gets added to the already-serious problem of executing the many-body dynamics: namely, preparing the input state. Initial quantum states in particle colliders experiments typically involve localized wave packets of composite quasiparticles, for example hadrons. Written in the elementary quantum fields, these wave packets have a well defined centerof-mass momentum and overall number density (usually one quasiparticle), but their internal wave function can be very complex. Clearly, the scattering simulation must include strategies to build these states (and control their momentum) by carefully manipulating the elementary quantum fields encoded as qudits, starting from the (entangled) dressed vacuum. Proposals to achieve such input-state preparation have been put forward for Quantum Tensor Network (QTN) [ 84 ,  85 ] but the optimal general strategy is still unclear, and requires further investigation. Notice that this problem will remain when it becomes possible to study scattering processes in future quantum processors. Thus, any partial or final solution developed for tensor network will be highly valuable also for future quantum computations and the simulation of scattering processes. Let us mention in passing that other real-time phenomena, such as quenching, see e.g. [ 17 ,  86 ], have also been studied with QTN techniques. 

#### (2+1)D QED 

As mentioned in the introduction, (2+1)D QED is one of the simplest quantum field theories that nevertheless retain interesting physics: for example it shares with QCD important properties such as asymptotic freedom and confinement, and it is an excellent starting point for future analysis of more intricate theories. We therefore propose (2+1)D QED as a very suitable benchmark and testbed model to explore the potential of quantum computing and, in particular, to compare it to TN calculations. 

The most used classical method to study lattice gauge theories numerically nowadays is the Markov Chain Monte Carlo (MCMC) approach, see the recent _ FLAG_ _review_  [ 87 ]. While MCMC can reach lattice sizes of order of \(100^{3}\times 200\), which are currently unthinkable for QC and TN techniques, the Hamiltonian formulation used for the latter methods has several advantages. For example, MCMC suffers from very large autocorrelation times towards the continuum limit [ 88 ]. In the regime of small to very small lattice spacing, we can take advantage of quantum computing or tensor network approaches that do not have this drawback. Furthermore, the Euclidean path integral used by MCMC is afflicted by the infamous _sign problem_  [ 5 ] which makes the study of quantum field theories at non-zero fermion densities impossible. More specifically for lattice QCD, this prevents the exploration and characterization of regions of the phase diagram at non-zero baryon density, which are relevant to understand the early universe, neutron stars, or the transition to a quark-gluon plasma. Another important aspect is the limitation for classical MCMC techniques in the presence of a topological term which, in stark contrast, can be treated straightforwardly in the Hamiltonian formulation, i.e. with QC or TN. Finally, a Hamiltonian approach will enable the study of real-time phenomena such as scattering processes, thermalization or the dynamics of physical systems after quenching, see the discussion in Sec. I and below. 

Although we are fully aware of the advancements of TN [ 10 ], in the spirit of this paper, we will focus on the quantum computing approach to study quantum field theories and, in particular, on the example of (2+1)D QED. 

Another pillar of quantum information science and technology is analog quantum simulators [ 37 ,  89 ,  90 ] which allow direct experimental access to various quantum many-body phenomena. Given recent advancements in quantum-simulator technology such as single-atom resolution through gas microscopes [ 91 – 93 ] and overall high levels of precision and control [ 94 ], quantum simulators have become an attractive venue on which to probe highenergy phenomena [ 9 ,  41 ,  95 – 97 ], affording the precious advantage of accessible temporal snapshots at any stage of the system dynamics. The _ modus operandi_  of quantum simulators is to map a _ target model_  described by a Hamiltonian  \(\hat{H}_{0}\)\(\hat{H}_{0}\) onto another quantum model amenable for realization in an experimental platform. This mapping is almost never exact but will lead to an effective model where  \(\hat{H}_{0}\)\(\hat{H}_{0}\) arises up to leading order in perturbation theory, along with (undesired) subleading terms \(\lambda\hat{H}_{1}\), with strength \(\lambda<1\). In the context of gauge theories, the model  \(\hat{H}_{0}\)\(\hat{H}_{0}\) hosts a gauge symmetry generated by local operators  \(\hat{G}_{j}\)\(\hat{G}_{j}\), while  \(\hat{H}_{1}\)\(\hat{H}_{1}\) explicitly breaks it. 

Initially, quantum simulators of gauge theories were restricted to cold-atom realizations of building blocks for both \(\mathbb{Z}_{2}\) [ 98 \(\mathrm{U}(1)\)gauge groups [ 99 ]. The experiment of Ref. [ 98 ] employed two species of bosonic cold atoms in a double-well potential. Periodic driving resonant at the on-site interaction strength and with the appropriate fine-tuning of the modulation parameters resulted in an effective Floquet Hamiltonian with the desired \(\mathbb{Z}_{2}\) gauge symmetry. On the other hand, the experiment of Ref. [ 99 ] employed inter-species spin-changing collisions to model the gauge-invariant coupling between matter and gauge fields. Although groundbreaking in their own right, these experiments were restricted to building blocks and suffered from uncontrolled subleading gauge-noninvariant processes that limited useful coherent times [ 100 ]. 

To probe gauge-theory physics relevant to high-energy phenomena, it became essential to devise experimentally feasible methods that could enable large-scale implementations on quantum simulators. This was made possible through the introduction of _ linear gauge pro-_ 