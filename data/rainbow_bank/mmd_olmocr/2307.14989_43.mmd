ing a \(Z\)-error defined by: 

\[\begin{split}&P(Z|X=1)=\frac{p_{Y}}{p_{X}+p_{Y}}\\ &P(Z|X=0)=p_{Z},\end{split}\] (22)  

where, \(P(Z|X=1)\) is the probability that a specific data qubit undergoes a phase-flip \(Z\)given that it has been considered to undergo a bit-flip \(X\), and \(P(Z|X=0)\) is the probability that a qubit which is considered to not have undergone a bit-flip has undergone a phase-flip \(Z\). This can be done once 

_et al._ ,  2023 ) or in a recursive manner ( deMarti iOlius _ et al._ ,  2022a ;  Yuan ,  2022 ). Moreover, it can be combined with the XY-code in order to enhance the susceptibility of the code towards \(Z\)-noise ( deMarti iOlius _ et al._ ,  2022a ;  Higgott _ et al._ ,  2023 ). 

Thus, it is important from the decoding (and code construction point of view) to consider the actual noise that the qubits of the surface code experience. As seen for the XZZX code, this tailoring does actually even significantly improve the code performance without needing to lose resources. Even if we have discussed noise bias here, there are many other important subtleties in the nature of the noise for each qubits technology that should be considered for integration in real hardware. For example, multi-qubit error correlation and time-varying noise are examples of this. The fact that the actual distribution of the errors in a real quantum processor is independent seems to be generally false. In this sense, studying the correlated nature of noise is an incipient sub-field in the topic and, thus, tailoring decoding to such correlated nature should improve the performance of the codes over such models ( Harper and Flammia ,  2023 ). Note that this quandary is not new for classical error correction ( Tse and Viswanath ,  2005 ), implying that many ideas of dealing with such noise can be extrapolated to the quantum domain. Modifications of decoders to take into account correlated noise have been already proposed for quantum turbo codes over channels with memory, resulting in a considerably improved performance of the code when compared to the decoder that is blind to the correlation ( Mohd Izhar _ et al._ ,  2018 ). Additionally, the noise experienced by superconducting qubits has been proven to be time-varying ( Etxezarreta Martinez _ et al._ , 2021 ;  Etxezarreta Martinez _ et al._ ,  2023 ), which implies that the performance of the codes experiences a degradation. In this sense, studying adaptive decoders that can estimate the noise level ( Wagner _ et al._ ,  2022 ) at a certain time in order to follow such fluctuating nature of the noise should considerably improve the performance ( Spitz _ et al._ ,  2018 ). 

To conclude, quantum error correction is still in a primitive stage before the potential of quantum computing can be unleashed by fault-tolerant machines. In this sense, surface codes represent the most promising family of codes to be implemented in the early post-NISQ era, principally due to their locality feature (and, in the case of planar instances, two-dimensional qubit placing) and their high tolerance to quantum noise. As extensively reviewed in this article, decoders represent a central part of QEC methods as they are key elements in posing a threshold for a code. Moreover, we have discussed the importance of the runtime of this algorithms due to the accumulation of other errors if the estimation of the channel error results to be too slow. As a result of this, there exists an important trade-off between accuracy and speed of decoders which implies that a selection of a decoder for real-time decoding depends on many factors that go from the hardware noise level to the pace at which more errors accumulate. Hence, the selection of the best decoder for an experimental implementation of a surface code is still an open question that many research teams, both in academia and industry, are trying to resolve. Due to the extense zoo of possible qubit technologies being investigated nowadays, it is possible that many of the exisitng candidates, or new ones, are the best fit as a function of the specifics of each of the quantum computing platforms. There is much work left to do, and each of us on the field should contribute our share in this Herculean quest. We live in exciting times. 

## DATA AVAILABILITY 

The data that supports the findings of this study is available from the corresponding authors upon reasonable request. 

## COMPETING INTERESTS 

The authors declare no competing interests. 

## ACKNOWLEDGEMENTS 

We want to acknowledge Nicolas Delfosse, Pavel Panteleev, Christopher Chubb, David Tuckett, Michael Newman, IËœnigo Barasoain and Javier Oliva for fruitful discussions. 

This work was supported by the Spanish Ministry of Economy and Competitiveness through the ADELE (Grant No. PID2019-104958RB-C44) and MADDIE projects (Grant No. PID2022-137099NB-C44), by the Spanish Ministry of Science and Innovation through the proyect Few-qubit quantum hardware, algorithms and codes, on photonic and solid-state systems (PLEC2021008251), by the Ministry of Economic Affairs and Digital Transformation of the Spanish Government through the QUANTUM ENIA project call - QUANTUM SPAIN 