Page dimensions: 595.3x841.9
[65x260]a
[65x260]being a crosswalk;
[65x211]parameters to be estimated are
[65x224]Uturn
[65x236]by interactions with the length so that the link-additive nature of the global path choice is retained. We also add a
[65x248]from Google Street View images using a deep learning model
[65x248]3
[65x431]Tourism of Japan, 2018), in the Kannai area, Yokohama city, Japan. The pedestrian network for the case study contains
[65x443]survey of the Sixth Tokyo Metropolitan Region Person Trip Survey (Ministry of Land, Infrastructure, Transport and
[65x455]model. The data is the same as used in Oyama (2023), based on GPS trajectories collected through a complementary
[65x467]environment while walking and locally adjust their path choice behavior, which we analyze by using the proposed
[65x479]path observations. Because walking is a slow mode of transportation, pedestrians may visually perceive the street
[65x506]5.2. Real pedestrian path choice application
[65x541]specifications with respect to attributes of interest, including one with the attribute introduced to both the global and
[65x565]by flexibly defining the global and local utility functions. Moreover, it was also shown that we can analyze to what
[65x613](Data L) Std.err. 0.14 0.08 0.10 0.13 0.13 0.11 0.12
[65x624]Model L (5.1b) Average -2.72 0.78 -2.47 1.97 -2.48 0.03 1.94
[65x669]ˆ
[65x669]Data generated by
[67x272]x
[71x260]x
[79x130]Oyama (2023) assumed
[79x407]In this case study, we consider the following three specifications of the reward function:
[79x577]These results show the difference between the global and local effects of an attribute, which our model can capture
[79x199]We hypothesized that the visual quality of the streets like GVI is locally perceived by pedestrians and affects their
[91x323]
[91x358]
[91x393]
[99x270]a
[99x270]and
[99x276]len
[102x313]v
[102x383]v
[102x297]v
[102x368]v
[107x311]G
[107x296]L
[107x331]L
[112x272]x
[112x297](
[113x313](
[116x297]a
[116x368]a
[116x332]a
[117x313]a
[117x348]a
[121x368]|
[121x313]|
[121x348]|
[123x368]k
[123x332]k
[124x313]k
[128x297]) =
[128x368]) =
[128x368]0
[128x313]) = (
[128x348]) = (
[128x383]) = (
[134x276]walk
[152x258]is the green view index (GVI) of the street, extracted as the vegetation pixel ratio (
[152x258]a
[152x266]green
[153x715]Table 3: Estimation results: averages and standard errors of the estimates over 10 samples.
[159x295]green
[159x336]L
[162x128]to be a dummy variable simply representing the presence of streetscape greenery. Instead, we calculated the
[162x134]green
[163x309]len
[163x344]+
[163x352]G
[163x379]+
[176x348]β
[176x383]β
[178x297]x
[178x332]x
[183x295]x
[183x303]green
[183x330]a
[183x330]x
[191x309]walk
[191x317]G
[191x387]G
[193x207]len
[193x215]G
[204x211],
[204x211]β
[207x301]len
[207x330]a
[207x336]len
[208x348]x
[208x383]x
[211x222]a
[213x310]+
[213x310]a
[213x317]walk
[213x346]a
[213x381]a
[213x381]+
[213x387]walk
[214x207]walk
[214x215]G
[216x222]k
[222x665]len
[224x685]Model G (5.1a) Model L (5.1b) Model GL (5.1c)
[231x211]β
[234x348]x
[239x346]a
[241x215]G
[247x311]green
[247x381]green
[258x211],
[266x313]x
[267x346]cross
[269x209]green
[269x215]G
[270x669]β
[271x310])
[271x310]a
[271x381])
[271x381]a
[271x671]ˆ
[274x667]cap
[274x672]G
[284x348]x
[290x211]β
[293x93]11
[295x383]x
[300x317]len
[300x381]+
[300x387]len
[312x215]L
[313x313]β
[313x383]β
[317x348]20
[320x669]β
[324x672]G
[328x317]G
[328x381]cross
[328x387]G
[332x211].
[332x352]uturn
[337x344]k
[342x701]Estimated model
[350x310]a
[350x317]cross
[350x381]−
[350x387]cross
[373x671]ˆ
[376x667]ˆ
[378x313]20
[378x383]20
[393x317]uturn
[393x379]a
[393x387]uturn
[396x309]|
[396x379]|
[397x272]a
[398x309]k
[402x272];
[412x270]is the dummy variable of
[422x669]β
[427x665]len
[427x672]G
[468x669]β
[469x671]ˆ
[472x667]cap
[472x667]ˆ
[472x672]G
[499x260]∈
[507x340](5.2b)
[507x305](5.2c)
[507x376](5.2a)
[510x260]0, 1
[517x669]β
[521x667]cap
[521x672]L
[524x260]\]
[527x260])
