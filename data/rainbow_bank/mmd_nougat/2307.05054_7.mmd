no polynomial algorithm over \(n\) and \(m\) can compute this mechanism just because of the sheer size of the output. However, given a game \(\Gamma\) and an output \(o\), it is not necessary to compute the whole description of the resilient truthful mechanism \(m_{d}^{*}\)for \(\Gamma\) that implements \(o\), we only need to be able to compute \(m_{d}^{*}(\vec{m})\)in polynomial time for each possible message profile \(\vec{m}\)\(\vec{m}\). We state this as follows. 

**Theorem 2.** _ There exists an algorithm_ \(\pi\)_ that receives as input the description of an information aggre-_ _gation game_ \(\Gamma=(S,A,\Omega,p,u)\)\(o\)for \(\Gamma\)\(k\)-resilient mechanism (resp., \(k\)-resilient mechanism), and a message input \(\vec{m}\)\(\vec{m}\)for the mediator, and \(\pi\)outputs a value \(q\in[0,1]\)such that the function \(m_{d}^{*}\)defined by \(m_{d}^{*}(\vec{m}):=A(\Gamma,o,\vec{m})\)\(k\)-resilient truthful mechanism \(k\)-resilient truthful mechanism) for \(\Gamma\)\(o\). Moreover, \(\pi\)_ runs in polynomial_ _time over_ \(|\Omega|\)_ and_ \(|S|\)_._ 

The proofs of Theorems 1 and 2 are detailed in Sections 4 and 5 respectively. Intuitively, each coalition imposes a constraint over the space of possible messages that the mediator may receive, implying \(0\)more often for some message inputs than others. These constraints induce a partial order over _ pure inputs_  (i.e., messages such that all senders report the same state), which is precisely the order defined by \(E\) in Theorem 1. It can be shown that, even though there may be exponentially many possible coalitions of size at most \(k\), this partial order can be computed in polynomial time over the number of states and senders. 

## Proof of Theorem 1 

In this section we prove Theorem 1. Note that, because of Lemma 1, we only have to show that, given a game \(\Gamma=(S,A,\Omega,p,u)\) with \(|\Omega|=m\) and \(|S|=n\), there exists a system of equations \(E\) as in Theorem 1 such that an outcome \(o\) is implementable by an honest mechanism that is \(k\)-resilient incentive-compatible (resp., strong \(k\)-resilient) for the senders if and only if \((o^{*}(\omega^{1}),\ldots,o^{*}(\omega^{m}))\) is a solution of \(E\). 

To understand the key idea, let us start with an example in which \(\Omega=\{\omega^{1},\omega^{2}\}\), \(S=\{1,2,3,4\}\), senders \(1,2\)and \(3\)prefer action \(0\)in \(\omega^{2}\), senders \(2,3\)and \(4\)prefer action \(1\)in \(\omega^{1}\), and in which we \(2\)-resilient incentive-compatible for the senders. If all senders are honest, then the mediator could only receive inputs \((\omega^{1},\omega^{1},\omega^{1},\omega^{1})\) or \((\omega^{2},\omega^{2},\omega^{2},\omega^{2})\) (where the \(i\)th component of an input represents the message sent by sender \(i\)). However, since senders could in principle deviate, the mediator could receive, for instance, an input of the form \((\omega^{1},\omega^{1},\omega^{2},\omega^{2})\). This input could originate in two ways, either the true state is \(\omega^{1}\)and senders 3 and 4 are misreporting the state, or the state is \(\omega^{2}\)\(1\)and \(2\)are misreporting. Even though a mechanism is honest, the mediatorâ€™s message function \(m_{d}\) should still be defined for inputs with different components, and it must actually be done in such a way that players are not incentivized to misreport. 

Let \(m_{d}^{*}\)be the function that maps each message \((m_{1},m_{2},m_{3},m_{4})\) to the probability that \(m_{d}(m_{1},\ldots,\allowbreak m_{4})=0\). If the honest mechanism determined by \(m_{d}^{*}\)\(2\)-resilient incentive-compatible for the senders, \(0\)should be lower with \((\omega^{1},\omega^{1},\omega^{2},\omega^{2})\) than with \((\omega^{2},\omega^{2},\omega^{2},\omega^{2})\). Otherwise, in \(\omega^{2}\)\(1\)and \(2\)can increase their utility by reporting \(1\)instead of \(2\). Thus, \(m_{d}^{*}\)must satisfy that \(m_{d}^{*}(\omega^{1},\omega^{1},\omega^{2},\omega^{2})\leq m_{d}^{*}(\omega^{2 },\omega^{2},\omega^{2},\omega^{2})\). Moreover, \(m_{d}^{*}(\omega^{1},\omega^{1},\omega^{2},\omega^{2})\geq m_{d}^{*}(\omega^{1 },\omega^{1},\omega^{1},\omega^{1})\), since otherwise, in state \(\omega^{1}\)\(3\)and \(4\)can increase their utility by reporting \(2\)instead of \(1\). These inequalities together imply that \(m_{d}^{*}(\omega^{1},\omega^{1},\omega^{1},\omega^{1})\leq m_{2}^{*}(\omega^{2 },\omega^{2},\omega^{2},\omega^{2})\), and therefore that \(o^{*}(\omega^{1})\leq o^{*}(\omega^{2})\). In fact, we can show that this is the only requirement for \(o\) to be implementable by a mechanism that is \(k\)-resilient incentive compatible for the senders. Given \(o\) such that \(o^{*}(\omega^{1})\leq o^{*}(\omega^{2})\), consider an honest mechanism determined by \(m_{d}^{*}\), in which \(m_{d}^{*}(m_{1},m_{2},m_{3},m_{4})\) is defined as follows: 