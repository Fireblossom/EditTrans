We use a penalty function that accounts for differences in the variance of the regressors which has not been studied in the literature before for least squares estimators, to our knowledge, and which is borrowed from the penalized quantile regression literature, see Belloni and Chernozhukov (2011). Although accounting for the variance is an appealing property on its own, we also prefer this penalty function as it means the penalization function of the coefficients in the VaR and ES estimation steps is equivalent. Indeed, we rely on the quantile regression estimator of Belloni et al. (2023) (from hereon BCMPW) to obtain the VaR predictions in the first step, although our results apply to any quantile estimator that satisfies the conditions. 

As financial data is often dependent over time and heavy-tailed, we derive our results under conditions that allow for these properties. Specifically, we allow the data to be \(\beta\)-mixing sequences with finite moments of a certain order. To obtain our results, we develop a Fuk-Nagaev inequality for \(\beta\)-mixing sequences, which may be of independent interest. Using the Fuk-Nagaev inequality we obtain rates on the parameters and penalty parameter that are directly comparable to those for the penalized quantile regression estimator in BCMPW. 

We apply our method in a systemic risk analysis. In this analysis we generate predictions of the Conditional Expected Shortfall (CoES) to measure the risk spillover from the financial sector to the entire stock market. The CoES measure was introduced in Adrian and Brunnermeier (2016) as an extension of CoVaR, an alternative systemic risk measure which is commonly used but is less prudent than CoES from a similar argument to the one that favors ES over VaR. The estimation of CoES relies on three stages of quantile regression and one stage of ES regression. Like Adrian and Brunnermeier (2016) we condition on seven lagged fundamental variables, but we extend their set of fundamental variables by also considering nonlinear transformations. Specifically, we use each the Chebyshev polynomials to transform each of the fundamental variables, where the degree of polynomials used may increase with the sample size. Our results show that the penalized VaR and ES estimators outperform the unpenalized benchmark estimator that strictly uses the untransformed set of fundamental variables by a considerable margin in terms of out-of-sample prediction error. We observe that a moderate degree of Chebyshev polynomials is optimal in our sample and generates CoES measurements that are more conservative than the benchmark and more responsive to news. Finally, we observe that the inclusion of nonlinear transformations of the fundamental variables results in a kind of leverage effect: risk predictions are less impacted by positive returns. 

In related literature, there are several papers that study the properties of LASSO estimators 