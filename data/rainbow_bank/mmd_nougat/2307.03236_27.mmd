The variational quantum eigensolver is a hybrid quantum-classical approach to obtain an approximation for the ground state of a (quantum) system [ 116 ]. The algorithm uses the quantum device to prepare an ansatz state in form of a parametric quantum circuit. Based on the measurement outcome of the expectation value of the Hamiltonian, a classical minimization algorithm is used to obtain a new set of parameters. Running the feedback loop between the classical computer and the quantum device until convergence, one obtains an approximation for the ground state and its energy, provided the chosen ansatz is expressive enough and the optimization did not converge to a local minimum. Main limitations of the VQE are barren plateaus (see Sec. IV B 2). 

VQD is an extension of the VQE allowing for computing low-lying excitations by running a VQE looking for a low energy state that is orthogonal to all previous states [ 117 ]. SSVQE is another approach used to compute excited states. This algorithm searches a low energy subspace by supplying orthogonal input states to the variational ansatz [ 118 ]. All the variational algorithms can be applied to Hamiltonians in both theoretical models and experimental analysis. 

### Tensor Networks 

Tensor Networks are a family of entanglement-based ans¨atze providing an efficient parametrization of the physically relevant moderately entangled states [ 10 ,  12 ]. TN algorithms allow for computing ground states, lowlying excitations, thermal states and to a certain extent real-time dynamics. While TN are extremely successful in situations with moderate entanglement, they cease to work for highly entangled scenarios such as outof-equilibrium dynamics. Moreover, in higher dimensions the numerical algorithms are computationally challenging but have a polynomial scaling in tensor size, thus allowed for first proof-of-principle demonstrations for LGTs [ 21 ,  83 ]. 

### QAOA 

The quantum approximate optimization algorithm is a hybrid quantum-classical approach, originally designed to tackle combinatorial optimization problems [ 367 ]. The problem is encoded in an Ising type Hamiltonian whose ground state is the optimal solution to the combinatorial optimization problem. QAOA can be seen as a special type of VQE, where the intial state is given by \(\bigotimes\ket{+}\)and the parametric ansatz circuit in its plain vanilla form consists of a series of two alternating types of layers, each one containing a single real parameter. The first one is the exponential of the problem Hamiltonian, \(\exp(-i\gamma\mathcal{H})\), followed by a mixing layer corresponding to \(R_{X}(\beta_{i})\)gates applied to each qubit. In the limit of infinitely many layers, QAOA can be interpreted as an adiabatic evolution of an eigenstate of the \(X\) operator to the one of the problem Hamiltonian. From a theoretical point of view the performance of QAOA is not entirely clear, it seems to depend on various factors and does not necessarily outperform classical algorithms [ 368 – 370 ]. Furthermore, the resulting quantum circuits can be deep making them hard to implement on noisy hardware [ 318 ,  371 ]. However, some of these issues may be alleviated by algorithmic advances such as warm-starts [ 372 ] and counteradiabatic driving [ 373 ]. 

### QKMEANS 

The classical \(k-\)means is an efficient algorithm to classify data into \(k\) clusters based on an unlabeled set of training vectors. It belongs to the family of unsupervised machine learning algorithms. The number \(k\) of clusters must be known _ a priori_  which somewhat limits the range of its application in HEP. The algorithm is iterative and assigns at each step a training vector to the nearest centroid. The centroid location is then updated according to the average over the cluster of vectors associated at the current step to the centroid. The most time/resources consuming part of the algorithm is the calculation of the distance. In the classical version, using Lloyd’s version of the algorithm, the time complexity is \(\mathcal{O}(NM)\)where \(N\) is the number of features and \(M\) is the number of training examples [ 374 – 376 ]. The quantum version of the \(k-\)means algorithm provides an exponential speedup for very large dimensions of a training vector. This is achieved through the introduction of two quantum subroutines, _ SwapTest_  and _ DistCalc_ , for the distance calculation [ 377 ] and quantum subroutine _ GroverOptim_  to assign a vector to the closest centroid cluster [ 378 ]. 

### Quantum Kernels 

Quantum kernels are a supervised quantum machine learning algorithm for classification and regression. The inputs can either be quantum (i.e., quantum states with an associated classical label) or fully classical (i.e. inputoutput data pairs). For the latter, the input classical data is first embedded into quantum states. For a quantum speed-up over classical algorithms, it is important to use an embedding (also called a quantum feature map) that is capable of recognizing classically intractable features [ 296 ,  379 ,  380 ]. For a given input pair of inputs one then evaluates a similarity measure between two encoded quantum states on a quantum computer. Formally, this is function corresponds to an inner product of data states, and is known as a quantum kernel [ 200 ,  379 ,  381 ]. The fidelity quantum kernel [ 200 ,  381 ] and projected quantum kernel [ 379 ] are two common choices in kernels. 