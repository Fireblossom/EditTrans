## 4. TinySiamese Network The proposed TinySiamese neural network takes on a new look and a new way of working which is different from the standard Siamese network. The difference first appears in the input processing of the network. Instead of having images as input, the input was the output feature vector of a pretrained CNN model. In other words, all input images would be transformed into feature vectors using a feature extractor (such as a pre-trained CNN model) as illustrated in Fig. 3. Then, the Tiny-Siamese encoded the features in a small set of layers and finally calculated the distance between two encoded feature vectors and generated similarity score. Using this score, the model was trained from scratch with the Adam optimization algorithm and binary cross-entropy loss function. 

### 4.1. Architecture Unlike the standard Siamese, the input of the TinySiamese was the encoded image as a feature vector. The backbone layers first aimed to extract relevant features using a linear fully-connected layer and a ReLU layer and then amplify them using another linear fully-connected layer and Sigmoid layer. The output size of the first linear layer had the half size of the input (n, n/2) and was followed by a non-linear ReLU layer. The second linear layer took n/2 features in input and came back to the same first input size in output (n/2, n). This layer was followed by a non-linear Sigmoid layer. The outputs of the TinySiamese sub-networks were encoded into an n-dimensional vector using inputs of a size equal to n. Siamese networks are usually trained 

Figure 3: The Proposed Architecture Based on TinySiamese Network for Verification. 