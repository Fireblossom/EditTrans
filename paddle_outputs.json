{
  "ocr": [
    "10 ID 112964 ID 3028398 ID 127824 ID 107554 JWST F115W HST F160W P = 20.26 days P = 23.63 days P = 38.65 days P = 67.67 days Figure 8. Four Cepheids in NGC 7250 discovered as part of the SH0ES project (bottom row: HST F160w/H-band exposures;. top row: JWsT F115W/J band). Each postage-stamp image is 2 x 2 arcsec on a side. The red circles are centered at the position of the Cepheid determined from the HST optical (F350LP white light) photometry. It is immediately evident that the crowding for these Cepheids is quite severe and the signal-to-noise ratio (SNR) for the H-band data tends to be low, ranging. from 1 to 23. In contrast, the SNR for the J-band data ranges from 36 to 121. On average, the JWST data have almost an order of magnitude greater SNR, and a four times better angular resolution, allowing the Cepheids to be distinguished clearly from the background. In Figure 9, we show the Leavitt laws for a sample of Cepheids in the LMC (Persson et al. 2004) and in NGC 7250 Owens et al. 2023). The scatter in the JWST F115W data for NGC 7250 is a factor of two smaller than in the SHoES F160w data; i.e., the improved resolution and higher signal-to-noise ratio of the JWST data results in a lower. variance (o?) for the F115w relation by almost a factor of four. This is all the more remarkable since the J-band data are single-phase observations only, while the HST observations have been corrected to mean light. The HST data exhibit more than three times the scatter of the H-band data for the LMC, the latter of which reflects the expected scatter for that band, as exemplified by the LMC data. 12. SUMMARY The accuracy of the Cepheid distance scale has continued to improve over the century during which it has been used. to measure the distances to nearby galaxies and set the scale for the determination of Ho. Still, challenges remain in overcoming systematic uncertainties. Many of these challenges will be overcome with new capabilities provided by the JWST. HST/WFC3 are significantly crowded (and biased to brighter apparent magnitudes) by nearby neighbors. A re-analysis of the SH0ES optical data, then coupled with the new high-resolution and higher signal-to-noise JWST F115W data. leads to significantly reduced effects of crowding and smaller photometric uncertainties. (2) These improvements result in a factor of two lower scatter in the near-infrared Leavitt law for JWST F115W compared with HST F160w, even with single-epoch F115W JWST photometry. The galaxies in our JWST CCHP program sample have all been selected to have with distances 20 Mpc, close enough to minimize crowding effects. As for the case of NGC 7250 presented here, these data will be combined with a re-analysis of the SHoES HST optical data for the Cepheids. TRGB, carbon star, and Cepheid distances to the same sample of galaxies being observed as part of the CCHP will allow measurement of three independent distances to each",
    "11 as follows: Qeff=eff (50) 2 20 N1 (51) (1+ k20  k10 + k20 2 2a Below we obtain the exact location xw and height  of 1 + k10 + k20 ) the LDW in terms of the control parameters. 2+20+28 2x 28 In the DW phase, particle number in T can be ex- 58 pressed as The LD-DW boundary equation (58) can be simplified NT= p(x)dx 52) further (detailed calculation is given in Appendix) after which it reduces to a form which we will obtain later in where a multiplicative factor L is introduced in the right- subsection V E. We find hand side to rescale the integration limit of the position variable x. Using (48) and (51) in (52), we get: (59) NT = L (53) as the LD-DW phase boundary, where N1/L is given by L N1 k10 + Identifying the steady state TASEP current in the DW k20 phase as JT = PLD(1  PLD) or JT = PHD(1  PHD) and L (60) substituting the expressions of NT [see eq. (53)] and JT in eq. (17a) together with PNC, we obtain the following two equations coupled in N1/L and xw: Therefore, the acceptable solution of N1/L is the one with a negative discriminant; see eq. (60). Next, the expression for N2 can be obtained using eq. (51). One N1 k2 finds Lk+k2[ 55 1  N1 L  L 1 k10 k20 While solving eqs. (54) and (55) for N1/L and xw, we 28 2aB 23 get a qudratic equation for N1/L with two solutions: k20 (61) 2x 2.32 k10 k20 Once we obtain the expression for N1/L in eq. (60), the 56 position xw of the domain wall can be obtained using eq. (54). We find: The density in the LD part of the DW is thus 1-a- -+2 (62) N1 1k10k20 1k10k20 1-2 22a2 22a2 k20 57 Having the expression of N1/L, it is straightforward to At the boundary between the LD and the DW phases, obtain the low and high densities in the DW phase: MFT must predict identical (low) density in the bulk of T. We now argue that in (57) the solution with a nega- tive discriminant is actually the physically acceptable so- lution. Equating the density in LD phase [eq. (25)] and  k20 OLD density in the LD domain of DW phase [eq. (57) with negative discriminant], we obtain the LD-DW boundary (63)",
    "For our experiments, ondemand mode with baseload cores 3 has an optimum energy usage when calculating same number of samples compared to other baseload and samples per second combinations. IV. CONCLUSION AND FUTURE WORK Recent research studies have focused on energy-efficient and carbon-efficient FL scheduling and client selection. However, (a) Energy Per Sample most of the research assumes simplistic energy consumption models for underlying FL clients. In this work, we showed that how energy per sample values under real-world scenarios such as different power modes and non-FL baseloads at CPU cores can vary and exhibit complex operational behavior patterns. For future work, following open research questions and possibilities could be explored further, . How do current FL systems communicate FL clients' energy related information? How to collect energy per sample, throughput per second and uncertainty related (b) Samples Per Second information at runtime? . How can we predict the power-performance character- Fig. 1: Power-Performance Characteristics for RPI istics, what are the relevant metrics? With more data about real-world impact factors affecting energy footprint of threads/CPU cores. For the FL training we utilized Flower of edge devices, can we build predictive models for framework 3. We simulate a computer vision IoT training task forecasting? using dataset CIFAR-10 4 and the computer vision model . How often do we need to measure before we can be SqueezeNet which is light-weight and deemed to be suitable certain? Can we report the uncertainty to be used in for edge computer visions applications. We assign higher scheduling? FL trainings are usually executed multiple kernel priority to baseload process to ensure the FL training times due to data distribution drifts and hyperparameter doesn't affect the CPU time of baseload in co-running sce- search. This repetitive FL training execution could be nario. For the energy consumption measurement, we utilized leveraged to collect more data about power-performance WLAN power socket switch'. We report mean energy per. behavior patterns of FL clients. sample and samples per second values for different power- .What's the impact of hardware accelerated edge devices modes and CPU core baseloads. the energy efficiency opportunities in FL and non-FL co- Ptotal - PBL EPS= (1) running scenarios? N REFERENCES EPS : Energy per Sample [1] H. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, Communication-efficient learning of deep networks from decentralized Ptotal : Total power consumption (FL and Baseload). data,\" in AISTATS, 2016. [2] X. Qiu, T. Parcollet, D. J. Beutel, T. Topal, A. Mathur, and N. D. Lane PBL : Power consumption due to Baseload \"A first look into the carbon footprint of federated learning,\" CoRR, N : Number of Samples ol. abs/2010.06537, 2020. [3] X. Zhou, J. Zhao, H. Han, and C. Guet, *Joint optimization of energy Energy per sample values were calculated using Eq. 1. consumption and completion time in federated learning,\" in ICDCS, IEEE, 2022. Figure 1a illustrates the mean energy per sample and 95% [4] C. w. Zaw, S. R. Pandey, K. Kim, and C. S. Hong, \"Energy-aware re- confidence intervals for each powermode, based on 1O repeated source management for federated learning in multi-access edge computing systems, IEEE Access, vol. 9, pp. 34938-34950, 2021. measurements. We observe significant difference in energy per sample and samples per second values when there is no non- efficient federated learning,\" in IEEE/ACM International Symposium on FL base load (O baseload cores) compared to a scenario when Microarchitecture (MICRO), pp. 183-198, 2021. [6] P. Wiesner, R. Khalili, D. Grinwald, P. Agrawal, L. Thamsen, and O. Kao, non-FL baseload is executing and utilizing all CPU cores. We Fedzero: Leveraging renewable excess energy in federated learning,\" also observe that while samples per second (Figure 1b) doesn't arXiv preprint arXiv:2305.15092, 2023. vary significantly when non-FL baseload is co-running with [7] B. Guler and A. Yener, \"A framework for sustainable federated learning,\" FL, energy per sample values fluctuate for baseloads 3 and 4. in International Symposium on Modeling and Optimization in Mobile, Ad hoc, and Wireless Networks (WiOpt), IEEE, 2021. [8] B. Rupprecht, D. Hujo, and B. Vogel-Heuser, \"Performance evaluation 3https://flower.dev of ai algorithms on heterogeneous edge devices for manufacturing, 4https://www.cs.toronto.edu/ kriz/cifar.html in International Conference on Automation Science and Engineering 5https://www.delock.com/produkt/11826/merkmale.html (CASE), pp. 2132-2139, IEEE, 2022.",
    "=Song Title Good life | Singer :G-Eazy,Kehlani === [KehlaniG-Eazy] We put the good in the good in the good life [Kehlani:] The good life Raise a cup up for all my day ones We put the good in the good in the good life Two middle fingers for the haters Life's only getting greater I said the goo dlife) Straight up from nothing we go We put the bad in the past, now we alright We alright) Higher than the highest skyscraper No Little League, we major Hey,hey,hey The proof is in the paper Yeah,yeah Hey,hey [KehlaniG-Eazy] in the in the g [G-Eazy:] We put the  life We put the good in the good in the good life Pour some Clicquot in the glass, have a toast to success No looking back from here, no more being broke and distressed We put the bad in the past, now we alright (Eazy) I put my heart into this game like I opened my chest Hey,hey,hey We only pray for more M's while you hope for the best Kehlani,I got you We make these plays, man I'm finessin' these checks Hey,hey Times up for everybody, I'm collecting on debts And I swear this champagne just tastes better on jets G-Eazy] I'm just out here being great, man, this is as real as it gets And it's a feeling that I can't explain How you make it and your team still stay the same I put my team in position, now they makin a killin Stay down from the jump and they never change Man, this a moment I could never trade, yeah I told my moms not to stress no more Ordering bottles of that Ace when they sit 'em Go hit the Bentley store and no credit card debts no more Til there ain't enough space up on the table to fit 'em Love you mom Go ahead and... Figure 6: Lyric Query Detection In the process of scanning the database, the system identifies all the songs that have the word 'good' either in their titles or in their lyrics. The first song that meets this criterion is 'Good Life' by Kehlani and G-Eazy. This song contains the word 'good' not only in its title but also within its lyrical content. It's important to note that the search doesn't stop at 'Good Life.' There might be many other songs with the word 'good' in their titles or lyrics within the database. The given information only indicates the first result that the system presents in response to the query 'good.' To summarize, the system is a music-centric search tool that uses the provided query to locate songs in its database containing the term 'good' either in their titles or lyrics. The first song it finds is 'Good Life' by Kehlani and G-Eazy, which contains 'good' both in its title and lyrics. The system can provide more results if the user wishes to explore other songs with the word 'good.' In Figure 7, the dataset consists of song lyrics from the year 1950 to 2019. This provides a well- spread dataset which allows us to get results from over 60 years, thus making the search engine efficient enough to provide songs from every year. The year 2017 has the most songs amounting upto 660 songs from various different genres and emotions. 00 200 Figure 7: Distribution of songs throughout the years In Figure 8, the dataset has been categorized into 7 major genres namely - pop, country, blues, rock, jazz, reggae and hip hop. There are about 7042 songs under the genre pop. This includes pop 8",
    "Dissecting Code Vulnerabilities: Insights from C++ and Java Vulnerability Analysis with ReVeal Model Conference'17, July 2017, Washington, DC, USA graph embedding size 200, batch size 128, maximum number k, and draw conclusions based on the observed dynamics. of batches 1oo00, number of gradient accumulation steps 8, To make set P3 to be independent of k, we fixed it to be maximum patience of 50 for C++ data and 20 for Java data. the complement of P1. That is, P3 consisted of functions that remained unchanged in the commits where only one 3Experiments with C++ data function was changed. Also, in order to balance different To answer the first research question, we used the original parts involved in training and testing, we restricted the size C++ method-level vulnerability dataset from [1]. After pars of P3: ing, we obtained the following statistics of the input graphs: |P3|=|Pi|+|P2| 11788 train graphs (956 vulnerable), 1667 validation graphs (133 vulnerable), 3385 test graphs (286 vulnerable) During the data cleaning phase, we ensured that in each To test each dimension of RQ 1, we performed 10 trials experiment, P3 did not contain functions that are contained ir of training the model. In each trial, the dataset was split P1 U P2. Also, we removed any duplicate functions from each into train, validation, and test parts anew. The results can be of the parts Pi, P2, and P3, and removed methods contained found in Table 1. in the training data from the test data. Table 2 shows the distribution of the collected Java meth- Configuration  Median F1  Median ROC AUC ods after stratification by k and cleaning the data: Baseline 27.29 0.696 Without SMOTE & RL 21.45 0.730 P1 P2 Without AST edges 27.65 0.706 k train test train test With pruning 30.83 0.724 410 205 135 (68) 00 0 0) Majority downsampling 26.61 0.678 399 (200) 145 (73) 343 (171) 122 (61) Table 1. Results of experiments for research question 1 416 (208) 132 66 696 347 228 (113) 414 (207) 128 (65) 960 (479) 346 (172) 415 (210) 129 (64) 1159 (575 433 (217) 414 (208) 131 (65) 1393 (692) 506 (254) 3.1Excluding SMOTE and RL 421 (212) 120 60 1583 789 596 (296) The model without SMOTE and RL achieves the worst perfor- 394 (197) 151 (75) 1870 (938 572 (284) 410 (207) 135 (67) 2027 (1012) mance with respect to the F1 score and the best performance 664 (330) with respect the ROC AUC measure. 10 411 (206) 131 (66) 2195 (1089) 632 (314) 399 (199) 150 (75) 2439 (1215) 708 (353) 3.2AST edges 12 400 (202) 144 (72) 2545 (1270) 769 (383) The model performs slightly better without including AST 13 397200 143 72 2619 (1303) 872 (434) edges. This is likely due to including too much of fine-grained 409 204 13668 2853 (1421) 845419 information or too many nodes. The model becomes more Table 2. Statistics of collected Java methods after stratifi- likely to overfit to irrelevant features in the input and fail to cation by k and cleaning. Each cell has the format Ni(N2),  generalize. where N is the total number of methods and N is the num- ber of vulnerable ones. 3.3Pruning The experiments also showed that the model performs better with pruning at operator nodes. Pruning makes a graph simpler and less entangled for the model to understand 4.1 Research question 2 In this research question, we investigate training on different 3.4Downsampling combinations of sets P1, P2, and P3, and testing on P1 UP2 UP3 Table 1 shows that the model performs worse with balancing or Pi U P3, which is a stricter test. The results can be found the train set by downsampling non-vulnerable methods. We in Figures 2 and 3. think that a rough balancing of the train part impacts the Figures 2 and 3 allow us to conclude that if the test set score negatively since it turns off SMOTE. includes part P3, then the inclusion of part P3 into training is critical to achieving a high performance. Overall, parts P2 4Experiments with Java data and P3 contribute the most to the prediction, as seen by the To answer the rest of research questions, we trained and red and blue lines on Figures 2 and 3. tested the model on different parts of the Java dataset (1): P1, Also, on Figure 3, we see a slight degradation of perfor- P2, and P3. In particular, we varied k in the range from 1 to. mance corresponding to training on P2 U P3 (red line) as 14. Then, we plotted the resulting ROC AUC scores against k increases. This might indicate the increasing amount of.",
    "3-6 1+5-1(63 0353=326. After expanding further the minors of above determinant based on Theorem 1, we see that this result is the same as the result of Example 2. For i = 2, we have: 4=2 5 -1 -3 0 33 1 2 0 3-2-32504 3] 2(2 9|1-s(3 +3 2f 1- 9 -31)+1-163 0(3 53 9)-326. After expanding further the minors of above determinant based on Theorem 1, we see that this result is the same as the result of Example 2. For i = 3, we have:. 30 A=25-1-3033 12 +(6 1= 9)-1  )+ )s-(6  90 2 1-911+139+ 3(2 53 0)- 326. After expanding further the minors of above determinant based on Theorem 1, we see that this result is the same as the result of Example 2. For j = 1, we have: + 05 2 5 03 50 4 +(  9)6  )+(8  )-  ) -- +6) )+ )(6= ) 1",
    "SHELAH'S MAIN GAP AND THE GENERALIZED BOREL-REDUCIBILITY 33 Let us denote by T = (k  w  acc()  y  k  k  k  )r. For every  E T there are functions { E <w | 0 < i  8} such that for all i  8, dom(i) = dom() and for all n E dom(), (n) = (1(n), S2(n), S3(n), S4(n), s(n), S6(n), 7(n), s(n). For every  E T let us denote (4, S5, S6, S7, 8) by . Definition 3.12. For all  E acc() and n E T with n E Jf, dom(n) = m <  define I as follows: If  E'J, then I is the set of elements  of T such that: 1) [m=n (2)  [ dom()\\m E W, (3) 3 is constant on dom()\\m, 43m=a (5) for all n E dom()\\m, let 2(n) be the unique r < w such that o(r) = (n) where (=In. If n  J, then Ig = 0. For n E T with n E Jf, dom(n) = m < y define. r(n)= U r. Eacc() Finally we can define Af by induction. Let Ty(0) = {0} and for all n < , Tf(n+1) =Tf(n) U U In) nETndomn=n For n   a limit ordinal,. Tg(n) = U Tg(m) m<n and Tf(n) =Tf(n) U{n E T|dom(n) = n & Vm< n (n[m E Tf(n))} For 0 < i  8 let us denote by s;(n) = sup{ni(n) | n < } and s(n) = max{si(n)|i 8}. Finally Af =Ty(t). Define the color function dt by. Scf(7) if s1(n) < sy(n) df(n) = f(s1(n)) if s1(n)=s(n) It is clear that Af is closed under initial segments, indeed the relations , (Pn)n<, and A of Definition 3.11 have a canonical interpretation in Af. Now we finish the construction of Af by using the k-colorable linear order I of Section 2. We have to define < [Sucar(n) for all n E Af with domain smaller than . Properly speaking, Af will not be an ordered coloured tree as in Definition 3.11, but it will be isomorphic to an ordered coloured tree as in Definition 3.11. Let us proceed to define < [Suca (n). Let F : I ->  be a k-coloration of I. For any n E Af with domain m +1 < 7, we will define the order < [Sucar(n) such that it is isomorphic to I and satisfies the following: (*) For any set B C Sucas(n) of size less than k, p(x) a type of basic for- mulas over B in the variable x, and any tuple (2,3) E w  acc() with 3  73(m), if p(x) is realized in Sucar(n), then there are K many  < k such that n(a,I2, I3,03(I2)) F p.",
    "7 whenever tr(p2)  2/d. Secondly, Lemma 7 and the vec- G, from a standard SAUR {S} of G', we call the follow- torization of matrices, Theorem 8 and Theorem 11 give ing SAUR a standard one of G: hints to the similarity of the role of o(G) in quantum contextuality and joint expectation values. {ok O S{}iEvx) U{Xio O id, Zjo O id}.(21) IV.  SELFADJOINT UNITARY If G has no edge, we assign id or 1 to all its vertices. REPRESENTATIONS If we take the pentagon C5 in Fig. 2 as the origi- The set of operators, where any pair either commutes nal graph, and (1,3) as the edge, then the Pauli-(1,3)- or anticommutes, plays an important role as exemplified induced subgraph G' is a triangle. Continually, the by the Pauli strings. The commutation and anticommu- Pauli-(4, 5)-induced subgraph G\" of G' is just the ver- tex 2. Hence, the standard SAURs{S},{S{} and{Si} tation relations of such a set {S} can be encoded into of G\", G' and G, respectively, are a so-called frustration graph G11, 12,where i ~ j ii {Si,Sj} = 0, and i  j if [Si,Sj] = 0. By checking S=1,S=Y,S4=X,S= Z, (22) extensive examples, it is conjectured in Ref. [34] that S1 = Xid,S2 = idY,S3 = Zid,S4 = X X,S5 = ZZ q({Si}) =a(G). (20) 23 Whether Eq. (20) can be violated is also an open ques- where we have omitted the symbol of tensor product, tion in Ref. [25].' Conversely, for a given graph G, we and Xid means X  id etc. can consider its representation by a set {S} of selfad- Theorem 14 (Cf. [41]). For a given graph G and one joint unitaries, in the sense that {S, Sj} = 0 if i ~ j SAUR {S} of G, there is a unitary U and standard and [St, Sj] = 0 if i  j. This representation is called SAUR {Si} such that US,Ut = Si  Di, where {Di} selfadjoint unitary representation (SAUR) [41]. By tak- is a set of commuting selfadjoint unitaries.. ing the graph-theoretic approach instead of starting from a special set, we denote (G,w) = q(Sac(G),w), where The standard SAUR is succinct, however, it loses the Sac(G) is the set of all SAURs of G. The conjecture in information of the symmetry in the graph. To reflect the Eq. (20) is equivalent to (G) = a(G). In Ref. [25], no structure of the graph, we introduce the edge SAUR. such an example is known that (G) > a(G). To con- tinue, we first introduce the standard SAUR of a given Definition 15. For a given graph G with n vertices and graph, which is defined deductively. The standard SAUR the edge set E, the set of selfadjoint operators {Ai}=1 can help us to reduce the complexity of considerations, with A; = eeEOe,t is called the edge SAUR of G, where since we only need to focus on the standard SAUR to Oe,i = X if i is the start of e, and Oe, = Z if i is the end obtain (G) as we will see later. of e, otherwise, Oe,, = id. For different SAURs of the same graph G, their joint Definition 12. For a given graph G and one of its edges expectation values are related. (io, jo), other vertices except io and jo can be devided into four groups Vo, V1, V2, V3, such that. Theorem 16. For a given graph G, q({Si}) = q({St}) . i  io and i  jo for any i E Vo; where {S} is a SAUR of G and {S} is a standard one. Proof. From the convexity of ,(S)?, we know that we . i  io and i ~ jo for any i E V1; only need to prove for the case that p is a pure state |)(y|. Since D, commutes with each other, we can as- . i ~ io and i ~ jo for any i E V2; sume Di's are diagonal matrices. Denote d2 the dimen- sion of Dt's, then we have the decomposition . i ~ io and i  jo for any i E V3. d2 The subgraph G' of G with vertices in U=oVi is said to U|y)=VPi($i) O|i), (24) be a Pauli-(io, Jo)-induced subgraph of G if i=1  when i E Vk1,j E Vk2 where k1  k2 E {1,2,3}, we where pi  0 and  Pi = 1. have i ~ j (or i  j) in G' if and only if i  j (or Hence, i ~j in G; {Si) =VPiPj{$k|Si|$i)<k|Dil) . otherwise, i ~ j in G' if and only if i ~ j in G. kl Definition 13. For a given graph G and one of its edges Pk($k|SikSi|Pk), (25) (io, Jo), denote G' the Pauli-(io, Jo)-induced subgraph of",
    "A.2  Checking SUsY for the Fibered Background. Here we aim to compute how many supercharges are preserved by the the backgrounds presented. in this paper. For the un-fibered background in eq.(2.1) we refer the reader to [12], [19], where it is shown that this solution preserves 16 Supercharges in an interesting way: the anti-commutator of. two supercharges includes the R-Symmetry generators. Now we present the analysis for the fibered. background in eq.(2.3). We perform all the analysis in the S-dual system, in terms of NS5 branes, where we only have H3 flux. First, note that the dilatino variation is a matrix equation of the form Me = 0. In order to have non-trivial solutions to this equation, we require M to be non-invertible, for which we need to impose. det(M) = 0. It is also possible to obtain a matrix equation from the gravitino variation. Noting that we can write the gravitino variation as a covariant derivative, for which we define the connection. FuT\"(i02)+ FvxTvX01+ (A.10) then we can write the gravitino variation as. oydx = (0E + We) dx = De. (A.11) We can get rid of the partial derivative of the spinor by acting with D a second time D^ De = (dW + W ^ W)e = Ovdx\" A dx's. (A.12) Each of the components of Ov defines a matrix equation, giving a total of 45 independent equa- tions. We need to make sure that det(Ov) = 0 for each of the components. The equations. ME=0OvE=0, (A.13) constrain the number of independent components of the spinor. After this procedure we use the gravitino variation to solve the dependence of the spinor on the spacetime coordinates.. Specialising to our background, the determinant of the Dilatino variation for the background in eq.(2.3) reads det(M) ~ (4(eBQs-eaQB)2+ m2) (4(eBQA +esQB)2 + m2)8. (A.14) In order to have non-trivial solutions we need to impose the following BPS conditions on the param- eters of the background. (A.15) With this conditions it is possible to check that det(Ov) = 0 is also satisfied. Solving these matrix equations shows that the spinor has 8 independent components. Then, solving for the gravitino varia- tion shows that these components are not independents, and in fact, the total number of independent. components its reduced to 4. The solution for the spinor is. E1=0 (A.16) 31",
    "The aim of this section is to assess the influence of individual branches on the performance of our proposed method. We evaluate the influence of each branch architecture, including low-level, mid-level, and high-level discriminators. All the ablation studies are carried out utilizing the MIT67 dataset, which is summarized in Table 2. The table shows the performance metrics for different cases. The comparison is as follows:. 1. Cases 1-3: In these cases, only one of the sub-models is utilized for prediction. Case 1, which solely uses low-level features, demonstrates the highest performance, followed by Case 3, which only incorporates. the high-level sub-model. On the other hand, Case 2, which considers mid-level features, achieves the lowest performance among all cases. 2. Cases 4-6: In these cases, EnTri incorporates a combination of two levels of sub-models. The highest performance is achieved by Case 5, which utilizes both low-level and high-level sub-models. Following. closely is Case 4, which takes into account both low-level and mid-level sub-models. On the other hand. case 6, which uses mid-level and high-level features, demonstrates the weakest performance among the cases. This suggests that low-level and high-level sub-models have a higher impact compared to the mid-level sub-model. 3. Case 7: All three levels of sub-models (low, mid, and high) are incorporated in this case, resulting in the highest performance and demonstrating their complementary roles for the recognition task. 1.2 Table 2: Ablation studies on the MIT67 dataset demonstrating the effect of different sub-models evaluated in terms of Top@1, Top@2, and Top@5 accuracy. Case Low-level (%) godoL(%) gdoL(%) lodolnael-yeaHnaee-pae > x x 84.47 90.75 94.18 2 x x 66.49 76.57 85.45 3 x x 77.31 86.04 92.61 4 ^ x 85.52 92.24 95.52 5 ^ 86.19 92.84 95.97 6 X V 79.62 87.76 93.06 7 V 87.69 93.58 97.54 Moreover, these textual explanations present the degree of agreement between the predictions made using. the three features through ensemble learning and the final prediction of our framework. 5.4. Explanation results and analysis To visualize the quality and intelligibility of the explanations produced by the proposed VTEG, we provided illustrative examples of the visual and textual explanations on different MIT67 scenes in Figure 9. It can be seen from the examples that the visual explanations attempt to highlight the most influential attributes of the scene in the prediction process of the recognition model, with the cumulative heatmap highlighting the regions that contributed to the prediction based on low-level feature and the masked segmentation map highlighting the important objects that contributed based on mid-level feature. These visual explanations are complemented by the textual explanation, which not only highlights crucial attributes such as object categories, frequencies, locations, and textural cues but also offers scores that represent the contribution of these objects towards the prediction. This textual explanation increases the certainty and confidence of users in their interpretation of the reasoning behind the prediction. Moreover, the ability to align the textual information with the visual contents allows for a clearer comprehension of the process and facilitates the diagnosis of the system at the modular level. By analyzing the scene and the confidence score of each sub-model, users can gain a deeper understanding of which type of information in the scene has the  greatest impact on recognition performance. Such insights can help users identify areas for modification and. adjustment and provide guidance in answering questions such as: 18",
    "Database (NVD) by inferring new classes, enriching relations,-  system diagram presentations. Firstly, we start by creating and expanding conceptual coverage. The ontology is used. the ontology of the cloud computing stack. Figure 2 depicts. to search for and query social media threads that contain. the ontology of the three cloud stack: Software as a Service cybersecurity-related information, and natural language pro- (SaaS), Platform as a Service (PaaS), Infrastructure as a cessing techniques are used to relate unstructured information Service (IaaS), Function as a Service (FaaS), Communication to concepts in the ontology. The paper highlights the advan- as a service (CaaS), and Desktop as a service (DaaS). Figure 1 tages of Semantic Web technologies in integrating information depicts the cloud service model. Cloud service has nine layers, from multiple and often heterogeneous sources, without human  green colored layers mean these layers are managed by the intervention. Rosa et.al. [8] presented a novel ontology-based  client while the other color refers to layers managed by the approach to utilize ontology to identify and map threats to cloud providers. assets. With the support of formally sound approaches, this process can be streamlined and made more efficient. From Commun.  Function. Desktop Platform Software Infrastructur an ontology perspective, the authors introduced ThreMA, Applications Applications Applications Applications Applications Applications an ontology-based approach for automating threat modeling Data Data Data Data Data  Data in ICT infrastructures. ThreMA provides a standard meta- Runtime Runtime  Runtime  Runtime Runtime Runtime model that describes the infrastructure and a set of rules for Middleware Middleware  Middleware Middleware Middleware Middleware threat modeling. The meta-model consists of three ontolo- o/s o/S o/s o/s 0/s o/s gies modules: ICT ontology for modeling the infrastructure, Virtualization Virtualization Virtualization VirtualizationVirtualizationVirtualization Data Flow ontology for representing data flow diagrams, and  Servers  Servers Servers  Servers Servers Servers threat ontology for characterizing threats. The use of ontology  Storage Storage  Storage  Storage  Storage Storage and inference rules allows for a syntactical representation of the problem, mimicking expert thinking. This approach NetworkingNetworkingNetworking Networking Networking Networking enhances extensibility, maintainability, and integration in a Fig. 1. Cloud computing stack. The green color depicts the layers managed by the used user. While the orange-colored boxes represent the layers managed rapidly changing context. The paper emphasizes the impor- by the cloud provider. tance of using ontologies to address the lack of context and low accuracy in threat modeling. Overall, ThreMA offers a comprehensive ontology-based solution for automating threat modeling in ICT infrastructures. Runtime Servers HII. METHODOLOGY Netwo ding This work presents an ontology for representing various data Data sources about cloud computing and security. This ontology StackLay Application enables a knowledge presentation framework for all cloud Vitualization computing and its relationships. The ontology consists of sev- eral modules: Cloud Computing and services, Cloud Service Storage underlying components, and CVE module.. dbo:compar CloudProvider A. Cloud Computing Stack and Services Ontology Module nic ation_as_a_service This section represents our proposed ontology module that 'Service Mod Software as a Service' Desktop_as_a_service covers the cloud computing stack and services. Our extension 'Infrastucture as a Sevice' Platform as a Service nction_as_a_Service important design criteria in ontology engine engineering [13, 14]. This ontology can be used to unify and provide a primary Fig. 2. Cloud computing stack ontology. baseline for cloud computing stack, threat understanding, and",
    "Q-NAGUMO NORMS AND FORMAL SOLUTIONS TO SINGULARLY PERTURBED Q-DIFFERENCE EQUATIONS for the q-analogue to , which reduces to [n]q=1+q+...+qn-1, for n e N+. We have that [0]q = 0 and (2.1) = [p]q[n]qp, n,peN+. q-1 qP-1 For future use, we note that. l[n]qI<[n]|q]] for n E N, and also that [n]q lim 1 (2.2) q-1 These constants appear naturally while considering Jackson's q-derivative of a. function f, which is given by. f(qx)-f(x) _q(f)(x)-f(x) dq(f)(x) := : qx-x whenever the expression is defined. As before, oq(f)(x) := f(qx). For analytic functions f E O(Dr), we see that. 2.3 oq(f),dq(f) E O(Dr/lql) and they can be computed term by term using its power series expansion according to the rules. dq(x\") =[n]qxn-1, Oq(xn) =q\"xn, n eN. On the other hand, this formula allows to consider dq, d : C[[x]] -> C[[x]], also defined term by term. In this setting, Leibniz rule is replaced by (2.4) dq(fg)(x) = dq(f)(x)g(x) + f(qx)dq(g)(x) We recall the coefficients (2.5) (a;q)n = (1- aq), (a;q-1)x=(1-aq-), a E C. i=0 The second one is convergent as we can compare it with a geometric series. The. q-factorial is defined accordingly as. (q;q)n (1-q)n In general, for |q| > 1, since  E R -> []|q] is a strictly increasing function, the same holds for the map n E N +-> [n]jq|. Therefore, [n- p]|q] [n- p]|ql [n - p]|q] 1 and thus [n - P]|q (2.6) 1 ([n]|q|)1/p<([n-p]|q)1/p' for integers n > p > 0.",
    "9 K. Zollner, P. E. Faria Junior, and J. Fabian, Phys. Rev. B 100, 085128 (2019). HB B. Huang, G. Clark, E. Navarro-Moratalla, D. R. Klein, R. Cheng, K. L. Seyler, D. Zhong, E. Schmidgall, M. A. McGuire, D. H. Cobden, et al., Nature 546, 270 (2017). HB C. Gong, L. Li, Z. Li, H. Ji, A. Stern, Y. Xia, T. Cao Dinter . W. Bao, C. Wang, Y. Wang, et al., Nature 546, 265 (2017) Y. Deng, Y. Yu, Y. Song, J. Zhang, N. Z. Wang, Z. Sun, HB Y. Yi, Y. Z. Wu, S. Wu, J. Zhu, et al., Nature 563, 94 Dintra (2018). O. Goser, W. Paul, and H. Kahle, Journal of Magnetism and Magnetic Materials 92, 129 (1990). E. J. Telford, A. H. Dismukes, K. Lee, M. Cheng, A. Wieteska, A. K. Bartholomew, Y.-S. Chen, X. Xu, A. N. FIG. 10. CrSBr bilayer lattice structure indicating analysed Pasupathy, X. Zhu, et al., Advanced Materials 32, 2003240 angles, distances, and magnetic moments. For values see (2020). Tab. I. Y. Guo, Y. Zhang, S. Yuan, B. Wang, and J. Wang Nanoscale 10, 18036 (2018). TABLE I. CrSBr lattice structure details for undoped and Z. Jiang, P. Wang, J. Xing, X. Jiang, and J. Zhao, ACS doped bilayers including angles, distances, and magnetic mo- Applied Materials and Interfaces 10, 39032 (2018). ments as indicated in Fig. 10. C. Wang, X. Zhou, L. Zhou, N.-H. Tong, Z.-Y. Lu, and undoped doped difference W. Ji, Science Bulletin 64, 293 (2019). lat. const. a [A] 3.483 3.496 -0.013 N. P. Wilson, K. Lee, J. Cenker, K. Xie, A. H. Dismukes, lat. const. b [A] 4.734 4.783 -0.049 E. J. Telford, J. Fonseca, S. Sivakumar, C. Dean, T. Cao, et al., Nature Materials 20, 1657 (2021). [.] o 95.84 94.77 1.07  [] 92.85 93.34 -0.50 J. Klein, B. Pingault, M. Florian, M.-C. Heibenbuttel, [.]  120.01 120.54 -0.53 A. Steinhoff, Z. Song, K. Torres, F. Dirnberger, J. B. Curtis, M. Weile, et al., ACS Nano 17, 5316 (2023). 8 [] 163.31 166.63 -3.32 intra [A] 2.00 1.93 0.08 M. Bianchi, S. Acharya, F. Dirnberger, J. Klein, D. Pashov, K. Mosina, Z. Sofer, A. N. Rudenko, M. I. Katsnelson. inter [A] 5.21 5.21 0.00 M. van Schilfgaarde, et al., Phys. Rev. B 107, 235107 HB 2.77 2.87 -0.11 2023. HB 2.77 2.78 -0.01 A. N. Rudenko, M. Rosner, and M. I. Katsnelson, npj HB -2.77 -2.78 0.01 Computational Materials 9, 1 (2023). HB -2.77 -2.87 0.11 J. Klein, T. Pham, J. D. Thomsen, J. B. Curtis, T. Denneulin, M. Lorke, M. Florian, A. Steinhoff, R. A. Wiscons, J. Luxa, et al., Nature Communications 13, 5420 doping. As a result we find the largest angle change in 2022). . As the inter-layer distance stays the same, the inner E. J. Telford, A. H. Dismukes, R. L. Dudley, R. A. Wiscons, and outer Cr atoms of the bilayer system experience a K. Lee, D. G. Chica, M. E. Ziebel, M.-G. Han, J. Yu, different change in their local environments, which we S. Shabani, et al., Nature Materials 21, 754 (2022). interpret as the reason for the intra-layer magnetic sym- A. Grubisic-Cabo, M. Michiardi, C. E. Sanders, M. Bianchi, metry breaking as reflected in B  3 and B  B D. Curcio, D. Phuyal, M. H. Berntsen, Q. Guo, and 39 M. Dendzik, Advanced Science (2023). N. D. Mermin and H. Wagner, Phys. Rev. Lett. 17, 1133 J. Strasdas, B. Pestka, M. Rybak, A. K. Budniak, N. Leuth, 1966). H. Boban, V. Feyer, I. Cojocariu, D. Baranowski, J. Avila, S. Chakravarty, B. I. Halperin, and D. R. Nelson, Phys. et al., arxiv.2211.05501. Rev. B 39, 2344 (1989). S. V. Hoffmann, C. Sondergaard, C. Schultz, Z. Li, and L. J. de Jongh, ed., Magnetic Properties of Layered P. Hofmann, Nuclear Instruments and Methods in Physics Transition Metal Compounds (Springer, 1990). Research, A 523, 441 (2004). V. Y. Irkhin, A. A. Katanin, and M. I. Katsnelson, Phys A. I. Liechtenstein, V. I. Anisimov, and J. Zaanen, Physical Rev. B 60, 1082 (1999). Review B 52, R5467 (1995). M. Gibertini, M. Koperski, A. F. Morpurgo, and K. S. G. Kresse and J. Furthmuller, Comp. Mat. Sci. 6, 15  Novoselov, Nature Nanotechnology 14, 408 (2019). (1996).",
    "4 describes the traveling-wave microwave photon transporting and along the transmission line with l = b, c refering to its left, right side, and the relevant bosonic operators satisfy the com- Cin/out =  iw(t-t')co(w), munication relation: [l(w), lt (w')] = (w-w'). Also, the flux 2 operator of the traveling-wave photon reads [14-16]: are the input- and output fields, respectively. After the Fourier dw [(w)eikn + t (w)e-ik] 7 x(t) = a(t), bin(t), cin(t), bout(t), and cout(t), respectively, we have with Zo being the characteristic impedance of the transmis- sion line, and thus iwa(w) = _dm ) a(w) 2 (12) hZo dwVw[i(w)ekx_it(w)e-ikx].(8) + K1bin(w) + K2Cin(w) and Under the sufficiently low current bias, the CBJJ Hamiltonian reads: HcBJJ ~ Hb, shown in Eq. 4. The physical boundary C+y iwaw a(w condition at x = 0, i.e., the location of the device, reads: 2 (13) f(0b,t) =i(0c,t), Vj =($0/2n)+$(Os)-$(0c) K1bout(w) - K2Cout(w). Thus, under the low-excitation limit and rotating-wave ap- For the configuration shown in Fig. 3, we can assume that proximation, i.e., the photon scattering is the desired elastic and any possibly created and annihilated of the photons at cin(t) = 0. Consequently, we have x = 0 is neglected, we have binw+boutw)=k1a(w) (14) HCBJJ-B=CJpo[$(0s) - $(0c)] Cin(w) + cout(w) =K2a(w). Therefore, the measurable transmitted- and phase shift spec- f dw[atl(w)-lt(w)a], ihs tra of the traveling-wave photons can be calculated as where kt = Zo/4Zj (l = b,c) describes the interaction Cout (w)|2 4K1K2 (15) between the CBJJ and the left/right traveling-wave photons, bin 4(w-wp)?+(k+7)2 Z J = L/CJ is the characteristic impedance of the Joseph- son junction. As a consequence, the Hamiltonian (with h = 1) and of the system [16-18]: 2(w-wp) Tg (w) = arctan (16) K+y HR respectively. In Fig. 4 we shows the spectra of the traveling- wave microwave photons scattered by a quantized CBJJ de- vice with the typical parameters: Ib = 0, Ic = 0.975 A, C = 11.18 pF, and thus wp ~ 2  2.595 GHz. It is seen 9 where y is decay rate of the cavity, K1 and 2 are the effective strengths of the boson coupled to the photons in the left and. right sides of the transmission line, respectively. By using the standard input-output theory [18, 19], we get the relations: da a + k1bin(t) +K2Cin(t), (10) dt / 0.96 0.98 and da FIG. 4: The transmitted spectrum (a) and phase shift spectrum (b) a-K1bout(t)-K2Cout(t), (11) of the traveling-wave scattered by the CBJJ. Here, the relevant pa- dt rameters are set as: K1 = 0.004, K2 = 0.008, y = 0.0008, and with K = K1 + K2, wp = 2  2.595 GHz. f dwe-iw(t-t')bo(w), clearly that, if the CBJJ device works as a boson, the peak of. bin/out = - 2 the photon transmission is located as the eigenfrequency of the",
    "1 Introduction Vectorlike (VL) fermions are key ingredients in many new physics models beyond the Standard Model (SM) adopted to resolve both theoretical and experimental issues. Since chiral fermions in the fourth family are excluded experimentally [1,2], these are considered to be vectorlike and their masses are given independently to the Higgs mechanism in the SM. The VL fermions are introduced in, for instance, supersymmetric models [3-10], gauge mediated supersymmetry breaking scenario [11-16], composite Higgs models [17-19], KSVZ axion models [20,21], axion- like particle models [22-25], alternative solutions of the strong CP problem [26,27], two Higgs doublet model augmented by VL fermions [28-38], and models for gauge coupling unification 39,40 Among the fourth family fermions, VL leptons (VLLs) with nonzero lepton number play unique roles in constructing lepton-philic dark matter (DM) models [41-46], mirror sector models [47-49], and explanations for the muon anomalies [50-65] 1. Interestingly, the lightest VLL is expected to be in the reach of the Large Hadron Collider (LHC) or High-Luminosity (HL)-LHC. Both ATLAS and CMS collaborations search for the pair production of VLLs each of which dominantly decays to a SM boson and a tau lepton [70-72]. For the doublet VLL 2, the ATLAS search excludes the mass range of 130 < mvLL < 900 GeV [72], and the CMS search excludes the mass up to 1045 GeV [71]. The singlet VLL is less constrained and the limit is less than 150 GeV [71]. Prospects of such VLLs at the future colliders are discussed in Ref. [73] The pair productions of the VLLs decaying to a SM boson and a muon (neutrino) are studied by the ATLAS [74] and the theorists [75, 76] using the Run-I data. The limit is obtained for mvLL  500 GeV when the neutral component of the lightest doublet VLL dominantly decays to a W boson and a muon [75]. There are also studies for the VLL produced from cascade decays of extra neutral Higgs bosons [28-31, 35, 36], and signals from the VLLs decaying to a DM particle [77] or Z' boson [78]. In this paper, we study pair-productions of the VLLs, through the Drell-Yan process, de caying to the second generation lepton, namely muon-philic VLL. Such VLL is well motivated to explain the experimental anomalies in the muon g - 2 [69, 79, 80] and the semi-leptonic B decays [81]. 3 In this work, we obtain the current limits using the Run-2 data at s = 13 TeV by simply recasting the ATLAS analyses searching for the triplet lepton in the type-III seesaw [84,85]. We then estimate expected sensitivities at the HL-LHC using the same channels. This paper is organized as follows. We briefly explain the VLLs in Sec. 2 and discuss the analysis strategy in Sec. 3. Our main results are shown in Sec. 4. Finally, we summarize the paper in Sec. 5.. 1The latest experimental result [66] confirms the previous results [67,68] which might deviate from the SM prediction [69]. 2Throughout this work, doublet (singlet) for VLL means iso-doublet (iso-singlet) under the SU(2)L gauge symmetry. 3The LHCb has recently announced the new result of Rk(*) consistent with the SM expectation [82] which requires efforts such as separate measurements of the branching ratio at Belle-II [83]. 1",
    "3.1.2Even L with a fermion parity defect. Let us introduce a G defect. A concrete Hamiltonian to keep in mind is -1 Hg =  Xe+1Xe - 2X1XL, (3.21) 2.4 l=1 where the defect is in the link connecting (L, 1). We use the subscript G for the Hamiltonian and symmetry operators in the system with a G defect. However, we emphasize that for most of our discussion the particular form of the Hamiltonian will not matter. Note that the defect can be moved to other links, e.g., to the link (1, 2), by conjugating Hc by a local G transformation, X1 or. g1. Let us determine the symmetry operators of the theory with the defect. We use the same. fermion parity operator G as in (3.10), because it commutes with Hg.21 On the other hand, instead of (3.5), the translation operator now acts on the fermion fields as Xe+1 l=1,2,.L-1 Tg : (3.22) -X1 l=L The algebra satisfied by these operators is. RG)=1RTc=RGRG)RTc=R(T)RG) (3.23) In contrast to the case without the defect (3.7),now we have det R(Tc)e,e = +1, (3.24) det R(G)e,e = +1. This means that the twisted translation operator is an SO(L) transformation and is constructed out of an even number of fermions, i.e., it is bosonic. Let us write Tg in terms of the fermion fields. Again, (3.22) does not determine its phase. normalization, and we will make an arbitrary choice below. Later, in Section 3.3, we will rescale it to Tnsns and compare it to the continuum operators. Its action in (3.22) means that we should. multiply T by an operator that maps X1 > X1 and leaves the other fermions unchanged, i.e., we should multiply it by g1 = -X2X3 ::- XL. Therefore, we take [81]22 1 Tc =(-1)gT= (3.26) 21 We do not write Gc because it is the same as G. 22 Alternatively, the translation operator for even L with a defect can be written as TG = (3.25) (Note that in this forms, Tc does not satisfy the locality condition (1.15).) 19",
    "Title Suppressed Due to Excessive Length 5 0.850.6% 0.7% AL .80 0.5% 0.4% .750.3% 0.2% 0.700.1% 0.1% (a) b) (c) (d) Fig. 2: (a-b) the correlation of four cities w.r.t POI distribution and behavioral patterns at category level; (c-d) two most correlated and least correlated cities. when measuring the correlation of cities. Although the correlation of cities can be measured from the aspect of POI distribution, the user behavioral transition pattern is a significant factor in the next POI recommendation task, we thus further explore such correlation from the angle of user sequential behaviors. Correlation of Cities w.r.t Behavioral Patterns. We examine the correla- tion of cities w.r.t. the categories of users' successive POI visits. In particular, given any two cities, Acat = [Acat, Agat...Afgt] and Bcat = [Bcat, Bat...Bcgt] re- fer to the category transition distributions among S transition types, e.g., Acat denotes the ratio of transition type FO -> SS within city A. Analogously, the similarity among different cities can be calculated via the Pearson correlation coefficient, shown in Fig. 2(b). Interestingly, we observe that the correlation of cities w.r.t behavioral patterns is quite different from that w.r.t POI distribu- tion. Specifically, PHO and CAL still keep higher similarity, whereas NYC shows comparably lower similarity with PHO and CAL. To further dig out how the four cities are correlated and different over the behavioral patterns, we compare the two most correlated cities (i.e., CAL and PHO) and the two least correlated cities (i.e., NYC and SIN). For ease of presentation, we select the 10 most frequent denotes the category transitions, e.g., AE  CU (AE2CU), and the y-axis shows the proportion of such a transition within a city. We find that the more correlated cities possess consistent distributions over the frequent category tran- sitions and vice versa. The above observations depict the various correlations between cities, which inspire us to differentiate their influence when transferring knowledge from auxiliary cities to the target city.. 4 The Proposed MERec This section presents the proposed MERec, which leverages the correlation of  behavioral patterns when transferring knowledge from auxiliary cities to the target city, i.e., paying more attention to more correlated knowledge. Problem Formulation. Each city has its unique user set l and POI set P without sharing any common users and POIs. For user u, all his check-in records, i.e., r = (p, c, g,t), are ordered by timestamps as in [22], where p, c, g,t denote POI p, category c, coordinate g (i.e., longitude and latitude) and timestamp t. We then split his historical records into sequences by day and obtain two",
    "6 SCHUR-POSITIVITY OF SHORT CHORDS IN MATCHINGS 2.2. Symmetric and Schur-positive sets As mentioned in Section 1, a set A is symmetric with respect to a statistic function D : A -- 2[N-1] if its generating function Qn,D(A) is a symmetric function. Moreover, it is Schur-positive if all Schur coefficients are nonnegative integers. One of the fundamental constructions of Schur-positive sets, regarding sets of standard Young tableaux (SYT), is due to Gessel [11]. Let SYT(A) denote the set of standard Young tableaux of. shape X. We draw tableaux in English notation, as in Figure 2. The descent set of T E SYT(A) is Des(T) := {i E [N - 1]| i + 1 appears in a lower row than i in T}. For example, the descent set of the SYT in Figure 2 is {2, 4, 7, 8}. 1247 36 58 9 FIGURE 2. A SYT of shape  = (4,2,2,1). The entry in row i and column j of a tableau T E SYT() is denoted as T;,j. In addition, we define row,(T) := {Ti,j |1  j  A} as the set of entries in the i-th row of T. For example, if we consider the SYT shown in Figure 2, then T3,2 = 8 and row3(T) = {5, 8}.. Theorem 2.4 (Gessel [11]). For every X F N, the set SYT() is Schur-positive with respect to Des. Moreover, Q(SYT(A)) = sx. In 2015, Adin and Roichman proved the following criterion. Theorem 2.5 ([2, Prop. 9.1]). A set A is symmetric with respect to D : S -> 2[N-1] if and only if tD(a)=cx tDes(T) aEA XFNTESYT(A) for some values cx, where t' := IIjeJtj for J C [N - 1]. The coefficients cx are the Schur- coefficients of A. Moreover, A is Schur-positive if and only if cx E No for all X F N. This criterion implies that proving the Schur-positivity of a set is achievable by establishing a statistic-preserving bijection between the set and SYTs of shapes corresponding to a specific. multiset. In this paper, we will also apply a recently formulated criterion for symmetry [19]. Definition 2.6. Let A be a finite set with a statistic D : A -> 2[N-1]. The set of elements that respect a given composition  F N, denoted Ap(), consists of the elements a E A such that D(a) C S, where Sa is the set corresponding to the composition a. When D is clear from the context, we. may write A() instead. Lemma 2.7. A set A is symmetric if and only if |A(a)| = |A()| for all a ~  F N. Note that only sets of permutations are considered in [19]. However, Lemma 2.7 applies to other sets as well.. Another useful result about symmetric sets and symmetric functions is due to Bloom and Sagan: Lemma 2.8 (Bloom and Sagan [6, Lemma 2.2]). For every set S  [N - 1], the function Fs is symmetric if and only if S = [N - 1] or S = 0.",
    "where onm is the Kronecker delta symbol. Such relation leads to the definition of the Laguerre transform of order v:. T'[f(x)]={ {#l} ={xp(x)f(x)#Iaxx_ (11) it must be emphasize that the Laguerre transform is a sequence of numbers in C. The inverse Laguerre transform is defined by. f(x)=(Tv)-1[{cn}]=cnLn(x) (12) k=0 3 Examples of applications 3.1 Applications to the Schrodinger equation In this section is consider the equation 1 d2 (13) which in appropriate units (h=M=1) is the steady state Schodinger equation defined in a one dimensional space, where V(r) is a potential function and E is the energy. Under the change of coordinates (see [0]), given by A-1(x) = dx/dr, where   0 has inverse length units, equation (13) becomes (14) where W(x) = V(r)  E. To obtain a Laguerre-type equation the change of In this way, equation (14) becomes A0 (15) where A, Ao, a, b are real parameters determined in terms of V(r) and E. To solve equation (15) it is proposed a solution of the form. y(x) = xe-Bxy(x), (16) where y = k=o cL(x), and Ln(x) are the Laguerre polynomials of order v, and a,,v are dimensionless parameters, free for the moment, but to be determined according to the concrete examples to be solved below. To solve (15) the use of the finite Laguerre transform is introduced. Many of the following transforms are known [0] or are obtained by direct calculation by using Laguerre polynomial properties found in [0] or in [0]. 5",
    "Andrei Teimurazov1, Matthew McCormack?,* Moritz Linkmann?, and Olga Shishkina1, 1Max Planck Institute for Dynamics and Self-Organization, 37077 GA Ittingen, Germany. 2School of Mathematics and Maxwell Institute for Mathematical Sciences, University of Edinburgh, UK August 3, 2023 Abstract In magnetoconvection, the flow of electromagnetically conductive fluid is driven by a combination of buoyancy forces, which create the fluid motion due to thermal expansion and contraction, and Lorentz forces, which distort the convective flow structure in the presence of a magnetic field. The differences in the global flow structures in the buoyancy-dominated and Lorentz-force-dominated regimes lead to different heat transport properties in these regimes, reflected in distinct dimensionless scaling relations of the global heat fux (Nusselt number Nu) versus the strength of buoyancy (Rayleigh number Ra) and electromagnetic forces (Hartmann number Ha). Here, we propose a theoretical model for the transition between these two regimes for the case of a quasistatic vertical magnetic field applied to a convective fluid layer confined between two isothermal, a lower warmer and an upper colder, horizontal surfaces. The model suggests that the scaling exponents  in the buoyancy-dominated regime, Nu ~ Ra~, and  in the Lorentz-force-dominated regime, Nu ~ (Ha-2Ra), are related as  = y/(1  2), and the onset of the transition scales with Ha-1/~Ra. These theoretical results are supported by our Direct Numerical Simulations for 10 < Ha  2000, Prandtl number Pr = 0.025 and Ra up to 10 and data from the literature. 1 Introduction Magnetoconvection (MC) governs most astro- and geophysical systems and is relevant to various engineering. applications [25, 7]. The former include, for instance, outer layers of stars and liquid metal planetary cores. [12], examples of the latter comprise liquid-metal batteries, induction heating, casting, liquid-metal cooling for nuclear fusion reactors and semiconductor crystal growth [6]. MC occurs in an electrically conducting fuid that is subjected both to a magnetic field and an imposed temperature gradient. The buoyancy forces induce convective fuid motion due to thermal expansion and contraction, while the magnetic field affects. this motion and distorts the global flow structure through the Lorentz force, which eventually influences. the heat transport in the system. The resulting main two control parameters, the strength of the imposed. thermal driving and that of the external magnetic field, are encoded in independent dimensionless groups,. the Rayleigh number Ra and Hartmann number Ha, respectively.. One of the key objectives in MC research is to provide scaling relations for the heat transport through the system, represented in dimensionless form by the Nusselt number Nu, as a function of Ra and Ha. However, the heat transport scaling relations also depend on the flow configuration, including the angle between the. magnetic field and gravity, the geometry of the container and the boundary conditions (BCs), and on whether the buoyancy forces dominate over the Lorentz forces in the system or vice versa. This inherent complexity results in the need, at least in principle, to derive separate heat transport scaling relations to describe each specific flow regime itself and transitions between distinct regimes. The considerable difficulty of doing so in a coherent manner is exacerbated by non-universal scaling relations even within specific regimes - the. scaling relations in the buoyancy-dominated and Lorentz-force-dominated regimes themselves change with the control parameters, and transitions between the different regimes are also non-universal. The objective of this paper is to offer a unifying heat transport model for the transition between the buoyancy-dominated and Lorentz-force-dominated regimes in quasistatic MC. We focus on Rayleigh-Benard. *A. Teimurazov and M. McCormack contributed equally. moritz.linkmann@ed.ac.uk #olga.shishkina@ds.mpg.de 1",
    "B. Compared Methods. don't consider the position of the neighbors at time The experiment includes a comparison of different models: tobs. Instead, we consider their predicted position at time tobs + ty using a Constant velocity model. We : I) MHA-LSTM [4]: This model only takes as inputs the assume that before predicting his goal, the target agent past trajectories of the agents in the scene and outputs first predicts the future positions of his surroundings L trajectories with their associated probabilities (see the according to their headings and current velocitites, architecture in the red rectangle in Fig. 1). We use L = 6 and then avoids the zones that are expected to be attention heads. crowded. While training this model, we calculate the . II) G-MHA-LSTM [17]: We add to the previous occup function using the grouth truth positions of the model a radial grid representation from which we extract potential goals. We predict the goal and then neighbors. the trajectories conditioned on the predicted goal. (see D. Implementation details the architecture in the orange rectangle in Fig. 1). We use K = 15 number of potential goals. Similar to [8], . III) DCM-MHA-LSTM : To predict the goal of the our interaction space is 40 m ahead of the target vehicle, target agent, we combine the DCM and the neural 10 m behind and 25 m on each side. We consider the network using the LMNL framework [15]. This model is neighbors situated in the interaction space at tobs. We also described in Section III and the architecture is illustrated take into account the neighbors that are susceptible of being in the blue rectangle in Fig.1. in this space from time tobs to ty. To do so, we predict . IV) ODCM-MHA-LSTM : This model only uses the the trajectories of all of the neighbors in the scene using a DCM to predict the goal of the target agent. Constant Velocity model and if they have a predicted position Goal set representations : We also compare different in the interaction space, we consider them in our model. We types of radial grids. For the methods II), III) and IV), argue that this representation allows to consider neighbors we compare our results for two types of radial grid : a that are not situated in the grid at tobs but that can appear dynamic grid (d) and a fixed one (f). Similar to [12], we in the grid from time t = tobs + 1 to t = tf. without build the dynamic grid by considering the target agent's having to create a bigger interaction space which can be current velocity vtobs. If vtobs = 0, we replace it with an more computationally expensive. We use L + K = 6 + 15 arbitrary value equals to 0.5 m.s-1. The fixed grid is built parallel attention operations. We use a batch size of 64 and using the value v = 5.83m.s-1, which corresponds to the Adam optimizer. The model is implemented using PyTorch mean of the velocities in the INTERACTION training set. [18]. C. Compared DCMs V. RESULTS We compare two types of DCMs for modelling the A. Evaluation metricss behavior of vehicle motion. For our case, the functions Our method for trajectory forecasting is evaluated with the modelling vehicle motion phenomenon which we consider following three error metrics: for goal selection in this work are: .Minimum Average Displacement Error over k 1) occupancy: directions containing neighbours in the (minADE) : The average of pointwise L2 distances vicinity are less desirable. between the predicted trajectory and ground truth over 2) keep direction: vehicles tend to maintain the same the k most likely predictions. direction of motion.. . Minimum Final Displacement Error over k 3) collision avoidance: when a neighbour vehicle's (minF D E) : The final displacement error (FDE) is the trajectory is head-on towards a potential goal, this goal L2 distance between the final points of the prediction becomes less desirable due to the chance of a collision. and ground truth. We take the minimum FDE over the : 1) DCM 1 : For the first DCM configuration, we use k most likely predictions and average over all agents. a utility function defined as: Collision II- Groundtruth collision Col-II) [19] ukX=Bdirdirk+Boccocck+Bcolcolk This metric calculates the percentage of collision (13) between the primary vehicle's prediction and the Where the functions dirk, occk, and col, correspond neighbors in the groundtruth future scene. respectively to keep direction, occupancy and collision avoidance. These functions are defined in [2] and [6]. B. Comparison of Methods : 2) DCM 2 : For the second DCM, the utility function We compare the methods described in Section IV-B. is defined as : The results are reported in Table I. DCM' and DCM2 refers to the first (resp the second) type of DCM described Uk(X) = Pdirdirk + Boccupoccupk in IV-C. (f) and (d) correspond to respectively, the fixed and (14) the dynamic radial grid representation for the extraction of Where the function dirk is the same as in (IV-C). potential goals. We can see that adding the DCM module For occupk, we use the same mathematical formula decrease the percentage of collisions. We can see that the as the occupancy function in (IV-C), however, we models using a fixed grid perform slightly better than when",
    "4 a) c0.02 Sc(K) 0.04 maxqK Sc(q) 0.08 0.020 0.007 + 0.364/N nn+ 0.000 + 0.278/N b 0.00 0.0 ).02 1/N a function of the graphene dispersion eG(k) exhibits a (softened) step at fillings v < 1/4, indicative of a Fermi liquid. (b) At v = 1/6, the connected density-density correlation function relative to the site marked in green shows clear signatures extrapolation of the static charge structure factor peak at q = K to the TDL. For fillings with solid lines in (a), the ground state is completely unique, while for dashed ones it is only unique in its symmetry sector. Red/blue outlined circles in (b) correspond to sites on the A/B sublattice. The clusters used are u = (1, 4), u2 = (5, -4), N = 48 for (a), and u = (3, 3), u2 = (3, -6), N = 54 for b) that local interactions play a subordinate role and the sured density-density correlation function hard-core constraint is largely inactive. As a result, the Ca(a)=(nni+a)where =A,B, qualitative behavior of the system is dominated by the 4 hopping processes, which naturally result in the forma- shown in Fig. 3(b), is expected to exhibit pronounced tion of a Fermi surface similar to the one in graphene at high hole doping. The hard-core nature of the fermions peaks. Indeed, as can be seen in Fig. 3(c), the peak at q = K extrapolates to finite values in the TDL while and their density-density interactions then enter as cor- other signals vanish, indicative of long-range order. rections to this pure Fermi-gas behavior. By measuring These ED results are corroborated by our HF simula tions, where the same type of symmetry breaking order tain the momentum-space occupation number n(k) of the prevails at v = 1/6 and ground state energies per site are ground state wave function as. relatively close to the ones obtained from ED (cf. Fig. 1 for v  1/6). HF also finds a charge density wave at 3 v = 1/8 consisting of a fermion delocalized around a hon- a=ABij eycomb for every enlarged 2  2 unit cell. This suggests a potentially more general instability towards charge order  For non-interacting fermions on the honeycomb lattice, above some critical filling in the dilute fermion regime. i.e. without density-density interactions or the hard-core constraint, n(k) should exhibit a clear step (whose mag III. ZERO-ENERGY STATE WINDOW nitude is the quasiparticle residue, Z) as a function of 1/4 v 0.292 the graphene dispersion eg(k). Fig. 3(a) clearly displays a step-like behavior for the occupation at lower fillings Starting from v = 1/4, i.e. one fermion per two unit v  0.2, consistent with the formation of a Fermi liq- uid. Increasing the fermion density leads to a gradual cells, the ground state of the SUSY model on the honey- softening of the quasiparticle residue, so that the Fermi comb lattice from Eq. (2) has exactly zero energy for a finite range of fillings. In fact, as illustrated in Fig. 4, we liquid appears to give way to a non-Fermi-liquid phase find robust zero-energy states for (almost?) all rational at v  0.25. fillings 1/4  v  0.292 within our finite-size simulations. Interestingly, we find that the Fermi liquid regime is This filling window extends beyond the homological pre- interrupted by a charge ordered phase at filling v = 1/6, dictions of Ref. [16]. which triples the unit cell and spontaneously polarizes In contrast to the finite-energy Fermi-liquid and charge into either the A or B sublattice. The expected six-fold ordered phases discussed in Sec. II, due to the supersym- ground state degeneracy in the many-body spectrum as well as the clear energetic preference of simulation clus- ters supporting this form of order strongly points at spon- taneous symmetry breaking as the root of this incom- 2 For the two rational fillings accessible to us in v E (0.286, 0.292), pressible phase. Additionally, the static structure factor states emerge for appropriate geometries Sc(q) obtained from Fourier transformation of the mea- but were unable to identify them in our study..",
    "8 University, Thailand. We acknowledge the support- (Thailand). URL:www.e-science.in.th. The Computa- ing computing infrastructure provided by NSTDA, CU,. tional Materials Physics (CMP) Project, SLRI, Thailand, CUAASC, NSRF via PMUB [B05F650021, B37G660013] is acknowledged for providing computational resource. [1] R. J. Needs and C. J. Pickard, Perspective: Role of struc- Machine-learning x-ray absorption spectra to quantita- ture prediction in materials discovery and design, APL tive accuracy, Phys. Rev. Lett. 124, 156401 (2020). Materials 4, 053210 (2016). [17] Z. Liang, M. R. Carbone, W. Chen, F. Meng, E. Stavit- [2] W. Kohn and L. J. Sham, Phys. Rev. 140, A1133 (1965). ski, D. Lu, M. S. Hybertsen, and X. Qu, Decoding [3] A. R. Oganov and C. W. Glass, Crystal structure predic- structure-spectrum relationships with physically orga- tion using ab initio evolutionary techniques: Principles nized latent spaces, Phys. Rev. Mater. 7, 053802 (2023). and applications, The Journal of Chemical Physics 124, [18] Y. Song and S. Ermon, Generative modeling by estimat- 2447042006. ing gradients of the data distribution, in Advances in [4] Y. Wang, J. Lv, L. Zhu, and Y. Ma, Crystal structure Neural Information Processing Systems, Vol. 32, edited prediction via particle-swarm optimization, Phys. Rev. by H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alche- B 82, 094116 (2010). Buc, E. Fox, and R. Garnett (Curran Associates, Inc., [5] C. J. Pickard and R. J. Needs, Ab initio random struc- 2019). ture searching, Journal of Physics: Condensed Matter [19] Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, 23, 053201 (2011). S. Ermon, and B. Poole, Score-based generative modeling [6] A. R. Oganov, C. J. Pickard, Q. Zhu, and R. J. Needs, through stochastic differential equations, in International Structure prediction drives materials discovery, Nature Conference on Learning Representations (2021). Reviews Materials 4, 331 (2019). [20] J. Ho, A. Jain, and P. Abbeel, Denoising diffusion [7] J. C. Schon, K. Doll, and M. Jansen, Predicting solid probabilistic models, in Advances in Neural Information compounds via global exploration of the energy land- Processing Systems, Vol. 33, edited by H. Larochelle, scape of solids on the ab initio level without recourse to M. Ranzato, R. Hadsell, M. Balcan, and H. Lin (Cur- experimental information, physica status solidi (b) 247, ran Associates, Inc., 2020) pp. 6840-6851. 23 (2010. [21] M. M. Bronstein, J. Bruna, T. Cohen, and P. Velick- [8] T. Xie, X. Fu, O.-E. Ganea, R. Barzilay, and T. S. ovic, Geometric deep learning: Grids, groups, graphs, Jaakkola, Crystal diffusion variational autoencoder for geodesics, and gauges, CoRR abs/2104.13478 (2021), periodic material generation, in International Conference 2104.13478. on Learning Representations (2022). [22] T. S. Cohen, M. Geiger, J. Kohler, and M. Welling, [9] C. Shi, S. Luo, M. Xu, and J. Tang, Learning gradient Spherical CNNs, in International Conference on Learning fields for molecular conformation generation, in Proceed- Representations (2018). ings of the 38th International Conference on Machine [23] N. Thomas, T. Smidt, S. Kearnes, L. Yang, L. Li, Learning, Proceedings of Machine Learning Research, K. Kohlhoff, and P. Riley, Tensor field networks: Vol. 139, edited by M. Meila and T. Zhang (PMLR, 2021) Rotation- and translation-equivariant neural networks pp. 9558-9568. for 3d point clouds (2018). [10] M. Xu, L. Yu, Y. Song, C. Shi, S. Ermon, and J. Tang, [24] D. P. Kingma and M. Welling, Auto-encoding variational Geodiff: A geometric diffusion model for molecular con- bayes, in International Conference on Learning Represen- formation generation, in International Conference on tations (2014). Learning Representations (2022). [25] R. Jiao, W. Huang, P. Lin, J. Han, P. Chen, Y. Lu, and [11] J. Guan, W. W. Qian, X. Peng, Y. Su, J. Peng, and Y. Liu, Crystal structure prediction by joint equivariant J. Ma, 3d equivariant diffusion for target-aware molecule diffusion on lattices and fractional coordinates, in Work- generation and affinity prediction, in The Eleventh Inter- shop on \"Machine Learning for Materials\" ICLR 2023 national Conference on Learning Representations (2023) 2023). [12] S. Kang and K. Cho, Conditional molecular design with [26] A. Okhotin, D. Molchanov, V. Arkhipkin, G. Bar- deep generative models, Journal of Chemical Information tosh, A. Alanov, and D. Vetrov, Star-shaped denoising and Modeling 59, 43 (2019), pMID: 30016587. diffusion probabilistic models (2023), arXiv:2302.05259 [13] J. Lim, S. Ryu, J. W. Kim, and W. Y. Kim, Molecu- [stat.ML]. lar generative model based on conditional variational au- [27] J. Gasteiger, S. Giri, J. T. Margraf, and S. Gunnemann, toencoder for de novo molecular design, Journal of Chem- Fast and uncertainty-aware directional message passing informatics 10, 31 (2018). for non-equilibrium molecules (2022), arXiv:2011.14115 [14] Y. Song, L. Shen, L. Xing, and S. Ermon, Solving inverse [cs.LG]. problems in medical imaging with score-based generative [28] w. Hu*, B. Liu*, J. Gomes, M. Zitnik, P. Liang, models, in International Conference on Learning Repre- V. Pande, and J. Leskovec, Strategies for pre-training sentations (2022). graph neural networks, in International Conference on [15] A. Cui, K. Jiang, M. Jiang, L. Shang, L. Zhu, Z. Hu, Learning Representations (2020). G. Xu, and J. Chu, Decoding phases of matter by [29] K. Schutt, P.-J. Kindermans, H. E. Sauceda Felix, machine-learning raman spectroscopy, Phys. Rev. Appl. S. Chmiela, A. Tkatchenko, and K.-R. Muller, Schnet: A 12, 054049 (2019). continuous-filter convolutional neural network for mod- [16] M. R. Carbone, M. Topsakal, D. Lu, and S. Yoo, eling quantum interactions, in Advances in Neural Infor-",
    "12 ALEXANDRU KRISTALY which is precisely (1.3) for p = 1 due to (3.12); the non-normalized case follows in a standard way. Since the Sobolev inequality (1.3) for p = 1 is equivalent to the isoperimetric inequality n(wnAVRg)nVolg(N)\"n  Pg(0N) (3.15) for every bounded open domain  C M with smooth boundary (Pg being the perimeter), and. (3.15) is sharp, see Balogh and Kristaly [2] and Brendle [4], it turns out that (1.3) is also sharp.  4. PROOF OF THE SHARP LP-LOGARITHMIC SOBOLEV INEQUALITY (THEOREM 1.2) 4.1. The case p > 1. Let p > 1 and fix f E Cg(M) arbitrarily; we may assume that f is nonnegative and fPdvg = 1 As before, let  = {x E M : f(x) > 0}; since f E C(M), then  is compact. Let xo E . For every X > 0 and k E N, we introduce the truncated Gaussian bubble Gx,k : M -> R given by Gx,x(x) = Pz(dg(x0,x)e-Adf (xo,x), where P, is defined in (3.2). We observe that the support of Gx.k is the ball Bxo(k + 1). Let Ix,k = Gx,k(y)dvg(y); clearly, 0 < Jx,x < oo for every X > 0 and k E N. W  (I + y)*g  y : I dnn nnbnn e pny unn nuo LnO Jo Annnn nng Aq pnnndnns nnndnen pushing  forward to v having the form T() = expx(-Vgu(x)) for a.e. x E , for some c = d?/2 concave function u :  -> R. The associated Monge-Ampere equation is (4.1) Jx,k Accordingly, by (4.1), a change of variables, Jensen's inequality and Propositions 2.1 and 2.2, we have fP log fPdvg = Jx,k det n DT(x) fP(x) log(Gx,k(T(x))) dvg(x) + n fP(x) log dvg(x) Jk JXk +n log Px Gx,k(y) log(Gx,k(y)) dvg(y) Jx.k JM +nlo",
    "J. Orell-Miquel et al.: Confirmation of He 1 in HD 235088 b's atmosphere. Table 1: Stellar parameters of 23. 2. Observations and data analysis 2.1. CARMENES observations and analysis Parameter Value Reference A single transit of the planet candidate 23.01 was observed with  Name HD 235088 HD the CARMENES1 (Quirrenbach et al. 2014, 2020) spectrograph TIC 293954617 TESS located at the Calar Alto Observatory, Almeria, Spain, on the TOI-1430 IOL night of 6 August 2022. CARMENES has two spectral channels: HIP 98668 HIP the optical channel (VIS), which covers the wavelength range of 0.52-0.96 m with a resolving power of R = 94 600, and the Coordinates and spectral types near-infrared channel (NIR), which covers 0.96-1.71 m with a  (J2000) 20h 02m 27s.4 Gaia EDR3 resolving power of R = 80 400. We observed the target with both +53 22' 36'.5 channels simultaneously and collected a total of 44 spectra of  (J2000) Gaia EDR3 5 min exposure time, with 28 of them between the first (T1) and Spectral type K2 V Sect. 3.1 fourth (T4) transit contacts. We obtained a median S/N of 72 Parallax and kinematics around the Ha line and of 86 around the He 1 triplet..  [mas] 24.25  0.01 Gaia EDR3 Fiber A was used to observe the target star, while fiber B was placed on sky, separated by 88 arcsec in the east-west direction. d [pc] 41.24  0.02 Gaia EDR3 The observations were reduced using the CARMENES pipeline a cos [mas yr-1] 165.05  0.02 Gaia EDR3 caracal (Caballero et al. 2016) and both fibers were extracted s_[mas yr-1] 145.17  0.02 Gaia EDR3 with the flat-optimized extraction algorithm (Zechmeister et al. y(a) [kms-l] 27.370 0.002 Gaia DR2 2014). We also processed the spectra with serva12 (Zechmeis- U [kms-l] 41.75  0.02 This work ter et al. 2018), which is the standard CARMENES pipeline to derive the radial velocities (RVs) and several activity indica- V [kms-l] 22.16  0.01 This work W [kms-l] This work tors: the chromatic radial velocity index (CRX) and the differ- 19.03  0.02 ential line width (dLW), as well as the Ha, Na1D1 and D2, and RUWE 0.966 Gaia DR3 Ca n IRT line indices. Magnitudes We corrected the VIS and NIR spectra from telluric ab- B [mag] 10.129  0.038 TYC sorptions with molecfit (Smette et al. 2015; Kausch et al.. 2015). We analyzed the spectroscopic observations via the well- V [mag] 9.19  0.03 HIP established transmission spectroscopy technique (e.g. Wytten- J [mag] 7.646  0.03 2MASS bach et al. 2015; Casasayas-Barris et al. 2017). We computed the Stellar parameters Ha transmission spectra (TS) following the standard procedure. However, because there are OH emission lines from the Earth's Lx [x1028 erg s-1] 1.89  0.07 Sect. 2.2 atmosphere close to the He1 triplet lines, we applied an extra L [Lo] 0.3609  0.0052 Sect. 3.1 step before computing the He1 TS. First, we planned the obser- Tefr [K] 503714 Sect. 3.1 vations to avoid a complete overlap or superposition of the OH log(g [cm s-2]) 4.63  0.02 Sect. 3.1 telluric lines and the He 1 planetary trace. We corrected the fiber [Fe/H] 0.010.02 Sect. 3.1 A spectra from OH telluric emission using fiber B information, 0.080.13 B18 which is used to generate an OH emission model for correct- R [Ro] 0.789+0.022 Sect. 3.1 ing the science spectra. This methodology is based in previous He 1 studies with CARMENES (Nortmann et al. 2018; Salz et al. M [Mo] Sect. 3.1 2018; Alonso-Floriano et al. 2019; Palle et al. 2020a; Casasayas- Vbroad [kms-1] 2.89  0.03 Sect. 3.1 Barris et al. 2021; Czesla et al. 2022). In particular, we followed v sini [kms-l] <2.90 Sect. 3.1 the procedure previously applied in Orell-Miquel et al. (2022). Prot [d] 12.0  0.4 Sect. 5.1 Figure D.1 compares our prediction for the telluric contamina- log(RHK) -4.242  0.016 M22 tion of the He 1 triplet lines with the real observations. Age [Myr] 600-800 Sect. 3.2 2.2. X-ray observations and planetary irradiation References. HD: Cannon & Pickering (1993); TESS: TESS Input Cat- alog v8.2 (Stassun et al. 2018); Gaia EDR3: Gaia Collaboration 2020; We used XMM-Newton archival observations of 23 (PI Gaia DR2: Soubiran et al. 2018; TOI: Guerrero et al. (2021); HIP: van M.Zhang) to calculate the X-ray luminosity of the star. The Leeuwen (2007); TYC: Hgg et al. (2000a); 2MASS: Cutri et al. (2003); star was observed on 7 July 2021. We reduced the data B18: Bochanski et al. (2018); M22: Maldonado et al. (2022). following standard procedures and used the three EPIC de- Notes. () Systemic radial velocity tectors to extract a spectrum for each of them, simultane- ously fitting them with a two-temperatures coronal model, us- ing the ISIS package (Houck & Denicola 2000) and the As- trophysics Plasma Emission Database (APED, Foster et al. 2012) v3.0.9. A value of interstellar medium (ISM) absorp- tion H column density of 110l9 cm-3 was adopted, con- sistent with the fit to the overall spectrum, and the distance we confirm the previous detection of He1 and, by analysing this He(2'S) signal, we study the hydrodynamical escape of this 1 Calar Alto high-Resolution search for M dwarfs with Exoearths with planet and derive the temperature and mass-loss rate of its upper  Near-infrared and optical Echelle Spectrographs. atmosphere. 2 https://github.com/mzechmeister/serval Article number, page 3 of 18",
    "35 9. ZEROS It is well known that the zeros of orthogonal polynomials with respect to a positive definite linear functional are real, simple, and located in the interior of the convex. hull of the support [15, 20]. With this in mind, let {xn,k(z)}t=1 be the the zeros of. Pn(x) in an increasing order, i. e., Pn(xn,k(z),z) = 0 (9.1) with Xn,1(z) < xn,2(z) <..:< xn,n(z) Next we will focus our attention on an electrostatic interpretation of the zeros of the polynomial Pn(x;z) in terms of the energy associated with a logarithmic potential and next we will study the dynamics of them in terms of the parameter z 9.1. Electrostatic interpretation. Evaluating the operator Dn+1 defined in (5.6) at x = xn+1,k, we get 0?Pn+1 (2xn+1,k-z) an+1 $(xn+1,k) Cn(xn+1k) +(Xn,k-bn)Cn-1(xn,h;z) 0n(Xn,k;z) + 0n-1(Xn,k;z) an$(Xn,k;Z) (z:y`ux)$ where Cn(x; z) and on(x; z) were defined in Proposition 5.4. Taking into account (5.4) the above expression reads 02 Pn+1 1 1 a 0xPn+1|x=xn+1,k Xn+1,k - Xn+1,k Xn+1,k- n Xn+1,k where n = -bn+1 + (2n +  + z + 3). Observe that the weight function associated. potential [22, Section 3.5]), then 02 Pn+1 1 1 1 + V(xn+1,k) 0xPn+1|x=xn+1,k (9.2) Xn+1,k-ZXn+1,k Xn+1,k-n Remark 9.1. If {n+1,k(z)}n+1 are the zeros of Qn+1(x) in an increasing order, i.e.. Xn+1,1 < Xn+1,2 < ... < Xn+1,n+1, then we have 02Qn+1| 1 1 1 a+1 +1 Xn+1,k (9.3) 0xQn+1x=zn+1,k Xn+1k-Z Xn+1,k Xn+1,k - n where n = -dn+1 + (2n + a + z + 4). Theorem 9.2. The zeros of Pn+1(x;z) are the equilibrium points of n + 1 unit charged particles located in the interval (0,z) under the influence of the external potential 1 1 1 Vp(x) = lr 1n ln +v(x), z>x>0 |x| |x-Bn|",
    "have l|w(t)|i,2-|wolli,2=pXk |w(s)|li2(0x(Vkw(s)),w(s))1,2dBk(s) l|wf(s)||i,2(kf(wf(s)),wf(s))1,2dBf(s) |w(s)|li,2(2<{Afwc(s),wf(s)))+||B(w(s))|IZ,) ds pp-2 |w(s)|i,(O(kw(s)), w(s))i,2ds . p(p-2) l|w(s)|i,\"(Vkf(w(s)),w(s))},2ds (4.25) 2 where we used the definition of the norm ||B(u)||L2. Next, using Burkholder-Davis-Gundy inequality: E sup l|w(s)|l,(x(Wrw(s)), w)1,2 dh( 703 3E(] l|w(s)|i4(Ww(s), w(s))},2ds )aO > |we(s)||i,2 d (4.26) sE[0,t] where v > 0 can be chosen arbitrarily small, and C is independent of v. Note that the expected values in (4.26) are finite due to (4.8) In a similar way, we get E sup l|wc(s)|li,2(Vkf(w(s)),w(s))1,2dk TE[0,t < 3E l|w(s)|l,24(kf(w(s)),w(s))1,2 ds (4.27 But kf(w(s)),w(s))1, kf(w(s))w(s) ds dx(Wkf(w(s)))0w(s) ds:=Ij+I2. (4.28) The estimate for I follows from the conditions imposed on f, namely |I1|< C|wf(s)|l2 15",
    "To simplify the analysis, a narrow frequency band was selected between 24 and 61 Hz, with the fourth and fifth bending modes of the blades dominating the response in this band. Although other modes appear to have a small influ- ence in this band, a 2DOF assumption was imposed. (This assumption results in smoothing of the FRF over the band, and might result in some loss of inter-. pretability, but is acceptable for these preliminary analyses). The real part was modelled as a probabilistic FRF, using the FRF estimate from Eq. (13) as the mean of the likelihood function, as described in Case 1, presented in Section 6 of this paper. The real parts of the averaged FRFs for each blade, at the second are shown in Figures 5a and 5b. Figure 5a shows the full measured bandwidth, and Figure 5b shows the FRF in the bandwidth of interest, between 24 and 61 Hz. Figure 3: Helicopter blade in a substantiated wall mount.. input force locatic . : . . . . 4.575 4.075 3.575 3.075 2.575 2.075 1.575 1.075 0.575 0.075 Z [m] Figure 4: Sensor locations on the helicopter blades.. Figures 5a and 5b show increasing variability with respect to frequency,. which is an expected result, given that higher-frequency modes are more sen- sitive to small physical changes than lower-frequency modes. For modes less than 80 Hz, the maximum frequency difference among the blades was approxi- mately 2.5 Hz; for modes greater than 80 Hz, the maximum frequency difference was approximately 6.3 Hz. Note the grouping visible at several of the peaks, where Blades 1 and 2 appear closely aligned in frequency while Blades 3 and 4 appear closely aligned. These results are quite relevant for PBSHM. All of the helicopter blades are healthy, and represent a normal-condition state of the. population. Consider a situation where only FRFs from one of the groupings. are available for training a model (or FRFs from the other groups are missing data). The normal condition could be heavily biased towards the training set, and incoming FRFs could be flagged as damaged, even if they are healthy. Fur- ther details regarding the data collection and processing for these tests can be found in [27]. 12",
    "Musk - fitting factor comparison 400 0.75 300- 0.5 0.25  100 - 0 0.5 1.0 1.5 2.0 0.5 1.0 1.5 2.0 1.01 1.005 0.5  0.25  0.995 0.99 0.5 1.0 1.5 2.0 1.0 1.5 2.0 h/num_of_stages h/num_of_stages s-AIA2 S - s-AIA2 Sw  s-AIA3 S  s-AIA3 Sw Figure 14: Musk BLR: The effect of the scaling approaches S and Sw (28) with (30) dimensionless stability interval (0,2) for comparison. Using Sw (in purple) helps to shift the best performance of both adaptive schemes towards the center of the stability interval. Moreover, max PSRF confirms that the stability limit is estimated better with Sw.. Appendix B. Derivation of Eyy[H] in (19) According to [8], for the harmonic oscillator with the Hamiltonian (A.1). and the equations of motion (A.2), the expected energy error produced by a k-stage palindromic splitting integrator Ih applied for L integration steps is. given by E[H] = sin2(LOh) p(h,z), (B.1) where Of = arccos Ah, and Af is defined in (A.3). For L = 1 and p(h, z) defined in (A.4), (B.1) yields E[AH] = (Bf + Ch)2 (B.2) 2 34",
    "[5] and the references there for some of the algorithmic developments. A particular feature of numeri- cal approximations of PDE solutions based on DNNs as approximation architectures that was observed in practice was the apparent insensitivity of the DNN approximation quality to the so-called \"curse of dimensionality\" (CoD for short). This is particularly relevant for approximating maps C-x:5 (1) between (in general, infinite-dimensional) separable Hilbert spacesl ' and y. Operators G as in (1) emerge for example as parameter-to-solution mappings for parametric PDEs within the field of Uncertainty Quantification (see, e.g., [48] and the references there), or in so-called digital twins of complex, physical systems governed by partial differential equations (PDEs) (see [32] and the references there). Owing to the infinite dimension of ' and Y in (1), efficient numerical approximations of maps G are to overcome the CoD. Several (intrinsically different) mechanisms for overcoming the CoD in DNN emulations have been identified and mathematically justified recently. This includes the seminal work of A. Barron [3], Monte- Carlo path simulation type arguments (e.g. [20, 29] and the references there), and the emulation of sparse (generalized) polynomial chaos expansions (e.g. [2, 17]) by DNNs (e.g. [56, 51, 57]). Specifically, in [56, 51, 57], a parametric representation of inputs x E  of G was used to prove DNN emulation rates for approximating 9. The construction used DNNs whose depth scales polylogarithmic in the parameter dimension, and polynomially in the DNN expression accuracy (i.e., emulation fidelity) Key in the proofs of these results is the holomorphic dependence of G(x) on the input x. The related DNN emulation results were obtained with sparsely connected, deep feedforward NNs with ReLU or smooth (e.g. sigmoidal or tanh()) activation. DNN emulation rate results that are free from the CoD for low regularity maps G between function spaces were obtained e.g. using the so-called Feynman-Kac representation of solutions of Kolmogorov PDEs in (jump-)diffusion models. These results used ReLU DNNs of moderate depth [20, 29], but the error bounds hold in a mean-square sense or only with high probability. While quantified, parametric holomorphy of solution families of parametric PDEs has been verified in many settings (particularly in elliptic and parabolic PDEs, e.g. [27, 66, 31, 12, 23]), there are broad classes of applications where relevant maps are Holder or Lipschitz, but not holomorphic. One purpose of the present paper is to obtain mean-square DNN expression rate bounds for Operator Network (ONet) emulations with architecture (2) below, of Lipschitz (and, more generally, Holder smooth) maps G between separable Hilbert spaces. 1.1  Previous work for operator networks A rather recent line of research uses so-called Operator Networks to emulate the possibly nonlinear input- output map 9, such as for example the coefficient-to-solution map in linear, elliptic divergence form PDEs of second order. A variety of DNN architectures has been put forward recently with the aim of efficient operator emulation, with distinct architectures tailored to the emulation of particular operators. A number of acronyms labelling these DNN classes has been coined (\"deepONets\" [45], Fourier Neural transformers, etc.). We refer to [35, 38, 21, 49, 42, 6] and the references there. In this paper, we discuss an architecture that belongs to the same general category as those proposed in, for instance, [25, 45, 24]. It reduces the task of approximating G to that of emulating (components of) countably-parametric maps G : e2(N) > l2(N) with DNNs: using an appropriate encoder &x : X -> l2(N) and decoder Dy : l2(N) -> Y, the map G in (1) allows the structural representation 9 = Dy o G o &x. (2) 1More generally, separably-valued maps G into an otherwise nonseparable target space y may be considered. In [35. Section 9, App. B] additional conditions on separable Banach spaces A and Y necessary to extend the present arguments to this more general setting are discussed. 2",
    "Let y E W4. Then y = [bk, do, d1, d2] for k = 0 or 1. The corresponding equation in (23) reads. -1 if do<d1<bx<d2 to= +1  otherwise -1 if bk<do<d<d2 or do<d<d<bk t1= +1 otherwise -1 if do<bk<dj<d2 2 +1 otherwise a[bo, b1]), the equation now reads Labelling the terms of Equation (25) in order 1 to 6, we can pair them off as follows. If k = 0 pair (1,3), (2, 5) & (4, 6). If k = 1, instead pair (1, 6), (2,4) & (3, 5). Then it can be shown that each pair sums to 0. For example, for k = 0, we have: (1) + (3) 2)+5 (4) + (6) tbo,do,d1,d2 sbo,b1,do,d2 + t5o,do,d,d2 gbo,b1,do,d For example, note that to and t1 have the same sign only if do < bo < d1 < d2. If this is the case, relative locations of b1. Thus (1) + (3) = 0. Similarly for the other pairs. The remaining cases can all be checked similarly. A similar argument holds for y = [do, d1, d2, d3] E W6 B An e-net for the Gaussian states For each j E An, define the regions S= l)=cjlj') EG:|cjllcjI Vj'EAn Clearly, the union over j gives all of G. In each region S,, Gaussian states may be defined by the set of amplitudes with labels within distance 2 of j, given by the set C = {cx : d(j,k)  2}. For these amplitudes, we have |cj| E [2'z\", 1] IckI E[0,lcjl]Vck EC\\{cj} Let N, = {|i)} C S; be a maximal set of pure states satisfying V|Wi),lVi) ENj,3x EAn s.t.d(j,x)<2 1(x|yi)-(x|Wi)| n Let N = U,Nj. We wish to find a suitable n so that N is an e-net. We require the 2 following. lemmas: 17",
    "one obtains from (3.75) y(2)=1-kz0(v(2)=1- (3.94) and due to (3.79) (3.95) Then, using the Taylor formula with respect to , we shift initial conditions (3.92) to the dy )). y(2) (3.96) 90 dy Substituting (3.93) into (3.91) and expanding with respect to , one obtains equations for the i-th approximations (; and Jj: dGi= R$(y) (3.97) dy dJi = R(J)(y) dy The solution of this system is Si(y) (3.98) Ji(v) J(y8)) For i = 1 one has. R($)(y) z f3 = k1/2 (3.99) y2-1-k(vo(y)-1) f4 R()(y) = Jok1/2 y2-1-k(vo(y)-1) 24",
    "30 Notice that at the optimal dual solution Aopt and {opt}, it must follow that Aopt > O and A(opt, {pt}) is of full rank (i.e., rank(A(Aopt, {pt})) = Nt), since otherwise, the maximum transmit power constraint in (22b) cannot be satisfied. Then, Proposition 1 follows directly from Lemma 3. This completes the proof.. APPENDIX B PROOF OF LEMMA 3 First, we have tr(A(,{k})S) = tr(AUH SU). Let Sx = UH SU. It is easy to figure out that tr(S1) = tr(Sx-'). Recall that S is positive semi-definite. We denote (T1, ..., TNt) as the diagonal entries of Sx to be determined. Note that tr(A(, {s})S) = i=1 QT;. Here, we introduce the following lemma to find the minimum of tr(Sx-') w.r.t. (T1,..., TNt), for which the proof can be found in [43, Appendix A] and thus is omitted. Lemma 5. [43] For a positive semi-definite matrix Bo E CMM, with (m, n)-th entry a(m,n), it holds that. M 1 (60) where the equality holds if and only if Bo is diagonal. Hence, Sx must be diagonal and we obtain. N tr(A(,{s})Sx)+tr(S') = tr(AS)+tr(S,~)=aT+ (61) i=1 i1 In this case, when N < N, for i > N, t; must approach infinity to achieve the minimum value O, i.e., for i > N, T > +oo. As for i  N, by checking the first order differentiation, we have S* = UEUH (62) x-1/2, for i < N. where  = diag(T1,..., TNt) with T -> +oo, for i > N, and t, = , When A(, {k}) is full-rank, we have. WN Nt 1 tr(A(A,{x})S)+tr(S) = tr(ASx)+tr(Sx~')=aiTi+ (63) Ti i=1 i=1 For any i  Nt, we need to set T, = ,1/2 to achieve the minimum value. Then, the S* is",
    "Proof. The proof is an adaptation of the proof of [Kye08, Lemma 4.6]. Since. wH(x(u)) = TH(u), X o x extends to an isometric embedding L2(Rep(G),rH) - lg(H) = L2(O(G),wH) The image  o x(O(G)) is a *-algebra that maps L2(Rep(G), ) into itself and hence maps L2(Rep(G),tH) into itself. Therefore AH(x(u)) has the. form [XH(X(u))|L2(Rep(G),H) 0 0 XH(X(u))|L2(Rep(G),rH)+ Hence l|XH(X(u))| =max{l|(X(u))|z2(Rep(G),g)|l||>(X(u))|z2(Rep(G),r)=|l} ||AH(X(u))|z2(Rep(G),rg)|l =|  (u)|. This proves that the map k : XH o X(O(G))  g(C[Rep(G)]),AH(x(u))) +> ,g(u) is bounded and therefore extends to a contractive *-homomorphism. k : X o x(O(G))  C*q(Rep(G)). To finish the proof, we claim k is injective. This easily follows from the observation wH(x(u)*x(v)) =wH(x(uv)) =TH(u v) For  E Irr(H) let P E l(H) denote the orthogonal projection onto Ha which is nothing more than the identity operator in Mno C l(H). It is easily observed that the map a +> P induces a unitary isomorphism. l(Irr(H)) = span{nn(Pa) : a E Irr(H)} C lg(H) From this and the duality it is also easy to check that. L2(x(O(G)),wH) = span{nH(qn(x(u))) : u E Rep(G)} c l?(Irr(H)) 27",
    "Quantitative analysis of optimal Sobolev-Lorentz embeddings with -homogeneous weights PETR GURKA, JAN LANG, ZDENEK MIHULA AbsTRAcT. This paper quantitatively investigates the structure of non-compactness of the optimal weighted Sobolev-Lorentz embedding with homogeneous weights in an. open convex cone. We prove the optimal embedding in question and obtain the exact values of all injective strict s-numbers (in particular, the Bernstein numbers) of the embedding. Opposite to the earlier results in this direction, the non-compactness in. this case does not occur uniformly over all sub-domains of the underlying domain Despite that, we find an infinitely dimensional subspace restricted onto which the. embedding is isomorphic, proving that the embedding is not strictly singular. 1. INTRODUCTION It is a truth generally acknowledged that Sobolev embeddings hold a prominent position in various areas of mathematics, making comprehensive understanding of their internal structure and behavior essential. One of their oft-studied aspects is their compactness and its quality. Quite often the quality of compactness is analyzed through the decay rate of different s-numbers. Various s-numbers are closely related to the spectral theory of the corresponding differential operators associated with Sobolev-type embeddings and provide estimates for the growth of their eigenvalues (see [14]). There is quite extensive literature in which the quality of compactness of Sobolev embeddings is investigated However, significantly less attention has been devoted to studying the structure of non- compact Sobolev embeddings, where the measure of non-compactness may be related to the shape of the essential spectrum (see [12]). Naturally, there are several ways which Sobolev embeddings can become non-compact, such as: (a) when the underlying domain is unbounded (see [1], cf. [15]); (b) when the boundary of the underlying domain is excessively irregular (see [20, 21, 25, 26]; (c) when the target function norm is overly strong in other words, the target function space is too close to the optimal one (see [19, 24] and references therein). Among these possibilities, the last one is particularly intriguing because it has not been explored quantitatively nearly as much as the others, despite the interest in optimal Sobolev embeddings (e.g., see [10] and references therein). Previous works investigating the case (c) (see [4, 18, 22, 23]) dealt with Sobolev embeddings that are non-compact Date: May 30, 2024. 2020 Mathematics Subject Classification. 46E35, 47B06, 46B50. Key words and phrases. Sobolev spaces, Sobolev-Lorentz embeddings, homogeneous weights, compact- ness, Bernstein numbers, measure of non-compactness. This research was supported by the grant GA23-04720S of the Czech Science Foundation. 1",
    "2 T.-H. MIURA which we call the limit equations of (1.2). Here unknown functions are the tangential velocity field v and the pressure q. Also, f is a given external force. We write P, Vr, divr, Dr(v), and Vv for the orthogonal projection onto the tangent plane of T, the tangential gradient, the surface divergence, the surface strain rate tensor, and the covariant derivative of v along itself, respectively. Also,  and ' are nonnegative constants which stands for the friction coefficients. For details of notations, see Section 2. Note that, when g = 1 on I and  = ' = 0, the limit equations (1.4) reduce to the surface Navier-Stokes equations with Boussinesq-Scriven surface stress tensor (see [4, 52, 2]) I uo f=b++ad (1.5) divrv=0 on I. Moreover, the equations (1.5) are equivalent to the Navier-Stokes equations on an abstract Riemannian manifold (see [14, 56, 10]) -v{bv+Ric(v)}+Vrv+Vrq=f on I, (1.6) divrv=0 on I, where 3 is the Bochner Laplacian on I and Ric is the Ricci curvature of I (see e.g. [34, Lemma C.11] for the equivalence of the above equations). In the nonstationary setting, we rigorously derived the limit equations (1.4) from the bulk equations (1.2) by the thin-film limit in our previous work [34]. There we proved under suitable assumptions that,. for an L?-strong solution uf to the nonstationary Navier-Stokes equations in e, its average Mu(y) = 91(y eg(y) Jego(y) uy+rnydryT converges weakly to a tangential vector field v on I in an appropriate function space as e -> 0, and derived the nonstationary limit equations on I by characterizing v as a unique L2-weak solution to the limit equations. We also obtained some estimates for the difference of uf and v which show that v approximates uo in the L? sense when e is small. As in the nonstationary case [34], we can derive (1.4) from (1.2) by means of convergence of a solution and characterization of the limit, but the procedure is the same so we omit it here. In this paper, we focus on difference estimates for the solutions uf to (1.2) and v to (1.4). Let us fix some notations and formally state our main results (see Section 2 for details). Let P. be the orthogonal projection from L2()3 onto a function space He given in (2.14), which is the standard L2 solenoidal space on  or its subspace. For a vector field u on Ns, let M,u be the tangential component of the average Mu on I. Let H(I,TT) ={v E H(r)|vn =0 on I} and H-1(I, TT) be the dual space of H1(F, TT). Formally speaking, our main results are as follows (see Theorems 2.5 and 2.6 for the precise statements).. Theorem 1.1. Let fc E L?(e), f E H-1(T,Tr), and uc and v be weak solutions to (1.2) and (1.4), respectively. Under suitable assumptions, suppose that there exist c1,c2 > 0 and a E (0,1] independent of E such that (1.7) l|Pefll2(8e)<c1e-1+a,|M,Pef\"llH-1(r,Tr)<c2 for all e > 0 sufficiently small. Then there exist c,p > 0 independent of e such that (1.8) l|M,uc -v|H1(r) <c(8(c)+|M,Pefc- fl|H-1(r,r)) for all s > 0 sufficiently small provided that |/lH1(r)  P, where. o(E) = c/4+  Moreover, we have the following difference estimate in Se: 1.9) e-1/2|uc -u||z2(Se) <c(8(E)+|M,Pefc-f||H-1(r,Tr) Here v is the constant extension of v in the normal direction of I. Note that the left-hand side of (1.9) is divided by e1/2 since the L2(e)-norm involves the square root of the thickness of . By (1.9), we can say that the solution v to the limit equations (1.4) approximates the solution uc to the bulk equations (1.2) when e is small. We also have an approximation result for Vu in , but it involves the Weingarten map (the second fundamental form) of I. For details, see Theorem 2.6. We further note that the difference estimate (1.8) also holds if we replace the tangential component Muc by the average Muc itself (see Remark 6.8).",
    "for all t E So, where E[] denotes the expectation. In this context, the functions t E So are named weakly convex. Moreover, [TV97, Lemma 6] gives a weaker version of Theorem 3: Let t E So. For a, b E [0, o) with a  b, it was shown that t(a + b) + t(a - b)  2r(a) + 2r(b). 1.3.5Statistics Theorem 1 can be applied to prove rates of convergence for certain kinds of means [Sch19]: We may want to calculate a mean value of some sample points in a metric spaces. One candidate for this is the Frechet mean [Fre48], also called barycenter. It is the (set of) minimizer(s) of the squared distance to the sample points. If Y is a random variable with values in a metric space (Q, d), the Frechet mean is arg mingeQ E[Y, q'], where we assume E[Y, q'] < oo for all q E Q. Similarly, one can define the Frechet median [FVJ09] as arg mingeqE[Y,q], or a more general r-Frechet mean. [Sch22] as argmingeqE[r(Y, q)] for functions r: [0, o) - R. Given a sequence of independent random variables Y1, Y2,... with the same distribution as Y, a standard task in statistics is to bound the distance between the sample statistics and its corresponding population version. In our case, assume the r-Frechet mean is unique and define m := arg min E[r(Y, q)], mn := arg min - qEQ i=1 We want to bound mn, m depending on n. One can employ quadruple inequalities such as (3) to obtain a suitable upper bound [Sch19, Theorem 1]. This approach is particularly useful, if we do Theorem 1, one can obtain such a bound for r-Frechet means with t E S (under some conditions). in this context, aside from t = T, are the Huber loss th,s [Hub64] and the Pseudo-Huber loss TpH, [Cha+94] for  E (0, o), 1x2 for x  , TH8x 7pH,s(x) := 8(x-1) for x>, as well as x +> ln(cosh(x)) [Gre90]. These functions are of great interest in robust statistics and image processing as their respective minimizers combine properties of the classical mean (2-Frechet mean) and the median (71-Frechet mean). 1.4 Outline In the remaining sections, we first discuss the set T, i.e., the set of quadruple transformations, see section 2. We continue with a discussion of the set S, i.e., nondecresing, convex functions with concave derivative, in section 3. Thereafter, we prove our main result, i.e., S C T. The basic ideas of the proof and variations of the main result are presented in section 4. The technical details can be found in appendix B and C. The proof of Theorem 3 can be found in appendix A. In section 5 we discuss implications of the main results and open questions. 2 Quadruple Transformations We explore some properties of quadruple functions r E T and their quadruple constant L*. 2.1  Properties Lemma 4 (Constant functions). (i) For c E R, let te := (x +> c). Then tc E T with L* = 0. 6",
    "The above assumptions are fundamental to our approximate calculation, and a further mild technical. assumption allows us to avoid tedious consideration of uninteresting cases:. . The time scales of relaxation of flagellar force and orientation are comparable:. YF/Yo ~ ord(1). (25) Indeed, we find this condition satisfied by the parameters we inferred from experimental observations in Table 1. Under the assumptions described above, we obtain the following approximation for the translational diffusivity: (X(c)(t) o X(c)(t)) lim =D 2t D* (26) where V*2 is the mean-square velocity coarse-grained over the flagellar time scale (19), and. a* 203 D=7 2y?7r(S2+ D+2) YE ii=  F(0) F(9)(F{9) cos(O{9) - F(0) cos(O{%)in(O() - 0{9) + 2 j-j'+2j Here * is the effective rotational drift coefficient and D* is the effective rotational diffusion coefficient. given in (8) and (10) respectively. As shown in Subsection 4.2, the error in our calculation is essentially fourth order in the small parameters oo and oF. The first two terms of the expression in Eq. (26) are exactly the translational diffusion for a colony with thermal diffusivity Dt, moving at a constant speed V* along an orientation with constant rotational drift Q* and constant rotational diffusion D*. As we shall shortly explain, the complicated terms in Dt are included for completeness and consistency with the results presented for general geometries in Subsection 5.2, but should typically be considerably smaller than the simpler terms presented in Eq. (26) for disclike geometries. Due to the nonpolynomial dependence of the translational diffusion on the effective rotational statistics, a rigorous computation of the demographic mean is complicated. We therefore content ourselves with an estimate for the demographic mean by averaging separately the numerator and denominator, neglecting. demographic correlations between the colony speed and rotational characteristics, and dropping the small contribution from Dt: E[D*] (27) All component demographic averages have been reported above, other than E[V*2] which is clearly representable as a linear combination of E[(V(c)|2)] and E[(F(0)2]. We do not report a demographic) standard deviation because it is cumbersome, and in any case is simply a compounding of the demographic fluctuations from the mean-square speed (21) and the the rate of velocity decorrelation induced by the effective rotational drift (9) and rotational diffusion (13) of the colony. 18",
    "QUENCHED DECAY OF CORRELATIONS FOR RANDOM CONTRACTING LORENZ MAPS ANDREW LARKIN AND MARKS RUZIBOEV AbsTRAcT. In this work we consider i.i.d. random perturbations of contracting Lorenz maps sufficiently close to a Rovella parameter. We prove that the quenched correlations of the random dynamical system decays exponentially. 1. INTRODUCTION The Lorenz system was introduced in [30] as a simplified model for atmospheric convection. Numerical simulations have shown that the Lorenz system admits a strange attractor, called the Lorenz attractor, which became one of the most iconic. examples in the field. A rigorous mathematical approach was developed with the introduction of the so called geometric Lorenz flow by [1, 26], which mimicks simulation of the dynamics of the Lorenz fow, and which has a robust strange attractor under C1 perturbations. Later in [37, 38] it was shown that the actual Lorenz attractor is indeed a singular hyperbolic attractor, further showing that the geometric Lorenz attractor represents the Lorenz attractor well. Moreover, it admits the so called Sinai-Ruelle-Bowen (SRB) measure, which is ergodic [11]. Its statistical properties, such as mixing rates, limit theorems and their stability under various perturbations, were studied intensively (see for example, [31, 10, 9, 7, 14, 13, 24]). Another class of systems with similar properties was introduced in [35] called the contracting Lorenz flow. A fundamental difference between these is that the attrac- tor of the system introduced by Rovella is not robust under perturbations, but still abundant in a measure theoretic sense. The set of measures for which the system is chaotic is called Rovella parameters and satisfies strong chaotic properties [8]; moreover, restricted to this set the system is stochastically stable [32, 33]. In [34] the authors addressed thermodynamic formalism for it. Up to now, the contracting Lorenz flow and one dimensional maps with critical points remain a profound exam- ple of a truly nonuniformly hyperbolic systems, which is studied via construction of induced schemes. We refer to [3] for a comprehensive account of these constructions. Recently, there has been increased interest in studying statistical properties of random dynamical systems, especially quenched (path-wise) properties. When the system has good uniformly hyperbolic properties, spectral techniques are still ap- plicable and imply strong statistical properties; we refer to [19, 20, 21, 23, 22] and references therein for results on quenched decay of correlations, limit theorems and stability results in this case. For the non-uniformly expanding (or non-uniformly hyperbolic) case, spectral techniques are not applicable directly. In this regards, it is customary to employ inducing techniques, in particular randomised version of Young Tower [39] construc- tion called random Young towers. This was first carried out in [15] for random 1",
    "though our model exhibits a larger variance in the estimated elasticity values compared to the BLP model. Own-Elasticity Estimation on Automobile Data Cross-Elasticity Estimation on Automobile Data 5 10 0.02 15 25 BLP Mode BLP Mode (a) Own-Elasticity Estimation (Our Model (b) Cross-Elasticity Estimation (Our Model vs. BLP Model) vs. BLP Model) Figure 4: Elasticity Estimation Comparison. Note: Figure 4 illustrates the distributions of the estimated own- and cross-elasticities obtained from our model and the BLP model. The filled areas in the violin plots represent the complete range of the elasticities, while the text labels indicate the mean values. We further estimate the average own-elasticity for high-priced, medium-priced, and low- priced cars and construct a confidence interval for each category using our inference proce- dure. We present our result in Table 14.. 6 Conclusion Choice models are fundamental in understanding consumer behavior and informing business decisions. Over the years, various methods, both parametric and non-parametric, have been developed to represent consumer behavior. While parametric methods, such as logit or probit-based models, are favored for their simplicity and interpretability, their restrictive assumptions can limit their ability to fully capture consumer preferences' intricacies. On the other hand, non-parametric methods offer a more flexible approach, but they often suffer from the \"curse of dimensionality\", where the complexity of estimating choice functions escalates exponentially with an increase in the number of products. In this paper, we propose a fundamental characterization of choice models that combines the tractability of traditional choice models and the flexibility of non-parametric estimators. This characterization specifically tackles the challenge of high dimensionality in choice sys- tems and facilitates flexible estimation of choice functions. Through extensive simulations, we validate the efficacy of our model, demonstrating its superior ability to capture a range of consumer behaviors that traditional choice models fail to capture. We also show how to 24",
    "Data Availability The original data analysed in this work are part of the Guaranteed Time Observation (GTO) program 1282 (PI: Th. Henning) with number 66 and will become public on 2 August 2023 on the MAST database (ht tps : / /mast . st sci . edu). The portion of the spectrum presented in Fig. 3 is available on Zenodo from the HITRAN database (https : / /hit ran. org). The Spitzer-IRS spectrum plotted in Fig. 1 is part of the Spitzer-IRS GTO program 40679 (PI: G. Rieke). The spectrum was extracted and calibrated The optical constants of the dust species considered in the fitting procedure for the dust continuum can be downloaded from the HJPDOC database (https : / /www2 .mpia-hd.mpg. de/HJPDOC). Code Availability The slab model used in this work is a private code developed by B.T. and collaborators. It can be ob- tained from B.T. upon request. The synthetic spectra presented in this work can be reproduced using the slabspec code, which can be found at https: //doi. 0rg/10. 5281/zenodo. 4037306. The fitting procedure for the dust continuum uses the publicly available MultiNest Bayesian fitting algo- rithm (https: //github. com/JohannesBuchner/Mu1tiNest) and the PyMultiNest package (https://github.com/JohannesBuchner/PyMultiNest). Figures were made with Mat- plotlib version 3.5.1. under the Matplotlib license at https : / /matplot 1ib. org/. Acknowledgements The MINDS team would like to thank the entire MIRI European and US instrument team. Support from STScI is also appreciated. The following National and International Funding Agencies funded and supported the MIRI development: NASA; ESA; Belgian Science Policy Office (BELSPO); Centre Nationale d'Etudes Spatiales (CNES); Danish National Space Centre; Deutsches Zentrum fur Luft- und Raumfahrt (DLR); Enterprise Ireland; Ministerio De Economia y Competividad; Netherlands Research School for Astronomy (NOVA); Netherlands Organisation for Scientific Research (NwO); Science and Technology Facilities Council; Swiss Space Office; Swedish National Space Agency; and UK Space Agency. G.P. would like to thank B. Bitsch and E. Gaidos for fruitful discussions and P. Hausschildt for kindly providing the model atmosphere. V.C. and O.A. acknowledge funding from the Belgian F.R.S. FNRS. Th.H., R.F. and K.S. acknowledge support from the European Research Council under the Horizon 2020 Framework Program via the ERC Advanced Grant Origins 83 24 28. B.T. is a Laureate of the Paris Region fellowship program, which is supported by the Ile-de-France Region and has received funding under the Horizon 2020 innovation framework program and Marie Sklodowska-Curie grant agreement. No. 945298. B.T. acknowledges support from the Programme National Physique et Chimie du Milieu Interstellaire' (PCMI) of CNRS/INSU with INC/INP cofunded by CNES. D.G. would like to thank the Research Foundation Flanders for co-financing the present research (grant number V435622N). D.G. and I.A. thank the European Space Agency (ESA) and the Belgian Federal Science Policy Office (BELSPO) for their support in the framework of the PRODEX Programme. I.K., A.M.A., and E.v.D. acknowledge support funding from H2020-MSCA-ITN-2019, grant no. 860470 (CHAMELEON). E.F.v.D. acknowledges support from the ERC grant 101019751 MOLDISK and the Danish National Research Foundation through the Center of Excellence \"InterCat\" (DNRF150). T.P.R acknowledges support from ERC grant 743029 EASY. D.B. has been funded by Spanish MCIN/AEI/10.13039/501100011033 grants PID2019- 11/21",
    "coupled WGM resonators to achieve multi-band tem parameters, we demonstrate the simultane- UR of photons through modulation of the inter- ous realization of UR and unidirectional trans- mode backscatterings of resonators[41]. In the missionlessness (UT). Moreover, the conversion reciprocal system that the equivalent transmis- between UR and UT can be achieved by adjusting sion in both directions was exhibited. Obviously, the coupling strength between WGM resonators these systems previously mentioned only inves- and optical fiber. Additionally, a one-to-one cor tigated the transmission or reflection characteris- respondence is established between the resonant tics, without considering achieving complete non- frequencies of QDs energy levels and the positions reciprocity in both channels, whereas directional of UR and UT peaks.. transport in both channels is vital to enhance the controllability of photons.. 1 Model and calculations. To this end, we propose a non-reciprocal sys- The schematic of system is shown in Fig.1 (a) and tem consisting of two WGM resonators that energy levels of QD is shown in Fig.1 (b). Assum- are individually embedded with a Zeeman split ing that the WGM resonators and QDs have the quantum dot (QD)[42-44] and indirectly coupled same loss rates y, then the Hamiltonian of the through an optical fiber. By optimizing some sys- system can be written as (assuming h = 1) 3CL(x)] + G;6[x-(j-1)d](CRCa+CCb,+H.c.)} j=1,2 +{[9j(Ca;Rj+Cb,0Lj)+hjCt,Cbj+H.c.] j=1,2 +(w0-Wj-iy)0Rj0Rj + (w0 +wj-iy)0LjOL +(waj - iy)Ct,Caj + (wb-iy)Cf,Cbj} (1) where C(x) (Cr(x)) and C}(x) (Ct(x)) are cre- strength between the jth wGM resonator and ation (annihilation) operators at x for forward. fiber (jth QD), and h, is transition rate be- and backward propagating photon along fiber, tween bj and aj. We set up wa1 = wa2 = wa respectively.Cf, (Cb,) and Ct, (Ca,) are cre- Wb1 = wb2 = wb, G1 = G2 = G, g1 = g2 = g and ation (annihilation) operators of CW mode b, and h1 = h2 = h for the sake of simplicity in the. CCW mode aj with resonance frequencies wbj following discussions.. and waj, respectively. Lj (oLj) and ORj (Rj) are transition operators which mean the transi- Assuming that photon with energy Ek = w = tions from states (9j) (eLj)) to (eLj) (lgj) and vgk is incident along the forward direction, where (gj) (leRj)) to (eRj) (lgj)), respectively. Vg is w and k are frequency and wave vector of the group velocity of photon. G; (gj) is coupling incident photon, and state of system is (assume Wa = wh = w and system is originally prepared in Accepted in <Ruantum 2017-05-09, click title to verify. Published under CC-BY 4.0. 2",
    "8 S. Sahu et al. with a step size of O.01. The final weights are used in our OwAF technique. Table 3 il- lustrates the effects of various fusion strategies. For fare comparison, we use both MRI and DTI data in all cases. The experimental results in the table 3 clearly reveal that the proposed OwAF outperforms other fusion strategies.  Table 4: Comparisons of the proposed method with State-of-the-art Approaches. PD vs HC PD vs. SWEDD|HC vs. SWEDD|PD vs. HC vs SWEDD Approach ML/DLMODALITY Ac Pr Re Ac Ac Ac Adeli 2016 [1] ML MRI 81.9 Cigdem 2018 [6] ML MRI 93.7 95 Prashanth 2018 [20] ML SPECT 95 96.7 Singh 2018 [2] MI MRI 95.37 96.04 93.03 99.01(M)|100(M) 99.3(M) Gabriel 2021 [21] MI MRI 87.10(F)97.2(F)100(F) 93.05 (A) Li 2019 [10] DL (AE)MRI + DTI 85.24 95.8 68.1 89.67 Tremblay 2020 [22] DL MRI 88.3 88.2 88.4 Chakraborty 2020 [7] DL MRI 95.3 92.7 614 Sivaranjini 2020 [23] DL MRI 88.9 89.3 Rajanbabu 2022 [8]DL (EL) MRI 97.5 97.9 97.1 95.53 Proposed method DL MRI + DTI 97.8 97.2 97.6 94.5 95.7 Pr: 93.64 Re: 91.99 Ac, Pr, Re, M, F, A, AE, EL, - Indicates Accuracy, Precision, Recall, Male, Female, Average, Auto Encoder, Ensemble Learning & data not available respectively. All the values are in %. 3.3Comparisons with State-of-the-art Approaches We compare our method with ten state-of-the-art approaches. There are no results avail- able for a direct 3-class PD classification. So, we compare our results with those papers that have addressed the PD classification on the PPMI database using single or multiple modalities and with three or fewer two-class classifications. The results of comparisons are shown in Table 4. Out of the ten methods we have considered, five are based on machine learning (ML) and the rest five are based on deep learning (DL). Further, in four out of five DL based approaches, only a single modality, namely, MRI is used for classification. Also note that eight of these ten techniques have only addressed a single two-class classification problem between PD and HC and did not consider the chal lenging SWEDD class at all. The remaining two approaches did consider SWEDD as a third class but have divided the three-class classification problem into multiple binary classes [2,10]. However, Li at al. [10] did not report the classification results for PD vs. SWEDD in their paper. In order to have fair comparisons, we have also included three binary classifications as obtained from our method in this table. Our direct three-class classification accuracy turns out to be superior than two-class classification accuracy of at least eight out of 10 methods. It is also higher than two out of three binary classifi- cation accuracy of [2]. Note that in [2], the authors used a somewhat different experi- mental protocol by considering two publicly available databases of ADNI and PPMI. In our work, we explicitly consider data with both MRI and DTI for the same individual",
    "2 VALENTIN LEMARIE We then define the damped mode:. (Q- s2)-(V-)+sQ+ ((s0)d) (1.4) We := As the first equation of (1.3) can be rewritten as. d-(P))-divV-)-1-)= divW) we expect the limit density N to satisfy the following parabolic-elliptic Keller-Segel system :. atN -(P(N)) = div(N VV) (1.5) -V=N- supplemented with the initial data lim eo.. Our second aim is to justify the passage to the limit when e -> 0 of the Euler-Poisson system towards the parabolic-elliptic Keller-Segel system.. Recall that (1.5) is a model for describing the evolution of density N = N(t,x) e R+ of a biological population under the influence of a chemical agent with concentration V = V(t, x) E Rd. Chemotaxis are an important means of cell communication. How cells are arranged and organized is determined by communi- cation by chemical signals. Studying such a biological process is important because it has repercussions in many branches of medicine such as cancer [0], [0], embryonic development [0] or vascular networks [0], [o]. The previous system is famous in biology and comes from E.F Keller and L.A Segel in [0]. This basic model. was used to describe the collective movement of bacteria possibly leading to cell aggregation by chemotactic effect. We refer to the articles [0] and [0] for more details and information about the different Keller-Segel models studied since the 1970s. Our aim here is to demonstrate that (1.5) may be obtained from the Euler-Poisson system with damping when the parameter e tends to 0. This question has been addressed in [0] on the torus case and Sobolev spaces in a situation where the potential satisfies a less singular equation : the author justifies the passage to the limit for regular periodic solutions. A lot of articles justify another limit: the passage from the parabolic-parabolic Keller-Segel system to the parabolic-elliptic Keller-Segel system (see e.g. the paper [0] by P-G. Lemarie-Rieusset for the case of Morrey spaces).. In the same spirit as this article, T. Crin-Barat, Q. He and L. Shou in [0] justified the high relaxation -V + bV = aN with a,b > 0) : this other system comes from the system (HPC) (hyperbolic-parabolic- chemotaxis) which is a damped isentropic compressible Euler system with a potential satisfying an elliptical equation. In comparison with what is done here, T. Crin-Barat et al used a parabolic approach to justify. their passage to the limit. Here, we have to handle the more singular case where the limit system is parabolic- elliptic. 2. MAIN RESULTS AND SKETCH OF THE PROOF In this section, we will first present and motivate the functional spaces used. Secondly we will state the results and the sketch of the proofs about the well-posedness behavior of Euler-Poisson system and the 2.1. Functional spaces.. Before describing the main results of this article, we introduce the different notations and definitions used throughout this document. We will designate by C > 0 an independent constant of e and time, and f  g will mean f  Cg. For any Banach space X and all functions f, g E X, we denote I|(f, g)llx : = I|fl|x +||gl|x. We designate by L2(R+; X) the set of measurable functions f : [0, +oo[-> X such that t +> l|f(t)l|x belongs to L2(R+) and write |I - I|2(R+;x) := II IIz2(x) In this article we will use a decomposition in Fourier space, called the homogeneous Littlewood-Paley decomposition. To this end, we introduce a regular non-negative function  on Rd with support in the",
    "4.5. Corollary. Let P be a polyhedron of dimension n with abelian 1(P) and finitely generated H,(P), for i  2. Then D(P) < i=1 ni, where n1 and ni (i > 2) are the number of nonzero direct summands in the canonical form of 1(P) and H(P), respectively. 4.6. Corollary. Let P be a polyhedron of dimension n with free 1(P) and finitely. generated H(P), for i  2. Then D(P) < rank(1(P)) + r=2ni, where ni is. the number of nonzero direct summands in the canonical form of H,(P). 4.7. Corollary. Let P be a polyhedron of dimension n with elementary amenable 1(P) of finite cohomological dimension and finitely generated H,(P), for i  2. Then D(P)  h(1(P)) + i=2ni, where h(1(P)) is the Hirsch length of 1(P) and ni is the number of nonzero direct summands in the canonical form of H,(P) Recently, in [14], Kolodziejczyk proved that 2-dimensional polyhedra whose fundamental groups are elementary amenable with finite cohomological dimension. have finite depth. In the sequel, we are going to present upper bounds for such polyhedra. Recall that if P is a polyhedron of dimension n, then Hn(P) is free abelian (see, for example, [18, Theorem 7.24]). Now we state our second main result. 4.8. Theorem. If P is a 2-dimensional polyhedron and sl(1(P)) < o, then D(P)  sl(1(P)) +rank(H(P)). Proof. Consider the following chain of CW-complexes:. X+1XX3<X<XX0=P. idn1(Xi+1) and H2(dx;+1)H2(ux+1) = idH2(X+i). As a result, im1(ux+1) and imH2(uxi+1) are retracts of 1(X;) and H2(X;). Assume that im(1(ux+1)) =1(X) and im(H(ux+1)) = H(X). Then 1(ux.+1) and H2(ux.+1) are isomorphisms. Accordingly, 1(dx+1) is an isomor phism and HXHX+1)since 1X1X+1)we have HX H1(X+1) by the Hurewicz Theorem (see [18, Theorem 4.29]). This fact and khnnn nea hhhnne (x)X ahee (1+x)X = (x)X gheg Ahdhe (1+x)H =(x)H Poincare characteristic of polyhedron X of dimension m. Now since dx+. :. X, -> Xi+1 is a homotopy domination between X, and Xi+1 that induces an isomorphism on the fundamental groups, it is a homotopy equivalence (by [14, Theorems 2]) which contradicts X+1 < X.Therefore, either im(1(ux,+1)) is a proper retract of 1(Xi) or im(H2(ux,+1)) is a proper retract of H(Xi) So by Lemma 3.3, sl(im(1(ux+1))) < sl(1(Xi)) or rank(im(H2(ux+1)))< rank(H2(X;)). Since n1(Xi+1) im(1(ux+i)) and H(Xi+1) im(H2(uxi+)); we have by Lemma 3.4 that sl(1(Xi+1)) < sl(1(X)) or rank(H(Xi+1))  rank(H2(X)). Thus for io := sl(1(P))+rank(H(P)), we have sl(1(Xio)) = 0 and rank(H(Xo)) = 0 which means by Lemma 3.4 that 1(Xio) = 1 and H2(Xio) = 0, Hence, Xi, is homotopically trivial and so the proof is finished. ",
    "Outline. We use Fenichel's reduction to regularize the singular perturbation in existence and eigenvalue problem in Section 2. In Section 4, we study the resulting regularized traveling wave problem using functional-analytic methods, using methods developed in [2, 4, 3] to find pulled and pushed front profiles as well as the transition curve. Section 5 establishes marginal spectral stability of these fronts thus justifying the pushed and pulled terminology. In Section 6, we briefly compare the expansions obtained in Theorem 1.2 to those obtained using numerical continuation. The appendix contains the construction and properties of traveling fronts at & = 0.. 2  Regularization via geometric singular perturbation theory 2.1  Reduction of existence problem. We express (1.5) as a dynamical system in the variable x by choosing coordinates U, W = U', H = U' = W W' = I(U,W, H, Z) d1 8H'= Z 8Z'= H+ T(U, W, H, Z), (2.1) where (A-I)N+HN+ ZM9+zM+ M=(Z'HM'N)I (2.2) When  = 0 the system (2.1) reduces to two algebraic equations coupled to two differential equations. One identifies the following reduced slow manifold comprised of solutions of the algebraic of equations in the singular limit & = 0,. (2.3) d1+ U The linearization of (2.1) at any such fixed point has two zero eigenvalues and two hyperbolic eigenvalues /1 +  for U  0. The eigenspaces of the non-zero eigenvalues are traverse to Mo. and therefore the reduced manifold is normally hyperbolic. Fenichel's Persistence Theorem [5] implies that Mo persists as an invariant manifold Ms with the following properties.. Proposition 2.1 (Reduction for existence problem). Fix 0 < d < d, M > 1, and an integer k  2. There exists a  > 0 such that all trajectories of (2.1) with || < , d < d1 < d satisfying. -d1 < U < M and |W|< M lie in a slow manifold Ms, which is normally hyperbolic and invariant under the flow of (2.1), and may be written as a graph Ms = {(U, W, H, Z) : H = WH(U, W; ), Z = yz(U,W;s)}, where H =yH(U,W;8) =yH(U,W) + 8yH(U,W) +82yH(U,W) +O(84); Z = yz(U,W;) = 8y(U,W) + O(s2) (2.4) 5",
    "Shallow classifier YAMNET37.40MB 102 0AB RF VGGish 295.37 MB LR SVM 3 M 6144 M256 90.01MB 101 3 M 6144 M128 67.49 MB L3 M 6144 L 56.55ME L3 M 512 M256 39.40 MB 100 L3 M 512 M128 40.60MB L3 M512L 41.21 MB L3 E 6144 M256  81.82 ME L3 E 6144 M128  66.13MB 10-2 L3 E 6144 L 86.39MB L3 E 512 M256 L3 E 512 M128 Base model 10-3 L3 E 512 L37.80MB  Fine-tuned model 0.6 0.7 0.8 0.9 1.0 0 2 4 6 8 PCA Explained Variance (%) Parameters (x10) (a) Shallow classifiers b) Fine-tuned models Figure 4: Memory footprint of (a) the considered shallow classifiers based on different input sizes (i.e., percentage of PCA explained variance), and (b) the fine-tuned deep learning models. Please, consider that in (a) the overall memory footprint is given by taking into account also the size of the deep embedding models to extract the input features from the raw audio sample.. the input data dimension. Figure 4a shows the memory size (in MB) of the 4 shallow classifiers considered in our experiments, based on the input size in terms of the percentage of PCA explained variance. As expected, the size of most of the classifiers increases according to the input dimension, except for Random Forest (RF), whose size remains nearly constant at around 1 MB (between 0.98 and 1.11). Logistic Regression (LR), the simplest classifier, is also the one with the lowest memory footprint in all the experiments, starting from less than 1 KB (i.e., 922 Bytes), up to 3.64 KB with 99% of PCA explained variance. On the other hand, AdaBoost (AB) results to be the most demanding model in terms of memory, with an overall size that ranges from just 5.74 MB with 60% of PCA, up to 185.05 MB with the full dimension of the input. Finally, SVM has an intermediate memory footprint among the other classifiers, ranging from 42.6 KB up to 1.88 MB. On the other hand, when the deep audio models are fine-tuned, the size of the additional fully-connected layers should be considered to estimate the overall memory footprint. Figure 4b shows the average size of the fine-tuned models, highlighting both the size of the original pre-trained models, and the size of the additional layers for classification. We can note that, in general, 24",
    "work called transductive learning uses test data to add constraints to the margin of SVMs [31, 11, 66]. The principle of transduction, as stated by Vapnik, also emphasizes locality [18, 67]: \"Try to get the answer that you really need but not a more general one.\" In computer vision, the idea of training at test time has been well explored for specific applica tions [30, 57, 46, 73], especially depth estimation [62, 63, 82, 84, 43]. Our paper extends TTT-MAE [19], detailed in Section 3. TTT-MAE, in turn, is inspired by the work Sun et al. [61], which proposed the general framework for test-time training with self-supervision, regardless of application. The particular self-supervised task used in [61] is rotation prediction [21]. Many other papers have followed this framework since then [24, 60, 40, 77], including [69] on videos discussed in Section 1, and [5] which we discuss next. In [5], each video is treated as a dataset of unordered frames instead of a stream. In particular there is no concept of past vs. future frames. The same model is used on the entire video. In contrast, our paper emphasizes locality. We have access to only the current and past frames, and our model keeps learning over time. In addition, all of our results are on real world videos, while [5] experiment on videos with artificial corruptions. These corruptions are also i.i.d. across frames Our paper is very much inspired by [45]. To make video segmentation more efficient, [45] makes predictions frame-by-frame using a small student model. If the student is not confident, it queries an expensive teacher model, and then trains the student to fit the prediction from the teacher online. Thanks to temporal smoothness, the student can generalize confidently across many frames without querying the teacher, so learning and predicting combined is still faster than naively using the teacher at every frame. Our method only consists of one model, which learns from a self-supervised main goal of our paper is to improve inference quality. Behind their particular algorithm, however, we see the shared idea of locality, regardless of the form of supervision. 3  Background: TTT-MAE Our paper extends the work of Test-Time Training with Masked Autoencoders (TTT-MAE) [19], and uses TTT-MAE as the inner loop when updating the model for each frame. This section briefly describes TTT-MAE, as background for our extension. Figure 3 illustrates the process of TTT-MAE The architecture for TTT with self-supervision [61] is Y-shaped with a stem and two heads: a prediction head g for the self-supervised task, a prediction head h for the main task, and a feature extractor f as the stem. The output features of f are shared between g and h as input. For TTT-MAE. the self-supervised task is masked image reconstruction [27]. Following standard terminology for autoencoders, f is also called the encoder, and g the decoder. Each input image x is first split into many non-overlapping patches. To produce the autoencoder input x, we mask out majority, e.g. 80%, of the patches in x at random. The self-supervised objective es(g o f(x),x) compares the reconstructed patches from g o f(x) to the masked patches in x, and computes the pixel-wise mean squared error. For the main task, e.g. segmentation, all patches in the original x are given as input to h o f, during both training and testing. 3.1Training-Time Training There are three widely accepted ways to optimize the model components (f, g, h) at training time: joint training, probing, and fine-tuning. Fine-tuning is unsuitable for TTT, because it makes h rely too much on features that are used by the main task. Our paper uses joint training, described in Section 4. In contrast, [19] uses probing, which we describe next for completeness. To prepare for probing, the common practice is to first train f and g with l, on the training set without ground truth. This preparation stage is also called self-supervised pre-training. TTT- 4",
    "COMPASS '23, August 1619, 2023, Cape Town, South Africa Hines et al. the temperature feature to evaluate its impact on the clustering algorithm's efficiency in identifying locations of interest. 3.3.1Obtaining Historical Temperature Data. However, such tem- perature analysis is only feasible when temperature data is avail-  able. Certain studies concerning elephant movement (Tsalyuk et al. [23]; Wall et al. [24]) lack a temperature feature. Therefore, we explored methods to approximate temperature data from other data sources. Using the meteostat python package and API, we identified weather stations proximate to the study site. The historical data was queried and appended to the study data, enabling calculation of Temperature-influenced centroids that would have been impossible to calculate otherwise. The procedure entailed three key steps: (1) Identifying a nearby weather station, (2) Matching timestamps with the queried data, and Figure 1: Comparing feature spaces with and without tem- (3) Evaluating the capability of the appended historical temperature perature on elephant AM306 from the Kruger dataset. Black data in calculating temperature-influenced centroids.. Xs represent centroids calculated with temperature included For the first step, the median latitude and longitude of the given in the feature space. Large colored dots represent centroids elephant's movement data was computed, which was then used of clusters calculated solely on location data. Parameters: to query a nearby station. The second step involved normalizing Without temp-influenced epsilon=0.1, minPts=35. Temp- and interpolating the time series data from the station, provided by influenced epsilon=0.2, minPts=50 meteostat, to ensure a higher temporal granularity that matches the given data. In the third step, the correlation between the historical station data and Kruger temperature data was evaluated using the balance between data retention and accuracy should be maintained coefficient of determination, R-squared. while deciding the value of 8. Our results indicate a moderate correlation between the study The integration of weather station temperature data with animal data and the station data. This correlation, combined with the per- movement datasets presented a significant challenge due to the formance of the Temperature-influenced centroids with the weather relatively low percentage of matching timestamps. For instance, data, gives us confidence to extend this technique to datasets that in the case of AM189 from Etosha, a mere 19.662% of timestamps lack temperature data. Based on our experiment with elephant corresponded. This limited overlap signifies a considerable loss AM306 (See Figure 1) from the Kruger dataset, we found that the of data, which undermines the analysis. To address this issue, we Temperature-influenced feature space aided in revealing more nu- utilized \"fuzzy\" timestamp matching. This method extends the cri- anced locations of interest within the larger clusters identified by teria of a match beyond exact timestamp equality, incorporating a the Without Temperature influence feature space.. pre-defined threshold for the discrepancy between two timestamps that still qualifies them as a match. The mathematical formulation 3.3.2 Fuzzy Timestamp Matching. Fuzzy timestamp matching is an of this concept is as follows: Given two timestamps t1 and t2, and advanced data processing technique that matches timestamps not. based on exact equality but within a certain tolerance level. This tolerance level, or fuzzy threshold, is usually calculated by taking Metric Value half of the median of the difference of timestamps in the dataset.. The mathematical representation of the fuzzy timestamp matching R-squared (zero-centered) 0.6871044690549571 Offset (study - station) process could be described as follows: 9.840106696689293 Given two timestamps, t1 and t2, and a tolerance level 8, the times- % of timestamps found. 61.6% tamps t1 and t2 are said to match if:. Table 1: Statistics for Figure 2 t1-t2 (2) where |t1 - t2| denotes the absolute difference between the times- a tolerance level (or fuzzy threshold) , the timestamps t1 and t2 tamps t1 and t2. In this case, 8 is calculated as: are said to match if the absolute difference between them, denoted 8 = 0.5 * median([t[i +1]- t[i]l), Vi 1 to N- 1 (3) as [t1 - t2], does not exceed . The fuzzy threshold 8 is calculated as half the median of the differences between all sequential pairs of where N is the total number of timestamps, and t[i] represents timestamps in the dataset. the ith timestamp in the ordered sequence. This fuzzy matching By employing fuzzy timestamp matching, the percentage of approach increases the likelihood of matches and can help to mit- matched data can be substantially increased. For example, in the igate data loss when aligning data from different sources or with case of AG191 from Etosha, conventional timestamp matching re  different temporal resolutions. However, it is important to note sulted in a match percentage of 41.85%. With the application of that this technique may also introduce some uncertainty into the fuzzy matching, this percentage rose to 74.50%. Notably, these ad- analysis due to the mismatched timestamps. Hence, an appropriate ditional matches, achieved through fuzzy matching, are proximal",
    "marking a quantity evaluated at the stationary expansion point (U, @) as X@. We will use this notation throughout this work.c Equation 7 yields an alternative formulation of Equation 4 using the exchanged second mixed derivative (Eq. 1) Grand canonical energy of a stationary point We can now insert the just derived potential dependent geometric shift of a stationary point r*(U) (Eq. 7) into the second-order expansion of the gcPES (Eq. 6) around a known stationary point (U, @), eliminating the spatial dependence and returning the potential-dependent grand canonical energy @*(U) of a stationary point accurate to second order: E*(U)=8(U +AU,7@+r*(SU)) =8(U,7)-q*U (H-(3g)sU)H(x-(3q)@sU) i,j,kl (cnV)o+(znV5-nV(nvg(se)-a3c)a(%e)3z where we dropped the force-contribution, since F$ = 0. Rearranging and using  H?- H$ - k.; then yields the energy @* of the stationary point at potential U = U + U: Cgeom 8*(U)=e@-q@sU-1(C@+t$-'(3q)(3q)@)sU2+0(sU3) (8) i,j Ctotal This expression is essentially the (double-)integrated form of Equation 5. We could equally obtain it by integrating Equation 5 twice from the potential U where all required properties are known cAs a further clarification on the difference between X* and X@: X*(U) essentially is a shortcut for writing X(U, 7*(U)), i.e. for denoting quantities evaluated at the stationary point at the desired potential. The additional circle. in X@ indicates a property evaluated at a stationary expansion point. Essentially, we derive quantities Y* at a desired. potential U based on quantities X* evaluated at a stationary expansion point (U, 7*(U)), i.e. at a different potential. Uo. 9",
    "0.9 0.8 8V 0.7 F =1 0.5 2=2 0.4 5 50 100 5001000 v Figure 2. Suppression of Chandrasekhar's formula for the dynamical friction force F/FA-o for finite values of the cutoff A in the simple case of a halo subject to Hubble drag. The solid black curve corresponds to a choice of halo formation redshift of zi = 1, and the dashed blue curve to zi = 2. In realistic applications we might expect A  Acoh/Rhalo  10  1000 as we will see in Sec. 5. and scales like m, such that the dynamical friction effect is dominated by the most massive neutrino eigenstate. We may then assume a single neutrino species for simplicity, or explicitly write the total dynamical friction force as a sum of individual contribution from different eigenstates.. In order to connect Eq. (3.19) with the results of future sections, it is convenient to rewrite it in. terms of a quantity with dimension of inverse time. Since F = Mdvh/dt, we can define: F.UH_2 M (my Ho (3.20) MvH-3 which is the characteristic time scale for an order one fractional decrease in the halo velocity due to the dynamical friction effect. Note that 1/rHo = v/v is the overall relative decrease in the halo velocity over the age of the Universe t ~ 1/Ho. We obtain a numerical value of v/v = 3.4  10-5 for a halo mass M = 1013Mo and individual neutrino mass m, = 0.1eV, when also assuming A = 100. This already suggests that the dynamical friction effect is quite small, although it can pick up some significant contributions from the clustering of nearby halos as we will see in Sec. 5.. 3.3Limitations to the 1-halo approach. Thus far we have determined the anisotropic clustering of massive neutrinos behind moving point mass halos and the corresponding dynamical friction force. A more realistic calculation would have to account for both the finite extent of the halo and the presence of large-scale structure. Indeed, the Eq. (3.20) involves an unknown Coulomb logarithm, logA, where in typical applications of the dynamical friction formula the cutoff A can be estimated as the ratio of maximum and minimum impact parameters, A ~ bmax/bmin [51]. Here bmin ~ Rhalo is the halo radius, and bmax ~ Acoh ~ 0.1 Mpc-1 is the CDM velocity coherence scale. The CDM bulk fow is only coherent over sufficiently small scales and hence our analysis based on a single moving halo is expected to break down at scales   Acoh.3 This point will be made more clear in the next section, where we also provide a precise definition for the velocity coherence scale.. 3We should also impose a cutoff corresponding to the distance traveled by free-streaming neutrinos, which sets the scale where neutrino inhomogeneities are coherent with CDM. As we shall see the neutrino free-streaming scale.",
    "JOURNAL OF ITX CLASS FILES, VOL. 14, NO.8, AUGUST 202 Branches Mutual Promotion for End-to-End Weakly. Supervised Semantic Segmentation Lei Zhu, Hangzhou He, Xinliang Zhang, Qian Chen, Shuang Zeng, Qiushi Ren, Yanye Lu*. Abstract-End-to-end weakly supervised semantic segmen- tation aims at optimizing a segmentation model in a single- stage training process based on only image annotations. Existing methods adopt an online-trained classification branch to provide pseudo annotations for supervising the segmentation branch. However, this strategy makes the classification branch dominate the whole concurrent training process, hindering these two branches from assisting each other. In our work, we treat these two branches equally by viewing them as diverse ways to generate the segmentation map, and add interactions on both their supervision and operation to achieve mutual promotion. For this purpose, a bidirectional supervision mechanism is elaborated C:E2E-wsSS with our es Mutual Promotion Strate to force the consistency between the outputs of these two branches. Thus, the segmentation branch can also give feedback to the classification branch to enhance the quality of localization seeds. Moreover, our method also designs interaction operations between these two branches to exchange their knowledge to assist each other. Experiments indicate our work outperforms existing end-to-end weakly supervised segmentation methods. Index Terms-- Weakly Supervised Learning, Image Segmenta- tion, Object Localization Fig.1.Comparison of wSsS strategies:A. Multi-stage WssS contains multiple training stages. B. Existing E2E-wsss unidirectionally supervises the segmentation branch with pseudo annotations online provided by the I. INTRODUCTION classification branch. C. Our proposed E2E-WssS strategy interacts both 7 EMANTIC segmentation is a primary vision task, aiming the supervision and operation between these two branches to achieve mutual promotion.  to annotate pixels in an image as target objects or back- grounds. However, training a segmentation model in a fully-  or determining reliable regions on the pseudo annotations [9], images, costing extensive human resources. To solve this [10]. problem, weakly supervised semantic segmentation (WsSS) In our work, we argue that current E2E-wsss methods appears and attracts extensive attention, which adopts only  may fall into a trap, following the multi-stage wsss to image-level annotation for the training process. However, as unidirectionally supervise the segmentation branch based on shown in Fig. 1 A, wSSS methods usually require multiple the prediction of the classification branch, without considering training stages, e.g., tuning a classification network with image the feedback of the segmentation branch. In this way, the annotations to producelocalization seeds [1]-[3], deriving  classification branch will dominate the whole training process, pseudo annotations after refining the seeds [4]-[6], and finally  even if it may perform worse than the segmentation branch, as training the segmentation network with the pseudo annota- visualized in Fig. 2. Thus, the classification branch will con- tions [7], [8]. verge to a similar optimum as the offline trained classification Recently, some end-to-end weakly supervised semantic. network but cannot stably provide pseudo annotations for the segmentation (E2E-WssS) methods arose to simplify the  segmentation branch, which causes the large performance gap between current E2E-WSSS and multi-stage WSSS methods. [12]. As shown in Fig. 1 B, these methods train a two- Actually, in the E2E-wsss setting, these two branches branch network in only a single stage, where the classifica-  are basically at equal status because they are concurrently tion branch supervised by image-level annotation can online optimized during training. From another perspective, the provide pseudo annotations for the segmentation branch. Com- segmentation branch can also assist the concurrently-trained pared with multi-stage WssS, the concurrently-trained classi-.  classification branch in generating better localization seeds, fication branch cannot stably provide seed to derive accurate which is a crucial trait of E2E-wSSS and yet to be explored pseudo annotations for supervising the segmentation branch..  by existing methods. Based on this perspective, our work treats So, existing E2E-WssS methods focus on improving the these two branches equally by viewing them as diverse ways classification branch to provide better supervision by refining to achieve the same goal, generating the segmentation map the localization seed with online spatial propagation [11]-[13] of input images. Thus, as shown in Fig. 1 C, interactions are",
    "shown that the dependence of mining rewards on propagation  easier function that only depends on the pairwise shortest path latency is more intricate than this [35]. Specifically, an honest  lengths between miners. Importantly, our MDP reward func- miner that is well connected with other miners inadvertently tion captures the property that a miner's mining gains depends creates efficient, low latency paths for other miners by acting  on how small the shortest path lengths between the agent and as a centrally located bridge between the miners. However, to Other miners are relative to the shortest path lengths between maximize the marginal gains in reward due to the network, it  other miners. Experimentally we show Cobalt outperforms or is important for a miner to have paths to other miners that are, matches heuristics on diverse network settings.. on average, of a lower delay relative to the delays of paths II. RELATED WORK between other miners. For example, if miners are arranged as a star topology with links of unit delay and uniform compute P2P network design for optimizing mining rewards has power across nodes, the central node receives a higher reward  remained a relatively under-explored topic in the community. compared to the leaf nodes by including more blocks on the The work that is closest to our is Perigee [34] which proposes blockchain. On the other hand, on a complete graph topology an adaptive peer-selection algorithm for minimizing block with unit delay links and uniform compute power as before, all propagation latency in the network. However, Perigee does nodes receive the same reward. A node identically connected not model the game-theoretic competition between miners to other nodes in the two cases (i.e., the central node in the Subsequent works [11], [43] consider optimizing the network star topology and any arbitrary node in the complete graph to maximize extractable value (MEV)from transactions.A topology: both have direct links to all other nodes) receives dif-  number of prior works have exposed the impact of the network ferent rewards, as rewards depend not only on the node's own on mining [12], [26], [28], [37], [40], [47], [48]. While connections but also on how other nodes' connections. Thus,  these works generally suggest that better network connectivity there is an inherent tension for a miner in increasing her own  translates to higher mining rewards earned, the competitive connectivity to the rest of the network while simultaneously effects of network connectivity and methods to optimize ensuring that the connectivity between other miners do not them have not been discussed. Other related works include significantly increase. A systematic research of this tension, KadCast [38] which proposes a Kadmila-based structured and efficient connection policies to maximize marginal mining  overlay for efficient block broadcast, and relay networks such reward gain due to the network, have not been done to our best as BloXroute [29] for transports blocks quickly across vast knowledge. geographic distances. In this work, we formalize the p2p topology construction  The idea of network coordinates for p2p networks has been problem as a game between miners and present Cobalt, a  prominently explored in the network systems literature since decentralized policy for optimizing reward. We consider a the turn of the millenium, including distributed approaches to simplified setting where only a single node chooses its con- learn them [19], [32], [36]. More recently, a number of theo- nections, while the rest of the network's topology is fixed. retical works have studied using low-distortion embeddings in We assume that the global topology of the p2p network is finite metrics (i.e., over finite graphs) for various applications, unknown to miners. We thus model the problem of optimizing e.g., sparse spanner construction [10], [13], [16], [21].] rewards by the connections-deciding miner node as a Markov Game theory of blockchains, especially at the consen decision process (MDP) with no state and an action set with  sus layer, has received considerable attention. For example, a combinatorial number of actions. Lewenberg et al. [33] use game theory to study how mining We derive the optimal neighbor selection policy using rewards can be shared across members of a mining pool. On a combinatorial multi-armed bandit (MAB) approach [14]. the other hand, prior works have considered various network In the MAB algorithm, the agent (miner) explores various games outside the context of blockchains [24], [39]. Our work candidate connection configurations, and gradually adapts its is the first (to our best knowledge) to consider network games connections based on past experience to gain the most min- in blockchains. ing rewards. A key contribution of our work is a network coordinates based model for efficiently learning the MAB III. PROBLEM FORMULATION environment [19]. In this model, miners are assigned real- Let us consider a complete directed graph G = (V,) valued vectors from an Euclidean space, which capture the where V is the set of nodes and & is the set of directed edges. relative location of miners with respect to each other in the Each node in the graph represents a mining server. The hash network. The coodinates are continuously updated based upon rate of the mining server v is denoted by H,. We use H to the reward feedback the agent receives from the environment. denote the hash rate vector H := (H)vev. A directed edge Thus, despite not having global knowledge of the network (v1, V2) E & represents a (TCP) link between the nodes v1, V2. initially, we show that it is possible for an agent to learn about The directed edge represents that node v1 can send messages the network by just using the observed reward information. (e.g., transactions, blocks etc.) to v2 as and when required by To enable the deployment of MAB algorithm, we have the protocol. The time take for a message sent from v1 to built a simulator. To simplify the reward computation in the reach v2 along the link (v1, v2) is denoted by l(v1, V2)  0. simulator, rather than simulating the actual mining process at each step of the MDP, we consider a computationally 1We assume if (v1, v2) E E then (v2,v1) E E for all v1, v2 E V.",
    "Batch Learning LR Weight Drop Embedding Window Head Patch Epoches Optimizer size rate  decay  decay path dim L size  size 300 Adam[17] 8 4e-4 cosine 1e-7 0.1 15 5 2 16 512 Table 1. Default training and network hyper-parameters used in our method, unless stated otherwise. of COMO-ViT, we conduct two branches of operations. In the first branch, we uniformly split it into n non-overlapping (w,w) is the window resolution. SNR [43] and STAR [52] downsample images, losing local structures and some important pixel-level information. Instead, the proposed Rs2 COMO-ViT completely models the dependencies among all pixels of an image via a local-to-global hierarchical self- TG AG attention. Locally, each pixel in a window P' is regarded as an individual, we thus reshape P' as follows: Pi- [pi,pi2, ..,pi,m] (10) where pij E Rlx1xe, m = w? is the number of pix- Rs3 GT els in Pi. With a linear projection, we then transform Figure 4. We observe that Rs3 keeps higher illumination than Rs2, = illustrating the effectiveness of our LGCM. It is corresponding [xi,1, xi,2, ... , xi,m], where x E Rcl is the j-th pixel pixel-wise local gamma map. embedding, c1 is the embedding dimension. For X', we utilize a local Transformer module to extract deep features as follows: Y'i = Xi + MSA(LN(X)), Global pixel dependencies are explored by calculating (11) window attention via a global attention module. Firstly, C Yi =Y+ MLP(LN(Y)), is transformed into a sequence of window embedding: where Yi is the feature learned by the local Trans- U= [u',u,..,un], u=FC(Vec(C)), 15) former module, MSA() is the Multi-head Self-Attention [35], LN() is layer normalization [1] for stable training where Vec() is vectorization operation. Then, we utilize and faster convergence, MLP() is multi-layer perceptron a global Transformer module to explore inter-window de- for feature transformation at channel dimension and non- linearity. In such a process, we adopt 1D learnable location l E {1, 2, .:: , L}, and L is the COMO-ViT number. When embedding to encode the spatial information of pixels. l = 1, Fi-1 is the fused feature F t in Eq. (9). To complement the non-overlapping window attention, The result of the second stage is obtained by decoding in the second branch which is parallel with local attention, FL with a convolutional layer (D(-)): we use a CNN module to model local pixel dependencies in Fi-1 via an overlapped sliding kernel to recover image Rs2 = Conv(FL). (16) details, in which a SE block [11] is used to explore channel relationship to boost representative power: We visually show Rs2 in Fig. 4, observing that the illu- F'=Conv(LN(F-1)),Fconv =F'OSE(F'). (12) mination is enhanced and image details are also recovered. Especially, the noise is well removed by our COMO-ViT. Fcony is then split into n non-overlapping windows Q = [Q1, Q2, .. , Qn] E Rn xwxwc, and each Q' is reshaped: LGCM.LGCM takes Rs2 as input, and learns local deep features to perceive illumination gap between Rs2 and Qi> [qi1,qi,2,.,qi,m]. (13) ground truth and elaborately enhances illumination to re- We combine the features from both branches as: duce local color deviation: C= [C, C2,,Cn], C=Q+ Yi (14) I=y(Conv3(Rs2)),Rs3=R (17)",
    "BW pulsar Wind Magnetic Fields 11 of 103 G (Reiners & Christensen 2010), we get a magnetic field strength of 4.5101 G at the eclipse edge ($b = 0.31). A magnetosphere field strength of 10 G is sufficient to trap and dominate plasma (assuming protons and electrons) of number density < 3  1013 cm-3 and velocity ~ Vorb. P E separation, and Be is the magnetic field of the eclipse medium. From this, the magnetic field strength of BE should be  8 G (Wang et al. 2021). Interestingly, the derived theoretical magnetic field strength (45 G) is more than sufficient for the re- quired field strength (8 G) at the eclipsing edge. However, these field strengths are more than three orders of magnitude higher than the value observed in our egress (10 mG). Pulsar wind The third scenario (Fig. 7 c) supplements the second one with pulsar wind and a shock boundary, and fixes the inconsistency mentioned above. Such a picture was proposed by Phinney et al. (1988) as one of the early models. In this picture, a shock boundary exists between the magnetosphere and the pulsar wind. Outside of the shock boundary are high-speed, low-density pulsar wind particles traveling with a low magnetic field, and inside, the slow-moving, high-density plasma trapped by the companion's magnetic fields. This is similar to the boundary shock observed from the Solar wind and the Earth magnetosphere (Sckopke et al. 1983) where both the electron density and magnetic field rose suddenly as the ISEE-1 probe traveled downstream of the Solar wind into the Earth magnetosphere. The majority of energy in the pulsar wind is carried by relativistic particles. The magnetic fields in the pulsar wind could be much smaller than the magnetic field of the companion at the orbital distance. After all, the pulsar's magnetic field is only 1.6 108 G at its 10 km radius surface (Tab. 1). The pulsar wind is almost transparent to the pulsar emission. This is because of the low density and the high Lorenz factor of the wind particles. The wind particles have motion masses far exceeding their rest masses, causing their Faraday rotation effect to be negligible (Quataert & Gruzinov 2000; Wang et al. 2011). When a moderate amount of slow-moving ionized materials from the companion's magnetosphere flow out of the boundary and come to the pulsar wind side, the combination of the extra slow electrons and a reasonably low magnetic field (10 mG) environment leads to the incomplete depolarization and the Faraday rotation. As we mentioned in the previous section, such a condition is rarely met (only be observed in MJD 59214). In most of the ingresses and egresses of this pulsar, the out-flowing electrons are either too dense or too variable and often completely depolarize the pulsar signal. Thompson et al. (1994) predicted that the pulsar wind could contain an oscillating part around the eclipsing edge with an oscillation length of cP/2  500 km, where c is the speed of light and P is the spin period of the pulsar. It should be noted that such reciprocating magnetic fields in the pulsar wind was already illustrated in the model of Phinney et al. (1988). But such field was never observed until now. We 8 International Sun-Earth Explorer 1",
    "between these works and ours is that they assume the buyer is fully strategic and processes fully how their actions today affect the seller's decisions tomorrow (whereas we instead model buyers as no-regret learners). The most related work to ours is in the [BMSW18] model itself. Here we provide a brief summary of the main results in [BMSW18] and their connection to our main results. [BMSW18] studies the one seller one buyer scenario, where the buyer employs a mean-based no-regret algorithm. The authors present three results, each obtained under different assumptions regarding the behavior of the buyers. Firstly (as we have already mentioned earlier in the introduction), [BMSw18] shows that for vanilla mean-based no-regret buyers, [BMSW18] can extract revenue that is an arbitrarily large fraction of the bidder's expected value. Our Theorem 4 extends this result to the multiple buyer setting, overcoming novel technical and conceptual challenges. Second, [BMSw18] designs a novel (not mean-based) learning algorithm against which the optimal mechanism for the seller is simply Myerson's auction in each round. Their proof of this result naturally accommodates multiple buyers. Finally, [BMSW18] shows that if the buyer is clever and mean-based no regret (where they do not overbid their value), then the optimal auction has a clean tractable format (pay-your-bid with declining reserve over time). As we have discussed in the \"No Overbidding\" section of the introduction, our work shows several formal barriers in extending these results to multiple buyers. In summary, our main result extends their first main result to multiple bidders. Their second result already holds for multiple bidders (so there is nothing for us to extend). Our secondary results establish formal barriers to extending their final main result to multiple bidders. Two recent follow-ups have extended the setting in [BMSW18] in a different direction. First [DSS19b] considers the problem of playing a two-player game against a no-regret learner. While technically not an auctions problem, there is thematic overlap with our main result. [DSS19a] extends the single-buyer results in [BMSw18] to be prior-free. Specifically, they show how to design auctions achieving the same guarantees as those in [BMSw18] but where the buyer's values are chosen adversarially. In comparison to these works, ours is the first to extend the model to consider multiple buyers. Finally, recent work of [CHJ20] considers interaction between a learning buyer and a learning seller. Their seller does not have a prior against which to optimize, and instead itself targets a no- regret guarantee. In comparison, our seller (like the seller in all previously cited works) optimizes expected revenue with respect to a prior 2 Preliminaries We consider the same setting as [BMSW18], extended to multiple buyers. Specifically, there are n buyers and T rounds. In each round, there is a single item for sale. Each buyer i has value vi,t for the item during round t, and each vt is drawn from D independently (that is, the buyers are i.i.d., and the rounds are i.i.d. as well). For simplicity of exposition (and to match prior work), we assume D has finite support 0  w1 < w2 < ... < wm  1 and we define qj to be the probability w, is drawn from D. Each round, the seller presents K arms for the buyers. Each arm is labeled with a bid, and we assume that one of the arms is labeled with 0 (to represent a bid of \"don't participate\"). Note that the same set of arms is presented to all buyers, and the same set of arms is presented in each round. In each round t, the seller defines an anonymous auction. Specifically, for all i,t, the seller defines 3",
    "8 MEYER ET AL. but consistent with a model where only the gravitational pared to the model without a gap. Moreover, a central potential of the gas is considered. gap in the gas distribution would be at odds with simula- To investigate the impact of the SMBH on the kine- tions and observations where the central ~ 400 - 500 pc matics of J0109-3047 further, we construct a simple region contains up to ~ 10 times the mass of the BH in \"dispersion-dominated + SMBH' model in QUBEFit. gas (e.g., Lupi et al. 2022; Walter et al. 2022). In this model the velocity dispersion is the sum of In summary, the flat velocity dispersion profile im the SMBH component of Eq. 1 and a constant dis- plies a fat radial mass density profile. The constant dispersion implies that the underlying mass distribution C1I,sMBH(r)? + o2onst). The intensity profile is assumed is not centrally peaked, consistent with the expectations to be exponentially declining as in the constant disper- of the gas mass distribution derived from the far-infrared sion model (see Section 3). We note that any additional continuum emission under standard assumptions. This contribution (besides the central SMBH) to the kine- leaves only few alternatives to explain the absence of a matics as a constant is in agreement with the inferred central peak in the velocity dispersion. One possibility gas mass profile (see Fig. 4). is that the gas mass decreases in the central 200 pc in or In Fig. 5 we show the best-fit dispersion fields for der to compensate the presence of a 0.6  1.1  109 Mo different SMBH masses from 108 Mo to 109 Mo. We black hole and produce a flat mass profile. However, find that the [C 1I] kinematics of J0109-3047 are clearly we have previously excluded the presence of a central incompatible with a ~ 109 Mo SMBH. A full MCMC gap in the [C II]-emitting gas, and the FIR continuum fit of the model to the data yields an upper limit of shows no sign of a central gap either. A decrease in the MsmBH < 6.5108 Mo(2o) (see Appendix A for the full central gas mass would imply fine-tuning of the physical posterior distribution of the model parameters). How- properties of the ISM at the center of J0109-3047 (to ever, even for the maximum-likelihood model (MH = 'offset' the mass of the SMBH). If such a conspiracy is 2.4  108 Mo), the BIC is slightly higher than for a excluded, the black hole mass is either smaller than ex- model without a black hole (BIC = 5.2), showing that pected, as discussed in this section, or the black hole is any SMBH contribution to the dispersion velocity field not located at the center of the galaxy as traced by the is disfavored by the observations. dust continuum, as discussed in the next section. One way to alleviate the tension with the rest-frame If confirmed, and applicable to the larger population UV mass measurement could be to change the radial of z > 6 luminous quasars, a mass of ~ 10&Mo for the [C II]-emitting gas profile. By definition, the observed SMBH in J0109-3047 would have several interesting im- [C II] kinematics are a luminosity-weighted, beam plications for early SMBH growth and formation. First, convolved realisation of the intrinsic kinematics. Fol- it would alleviate the need for massive seeds and/or su- lowing Eq. 1, the velocity dispersion increases exponen- per-Eddington accretion events at z > 7 (e.g., Banados tially close to the black hole, and due to the exponential et al. 2018; Wang et al. 2021; Volonteri et al. 2021). intensity profile, these inner regions will contribute more Second, a SMBH mass of 10 M for a total galaxy (dy- to the beam-convolved velocity dispersion measurement namical) mass of 2.34  1010 Mo (see Section 4) would in the center. As a result, the observed velocity disper- place it on the local relation, meaning that J0109-3047 sion could be reduced, if the [C II] intensity profile is is not part of an overmassive SMBH population at z > 6 not increasing close to the black hole (for example due (Pensabene et al. 2020; Neeleman et al. 2021), and the to feedback). offset from the local relation seen in the z > 6 luminous To address this further, we have used a toy model quasar sample could be due to systematic overestima- where the gas density profile follows an exponentially tion of black hole masses. Third, the accreting BH at declining profile with a central gap where the [C II] the heart of J0109-3047 would be definitive evidence for emission is null. As in the fiducial model, the veloc- super-Eddington accretion at z > 6 with an Eddington ity dispersion is composed of the SMBH component and ratio AEdd  5. a constant. We use this simple model to calculate the size of the central gap necessary to \"hide' the SMBH 6. AN OFFSET OR RECOILING SMBH AT impact on the [C II] kinematics tracer. We find that. REDSHIFT Z=6.79? for a SMBH with a fixed mass MBH = 1.1  10Mo, the The previous section relied on the assumption that best-fit central gap is constrained to be r < 22 pc (2o) to the black hole is located at the center of the host FIR reproduce the [C II] profile and kinematics. The best-fit continuum emission. However, if the accreting SMBH is formally ruled out with an increased BIC = 10.42 com- not located at the center of the host galaxy, the [C II] kinematics are not expected to be strongly influenced",
    "KIRILLOV STRUCTURES AND REDUCTION OF HAMILTONIAN SYSTEMS BY SCALING AND STANDARD SYMMETRIES 21 The particular case of a Lie group. In what follows, we will show the previous reduction process in the particular case when the initial manifold Q is a Lie group G. In such a case, one may use the left. trivialization of the cotangent bundle T*G in order to identify T*G with the product manifold G  g*, where (g, [, lg) is the Lie algebra of G, in such a way that the canonical projection tg : T*G -> G is just the first projection p1 : G  g* -> G. The left action  : G  G -> G on G is the one defined by the group operation of G. We take the left invariant vector field Y =  on G induced by an element  of g. In the first reduction with the cotangent lift of , the reduced space is (T*G - 0g)/G  g* - {0} and the reduced function induced by Y is the restriction to g*  {0} of the linear map gl associated. with & E g, i.e. g*-{0}->Ra=a On the other hand, the Lie-Poisson bracket {, }g* on (T*G - 0g)/G  g*  {0} is characterized by {S1,2}g*=-[1,2] for all 1, 2 E g. The scaling symmetry on g* - {0} is just (40) GR-{0})g*-{0})>g*-{0}) ssx Now, we apply the second reduction step to the (Lie)-Poisson Hamiltonian system (g*--{0}, {, }g*, ). with respect to the scaling symmetry $G. In this case, the reduced space is the projective space Pg*. The corresponding line bundle  : L := (g* - {0}  R)/(R - {0}) -> Pg* is defined by the action G: (IR-{0}) ((g*-{0})  IR)>(g*-{0}) R, $x,t=sa, The section of the dual line bundle L* : L* -> Pg* associated with the linear map l : g* -{0} -> R is hg(p(a))([(a,t)]) = ta(), with [(a,t)] E L, where p : (g*  0) > Pg* is the quotient projection. The Kirillov bracket on the projective space Pg* is characterized by. [hg1,hg2]Pg(p(x))((a,t)]) =-h{cf,s};(p(x))(a,t)]) =-t{Sf,S2}g() =ta([1,2]g) = h[s1,2](p(a))([(,t)]) This structure on the line bundle L -> Pg* may be considered as the Kirillov version of the Lie- Poisson structure on g* and for this reason we will use the terminology the Lie-Kirillov structure on Pg* The reduced dynamics is determined by the p-projection of the Lie-Poisson Hamiltonian vector field associated with the linear function g' e C(g*  {0}), that is, locally characterized by (22). 5. REDUCTION OF SYMPLECTIC HAMILTONIAN SYSTEMS USING FIRST THE SCALING SYMMETRY AND THEN THE STANDARD SYMMETRIES As in the previous section, we have a symplectic Hamiltonian system (S,w, H) with a scaling symmetry $S : R*  S -> S and a symplectic G-symmetry $ : G  S -> S which are compatible. In what follows we describe the reduction process of the system (S,w, H) in two steps, but in the following order: the first reduction is obtained. by a scaling symmetry and the second step is done using the standard symmetry. First of all, we will show a reduction process for Kirillov structures in the presence of a standard symmetry.",
    "Models Data Success Diff. CC-Net [28] 2.4M 32.0% WebN-T5-XL [24] 12K 48.4% LongT5-Base 53.8% 0.0 LongT5-Large 12K 56.3% 0.0 LongT5-XL 60.4% 0.0  Flan-LongT5-Base 54.1% +0.3 Flan-LongT5-Large 12K 56.1% -0.2 Flan-LongT5-XL 61.1% +0.7 HTML-T5-Base (ours) 57.0% +3.2 HTML-T5-Large (ours) 12K 60.8% +4.5 HTML-T5-XL (ours) 63.3% +2.9 Flan-T5-XL [19] 75.5% Flan-T5-XXL [19] 347K 79.0% HTML-T5-XL (ours) 347K 79.4% Table 4: Average success rate of MiniWoB++ with 56 tasks. We use 12K demonstrations [42], and compare HTML-T5 among supervised-finetuned baselines [24, 28]. HTML-T5-XL remarkably outperforms WebN-T5- XL, the prior best method, by 14.9%, and HTML-denoising improves the success rate better than instruction tuning. We also finetune HTML-T5 with 347K expert traces [19], which performs better than Flan-T5-XXL (11B parameters) even with 3B parameters. See Appendix H for the detailed results. community filtered by Tutorial tag on social media web- site?), and acts via planning, summarizing by HTML-T5, and then programming by Flan-U-PaLM. See Appendix C for the example workflow. We finetune HTML-T5 with traces that are collected using scripted agents by procedu- rally generating instructions from human curated templates. This results in 260 episodes on real estate website and 230 episodes on social media website (about 20/10 steps per episode respectively). We prepare 20 different natural language instructions, and measure the success rate and score for the evaluation. The score represents the percentage of required attributes covered during the episode [81]; for instance (1) apartments for (2) corporate housing with (3 studio bedroom and (4 1+ bathroom located in (5) oroville, ca. When the agents could search the housing satisfying (1), (2), (5) and not (3), (4), the score would be 60 (= 100  3/5). When the agents could achieve 100 score, that episode would mark as success. Results For comparison, we prepare three baselines, con- sisting of partial plug-in language models and a single LLM prompting different examplers per role: WebAgent replacing closed-loop planning from HTML-T5 with few- shot open-loop planning from Flan-U-PaLM (Plan: ), replacing HTML summarization from HTML-T5 with regular-expression-based retrieval (Sum: ), and both of them (Plan: X, Sum: ). Table 2 shows that WebAgent with HTML-T5 for planning and summarization (Plan: /, Sum: ) achieves best 65% success and 87.6 score on real-estate and 70% success and 85.8 score on social-media, significantly outperforming single LLM (Plan: , Sum: ), that with open-loop planning (Plan: ), and that with regular-expression retrieval (Sum: ) (most of those roughly achieve only 10 - 20% success). This result suggests that closed-loop planning grounded on HTML observations via finetuning of domain language models is much more suitable for open-ended web navigation than open-loop planning with few-shot LLMs, which is remarkable in real-estate (even Sum:  achieves 50% success), where the longer planning horizon is needed to fulfill instructions. We guess enhancing the planning ability to decompose the given instructions adaptively and robustly can help further improve WebAgent.",
    "26 ZHUCHAO JI, JUNYI XIE, AND GENG-RUI ZHANG [JX23b] Zhuchao Ji and Junyi Xie. Homoclinic orbits, multiplier spectrum and rigidity the orems in complex dynamics. Forum Math. Pi, 11:Paper No. e11, 37, 2023.. [Lev14] A. Levy. Aim workshop postcritically finite maps in complex and arithmetic dy- namics. 2014. [McM87] Curt McMullen. Families of rational maps and iterative root-finding algorithms. Ann. of Math. (2), 125(3):467-493, 1987. [Mil06] John Milnor. On Lattes maps. Dynamics on the Riemann Sphere: A Bodil Branner Festschrift, page 9, 2006. [MS14] Alice Medvedev and Thomas Scanlon. Invariant varieties for polynomial dynamical systems. Ann. of Math. (2), 179(1):81-177, 2014. [Nar04] Wladyst aw Narkiewicz. Elementary and analytic theory of algebraic numbers. Springer Monographs in Mathematics. Springer-Verlag, Berlin, third edition, 2004. [Pak23] Fedor Pakovich. Invariant curves for endomorphisms of P1  P1. Math. Ann., 385(1- 2):259-307, 2023. [Poo17] Bjorn Poonen. Rational points on varieties, volume 186 of Graduate Studies in Mathematics. American Mathematical Society, Providence, RI, 2017.. [Si198] Joseph H. Silverman. The space of rational maps on P1. Duke Math. J., 94(1):41-77, 1998. [Si107] Joseph H. Silverman. The arithmetic of dynamical systems, volume 241 of Graduate Texts in Mathematics. Springer-Verlag, New York, 2007.. [Sil12] Joseph H. Silverman. Moduli spaces and arithmetic dynamics, volume 30 of CRM Monograph Series. American Mathematical Society, Providence, RI, 2012. [Tuc14] T. Tucker. Problem 6 in the problem list of the aim workshop postcritically finite maps in complex and arithmetic dynamics, 2014. [Xie17] Junyi Xie. The existence of Zariski dense orbits for polynomial endomorphisms of. the affine plane. Compos. Math., 153(8):1658-1672, 2017. [Xie22] Junyi Xie. The existence of Zariski dense orbits for endomorphisms of projective. surfaces (with an appendix in collaboration with T. Tucker). J. Amer. Math. Soc., 2022. published online. [Xie23] Junyi Xie. Remarks on algebraic dynamics in positive characteristic. J. Reine Angew. Math., 797:117-153, 2023.. [XY23] Junyi Xie and Xinyi Yuan. Partial heights and the geometric Bombieri-Lang con- jecture. arXiv:2305.14789, 2023. [Yua08] Xinyi Yuan. Big line bundles over arithmetic varieties. Invent. Math., 173(3):603 649, 2008. [Zdu14] Anna Zdunik. Characteristic exponents of rational functions. Bulletin of the Polish Academy of Sciences. Mathematics, 62(3), 2014. [Zha95] Shou-Wu Zhang. Small points and adelic metrics. J. Algebraic Geom., 4(2):281-300, 1995. [Zha98] Shou-Wu Zhang. Equidistribution of small points on abelian varieties. Ann.of Math (2), 147(1998), 147:159-165, 1998. INSTITUTE FOR THEORETICAL SCIENCES, WESTLAKE UNIVERSITY, HANGZHOU 31OO30, CHINA Email address: jizhuchao@westlake.edu. cn. BEIJING INTERNATIONAL CENTER FOR MATHEMATICAL RESEARCH, PEKING UNIVERSITY,S BEIJING 100871, CHINA Email address: xiejunyi@bicmr.pku.edu.cn SCHOOL OF MATHEMATICAL SCIENCES, PEKING UNIVERSITY, BEIJING 1OO871, CHINA Email address: grzhang@stu.pku.edu.cn",
    "some additional components are added to the matter distribution due to which the number of unknowns grow that make more challenging to solve the Einstein field equations analytically. In this regard, such analytical solutions developed via gravitational decoupling (GD) with minimal geometric deformation (MGD) method in both cosmology. and astrophysics [21, 22].  Multiple methods studied to investigate important properties of self-gravitating objects, including the phenomenon of stability and hydrodynamic equilibrium, the upper limit of the mass-to-radius ratio, the upper limit of superficial redshift, and dynamics of matter content under energy conditions, etc. [23]. One of these techniques is MGD approach, which was initially intended as an optional means of deforming Schwarzschild space-time in framework of the Randall-Sundrum braneworld [24, 25]. Recently, there is a lot of interest in developing novel analytic and an anisotropic solutions for Einstein field equations, which is a difficult task as Einstein field equations are non-linear and difficult to handle. In this way, the method of MGD to gain new models representing relativistic objects with well-determined characteristics have been proposed [26]. For a compact spherical distribution, the analytical solution of an anisotropic fluid as well as the braneworld model of Tolman IV solution have been found [27]. Two essential components are required in which first one is dimensionless coupling constant \" to incorporate an extra source into the stress-energy tensor of seed solution. Second one is MGD method on the metric potentials (often on the radial component of metric) in the context of braneworld model. If the seed solution is assumed to be anisotropic, the inclusion of this additional component combined with a static and spherically-symmetric system gives rise to a complex simultaneous equations. The MGD technique separates Einstein field equations into two systems, namely the \"Einstein system\" and \"quasi-Einstein system\", which in comparison to the original system are easy to solve. At this point, a few observations are appropriate, firstly, the decoupled systems satisfy Bianchi Identities and secondly, the extra source may be a scalar, vector, or tensor field [28-32]. Moreover, a number of interesting results on the solutions of black hole with 2+1 and 3+1 decomposition obtained in [33-36]. Additionally, the solutions of new hairy black hole have just been explored [37], and a mechanism is created as well to turn any non-rotational black hole into a rotational one [38, 39]. When weak gravitational forces are at work, the hypothesis in GR has effectively aligned with many tests carried. out within the solar system, demonstrating its success in cosmology. To get more accurate and dependable results, These changes may be very important in explaining the phenomena of accelerated expansion. These modifications are termed as modified theories (see, for instance 40-47) Many modified theories of gravity [48-52] are taken into account by changing the Einstein-Hilbert action that is frequently used to study both the existence of dark energy and dark matter as well as the mystery of universe rapid establish novel junction condition [53]. Several researchers are interested to explore the gravitational collapse phenomena because it is a prominent case in a strong-field regime [54-56]. Jordan [57] developed a full gravitational theory which gave the title of a gravitational scalar field to gravitational constant. Brans and Dicke [58] developed a scalar-tensor field theory named as the Brans- Dicke (BD) theory obtained by substituting a time modifying constant G(t) and with the help of a scalar field () having interaction along with the geometry. Additionally, the well-known scalar field coupling constant or parameter (wBD) of the BD theory is a constant that can be adjusted to get the desired outcomes in Jordan frame. It is assumed geodesics according to the BD theory, they consequently obey the weak equivalence principle, which states that the gravitational mass and inertial mass are equivalent. Mach principle, agreement with the weak equivalence principle, and Dirac's large number hypothesis are the main ingredients of the BD theory. This theory includes a metric tensor and a scalar field that describes gravity.. The large value of  describes the fast expansion of the universe, is found by recent study in cosmology, including the redshift and distance-luminosity connection of type Ia Supernovae [59]. The evidence for various cosmic concerns, including the late behavior of the universe, cosmic acceleration, and the inflation issue, etc are also supported by the BD theory [60]. This theory has drawn interest in recent years due to its precision in describing early inflationary era and late time expansion of the cosmos. Several authors studied the Friedmann-Lemaitre-Robertson-Walker model in the context of the BD theory [61-63]. The main purpose of this work is to extend [64] in the BD theory. The paper is organized as follows. The appropriate. BD theory for the GD formalism is discussed in Sec. II. In Sec. III, the MGD technique to a spherically symmetric geometry filled with two sources in the BD theory is introduced. In Sec. IV, junction conditions are established to match an outside Schwarzschild line element with the inside solution. In Sec. V, we studied mathematical and physical solutions to the modified field equations using the MGD method with constraints apply to matter density and radial pressure for anisotropy in the setting of the BD theory. In Sec. VI, the physical characteristics of an anisotropic stellar structure with the help of polytropic equation of state are provided. The main results are summarized in Sec. VII.",
    "Adaptive Low Rank Adaptation of Segment Anything to Salient Object Detection Ruikai Cui, Siyuan He, and Shi Qiu Australian National University {ruikai.cui, siyuan.he, shi.qiu}@anu.edu.au Abstract. Foundation models, such as OpenAI's GPT-3 and GPT-4, Meta's LLaMA and Google's PaLM2, have revolutionized the field of artificial intelli- gence. A notable paradigm shift has been the advent of the Segment Anything Model (SAM), which has exhibited a remarkable capability to segment real-world objects, trained on 1 billion masks and 11 mil- lacks the intrinsic ability to detect salient objects, resulting in subopti- mal performance in this domain. To address this challenge, we present the Segment Salient Object Model (SSOM), an innovative approach that adaptively fine-tunes SAM for salient object detection by harnessing the low-rank structure inherent in deep learning. Comprehensive qualita- tive and quantitative evaluations across five challenging RGB benchmark datasets demonstrate the superior performance of our approach, surpass- ing state-of-the-art methods. Keywords: salient object detection - large-scale pre-trained models . parameter-efficient fine-tuning.. 1 Introduction Foundation models [3, 14, 23] have received significant interests in recent years, owing to their exceptional performance across a multitude of diverse tasks These models typically consume billions of parameters, trained on expansive web-scaled datasets for fundamental tasks such as next token prediction [6] or masked re- gion completion [7]. A particularly compelling instance of these models is the Segment-Anything Model (SAM) [14], which has been trained on an unprece- dentedly vast dataset comprising 11 million images and 1 billion masks. Despite the Segment-Anything Model's (SAM) noteworthy proficiency in generating masks to segment real-world objects, it is deficient in the detec- tion of salient objects. This shortcoming leads to suboptimal performance in isolating a single salient object from a given RGB image, a crucial aspect of computer vision that emphasizes the identification of the most visually striking or attention-demanding object within an image. Traditional approaches for harnessing the capabilities of foundation models for downstream tasks generally include fine-tuning the entire model [11] or inte- grating additional adapter layers [9]. However, most foundation models possess",
    "TABLE III TRAINING DETAILS FOR TASK-AGNOSTIC LANGUAGE MODELS. FOR EACH MODEL, WE LIST HARDWARE DETAILS, TRAINING TIME IN hOUTS AND ESTIMATED ENERGY CONSUMPTION IN k:W/ h, IF THE INFORMATION IS AVAILABLE. Approach Year Language Hardware Time in hours kWh BLOOM [13] 2022 Java, PHP, C++, Python, JavaScript, C#, Ruby, Lua, server: 384 NVIDIA A100 GPUs, 80 GB 1,082,990 433,196 TypeScript, GO, C, Scala, Rust Prophetnet-x [91] 2021 Go, Java,JS,Php,Python, Ruby NVIDIA Tesla V100 GPUs 30,000 15,330 CodeBERT [92] 2020Python, Java, JavaScript, PHP, Ruby, Go server: 16 NVIDIA Tesla V100 GPUs, 32 GB 1,320 10,610 Dobf [93] 2021 Java, Python 32 NVIDIA V100 GPUs 192 3,080 Codet5 [94] 2021 Ruby, JavaScript, Go, Python, Java, Php, C, C# server/cluster: 16 NVIDIA A100 GPUs, 40 GB 288 1,930 PLBART [95] 2021 Java, Python 8 NVIDIA RTX 2080 Ti GPUs 276 925 Mastropaolo et al. [96] 2021 Java Google Cloud, Colab: 8 TPUs, 35.5 GB memory 343 766 Graphcodebert [97] Ruby,JS,Go,Python, Java, PHP 83 667 2021 rver: 32 NVIDIA Tesla V100 GPUs, 32 GB CodeTrans [98] 2,088 GREAT [99] 2022 Python 1 Tesla P100 GPU Javabert [100] 2021 Java 3 NVIDIA Titan X GPUs, 12 GB code2vec [101] 2019 Java 1 NVIDIA Tesla K80 GPU 336 18 OpenVocabCodeNLM [102] 2020Java, Python, C GPUs GraphCode2Vec [103] 2022 J Java server: 40 CPUs@2.20GHz, 256GB; 1 NVIDIA Tesla V100 GPU Spt-code [104] Java, Python, JavaScript, PHP, GO, Ruby 4 NIVDIA A100s9 GPUs StructCoder [8] Java, Python, PHP, JavaScript 4 RTX 8000 GPUs, 48GB Codex [10] 2021 Python Azure Cotext [105] 2021 Python, Java, JavaScript, PHP, Ruby, Go 1 TPU v2-8 CuBERT [106] 2020 Python TPU TSSA [107] 2020 Java 1 NVIDIA P100 GPU, 16 GB; 1 K80 GPU, 16GB memory CodeGPT [108] 2021 Python, Java ContraCode [109] 2021 JavaScript CodeTransformer [110] 2021Python, JavaScript, Ruby, GO DAMP [111] 2020Java,C# Obfuscated Code2Vec [112] 2020 Java code2seq [113] 2019Java, C# ten publications were applied to more than one language: steps can also require considerable amounts of time and six publications considered two programming languages, one compute resources, ranging from 5-12 days [73, 78, 81]. publication considered three languages, and three publications The majority of task-specific publications provided access considered four languages. This results in an average of 1.33 to the full trained models, some of which one needs to request programming languages considered per publication. access to [51, 76]. Moreover, there are approaches shared as In addition to programming languages considered, we col- online tools [44, 49, 86] or IDE extensions [47, 48, 83, 85]. lect training details, such as hardware used and training time There are also 12 out of 52 publications that did not share the for each publication. However, those are not always provided. full model, but trained embedding files, which are used by the There are 22 out of 52 publications without hardware details model. These are marked in Table II with the ' symbol. (42%) and 26 out of 52 without training time (50%), 33% V. TASK-AGNOSTIC CODE MODELS shared neither information (17 out of 52 publications). The This section presents task-agnostic code models which share training time of 26 publications with such details ranges from means of representing source code as embeddings, for a variety two hours or less [41, 55, 78, 79, 85] to hundreds of hours [47, 53]. While it is common to perform training on GPUs, there of downstream tasks. These models are able to transform code are four publications that did not use any GPU for their snippets to embeddings, which can be fine-tuned to SE tasks. For example, Lu et al. [108] provided fine-tuning details for the training procedure, published from 2015-2019 [41, 53, 77, 86]. CodeXGLUE benchmark, with information for task-specific Commonly, publications used a single GPU for training [39, training and inference time for each task.? The fine-tuning 40, 43, 44, 49, 55, 63, 68, 75, 78-80, 87, 88], sometimes in time ranges from 2 GPU hours (defect detection) to 60 hours combination with CPUs. The highest amount of GPUs have been used by Svyatkovskiy et al. [47]. They utilized 5 Lambda (text-to-code generation, documentation translation). V100 boxes, with 16 V100 GPUs each, resulting in 80 GPUs. In total, we collected 27 task-agnostic models, as shown in While we focus on the training procedure and the energy. Table III. For each publication, we list the model name and the programming languages it was trained on. If available, associated with creating and sharing an ML model, we note we list details on hardware configuration and training times. the application of such models can vary highly for different Among the 27 publications, 52% did not provide training time SE tasks. Usually, the reported tested times are lower than details (14 out of 27) and 26% did not provide their hardware the required training time (e.g., more than 100 times quicker configurations (7 out of 27).For publications without hardware than training [40, 75, 76]), but in particular, program repair details, training time is not reported as well.. experiments can require long testing times. For example, Chen Among the publications that shared training time details, et al. [55] applied Sequencer for 130 hours to find patches for the shortest duration is found for code2vec [101], which was 75 bugs. White et al. [56] applied their program repair tool DeepRepair for 2,616 days. Data extraction and preparation 3 https://microsoft.github.io/CodeXGLUE/ 6",
    "For the fourth property we need to find a value for  such that |Opt(G) - |IF|l  3|Opt(Tg,TQ) - |F||. Let l = |IF| be the number of Ay in F\" that are covered by 6 Opt(TG,TG) -|F|| =|F|-Opt(TG,TG) |F\"I- Opt(TG,TG) =12n-l-Opt(TG,TG) =12n-l-(12n-k) =k-l =|Opt(G) -|IF| So we pick  = 1 and we are done. 5 A tight 7k kernel Recall the definitions of common subtrees and common chains from the preliminaries. It is well-known that the following two polynomial-time reduction rules do not alter the size of the uMAF [2]: Subtree reduction. If T and T' have a maximal common pendant subtree S with at least two leaves, then reduce T and T' to Tr and T', respectively, by replacing S with a single leaf with a new label. Chain reduction. If T and T' have a maximal common n-chain C = (l1, l2,..., ln) with n  4, then reduce T and T' to T, = T|X\\{l4, l5,..., ln} and T = T|X\\{l4, l5,..., ln}, respectively When applied to exhaustion on two unrooted binary trees, at which point we say the trees are fully reduced, these rules yield an instance with (ignoring additive terms) at most 15k taxa [10], where k is the size of the uMAF3, and the analysis is tight. Note that applying the subtree or chain reduction to a caterpillar produces a new cater- pillar. In this section we will show that, when applied to exhaustion on two caterpillars, a much smaller kernel is obtained than on general unrooted binary trees. Theorem 4. There is a 7k kernel for uMAF on caterpillars using only the common chain and subtree reductions, and this is tight up to a constant additive term. 3The kernel bound given in [10] is in terms of TBR distance, rather than uMAF, but as noted earlier these quantities only differ by 1, so only additive terms are affected. 13",
    "all pi's are integers and B = 4ac*. We can compute min(hzo(x), B) exactly using standard dynamic programming in O(|Z| : B) = O() time. The complexity of the resulting function is O(Zl) = O() In O(n + ) time, we can compute a function fzg that approximates min(frg, s/2) with a factor of 1 + O() via Lemma 7. The additive error caused by frg is at most O(e. 3/)  O() as a  a1/2, and the complexity of fro is O(). Lemma 13. Let fr9 and fr be two functions that approximate max(fr,p() - 43/2) and fo  fr with additive error O() and complexity O(1) in O() time. Proof. Let u = max(0,p() - 4%). Note that fzo have a range contained in [u,p()], so frg - u + 1 have a range contained in [1, 43/2 + 1]. Since fzg  frg = (fz-u+1)  frg) + u-1 To approximate fo  fzo, it suffices to approximate (fzo - u + 1)  fzo with an additive error of O(). Both (fzo - u + 1) and fzg have ranges contained in {0} U [1, 43/2 + 1], therefore, the approximation factor we are allowed to incur is 1 + O(c/2). We can approximate the two functions via Lemma 4 using O( + &) = O() time. The complexity of the resulting function is O(i%) < O(1). Lemma 14. Let g be a function that approximates max(f,p() - 43/2)  min(fg, a3/2) with additive error O() and complexity O(). We can approrimate g  fr9 with additive error O(a) and complexity O() in O() time. Proof. The items in Z have at most O(8) = O(-1/2) distinct profits. By dividing L into groups by profits, and merging the functions for the groups via Lemma 5(ii), we can compute a function fzo that approximates fzo with factor 1 + O(e) and complexity O() in time O((L2| + )  O(n + ) time. The additive error of fz is at most O(e) - fzg(t) < O(a). Merging g and fr, via Lemma 4(i) takes O() time. Lemma 15. In O(n + ) time, we can compute a function with complexity O() that approx- Proof. Computing fzo that approximates max(fr9,p() - 4/2) via Lemma 12 takes O() time. Computing fz9 that approximates min(fg, 43/2) via Lemma 7 takes O(n + ) time. Computing a function g that approximates f1,  fo via Lemma 13 takes O() time. Finally, by O(), and the total running time is 1.a2 +u)0>( 11",
    "Many of the earlier mathematical works on rcsps focused on determining their satisfiability thresholds and verifying the sharpness of sAT-uNsAT transitions. For models that are known not to exhibit RsB, such goals were established. These models include random 2-sAT [CR92,BBC+01], random 1-IN-k-sAT [ACIM01], k-xOR-sAT [DM02, DGM+10, PS16], and random linear equations [ACOGM20]. On the other hand, for the models which are predicted to belong to 1Rsb class, intensive studies have been conducted to estimate their satisfiability threshold, as shown in [KKKS98, AP04, COP16] (random k-sAT), [AM06, COZ12, COP12] (random k-NAE-SAT), and [AN05, CO13, COV13, COEH16] (random graph coloring). More recently, the satisfiability thresholds for rcsps that exhibits Rsb have been rigorously determined for several models, namely the random regular k-NAE-sAT [DSS16b], maximum independent set on d-regular determining the location of q-colorability threshold for the sparse Erdos Renyi graph is left open, the con- densation threshold acond for random graph coloring, where the free energy becomes non-analytic, was settled in [BCOH+16]. They carried out a technically challenging analysis based on a clever \"planting\" technique where the results were further generalized to other models in [COKPz18]. Similarly, [BCO16] identified the condensation threshold for random regular k-sAT, where each variable appears d/2-times positive and d/2-times negative. Further, in the condensation regime a E (acond, Qsat), many quantities of interest was established for random regular k-NAE-sAT with large enough k, matching the statistical physics prediction. Namely, the number of solutions at exponential scale (free energy) [Ssz22], the concentration of the over lap [NSs20, NSS21], and the local weak limit [SS23] were established. Establishing the same quantities for other models in the condensation regime is left open. The closest result to ours in the literature is by Ayre, Coja-Oghlan, and Greenhill [ACOG22], where they lower bound the chromatic number (or equivalently, upper bound the colorability threshold) of the random regular graph of any degree, which is conjectured to be tight. [ACOG22] also considers the sparse Erdos Renyi graph, which is more complicated since the conjectured chromatic number is defined in terms of a distributional (rather than real-valued) optimization due to the randomness of the local neighborhoods. In this work, we do not consider Erdos Renyi type problems, but we additionally address the question of the uniqueness of the BP fixed point for any k  3 (unique solution to the equation (1.1)). As in [ACOG22]. we use an interpolation bound, which gives an upper bound of the satisfiability threshold also for the (non- regular) random k-NAE-sAT model. It would be interesting to address the uniqueness of the BP fixed point for random k-NAE-SAT and random k-sat for small k  3. We refer to [ST03, MRSY19, YP22, GP23] which addresses the uniqueness of Bp fixed point for various models.. 1.2Proof methods We aim to rigorously establish the upper bound the satisfiability threshold predicted by the so-called '1RsB cavity method' from statistical physics [DRz08]. To do so, instead of using moment methods, we use a technique called interpolation method' from the theory of spin glasses developed by [FL03, Gue03, PT04]. The interpolation method has been successful in upperbounding the satisfiability threshold for random k- SAT [DSS15] for large k, the free energy for random regular k-NAE-SAT [SSZ16], and the colorability threshold for random graphs [ACOG22]. We first introduce the notations and mathematical framework that we use throughout the paper. For both the d-regular k-uniform hypergraphs and the k-NAE-sAT formula, we can represent them as (labelled) (d, k)-regular bipartite graph. Let V = {v1,..., Un} be the set of variables or nodes and F = {a1,..., am} be the set of clauses or hyperedges. An edge is formed if the variable or node v, is included in the clause or hyperedge a;. For an edge e, we denote v(e) (resp. a(e)) by the variable (resp. clause) adjacent to it. Denote G = (V, F, E) by the resulting bipartite graph. We denote the neighborhood of v E V (resp.  = m = d. For the NAE-sAT formula, there is an extra label for each edge e E E, namely the literal Le E {0, 1}, which specifies how the variable v(e) participates in the clause a(e). Then, the labelled graph G = (V, F, E, L) = (V, F, E, (Le)eEE) represents a NAE-SAT instance. Definition 1.3. Given a NAE-SAT instance G = (V, F, E,L), x E {0, 1}V is a (NAE-SAT) solution if II g((xv(e)  Le)eE8a) = 1, EF 4",
    "2 Elliot M. Lynch and Guillaume Laibe expanding box like model valid for both radially and tempo- Global Model Local Model rally varying spherical fows. The generalisation of the ex-. LH panding box model to radially varying flows was done in X [x,y Tenerani & Velli (2017). The generalisation to background fows which are also time dependant, motivated by the stellar formation problem, results in a model close to the acceler- ated expanding box (although our treatment of pressure will be closer to the distorted shearing box models of Ogilvie & Latter (2013); Ogilvie & Barker (2014)). We shall focus, in this paper, on the hydrodynamic case as it posses a number of important features that are worth understanding before generalising to MHD. In Section 2 we present the derivation of our local model. Sections 2.4 and 2.5 derives symmetries and con- servation laws of the local model. Section 3 presents some Figure 1. Geometry of the domain. Globally (left) the domain nonlinear solutions to the local model - and discuss how these relate to the global problem. In Section 4 we derive is bounded by radial shells which can approach or recede from each other depending on the gradients in the background veloc- the linear theory of our local model. We discuss possible ity. Points within the domain move in the radial direction due extension of our model in Section 5. We present our con- to the spherically symmetric background fow. The local model clusions in Section 6 and additional mathematical details (right) is a rectangular domain where the horizontal coordinates (including alternative formulations which maybe more con- are equivalent to the latitude/longitude on the sphere and the venient for implementation in hydrocodes) are presented in vertical direction moves between spherical shells comoving with the appendices. the background flow. The aspect ratio of this local box changes. as the distance between the spherical shells varies. 2 DERIVATION 2.1 Global geometry Du+  de+ (6) To derive a local model for spherical collapse/expansion con- Du$ + Ru$=-R- (7) sider a local neighbourhood of a point, o, located on the equator of a sphere of radius R. The line element of the DuR-Ru$u$-Ruu=- R+=ORP (8) usual spherical polar coordinate system is Dp =-pR-20i(R2u'), (9) ds2=dR2+R2do2+sin0d (1) where the Lagrangian derivative is. We are interested in describing the local dynamics near to p occurring on a horizontal lengthscale LH < R (See Figure !e n + 'e = a 10) 1, which show the relationship between the global and local geometries). Without loss of generality, we can locate our Note, we have listed the R component of the momentum local model on the equator of the sphere (0 = /2) meaning equation last as it will become the z momentum equation in. we can approximate the line element by the local coordinate system. To close this system of equa- ds2 = dR2 + R2(do2 + dg2) +O((LH/R)2d$2), tions we must supplement them with an equation of state (2) determining p, which we assume is barotropic,. which results in metric tensor components, p=pp. (11) 8RR=1, 800=8=R2, (3) and inverse metric tensor components gRR=1, g00=g$$=R-2, (4) 2.2Spherical Collapse/Expansion For the background fluid flow we wish to consider a spher- with all other components zero. The Christoffel Symbols ically symmetric expanding/contracting fluid in a (poten components, for this coordinate system, are. tially time dependant) central potential  = $(t,R). Con- sider a spherically symmetric fuid in this potential with ro=r=-R density po = po(R,t) and purely radial velocity field U' = (5) U(R, t)eR. The density of the fluid then evolves according to TOR=TRo=T$R=FR=R-1, the continuity equation, with all others vanishing. The fluid equations in this coor- dinate system are Dopo = -PoR-2aR(R2U), (12) MNRAS 000, 1-20 (2019)",
    "MM '23, October 29-November 3, 2023, Ottawa, ON, Canada Yuxuan Tan et al.. Table 4: Ablation study on the Synthetic set Difficult Normal Easy Model IoU MCC NMM IoU MCC NMM IoU MCC NMM TAF-separate 0.6239 0.7167 0.2963 0.8738 0.9143 0.7744 0.9490 0.9604 0.9164  MSTAF-separate 0.7712 0.8432 0.5670 0.9210 0.9486 0.8583 0.9693 0.9764 0.9488 TAF 0.8001 0.8586 0.6312 0.9379 0.9605 0.8937 0.9753 0.9811 0.9617 MSTAF 0.8394 0.8918 0.7064 0.9510 0.9700 0.9151 0.9788 0.9838 0.9646 Table 5: Ablation study on the Scale set Model Difficult Normal Easy IoU MCC NMM IoU MCC NMM IoU MCC NMM TAF 0.7009 0.7644 0.4400 0.8789 0.9160 0.7807 0.9704 0.9769 0.9550 MSTAF 0.7427 0.8022 0.5206 0.9105 0.9410 0.8406 0.9752 0.9808 0.9602 KV Stage 1_3 Stage 3_1 Stage 3_6 with unified pipeline design and multi-scale attention mechanism.  presents the best localization performance on all three subsets. PtoP self In [16], they use the Scale set to analyze the model's robustness against scale transformation. To further verify the effectiveness of the multi-scale attention mechanism. We also use Scale set to evalu- D to D ate our models and the result as shown in Tab 5. In the Scale set, the self spliced region is only processed with scale transformation of differ- ent degrees for ablation in [16]. It contains 9000 testing pairs and is equally divided into Difficult, Normal, Easy subsets. In the Difficult subset and Normal subset, there are more samples with larger scale PtoD cross degrees. On the contrary, in the Easy subset, the size of the spliced region between the two images tends to be more consistent. We can see that with the help of multi-scale attention mechanism, MSTAF achieves much better localization performance than TAF on the D to P cross Normal and difficult subset. It demonstrates that MSTAF has an. advantage in dealing with various scale transformation samples. After introducing the multi-scale attention mechanism, MSTAF is Figure 8: Visualization of attention maps. The blue point more robust against scale transformation. The visual comparison represents the token we selected to present attention maps. can refer to Fig. 6 and Fig. 7. Stage i_j represents attention maps from the j Target-Aware Attention modules in stage i.. 5 CONCLUSION In this work, we propose a Multi-scale Target-Aware Framework to simplify the pipeline of existing methods. It adopts self-attention for feature extraction and cross-attention for correlation match- We design a unified pipeline implemented by Target-Aware At- ing simultaneously. This unified design enables feature extraction tention Framework (TAF), which is different from the separate and correlation matching to mutually promote each other, thereby pipeline used by existing methods. In order to evaluate the effec- enhancing the matching performance of the model. We further. tiveness of the unified pipeline, we built a separate pipeline model design a multi-scale attention mechanism to model the matching for comparison. The TAF-separate model adopts the same archi- between image patches of different scales, which further improves tecture as TAF. It implements self-attention for both two heads the robustness against scale transformation. Experiment results. of all Target-Aware Attention modules in the front, while the last demonstrate that our model is robust against scaling and outper- Target-Aware Attention module only implements cross-attention forms state-of-the-art methods. for both two heads. We use the Synthetic dataset to conduct ab. ACKNOWLEDGMENTS lation study, the results are shown in Table 4. By comparing the TAF-separate model and the TAF model, we can see that the TAF This work was supported in part by the Natural Science Foundation with unified pipeline performs better than the separate pipeline of China under Grant 62001304; in part by the Guangdong Basic and After introducing the multi-scale projection mechanism to achieve Applied Basic Research Foundation under Grant 2022A1515010645; multi-scale attention, the MSTAF-separate and MSTAF models both in part by the Foundation for Science and Technology Innovation  showed improvements in localization performance. The MSTAF of Shenzhen under Grant RCBS20210609103708014 and the Key",
    "the geometry of these regions is identical to the Einstein-Rosen bridge in a two-sided BTZ. geometry with the same mass as the corresponding operator. We will take the interpretation that the details of what appears outside the domain of dependence of W is part of the definition of the operator associated to that region. So in sum, the action of the Lorentzian. cap is 1 (6.8) i=BH Hence we see that it is the sum of three contributions that each depend only on one of the three operators. Thus, we can absorb the corresponding phase generated by the action of the Lorentzian geometry into the definition of the operators, and we will arrive at a real result. for the three-point function.. Hence we arrive at the total action for the single-sided geometry. Isingle-sided = Iwormhole + i  f(i) (6.9) Again, it is a nontrivial result that the imaginary term is given by the sum shown above since this allows us to absorb the corresponding phases into the definition of the operators. After eliminating these phases, we recover the three-point function from the single-sided bulk geometry, i.e., e-I ~ GL(z1,Z2,Z3), (6.10) where G1(z1, 22, 23) is the semiclassical Liouville three-point correlator in [17] 7Discussion In this paper we discussed three-dimensional asymptotically AdS3 geometries that are sourced by the insertion of boundary operators whose scaling dimensions is heavy as the central charge of the holographic CFT2. The presence of any such operators deforms the AdS geometry by inducing a non vanishing expectation value for the holographic stress tensor, close to the boundary. This is true perturbatively in general dimensions, but in three-dimensions there is an exact solution, due to Banados [4], that describes such deformation. However, this metric does not describe the full bulk spacetime. When only two black hole operators are inserted,. we showed that the full geometry is simply an infinite covering of the Euclidean BTZ black hole [1], but when three or more operators are inserted, we found that the completion of. the Banados metric into the bulk is a wormhole geometry involving multiple asymptotic boundaries. To understand this rather non trivial fact we rephrased the construction of the bulk geometry as a quotient of AdS realized by domes and doors. The dome construction is a well know characterization of hyperbolic geometries with an asymptotically AdS3 metric, and more familiar from the study of black hole thermodynamics, see e.g., [38], but the addition of the doors is new as far as we can tell.. As in the description of a Euclidean two-point function geometry in section 2, i.e., as empty AdS3 with identifications, the doors are needed to describe the insertion of boundary 29",
    "3.1.3. The case of a general periodic force. Finally, we remark that in the general case of a 0-periodic force of the form (3.20) l=1 A whose real valued Fourier coefficients satisfy t(lFe)2 < +o, the work per- formed by the force can be determined from the formula: (3.21) =1 Therefore its behavior, as n gets large, can be determined from the term by term. analysis of the series appearing on the right hand side of (3.21). 3.2. Energy. As in Section 3.1 we assume that the periodic force F(t) is given by. (3.3). The time average of the expectation of the total energy energy of the chain E(w,n) breaks up into the sum of thermal component Eth(w,n) = reIn((eth)) and the mechanical one Emech(w,n) = xeIn((emech)), with eth and emech defined in (2.17) and (2.16), respectively. Considering the behavior of the thermal energy functional, defined in (2.15), it has been shown in [0], that in the case wo = 0 and y- = /+ we have ((eth)) = (T- + T+) for all x = 1,...,n - 1. If wo > 0 and - = /+, then [0, formulas (38) and (42)] give C ({eth))=(T+T+)(1+0r),where|0x|<- gx^(n+1-x) for some constants C > 0, g > 1 independent of n. As a result we have Eth(w,n) ~ n, as n - +o. 3.2.1. Formula for the total mechanical energy functional for a single mode os-. cillating force. In what follows we consider the behavior of the mechanical com- ponent of the energy. Again, assume that the force is given by (3.3). It turns out, see Section C of the Appendix, that the time average over the period of the microscopic mechanical energy density equals F2 Mx(w,n) (3.22) where D(w,n) is given by (3.5) and Mx(w,n) =G(w,n)?(w+w3)+(V*G%)(w,n)+(2wy-)[9x(w,n)2+(V*Gx)(w,n)2 12",
    "Goldi and Rietsche Recommendation 2Riddle 3Search Feedback .0 You want a movie . <You want the .O &You have a friend Questionnaires chatbot to help  that you want to with this riddle: impress with a sOd NFC-15 S What is taken Dem cool story from from a mine and one of last years shut in a wooden cricket match, case?> which the chatbor should supply to Figure 2: Study 1 procedure. 4.2Study1 Based on the pilot, we decided to proceed by fixing the reported bugs and replacing the usability scale with potential mediators to better assess which users would prefer the different bots. We conducted this study with n=71 participants. (see Section 3). 4.2.1Measures In Study 1, we added 7-level bipolar rating scales for direct comparison (See Section 3.2). We were interested in how chats; and how satisfied they were with them. See Table 2 for items and reliabilities of the constructs. To account for potential mediation, we assessed interindividual difference variables, namely the most prominent shaping expectations, we also assessed our participants need for cognitive closure (NFC-15) [40]. Scale Items  Reliability Which of the two chats.... enabled more personal direction?. Study 1:  = .77, X = .79 (overall), for scenarios Control offered you more autonomy? .77/.79, .84/.85, .91/.91 each; Study 2:  = .81, X = .84 let you steer the conversation more? seemed more authentic?. Study 1:  = .93, X = .93 (overall), for scenarios Naturalness had a more genuine feel? .93/.93, .92/.91, .97/.97 each; Study 2:  = .93,  = .95 was more natural?. had more suitable responses?. Study 1:  = .93, X = .93 (overall), for scenarios Intent-Effectiveness lived up to your expectations better?. .93/.91, .95/.93, .96/.95 each; Study 2:  = .95, X = .96 was more to your liking?. Study 1:  = .95, X = .95 (overall), for scenarios Satisfaction was more satisfactory? .95/.95, .92/.92, .97/.97 each; Study 2:  = .98, X = .97 Table 2: Direct comparison bipolar rating scales with Crohnbach's  and Guttman's X 6. 4.2.2Procedure After a short demographic questionnaire, n=71 participants were given 3 scenarios (see Figure 2), rating each before turning to the next (see Figure 3.2). Having completed all scenarios and evaluations, feedback was elicited and interindividual variables were assessed.. 4.2.3Feedback To quantify the feedback, we repeated the procedure described for the pilot. Feedback on the study was 69.01% positive (neutral opinions tend to be rated as negative as well, e.g. \"I have no opinion about the study.\"), on the interface only 52.11% (negatives include no feedback at all, neutral statements such as \"It was fast and responsive, just feel like the trigger a loading animation that the bot would never reply to, so I had to prompt again, which left the loading anim on the screen for one of the bots but not the other, not a big deal.\" or \"It was frusting when it could not listen or answer all. 6",
    "1. INTRODUCTION The (logarithmic) Mahler measure of a non-zero rational function P e C (x1,...,xn)* is defined by dx1 dxn (1) m(P) =m(P(x1,...,xn)) := gPx1 xn (2i)\" X1 Xn where Tn ={(x1,...,xn) E C*  C*  ..  C* : |x1| =...= |xn| = 1}. The first appearance of this quantity (for one variable polynomials) can be traced back to Lehmer's work [1] on Mersenne numbers, and its several variable form first appeared in the. work of Mahler [2] regarding a simpler proof of the Gel'fond-Mahler inequality, and it was later named after him. In the early 80's, Smyth [3] discovered the following remarkable identities: 33 m(x+y+1) = Lx-3,2 4 7 m(1+x+y+z) where L(x-3,2) is the Dirichlet L-function of the quadratic character X-3 of conductor 3 and ((s) is the Riemann zeta function (for more details see [4]). These are two of the initial. formulas for several variable cases. Later the work of Boyd [5], Deninger [6], Rodriguez-Villeags [7] and others provided us with interesting connections among Mahler measure, higher regulators, and Beilinson's con- jectures. The conjectural formulas to support their work, such as. m(Pk(x,y)) =rkL'(EN(k),0), rk E Qz were eventually proved for certain polynomials, due to Rodriguez-Villegas [7], Rogers and Zudilin [8, 9] et al. Here En() is an elliptic curve of conductor N(k) associated to Pk, and the question mark stands for a numerical formula that is true for at least 20 decimal places. (See the book of Brunault and Zudilin [10] for more details.) In a different direction, Cassaigne and Maillot [11] generalized the formula found by Smyth to m(a + bx + cy) for arbitrary complex constants a, b, and c :  log|a| + log|b| + y1og|c| + D ( if  holds, 2 max+by+c= log max{|a], |b], |c|} if  does not hold. where  stands for the statement that |a], [b], and [c| are the lengths of the sides of a planar triangle, and in that case, a, , and y are the angles opposite to the sides of the lengths. [a], [b] and [c] respectively (see Figure 1). We also remark that the constant coefficient can be replaced by a variable without changing the Mahler measure, in the sense that m(ax + by + c) = m(ax + by + cz). Additionally, it is.",
    "u. However, to make this iteration practical, we need to recall that each application of the filter G requires the inversion of a differential operator. (17) Equation (17) requires to solve a linear system at each iteration n = 0, . .., N- 1. As discussed above, in order to employ the van Cittert AD in a ROM setting, by multiplying (17) by each test function in our ROM space and expanding our prospective solution as a linear combination of ROM basis. functions, we obtain the linear system (18) coefficients of the ROM AD velocity as n=0,...,N-1, 3.3. The Tikhonov AD. The Tikhonov method of approximate deconvolution is defined as uAD = Du = (G*G + I)-'G*u (19) where G* denotes the adjoint of the operator G, and  E R+ is a posi- tive constant; we refer, e.g., to [39, section 3.3.1] for further details on the Tikhonov AD. When plugging in the specific filter from (12) and proceeding formally, we can write. [G*G + I]uAD = G*u, [n*_(Vz8-I)=aVn[Ir+1-(Vz8-I)*-(Vz8-I)] [(I- 82)-1+ (I-82)*]uAD =u, [I + (I-8)(I-8)*]uAD=(I-8)u, [I + (I- 82* - 82+ 8282*)]uAD = (I - 82)u, [I + (I282 + 84)] uAD = (I 82)u. (20) 8",
    "(a) (b) Figure 2: Coded masks for 1D measurement with the small-scale prototype (a) and for 2D measurement with the three-layered PET array (b). to accept a trigger of 40 ns and an integration time of 325 ns to collect photons. on the sensor tile. The overvoltage of the silicon photomultipliers (SiPMs) is set to 3 V. As this is a digital tile it is possible to disable the SPADs which produce a high number of dark counts. This inhibit fraction is set to 10%. The surface of each sensor tile is covered with a glass plate of 1.1 mm. The sensor tiles are connected to a singles processing unit (SPU) which manages their voltage sup- ply and feeds their data to the data acquisition and processing server (DAPS). During the measurement, the tiles are cooled by a 15C liquid cooling system. 2.1.3.Masks We perform measurements in one and two dimensions, i.e., we reconstruct an image along one axis or on a plane. For these two tasks, we use a one- and a two-dimensional versions of a MURA mask of rank 476, clipped to 31  31 central pixels (see Fig. 2). The mask rank as well as the setup geometry have been optimised via Monte Carlo simulations before the experiment. To construct the physical masks we use tungsten rods of 2.26  2.26  20) mm which are inserted into 3D printed rasters made from Pro Grey Resin. The rod manufacturing reaches a precision of 0.1 mm. The resulting masks have a dimension of (73.6  73.6) mm?. The rasters have a total thickness of 13 mm and the holes to insert the rods are 10 mm deep. To prevent the rods from falling out, the assembled masks are wrapped in cling film. 2.2. Radioactive sources For image reconstruction, the experimental data were obtained with a ra-. dioactive 22Na source with an activity of 2.89MBq. The active material in that source covers an area of 1 mm  1 mm. As a +-emitter, 22Na provides two photons of 511 keV emitted back-to-back, which can be used for electronic collimation. For calibration of the detectors we additionally used the 1275 keV gamma line at 662 keV with an activity of 1.73MBq and a 133Ba source with 5",
    "zz0 = cell(1, N); for i = 1 : N-1 zz0(i) = {[initial_position(:, i); initial_position(:, i + 1)]}; end zz0(N) = {[initial_position(:, N); initial_position(:, 1)]}; end Such that the overall problem can be set up with the following function: function [sProb ] = setupSolver(N, sigma) n = 4; d = 2; y = sym('y%d%d', [N n], 'real'); y=y'; [eta, eta_bar] = getEta(N, d, sigma); F = get0bjective(N, y, eta, eta_bar, sigma); H = getInequalityConstr(N, y, eta_bar); AA = getCouplingMatrix(N, n); zz0 = getStartValue(N, sigma); sProb.llbx = cell(1, N); sProb.uubx = cell1, N); fori=1:N sProb.llbx(i) = mat2cell([-inf; -inf; -inf; -inf], 4, 1); sProb.uubx(i) = mat2cell([ inf; inf; inf; inf], 4, 1); end sProb.locFuns.ffi = cell(1, N); sProb.locFuns.hhi = cell(1, N); fori=1:N sProb.locFuns.ffi(i) = {matlabFunction(F(i), 'Vars', {y(:, i)})} ; sProb.locFuns.hhi(i) = {matlabFunction(H(i), 'Vars', {y(:, i)})} ; end sProb.AA = AA; sProb.zz0 = zz0; 12.2.4 Runtime Analysis For the runtime analysis, the idea is to run the sensor network localization problem with varying number of sensors both with a decentral and a central optimization step. To do so, firstly a vector with a number of sensors is needed and secondly a vector with variances. Then, the time needed for the decentral and the central optimization is measured and can be plotted.. N = [5, 10, 15 , 20, 25, 30, 35, 40, 50, 60, 70, 80, 90, 100]; sigma = [0.5, 1, 1.5, 2, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5]; time = zeros(2, length(N)); for i = 1 : length(N) sProb = setupSolver(N(i), sigma(i)); 22",
    "Definition 4.11. We say a spin system  on Zd satisfies the strong spatial mixing (SsM) condition if there exist constants a, y,L > 0 such that for every d-dimensional rectangle A c Zd of side length between L. and 2L and every subset B c A, with any pair (t, t') of boundary configurations on dA that only differ at. a vertex u, we have. llB() - B ()llrv  y  exp(-a  dist(u, B)) where dist(., -) denotes graph distance. The definition above differs from other variants of SSM in the literature (e.g., [DSVWo4, BCSV19,MOS94]) in that A has been restricted to \"regular enough\" rectangles. In particular, our variant of SsM is easier to satisfy than those in [DSVW04,MOS94] but more restricting than the one in [BCSV19] (that only considers squares). Nevertheless, it follows from [CP21,MOS94,Ale98,BDC12] that for the ferromagnetic Ising model, this form of SSM holds up to a critical threshold temperature  < c(2) = ln(1 + 2) on Z2. Corollary 1.9 from the introduction states that for b-marginally bounded monotone spin system on d-dimensional cubes V  Zd, sSM implies that the mixing time of any systematic scan Pg is O(log n). As mentioned there, this result in turn implies that any systematic scan dynamics for the ferromagnetic Ising model is mixing in O(logn) steps on boxes of Z? when  < c(2). Another interesting consequence of Corollary 1.9 is that we obtain O(log n) mixing time for any systematic scan dynamics P for the hardcore model on Z? when  < 2.538, which is the best known condition for ensuring SSM [SSSY17,RST+13]. Our proof of Corollary 1.9 relies on Lemma 4.12 that is restated below. Remarkably, Lemma 4.12 gen- eralizes beyond monotone systems and may be of independent interests. Lemma 4.12. For a spin system on a d-dimensional cube V  Zd, SSM implies n-spectral independence,. where n = O(1). Proof of Corollary 1.9. Assume a monotone spin system satisfies SSM condition. Then the spin system satisfies n-spectral independence, where n = O(1) by Lemma 4.12. By noting that  = 2d the corollary follows from Theorem 4.3. Lastly, we give a proof of Lemma 4.12. For this, we recall the notion of a k-contractive coupling which is known to imply spectral independence. We say a distribution  is k-contractive with respect to a Markov chain P if for all Xo, Yo e Q, there exists a coupling of step of P so that E[d(X1, Yi) |Xo,Yo]  kd(Xo, Yo), where d(, -) denotes the Hamming distance of two configurations. The following lemma from [BCC+22] shows that spectral independence follows from the existence of a contractive coupling with respect to a. heat-bath block dynamics. Lemma 4.13 ([BCC+22]). If  is k-contractive with respect to a block dynamics, then  is (2DM)-spectrally independent, where M is the maximum block size and D is the maximum probability of a vertex being selected. as part of a block in any step of the block dynamics. With this lemma on hand, we can now prove Lemma 4.12. Proof of Lemma 4.12. Let L be a sufficiently large constant so that the SSM condition is satisfied; we will choose L later. Let V be a d-dimensional cube of Zd. We define a heat-bath block dynamics P with respect to a collection B of d-dimensional rectangles in V. Precisely, let Sy := {w e Zd : d(w, u) < L}, and let B be the set of blocks {S n V}vev. Given a configuration Xt, the heat-bath block dynamics P obtains a configuration Xt+1 in 3 steps as follows: 25",
    "AEC and KEP numerical fluxes for compressible Euler equations A PREPRINT The initial conditions for the Taylor-Green vortex are. p(x,y,z) = 1 u(x, y, z) = sin(x) cos(y) cos(z) v(x, y, z) = - cos(x) sin(y) cos(z) w(x,y,z) = 0 cos2x+cos2ycos2x+2-2 p(x,y,z)=10+ 16 with a pressure value corresponding to a Mach number M ~ 0.26. The triperiodic domain has side length 2 in all directions and is discretized using 32  32  32 nodes. The chosen CFL value is sufficiently small that linear invariants are exactly conserved to machine precision for all schemes. The time evolution of the entropy integral for this test is no longer equivalent to Ap-Ap; in this case we have better performances from Ap-He and Gp-Ge when compared to Ap-Ap and Ap-Ae and this result is found for both fourth-order and six-order accurate fluxes. An improvement can be obtained using an additional term in the expansions and KEEP(1) and AEP(1) are the schemes which more closely achieve a constant value for the entropy integral. Information about the reliability of the scheme can be obtained thorough the study of the evolution of thermodynamic fluctuations in time. We checked that for all the schemes tested, the density and temperature fluctuations do not have an unbound growth (not shown). This is the desired behaviour, since for inviscid isotropic homogeneous turbulence they are reported to level off to a constant value [18, 2] 6 Conclusions We proposed a new class of asymptotically entropy-preserving fluxes for the discretization of the convective terms in the compressible Euler equations with interesting properties. It provides a consistent asymptotic approximation of an existing entropy-preserving scheme based on the logarithmic mean, and it consists of economical algebraic fluxes based on the harmonic mean. Moreover, at all orders of approximation, the numerical fluxes have the pressure-equilibrium preservation property. The theoretical predictions are confirmed on two test cases, verifying that the new schemes are able to numerically maintain pressure equilibrium and demonstrating good entropy-conservation property. It was also shown that the error on entropy can be reduced by using additional terms in the expansion of the AEC fluxes. These results suggest that AEC fluxes could be good candidate for the discretization of compressible flow equations in high performance solvers. Due to the their algebraic form, they are less computationally expensive than the fluxes based on the logarithmic mean, while retaining many important properties. In fact, they guarantee the KEP and PEP properties, combined with arbitrarily small error on entropy preservation.  High-order extension The second-order accurate two-point fluxes presented in this article can be extended to higher-order formulations by using the approach proposed by Ranocha [7] in the context of Discontinuous Galerkin discretization of the Euler equations. The main result of interest for us is that contained in Theorem 3.1 of [7], which can be reformulated in FD terms as follows. We consider a numerical flux F(w, wi+k) for a generic quantity pp, which depends on the values of the variables vector w in the nodal points i and i + k. In our context F can be any of the numerical fluxes flux is smooth, symmetrical (i.e. F(w, wi+k) = F(wi+k, w)) and consistent with the continuous flux f so that F(w, w) = f(w). Under these hypotheses, by following the steps of the proof to Theorem 3.1 in [7], we can show given by 2akF(wi,Wi+k) (16) and it has the same order of accuracy as the original derivative formula with weights a. If one considers central derivative formulas, for which ak = ak, by using the symmetry of the flux F, Eq. (16) can be rewritten as 2ak(F(Wi,Wi+k)-F(Wi-k,Wi)) (17)",
    "C. Empirical data We observe the changes of activity over time of the empirical networks for the four data sets (Figure 11). The US school presents periodic patterns, varying from low contact periods when the students. are in class to high contact periods when there is a recreational time. The US flight and Conference networks have circadian patterns as there are respectively less flights and less contacts at night.. Finally, the Resistance game does not present any periodic change in its activity as every player of the game is looking at someone else at each time step. a b 1e2 US middle school le1 US flight ts 2.5 MM 0 3 9 0 12 24 36 48 60 72 84 Time (in hours) Time (in hours) d Number of events 1e2 Conference Resistance game 1 0 12 24 36 48 60 72 6 13 33 40 Time (in hours) Time (in minutes) Figure 11: Number of events as a function of time for the four data sets: the US school (panel a), the. US flight (panel b), the Conference (panel c) and the Resistance game (panel d). The US school network contains high activity periods during recreational moments of the students' day, while the US flight and the Conference networks present circadian patterns. The Resistance game network does not have particular periodic activity changes. References [1] Petter Holme and Jari Saramaki. Temporal networks. Physics reports, 519(3):97-125, 2012. [2] Petter Holme. Modern temporal network theory: a colloquium. The European Physical Journal B, 88:1-30, 2015. [3] Naoki Masuda and Renaud Lambiotte. A guide to temporal networks. World Scientific, 2016. [4] Alain Barrat and Ciro Cattuto. Temporal networks of face-to-face human interactions. Temporal networks, pages 191-216, 2013. [5] Sune Lehmann. Fundamental structures in temporal communication networks. Temporal Net- work Theory, pages 25-48, 2019. [6] Mohammed Saqr and Sonsoles Lopez-Pernas. The why, the what and the how to model a dynamic relational learning process with temporal networks. In Proceedings of the NetSciLA22 workshop, 2022. 16",
    "THE POISSON BOUNDARY OF LAMPSHUFFLER GROUPS P*9(x)0(-x) |x|(n-1)Nkj 5 B*(x) |x|n-1)Nk =*-(n-1)Nk-1n-1)Nk-1  en, where we used the fact that k, satisfies Equation (2), with kj  Pn.. We conclude that v*n(0) = y1(0) + y2(0)  2en, which finishes the proof.. If we weaken the hypothesis E (|supp(1)l) < oo from Lemma 4.10 it is possible that the permutation coordinate never stabilizes. Indeed, with ideas similar to an example of. [Kai83], we obtain the following. Proposition 4.14. The group Shuffler(Z) admits probability measures  with an infi-. nite first moment and a finite (1- e)-moment, for every 0 < e < 1, that induce a transient random walk on Z and for which the permutation coordinate of the -random walk does not stabilize. Such measures can be chosen to satisfy E(|supp(o1)l) = oo and. E(|supp(o1)|1-s) <  for every 0 < e <1. Proof. For each n  1, denote by rn : Z -> Z the permutation. (x+1,if0x<n-1, rnx= 0, if x = n-1, and x, otherwise. We define the measure  on Shuffler(Z) as follows. Let ((id,1))=1/8,((id,-1))=3/8, and ((rn,0)) = z 1 for n  1. 2n(n+1)' |supp(rn)! = n. From this, the fact that the harmonic series n1  diverges implies that E(|supp(o1)|) is infinite. Moreover, since ||(rn, O)||ssta  |supp(rn)|, we also have that  convergent and thus E(|supp(o1)|1-) is finite. The element rn has word length at most 3n (since it can be expressed as the product of at most n transpositions together with 2n movements in the Z coordinate), and hence n1-c n(n+1) n>1 which is finite. Hence,  has a finite (1 - s)-moment. Let us show that the value Fn(0), n  1, almost surely changes infinitely often. By definition of the group operation and the -random walk, we can write Fn = Fn-1o(Sn on) Hence, Fn(0)  Fn-1(0) if and only if Sn n(0)  0, which can be rewritten as on(-Sn) / -Sn, by using the definition of the action of Z on FSym(Z) (here we use an additive notation for the group operation on Z). The induced random walk on Z is drifted to the negative numbers, and hence almost > -oo. Also, at time n the projection to Z satisfies Sn  -n, since the 17",
    "(a) Signal of a person saying a short phrase. 1 10 100 00 0.5 1.5 time (b) MFCC generated from the above speech signal. Figure 6. MFCCs generated from a short audio signal. 2.3 Metrics Three metrics were widely used across the papers: accuracy, specificity, and sensitivity. The equations for. these four metrics can be seen below. Correctly classified speech Accuracy = (1) Total speech samples Correctly classified healthy speech Specificity = (2) Total healthy speech. Correctly classified pathological speech Sensitivity = (3) Total pathological speech. Another metric was often used in the papers using multi-class classification - unweighted average. recall (UAR). This metric is calculated by averaging the recall value for each of the specific pathologies included in the dataset. Equation 4 shows how it is calculated, where N is the number of pathologies in the dataset and R; is the recall of the ith pathology in the dataset.. Ri UAR = (4) N 2.4 Binary Classification Literature ? (2020) investigate the classification of cancer patients from healthy controls using six machine learning. algorithms. The dataset used includes recordings of the prolonged vowel /ah/ from 50 male laryngeal 8/19",
    "MacBook keystroke waveform Zoom mel-spectrogra Figure 2: Waveform and corresponding mel-spectrogram of Left: Phone record- ing, and Right: Zoom recording.. for this paper, since a majority of features in keystroke sounds are within the lower frequencies [15, 3, 4] and would therefore be less distinguishable on a linear scale. Meanwhile, MFCC involves performing the discrete cosine transform on a mel-spectrogram, producing a compressed representation that prioritises the frequencies used in human speech. Since, for this paper, human speech is not the target, and the removal of frequencies could risk the loss of relevant data, MFCC was decided to be less suitable than mel-spectrograms.. Data augmentation: Prior to feature extraction, signals were time-shifted randomly by up to 40% in either direction. This time shifting is an instance of data augmentation, in which the amount of data input to a DL model is artifi- cially increased by slightly adjusting existing inputs [28]. The mel-spectrograms were then generated using 64 mel bands, a window length of 1024 samples and hop length of 500 (255 for the MacBook keystrokes, given their shorter length), resulting in 64x64 images. Using the spectrograms, a second method of data augmentation was implemented called masking. This method involves taking a random 10% of both the time and frequency axis and setting all values within those ranges to the mean of the spectrogram, essentially blocking out' a portion. of the image. Using time warping and spectrogram masking combined is called SpecAugment and was found to encourage the model to generalise and avoid overfitting the training data [25, 10]. Having converted keystrokes from each data set into a more visual medium, more direct comparisons could be made. MacBook keystrokes (similar to the keystrokes examined in the literature [4, 39, 6]) have only 2 visible peaks: the 'push' and 'release' peaks respectively. The 2 peak structures shown in Fig. 2 are similar to each other, implying that such a structure is native to the Mac- Book keyboard regardless of recording method, a noticeable difference however is the large range of frequencies present in the zoom recording. The Zoom peaks extend much higher than that of the phone-based recordings, indicating significant data in multiple frequencies that were not present when recorded via phone. The overall data preparation procedure for our data was inspired by the structure presented in 10 and is shown in Fig. 3. 3.2 Model Selection and Implementation.",
    "CNPq through grant 308900/2019-7. R. Clemente acknowledges partial support from CNPq through grant 304454/2022-2. 99 Abreu, E., O, J. & Medeiros, E. Properties of positive harmonic functions on the half-space with a nonlinear boundary condition. J. Differential Equations. 248, 617-637 (2010), https://doi.org/10.1016/j.jde.2009.07.006 Adams, R. & Fournier, J. Sobolev spaces. (Elsevier/Academic Press, Amsterdam,2003) Aleksandrov, A. Uniqueness theorems for surfaces in the large. I. Amer. Math. Soc. Transl.. (2). 21 pp. 341-354 (1962), https://doi.org/10.1090/trans2/021/09 Alexandrov, A. A characteristic property of spheres. Ann. Mat. Pura Appl. (4). 58 pp. 303-315 (1962), https://doi.org/10.1007/BF02413056 Allegretto, W. & Huang, Y. A Picone's identity for the p-Laplacian and applications. Nonlinear Anal.. 32, 819-830 (1998), https://doi.org/10.1016/S0362-546X(97)00530-0 Bonder, J. & Rossi, J. Existence results for the p-Laplacian with nonlinear boundary conditions. J. Math. Anal. Appl.. 263, 195-223 (2001),. https://doi.org/10.1006/jmaa.2001.7609 Chipot, M., Chlebik, M., Fila, M. & Shafrir, I. Existence of positive solutions of a semilinear elliptic equation in R? with a nonlinear boundary condition. J. Math. Anal Appl.. 223, 429-471 (1998), https://doi.org/10.1006/jmaa.1998.5958 Cuesta, M. & Takac, P. A strong comparison principle for positive solutions of degenerate elliptic equations. Differential Integral Equations. 13, 721-746 (2000) Damascelli, L. & Pacella, F. Monotonicity and symmetry of solutions of p-Laplace equations, 1 < p < 2, via the moving plane method. Ann. Scuola Norm. Sup. Pisa Cl. Sci. (4). 26, 689-707 (1998), http://www.numdam.org/item?id=ASNSP 1998.4.26_4_689_0 Damascelli, L. & Sciunzi, B. Regularity, monotonicity and symmetry of positive solutions of. m-Laplace equations. J. Differential Equations. 206, 483-515 (2004), https://doi.org/10.1016/j.jde.2004.05.012 Degiovanni, M., Musesti, A. & Squassina, M. On the regularity of solutions in the Pucci-Serrin identity. Calc. Var. Partial Differential Equations. 18, 317-334 (2003), https://doi.org/10.1007/s00526-003-0208-y O, J. & Medeiros, E. Remarks on least energy solutions for quasilinear elliptic problems in RN. Electron. J. Differential Equations. pp. No. 83, 14 (2003) Escobar, J. Sharp constant in a Sobolev trace inequality. Indiana Univ. Math. J.. 37, 687-698 (1988), https://doi.org/10.1512/iumj.1988.37.37033 Farina, A., Montoro, L. & Sciunzi, B. Monotonicity and one-dimensional symmetry for solutions of -pu = f(u) in half-spaces. Calc. Var. Partial Differential Equations. 43, 123-145 (2012), https://doi.org/10.1007/s00526-011-0405-z Farina, A., Montoro, L. & Sciunzi, B. Monotonicity of solutions of quasilinear degenerate elliptic equation in half-spaces. Math. Ann.. 357, 855-893 (2013), https://doi.org/10.1007/s00208-013-0919-0 28",
    "to Ax = b has full support. By Proposition 4, columns of A are integrally independent. It follows from Theorem 6 that inequality (5) holds.. Remark 1. We demonstrate how to modify the proof of Theorem 6 to obtain the bound (7) given in. [AADLO22]. We use the same notation as in the proof of Theorem 6. For any m  m submatrix of A whose columns are indexed by J where [J| = m, we have |det(A[m]xJ)| =|det(D)| |det((U-1)[m]xJ)| = gcd(A) |det((U-)[m]xJ)| = gcd(A) :|det(U[n]J x [m+1:n])| We also know that. I qi||det(U[nJJ x [m+1:n])] ie[n]V and thus |det(A[m]xJ)| I qi gcd(A) iE[n]\\J where qi,i E [n]J are primes numbers and with the same prime repeating at most m times in{qi | i E [n]J}. Recall notation Qm(z) = i=1 min{si, m} for the prime factorization of z = ri' ..- rg* with mul- Moreover, since the multiplicity ofeach q; in Iie[n]V qi is at most m, we have m(IIie[n]V qi) = |[n]J| = n - m. gcd(A (|det(A) . Applying the same argument as in the proof of Theorem 2 detA gcdA 3.3Upper bound on h(m,t). Recall h(m,t) is the maximum, taken over all integer matrices A with m rows and largest entry t, of the smallest support size of an integer solution to Ax = b for some b e L(A) (formally defined in (3). Using a relation between the size of largest entry of a matrix and the size of its. subdeterminant, we want to use results in Section 3.2 to obtain an upper bound for h(m,t). We will use the well-known Hadamard inequality [Had93], which gives us an upper bound on the determinant of a matrix, i.e. for any matrix B e Rmm I det(B)| < (m|B)m. Applying this to inequality (5), we obtain the following corollary. Corollary 9. h(m,t) satisfies. m t)m> PP3  p[hm P[mm] h(m,t)-m[h(mt) ] (9)",
    "Figure 15: Smaller Network, Original Images (First Four), Reconstructed Images (Last Four) (a) Row 1: codebook. size=8192, latent dimension size = 256, 65 images, without positional encoding. (b) Row 2: codebook size=8192, latent dimension size = 256, 65 images, with positional encoding. (Figure 16(b)) VQ Train Los VO Validat Epochs Figure 16: (a) Column 1: codebook sizes = [1024, 8192, 1024], Latent dimensions = 256, image sizes = [2700, 185, 2700], with, with and without positional encoding respectively. (refer Figure 12 & Figure 8) (b) Col-. umn 2: Smaller network, codebook size = 8192, latent dimension size = 256, image size = 65, without and with. positional encoding. (refer Figure 15) 3.9 Comparative Analysis of Smaller Dataset (65 Images) and Larger Dataset (2700 Images) using Principal Component Analysis We conducted an experiment using Principal Component Analysis (PCA) for image reconstruction with both smaller (65 images) and larger (2700 images) datasets, utilizing 50 principal components for representation. The explained. variance for the smaller dataset was approximately 98.19%, while for the larger one it was roughly 98.35% (Figure 18). However, visual inspections revealed a marked degradation in quality between the two datasets(Figure 18). In the 65- image dataset, the reconstructions showed anomalies like purplish lines in the background and bluish color distortions. For the 2700-image dataset, the performance was even worse, with greenish horizontal lines appearing in the foreground and failure in capturing essential details. Several factors may contribute to this unexpected result. The increased complexity and variability within the larger dataset might have overwhelmed PCA's ability to represent finer details. Since PCA relies on linear assumptions, it might have failed to handle the nonlinear structures and dependencies that become more pronounced with the increase in data complexity. The 1.5% - 2% unexplained variance might contain critical information affecting the visual quality, especially in a larger, more intricate dataset. Moreover, the choice of 50 components might have been insufficient for capturing nuanced variations in the larger dataset, despite sufficing for the smaller one. These observations highlight PCA's limitations in handling highly complex image data and emphasize that capturing a high percentage of variance does not guarantee accurate or visually pleasing reconstruction. 14",
    "IEEE INTERNET OF THINGS JOURNAI 11 that, for the same projection point, the higher height indicates that the transmission link is more likely to be LoS, which means the signal strength from the interfering UAV becomes 0.9 stronger. Hence, when the misalignment for the beamforming is non-negligible, the lower deployment of UAVs is preferred for both schemes. Under the case of perfect beam alignment, from Fig. 6(b), it can be seen that the outage probability of MAPAS is smaller for the lower height of UAVs. The H =150 m, H=200 m; MAPAS explanation is the same as before. However, in terms of the H=200 m, H=250 m; MAPAS performance of CDAS, it seems that the outage probability H=250 m H=300 m; MAPAS H =150 m, H=200 m; CDAS for the higher altitude of UAVs can be better. This is mainly 0.4  H =200 m, Hz=250 m; CDAS because of the fact the UE is associated with the closest UAV o- A H, =250 m, H=300 m; CDAS and their link can be either LoS or NLoS. As mentioned 0.3 4 9 16 25 36 before, for the same projection point, the link from UAV at the Number of Transmitting Antennas N lower height is much more likely to be NLoS, which reduces (a) Imperfect beam alignment case. the desired signal strength at the UE whereby degrading the outage performance. 10  H =150 m, H=200 m; MAPAS D. Effect of UAV Density  H =200 m, H=250 m; MAPAS  H =250 m, H=300 m; MAPAS Fig. 7 plots the outage probability versus the number of H=150 m H=200 m CDAS antennas for UAV under different UAV densities for both 0 m, H=250 m; CDAS imperfect and perfect alignment cases. Under the imperfect =250 m, H=300 m CDAS 101 beam alignment scenario, as expected, the outage probability drops at first and then rises with the increase in the number of antennas. Moreover, since more interfering UAVs are involved in the system, the higher UAV density leads to worse outage 10-2 probability performance. Besides that, Fig. 7(a) shows that the optimal number of UAV antennas increases as the UAV density rises, e.g., for MAPAS, the optimal number antennas is 4 for Xx = 0.5  10-5 m-2 while it goes to 16 for 4 9 16 25 36 Number of Transmitting Antennas N Ak = 5  10-5 m-2. The reason is as follows. When the b Perfect beam alignment case UAV density is very sparse, the number of interfering UAVs falling into the region covered by the main-lobe beam of the Fig. 6. Outage probability versus the number of antennas for UAV N under UE is very small. In other words, the interference is not that different UAV heights for both imperfect and perfect alignment cases. severe. Then the serving UAV needs to ensure that the typical UE is covered by its main-lobe beam; hence, a larger main- beam alignment case, an excessive number of antennas is lobe beamwidth (equivalently, a smaller number of antennas) is adverse to the network coverage probability. As for the perfect preferred. However, when the interfering UAVs are very dense, beam alignment case, Fig. 6(b) shows that, as the number the interference becomes very severe. One way to reduce the of antennas becomes large, the outage probability decreases, interference is to reduce the density of interfering UAVs with and the trend of decreasing gradually slows down. This figure  main-lobe beam pointed to the typical UE. From our analysis, implies that from the perspective such as hardware cost, it is this can be achieved by narrowing the main-lobe beamwidth. not necessary to equip the UAV with too many antennas since Note that it cannot be too narrow, because this can degrade the performance gain is very small. the signal strength from the serving UAV due to the beam misalignment. Hence, a relatively larger number of antennas is preferred for the case of denser UAVs. Under the perfect beam C. Effect of UAV Deployment Height scenario, for the MAPAS, sparse UAVs lead to a lower outage With regards to the effect of UAV deployment height, probability as expected. However, this is not the case for the Fig. 6(a) shows that the higher deployment of UAVs will lead CDAS. Fig. 7(b) shows that the denser UAVs can even result in a better outage probability, especially when the number of case. The reason is as follows. The higher height implies the  antennas is large. The reason is as follows. When the UAV larger coverage area of the main-lobe beam on certain tiers,  density is very sparse, the closest UAV (i.e., the serving UAV) which introduces more interference from more UAVs to the  can be very far away, which consequently leads to a very weak typical UE with the main-lobe pointed. When the beam is mis- signal strength from the serving UAV. Increasing the density of pointed, this kind of effect on SINR becomes worse. Besides  UAVs somehow improves the signal strength from the serving",
    "This iteration was introduced by Nadel in [31] where he also proved that periodic points of order two or three must be Kahler-Einstein metrics. This was generalized [20, 33] to periodic points w of any order, that is, those satisfying p = Aw for any k E N. The iteration (3) can be regarded as a discretization of the Kahler-Ricci flow. Observe that, if the manifold M is compact, by Calabi's conjecture one does not need positivity assumptions to reverse the construction above and define the inverse Ricci-Kahler iterations pk. Both of this discrete dynamical systems have been studied in the literature, see for instance [5, 13] Here we focus on the following generalized Monge-Ampere equation on a complex manifold M (4) P = A where  is again a Kahler form. In particular we study equation (4) for a special class of well- behaved Kahler metrics. Our second result is the following theorem dealing with Kahler metrics. induced by the flat metric (which are well-behaved by Example 4 below). Theorem 2. Let M be a complex manifold with two metrics g and G induced by the flat metric. If. the corresponding Kahler forms w,  satisfy p = X for some k > 1 and X E R, then (M, g) is a totally geodesic submanifold of the flat ambient space.. Observe that this result can be seen as a generalization of [40, Theorem 2.1]. Namely, when k = 1 and g = G, Theorem 2 shows that a Kahler-Einstein submanifolds of Cn with the flat metric is necessarily Ricci-flat, hence a totally geodesic submanifold. It is worth pointing out that the metric g is assumed to be induced by a flat one for simplicity, but the hypothesis on g can be. sensibly relaxed, cf. Remark 11 below.. Our third and last result deals with Kahler-Ricci solitons (KRs). Recall that a Kahler metric G is a KRS if there exists a holomorphic vector field X (the solitonic vector field) such that Ric(G) =- G + LxG where Ric(G) denotes the Ricci tensor of G and Lx the Lie derivative in the direction. of X. Kahler-Ricci solitons are important generalizations of Kahler-Einstein metrics which arise in the study of the Kahler-Ricci flow. Our next result show that KRS cannot arise as Kahler-Ricci iterations of metrics induced by complex space forms.. Theorem 3. Let M be a complex manifold with two real analytic Kahler metrics g and G. Assume that g is induced by a complex space form and G is a KRs. If the corresponding Kahler forms w,  satisfy p, = X for some   0 and k > 0, then G is trivial, i.e. Kahler-Einstein.. Observe that, when  = 0, one cannot draw any conclusion. Take for instance g to be the flat metric on C and G to be Hamilton's cigar KRS [17]. It is worth mentioning that we do not know of any Kahler-Einstein metric G and Kahler metric g induced by a complex space form which satisfy p = XQ for X < 0 unless g = G and k = 1. In that case M is forced to be a totally geodesic submanifold in CHn [40]. On the other hand, such examples for X > 0 are discussed in Section 3, see in particular Proposition 2. Also in this case we generalize some recent results on KRS induced by complex space forms which indeed served as partial motivation for this paper. In particular, if we assume k = O (and X > 0) in Theorem 3, we recover [25, Theorem 1.1]. If we restrict to compact complex manifolds. then this result can be rephrased in terms of the inverse Kahler-Ricci iterations. Namely, Theo- rem 3 shows that none of the inverse Kahler-Ricci iterations p of a non-trivial KRS (g, X) on a compact complex manifold M can be induced by a complex space form.. 5",
    "Finally, let us simplify Term 1:. Term1 = exp({) - i1(s)E} exp({) - ia2(s)P} exp({) - ia3(s)Q}(exp({) - ia4(s)H}a4(s)H = a4(s) exp({)- ia1(s)E} exp({) - ia2(s)P}exp({)- ia3(s)Q}H) exp({) -ia4(s)H} eia3(s)Qe-ix3(s)Q Identity operator inst exp({)- ia4(s)H} = a4(s) exp({) - ia1(s)E} exp({)- ix2(s)P}exp({) - ia3(s)Q}H exp({) ia3(s)Q} Apply Baker-Campbell Hausdorff formula. exp({)- ia3(s)Q} exp({)- ia4(s)H} exp({)- ia3(s)Q} exp({)-ia4(s)H} =a4(s) exp({)- ia1(s)E} exp({) -ia2(s)P}H exp({) - ia3(s)Q} exp({) - ia4(s)H} + 4(s) exp({) - ia1(s)E} exp({)- ia2(s)P}a3(s)P exp({) - ia3(s)Q} exp({) - ia4(s)H} 2 exp({)- ia2(s)P} exp({)-ia3(s)Q} exp({)-ix4(s)H} o4(s)H - a4(s)a2(s)Q + 2o4(s)a2(s) E + o4(s)a3(s)P+a4(s)a3(s))U(s) (B.24) The above form of dU(s)/ds is exactly what was required. Now we one simply match the coefficients of the corresponding generators on both sides and arrive at the following  45 -",
    "34 KYUNGKEUN KANG AND CHANHONG MIN The first integral of (5.21) can be estimated as follows: for any e > 0, log (2+ - s2x The second integral of (5.21) can be estimated as follows: 1 |y|<1(t-s)(x-y'|2+(t-s)\"2(1- s)1-a ly'd 1og (2+ Vt-s) t-s1-s1-a log(2+) LN* 1-t+u21-a t- (1+c LN* 1-t+u21-a 1 LN* dv LN* 2 ||>2 v1-at-1+v2 LN* LN* 1x<2+ Thus we conclude that LN* LN* (5.22) |I2|(t-1) Hence (5.17), (5.19) and (5.22) give |I2|1|x|<2 LN* +(1<t1+1t>1) LN* For the estimates of the higher spatial derivatives, the similar argument as above gives the result, and this proves the pressure estimate. ",
    "Xie L.et al.Sci.China-Phys.Mech.Astron.04 2023Vol.xxNo.x 000000-10 LP/M05/SB LP/CB07/SE 6 10 LP/M05/ExD 6 10 LP/MO5/SE .0 12 11 12 log(M/Mo) (LP/BC03/spec-z) LP/BC03/Ex 6 10 11 17 log(M/Mo) (LP/BC03/spec-z) Figure 4Stellar mass estimates as for Fig. 3 but using the GaZNet morphoto-metric redshifts. corresponding statistical estimators. In this case, we also use the LP/B03/ExD model from the spec-z as reference to check the in Fig. 3, the relative bias of the different configurations is not worsened, meaning that the accuracy of the mass estimates is not. affected by the use of the morphoto-z. This is eventually a consequence of the good accuracy of these latter as seen in Fig. 2. On the other hand, we register an evident increase of the NMAD as a consequence of the morphoto-z intrinsic statistical errors and. outlier fractions, which is also mirrored by the scatter of the residual, at the bottom of the 1-to-1 relations, which is now of the order of 0.23 dex, for log M,/M > 9, and 0.49 dex for log M,/M < 9, on average. These large scatter at low stellar masses. are mainly caused by the trend we see that below log M,/Mo = 8.5, where stellar masses are systematically overestimated compared to those obtained with the spec-z. This is not an effect that comes from the particular set-up of the fitting procedure, as shown by the comparison of the LP/B03/ExD/morphoto-z against the same set-up with spec-z (bottom/left plot in Fig. 4). Even in this latter case, we see that below log M./Mo = 8.5 the positive bias is similar to the ones of all other configurations. We track the motivation of this systematics to some bias of the GaZNet redshifts for a group of objects at very low redshifts (z < O.05 see Fig. 2), which turn-out to have also low masses. This can be due to some residual contamination from stars, not picked in the spectra classification, or just a failure of the GaZNet predictions at very low-z, which clearly impact the mass predictions. We will come back to this on Sect. 4. However, still looking at the LP/B03/ExD/morphoto-z vs. spec-z, above log M./Mo = 8.5, the bias is almost absent and the only relevant effect is the GaZNet redshift scatter that, from the NMAD, is quantified in 0.09. This is confirmed by noticing that the general increase of the NMAD from the spectroscopic sample to the morphoto-metric sample, in Table 2, is compatible with the sum in quadrature of the NMAD of the former with 0.09 coming from the latter, consistently with some pseudo-Gaussian distributions. This is consistent with a log-normal distribution of the. uncertainties of the stellar masses, which are confirmed by the outlier fractions that are all of the order of 5-6% above 2 of the",
    "Improving Generalization in Visual Reinforcement Learning via. Conflict-aware Gradient Agreement Augmentation Siao Liu Zhaoyu Chen Yang Liu Yuzheng Wang Dingkang Yang Zhile Zhao Ziqing Zhou Xie Yi Wei Li Wenqiang Zhang Zhongxue Gan Academy for Engineering & Technology, Fudan University. {saliu20, zhaoyuchen20, yang_liu20, yzwang20, dkyang20, fd_liwei, wqzhang, ganzhongxue}@fudan.edu.cn {zhilezhao21, ziqingzhou21, yixie22}@m.fudan.edu.cn Abstract of a pretrained RL agent to perform well in unseen environ- ments. Due to the dynamic nature of the real world, even Learning a policy with great generalization to unseen minor perturbations in the environment can result in signifi-. environments remains challenging but critical in visual re- cant semantic shifts in the visual observations, which makes inforcement learning. Despite the success of augmenta- visual RL generalization challenging. tion combination in the supervised learning generalization, To improve generalization performance, data augmenta- naively applying it to visual RL algorithms may damage tion [29] is a widely adopted technique in reinforcement the training efficiency, suffering from serve performance learning. Numerous studies [22, 13] utilize data augmen- degradation. In this paper, we first conduct qualitative tation methods to generate synthetic data and diversify the analysis and illuminate the main causes: (i) high-variance training environments, yielding considerable performance gradient magnitudes and (ii) gradient conflicts existed in improvements. However, recent methods [14, 3, 44] mostly various augmentation methods. To alleviate these issues, select a single augmentation technique to improve the gen- we propose a general policy gradient optimization frame- eralization capability, resulting in a poor performance in the work, named Conflict-aware Gradient Agreement Augmen- environments with observations varying far from the aug- tation (CG2A), and better integrate augmentation combina- mented images. For instance, ColorJitter [23] is the pre- tion into visual RL algorithms to address the generalization ferred choice for addressing color variations, but agents bias. In particular, CG2A develops a Gradient Agreement trained with such augmentation still hard to cope with in- Solver to adaptively balance the varying gradient magni- tricate texture patterns. In other words, the generalization tudes, and introduces a Soft Gradient Surgery strategy to al- ability heavily relies on the selection of specific data aug- leviate the gradient conflicts. Extensive experiments demon- mentation technique, which is so-called generalization bias. strate that CG2A significantly improves the generalization Compared to single data augmentation, Augmentation performance and sample efficiency of visual RL algorithms. Combination (AC) [16] integrates multiple data augmenta- tion methods to enhance the diversity of augmentations and. alleviate the generalization bias, which is a more promising pre-processing solution. Unfortunately, there is a dilemma 1. Introduction in incorporating AC into visual RL. Although data augmen- tation combination can effectively improve generalization With the development of deep learning in various capability in the supervised visual tasks, RL algorithms are tasks [28, 26, 25, 27, 7, 6, 38, 40, 39, 24], visual Rein- quite sensitive to excessive variations, resulting in perfor- forcement Learning (RL) has achieved impressive success mance degradation and training sample inefficiency. There- in various fields such as robotic control [11], autonomous fore, it is necessary to rethink why visual RL algorithms driving [17], and game-playing [35]. Previous works usu- cannot benefit from AC as much as supervised learning. ally formulate it as a Partially Observable Markov Deci- From the perspective of gradient optimization, we con- sion Process (POMDP) [33], and the agent receives high- duct numerous qualitative analysis to illustrate the causes dimensional image observations as inputs. As depicted of performance degradation and training collapse that occur in [15, 14], visual RL generalization refers to the ability when employing augmentation combinations during train-",
    "10 UNIQUENESS OF ROOTS IN CIRCULAR AND HOSOHEDRAL-TYPE GARSIDE GROUPS Lemma 2.9. Let x = k for some nonzero integer k. We have SSs(k) = {k}. The centralizer of k in G(m, l) is either G(m,l) if kl is a multiple of m, or cyclic and generated by  otherwise. Proof. We have that y E G(m,l) lies in SSs() only if inf(y) = k = sup(y). The only element satisfying this is , which is conjugate to itself. Thus we have SSs() = {k}. Now, let s(j, q) be a simple element in M(m, l). Since both 1 and  conjugate k to itself. we can assume that q E [1, m - 1]. We have s(j,q)-'^s(j,q) =s(j,q)k-1s(j,q) =s(j+q,l-q)k-1s(j,q) =k-1s(j+q+(k-1)l,l-q)s(j,q) In order for this element to lie in SSs(), the word s(j + q + (k - 1)e, l - q)s(j, q) must not be greedy. This is equivalent to j + kl = j[m]. If kl is a multiple of m, this is true for all j E [0, m - 1], and we obtain s(j, q)-1s(j, q) = h: the arrows from k to itself in CG(k) are given by all the simple elements. Otherwise, j + kl = j[m] is never true for j E [1, m  1] and the only arrows from k to itself in CG(k) are given by 1 and .  Lemma 2.10. Let x = s(i,p) be a periodic element in M(m,l) with p E [1,m - 1]. We have SSS(x) = {s(n,p) | n E [0,m - 1]}. The centralizer of s(0,p) in G(m,l) is cyclic and generated by s(p, m).. Proof. The assumption that x is periodic is equivalent to kl +p = 0[m] by Lemma 2.8. Let. s(j, q) be a simple element in M(m, l). We have xs(j,q) =s(j,q)-1s(i,p)s(j,q) =k-1s(j+q+(k-1)l,l-q)s(i,p)s(j,q). Again, in order for this to lie in SSS(x), we must have either j + kl = i[m] or i + p = j[m]. Since kl + p = O[m], those two assertions are equivalent. If they are satisfied, then we have. (17) xs(j,q) =s(j+q-P,p) =^s(i+q,p). In particular, s(p,n) gives a conjugating element from s(0,p) to s(n,p) for n E [0, m-1]. Moreover, for s(n,p) E SSS(x), the simples s such that (s(n, p))s E SSS(x) are all divisible by s(n + p, 1). The conjugacy graph of x is then given by s(p,1) > ks(1,p) (18) ks(0,p) sp+m-1,1 and the centralizer of s(0,p) is cyclic and generated by (19) sp1sp+1,1sp+m-1,1=spm We can use these two lemmas to determine the center of circular groups. Recall that the Garside automorphism $, corresponding to conjugacy by  on the right, sends a simple element s(i,p) to s(i + l,p). If m  1  l, then the smallest trivial power of $ is mAe, and m^e is the smallest central power of  in G(m, l). Corollary 2.11. (Center of circular groups) Let m, l be two positive integers. If m = 1 or l = 1, then G(m,l) ~ Z is abelian. If m = l = 2, then G(m,l) = Z2 is abelian. Otherwise Z(G(m,l)) is infinite cyclic and generated by mAl.",
    "10 Husain et al. 2023 ture during a significant decrease in disk contribution, as well as the Merloni A., et al., 2o00, Monthly Notices of the Royal Astronomical Society, study of timing characteristics in that state. 313, 193 Miller J., et al., 2008, The Astrophysical Journal, 680, 1359 Mineshige S., et al., 1994, The Astrophysical Journal, 426, 308 Mitsuda K., et al., 1984, Publications of the Astronomical Society of Japan, 6 ACKNOWLEDGEMENTS 36, 741 We would like to thank the anonymous referee for their valuable Morningstar W. R., Miller J. M., 2014, The Astrophysical Journal Letters, 793,L33 suggestions, which improved the quality of this work. This work Mudambi S. P., et al., 2022, Monthly Notices of the Royal Astronomical has utilized data from AstroSat mission which is archived at Indian Society, 517,4489 Space Science Data Centre (ISSDC). We are grateful to the SXT and Negoro H., et al., 2021a, The Astronomer's Telegram, 14701, 1 LAXPC POC teams for providing the data and requisite softwares to Negoro H., et al., 2021b, The Astronomer's Telegram, 14708, 1 perform data analysis. NH acknowledges the financial support pro- Negoro H., et al., 2022, The Astronomer's Telegram, 15715, 1 vided by Department of Science and Technology (DST) under the Orosz J., et al., 2002, in American Astronomical Society Meeting Abstracts. INSPIRE fellowship scheme. AG, RM and SS acknowledges the pp 1511 financial support provided by Department of Space, Govt of India Orosz J., et al., 2003, in Proceedings of IAU Symposium. (No.DS_2B-13012(2)/2/2022-Sec.2). Park S. Q., et al., 2004, The Astrophysical Journal, 610, 378 Ponti G., et al., 2012, Monthly Notices of the Royal Astronomical Society: Letters, 422, L11 Prabhakar G., et al., 2023, Monthly Notices of the Royal Astronomical Soci- 7 DATA AVAILABILITY ety Rawat D., et al., 2022, Monthly Notices of the Royal Astronomical Society, The data used in the publication is publicly available 511, 1841 for download at https://astrobrowse.issdc. gov.in/astro_ Reeves J., et al., 2008, Monthly Notices of the Royal Astronomical Society: archive/archive/Home.jsp using the observation IDs men- Letters, 385, L108 tioned in Tab 1. Remillard R. A., McClintock J. E., 2006, Annu. Rev. Astron. Astrophys., 44, 49 Shafee R., et al., 2005, The Astrophysical Journal, 636, L113 Shakura N. I., Sunyaev R. A., 1973, Astronomy and Astrophysics, 24, 337 REFERENCES Shimura T., Takahara F., 1995, The Astrophysical Journal, 445, 780 Agrawal P., et al., 2017, Journal of Astrophysics and Astronomy, 38, 30 Singh K. P., et al., 2016, in Space Telescopes and Instrumentation 2016: Ul- Antia H., et al., 2017, The Astrophysical Journal Supplement Series, 231, 10 traviolet to Gamma Ray. pp 389-398 Asplund M., et al., 2009, Annual review of astronomy and astrophysics, 47, Singh K., et al., 2017, Journal of Astrophysics and Astronomy, 38, 1 Steiner J. F., et al., 2010, The Astrophysical Journal Letters, 718, L117 481 Belloni T. M., et al., 2011, arXiv preprint arXiv:1109.3388 Takahashi H., Makishima K., 2006, Proceedings of the The X-ray Universe Bhargava Y., et al., 2022, Monthly Notices of the Royal Astronomical Soci- 2005 (ESA SP-604). 26-30 September 2005, El Escorial, Madrid, Spain. ety, 512,6067 Editor: A. Wilson, p. 309, 604, 309 Capitanio F., et al., 2009, Monthly Notices of the Royal Astronomical Soci- Trigo M. D., et al., 2007, Astronomy & Astrophysics, 462, 657 ety, 398, 1194 Verner D., Ferland G. J., Korista K., Yakovlev D., 1996, arXiv preprint astro- Chevalier C., Ilovaisky S., 1992, International Astronomical Union Circular, ph/9601009 5520, 1 Wang J., et al., 2022, The Astronomer's Telegram, 15253, 1. Connors R., et al., 2021, The Astronomer's Telegram, 14725, 1 Watarai K.-y., et al., 2o00, Publications of the Astronomical Society of Japan, Dauser T., et al., 2014, Monthly Notices of the Royal Astronomical Society: 52, 133 Letters, 444, L100 Wilms J., et al., 2000, The Astrophysical Journal, 542, 914. Davis S. W., et al., 2005, The Astrophysical Journal, 621, 372 Zhang X., et al., 2022, The Astronomer's Telegram, 15157, 1 Done C., et al., 2007, The Astronomy and Astrophysics Review, 15, 1 Zimmerman E., et al., 2005, The Astrophysical Journal, 618, 832 Draghis P. A., et al., 2022, arXiv preprint arXiv:2210.02479, DR22 Ebisawa K., et al., 1993, Astrophysical Journal, Part 1 (ISsN 0004-637X), vol. 403, no. 2, p. 684-689., 403, 684 Ebisawa K., et al., 2003, The Astrophysical Journal, 597, 780 Garcia J., Kallman T. R., 2010, The Astrophysical Journal, 718, 695 Garg A., et al., 2022, Monthly Notices of the Royal Astronomical Society Gierlinski M., Done C., 2004, Monthly Notices of the Royal Astronomical Society, 347, 885 Gierlinski M., et al., 1999, Monthly Notices of the Royal Astronomical So- ciety, 309,496 Harmon B., et al., 1992, International Astronomical Union Circular, 5510, 2 Husain N., et al., 2022, Monthly Notices of the Royal Astronomical Society, 510, 4040 Kallman T., Bautista M., 2001, The Astrophysical Journal Supplement Se- ries, 133, 221 Kitamoto S., et al., 1984, Publications of the Astronomical Society of Japan, 36, 799 Kubota A., et al., 2007, Publications of the Astronomical Society of Japan, 59,S185 Li L.-X., et al., 2005, The Astrophysical Journal Supplement Series, 157, 335 Matilsky T., et al., 1972, The Astrophysical Journal, 174, L53 McClintock J. E., et al., 2006, The Astrophysical Journal, 652, 518 MNRAS 000, 000000 (2023)",
    "2 the presynaptic and postsynaptic neuron activities have low correlation their connection are likely to be removed. The latter process is called synaptic pruning and it is considered essential for optimizing activity propagation and memory capacity(Chklovskii, Mel, and Svoboda, 2004; Knoblauch et al., 2014; Knoblauch and Sommer, 2016). Furthermore, it is commonly believed that synaptic pruning and rewiring dysfunction are one of the neural correlate of developmen- tal disorders such as autism or schizophrenia (Bourgeron, 2oo9; Moyer, Shelton, and Sweet. subjects(Hutsler and Zhang, 2010; Pagani et al., 2021; Glantz and Lewis, 2000).. In the last decades computational neuroscience has investigated brain dynamics at different scales, from cellular (Markram et al., 2015) to mesoscopic and macroscopic through mean-field approaches (Wilson and Cowan, 1972; Amit and Brunel, 1997; Hopfield, 1984; Renart, Brunel. and Wang, 2004; Leon et al., 2013; di Santo et al., 2018; Capone et al., 2019; Carlu et al. mechanisms that involve strengthening or weakening of existing synapses, like short-term plastic- ity (STP) (Tsodyks, Pawelzik, and Markram, 1998) or spike timing-dependent plasticity (STDP) (Gutig et al., 2003) and on their role in short-term, long-term, working memory and learning (Mongillo, Barak, and Tsodyks, 2008; Tiddia et al., 2022b;  Song, Miller, and Abbott, 2000; qiang Bi and ming Poo, 2001; Golosio et al., 2021; Capone et al., 2022). Only in recent times computational models of structural plasticity and connectivity rearrangements during learning were developed, showing intriguing results. Knoblauch et al. (2014) and Knoblauch and Som- mer (2016) describe a model of structural plasticity based on \" effectual connectivity\", defined in these works as the fraction of synapses able to represent a memory stored in a network. By memory are moved in order to optimize network's connectivity. Their model defines synapses using a Markov model of three states: potential (i.e. not instantiated), instantiated but silent or instantiated and consolidated. Structural plasticity is thus related to the passage of the synapses from a potential state to an instantiated state (and vice versa), whereas changes only related to the synaptic weight are described by the consolidation of the instantiated synapses. With such a model, it is possible to show that networks with structural plasticity have higher or comparable memory capacity to networks with dense connectivity and it is possible to explain some cognitive mechanism such as the spacing effect (Knoblauch et al., 2014).. Spiess et al. (2016) simulated a spiking neural network with structural plasticity and STDP, showing that structural plasticity reduces the amount of noise of the network after a learning process, thus making the network able to have a clearer output. Furthermore, such a network with structural plasticity shows higher learning speed than the same network with only STDP implemented. Some new insights about the importance of synaptic pruning are also shown in Navlakha, Barth. and Bar-Joseph (2015), in which different pruning rates were studied suggesting that a slowly decreasing rate of pruning over time leads to more efficient network architectures.. As discussed above, the biochemical and biophysical mechanisms underlying structural plas- ticity are extremely complex and only partially understood to date. For this reason, rather than attempting to build a biologically detailed model, this work exploits a relatively simple phenomenological model, including both the activity-driven and the homeostatic contributions; of the consolidation of synaptic connections between neurons with a high activity correlation as well as those of pruning and rewiring the connections for which this correlation is lower. This approach is also justified by the requirement for a simple and effective computational model suitable for simulating networks with a relatively large number of neurons and connections and for representing learning processes with sizable numbers of training and validation patterns. This model will then serve as the foundation for the creation of a mean-field-based theoretical framework for learning through synaptic plasticity capable of accounting for a variety of biolog- ical network properties. This framework will be used in a training and validation procedure to characterize learning and memory capacity of plastic neuronal networks as the number of train- ing patterns and other model parameters vary. The results will then be compared with those obtained through simulations based on firing-rate-based neuronal networks. The model consid-",
    "4 length &1 which is given by [width=85mm]figure2.pdf FIG. 2. (a) Plots of the magnetization m1 versus T for vol- 1 (q2) (11) ume fraction  = 0.4. Symbols , , , , and . stand for 4sin2(k/2)\\<l q(k) l2) N = 125,216, 512, 1000 and 1728 respectively. b) Plots of where qk)  = 0.4. Same symbols as in (a). (c) Same as in (b) but for volume fraction  = 0.1. 2ikr E (12) [width=82mm]figure3.pdf with r; the position of the j-th NP, k = (2/L, 0, 0) and FIG. 3. (a) Plots of the magnetization m1 vs T for  = 0.18. k = 1|||=2/L39. Symbols  and o stand for N = 216,512,1000 and Errors in the measurements of these quantities have 1728 respectively. (b) Plots of the Binder cumulant of the magnetization Bm vs T for  = 0.18. Same symbols as in (a).  been calculated as the mean squared deviations of the sample-to-sample fluctuations. N. An extrapolation of the positions of the maxima of HII. RESULTS those peaks vs 1/N provides a value for the transition temperature, Te( = 0.4) = 1.9(1), in agreement with A. Phase diagram for isotropic HS-like the estimated T. obtained from the analysis of Fig. 1(a). configurations For T < Te we find that Xm does not diverge with N, a fact that validates the above conclusions on FM order. In this section we investigate the magnetic order as All that is in contrast to the results obtained for  = 0.1, a function of the volume fraction  for frozen configu- shown in Fig. 2(c) where we see how the values of Xm rations obtained from equilibrium states of hard sphere increase with N for low T. Data are consistent with a fuids in the range 0 <   0.49.  measures the degree trend Xm ~ NP for p ~ 0.45 and T  0.2. This behavior of spatial disorder on such configurations. We will show suggests the existence of a SG phase.. that for decreasing  (which means increasing disorder) Let us discuss now the threshold value of  at which SG order replaces the FM order.. the FM order disappears. Mean-field calculations predict A first overview can be grasped from Figs. 1-2. Fig. 1(a) displays plots of the specific heat c vs T for The plots in Fig. 3 show that the FM order persists at  = 0.4. The curves exhibit a marked lambda-shaped  = 0.18. The curves of m1 vs T in panel (a) indicate peak. Their evident dependence on the number of NP an increase in magnetization with N at low T, although indicates the presence of a singular point in the curve they also exhibit relevant finite size effects. The Binder that corresponds to N  oo at Te ~ 1.9. That singular parameter of panel (b) allows to determine the transition behavior is expected in PM-FM second order transitions. temperature within good precision. In general this pa- Data are consistent with a logarithmic divergence of c. rameter tends to 1 for N  oo in FM phases, while from with N. Fig. 1(b) shows the plots obtained for  = 0.1. the law of large numbers it follows that in PM phases In contrast to the previous ones, these plots are smooth Bm  0 as N increases. On the other hand, since Bm is and depend little on the sample size. So, there is no sign dimensionless, it must be independent of N at the crit- of any singular behavior. This is expected in PM-SG ical point. As a consequence, curves of Bm vs T for transitions with strong structural disorder. different values of N cross at T for second order transi- FM order entails the presence of non-vanishing mag- tions. Instead, in presence of an intermediate marginal netization m. Fig. 2(a) displays m1 vs T for  = 0.4 at phase of quasi-long-range FM order, the curves do not several N. They show that m1 tends to non-zero val- cross but join. Plots of Bm vs T for several N are shown ues for N - oo and low T, revealing the existence of in Fig. 3(b) for  = 0.18. Those curves cross at a well strong FM order. The curves plotted in Fig. 2(b) for. defined critical temperature for N  512.38 with simi- lar results obtained for   0.17, we can draw a line of.  sion as they show peaks that become sharper for large transition between PM and FM phases. The corresponding plots for  = 0.14 are shown in Fig. 4. The qualitatively different results illustrate the [width=85mm]figure1.pdf absence of FM order at this value of . The plots of FIG. 1. (a) Plots of the specific heat c versus T for volume the magnetization in panel (a) show that m1 gradually fraction  = 0.4. Symbols v, , , , and . stand for N = decreases as N increases for all T. The data of m1 for 125, 216, 512, 1000 and 1728 respectively. (b) Same as in (a) low temperature agree with an algebraic decay m1 ~ NP for volume fraction  = 0.1. for p < 1/2, hence a marginal order is a priori not ex- cluded. However, the plots of Bm vs T from panel (b)",
    "WHEN DOES THE CHAOS IN THE CURIE-WEISS MODEL STOP TO PROPAGATE? Let us now informally discuss the case when a > 0. For simplicity, we consider (13). The limit on the right-hand side is non-zero, which suggests that there is a residual dependence between the k(N) spins under the Gibbs measure. The reason for the non-zero limit is the fact that the distribution of Pa() and. the corresponding binomial distribution satisfy central limit theorems with different variances, the variance of Pk() being strictly larger, which comes from the fact that the spins are positively correlated under the Gibbs measure. The distance between these normal distributions appears on the right-hand side of (13). In Theorem 3.5, we shall determine a mixed binomial distribution which approximates the distribution of Pk(n) under y. In some sense, this describes the residual dependence between the spins under the Gibbs measure. Remark 1.2. The exchangeability of the measure y has been used to investigate the Curie-Weiss model for example, in [17, Section 5.2] and [2]. In particular, an explicit representation of y as a mixture of Bernoulli measures (valid for each fixed N) can be found in [17, Theorem 5.6]. A general propagation of chaos principle stating that the distribution of k entries in a finite exchangeable vector of length n can be approximated by a mixture of i.i.d. distributions can found in [7]. The paper is organized as follows. Our proof relies on local limit theorems for the magnetization my and also for the total number of positive spins P under y. In some regimes those are known. We collect the corresponding results in Section 2 below. The proofs of these local limit theorems, which we have not been able to locate in the literature, are given in Section 4. The proof of Theorem 1.1 is given in Section 3, including the statement of residual dependence. Two auxiliary technical results related to calculations of the total variation distance are presented in Section 5. 2. LOCAL LIMIT THEOREM FOR THE MAGNETIZATION Denote by / (m, v2) a Gaussian distribution with mean m and variance v2, so N(m,v2)(A) =]o(t;m,v2)dt, A EB(R). Put d := (1 - (1))/2. This correction term appears below in the local limit theorems for mn, since Nmy always has the same parity as N.. Proposition 2.1. Assume that h  0 or 0 <  < 1. Then NN(mN-m(,h))E)>V(0,v3,h)N, and the following local limit theorem holds true:. NmN+8N Nm(,h) NvB,n)  lim Nsup|v (16) lEZ 2 4",
    "Mitigating Task Interference in Multi-Task Learning via Explicit Task Routing with Non-Learnable Primitives Chuntao Ding1* Zhichao Lu2+  Shangguang Wang3 Ran Cheng4 Vishnu N. Boddeti5 1 Beijing Jiaotong University2 Sun Yat-sen University3 Beijing University of Posts and Telecommunications 4 Southern University of Science and Technology. 5 Michigan State University chuntaoding@163.com {luzhichaocn, ranchengcn}@gmail.com sgwang@bupt.edu.cn vishnu@msu.edu Abstract Multi-task learning (MTL) seeks to learn a single model to accomplish multiple tasks by leveraging shared infor- mation among the tasks. Existing MTL models, however, aResNet18 bLayer 1,4, nd 8 of ResNet18 (from left to right) have been known to suffer from negative interference among Figure 1. (a) Learning progression of multi-task networks (MTNs) tasks. Efforts to mitigate task interference have focused on on CelebA for eight tasks. Hard-sharing models with fully learn- either loss/gradient balancing or implicit parameter par- able parameters (gray) learn rapidly and then suffer from perfor- mance degradation due to conflicting gradients from task interfer- titioning with partial overlaps among the tasks. In this ence. Networks with non-learnable primitives (NLPs; blue) do not paper, we propose ETR-NLP to mitigate task interference suffer from task interference by design, while explicit task rout- through a synergistic combination of non-learnable prim- ing (ETR; green), and ETR with NLPs (red) do not eliminate but itives (NLPs) and explicit task routing (). Our key idea suffer less from task interference. (b) Gradient correlations mea- is to employ non-learnable primitives to extract a diverse sured via CKA [19] across all pairs of tasks for different layers of set of task-agnostic features and recombine them into a a standard MTN at the end of training. Observe the acute lack of shared branch common to all tasks and explicit task-specific correlation between tasks (low off-diagonal magnitude).. branches reserved for each task. The non-learnable prim- itives and the explicit decoupling of learnable parame- For instance, consider the learning progression of an ters into shared and task-specific ones afford the flexibility MTN with a standard learnable convolutional layer in Fig- needed for minimizing task interference. We evaluate the ure 1a (blue curve). Observe that the model learns rapidly, efficacy of ETR-NLP networks for both image-level clas- we posit, by exploiting all the shared information between sification and pixel-level dense prediction MTL problems. the tasks, i.e., gradients pointing in similar directions. How- Experimental results indicate that ETR-NLP significantly ever, the performance starts degrading on further training outperforms state-of-the-art baselines with fewer learnable since the model needs to exploit dissimilar information be- parameters and similar FLOPs across all datasets. Code is tween the tasks for further improvement, i.e., gradients available at this URL. point in different directions. The latter can be verified by observing the similarity (centered kernel alignment [19]), or the lack thereof, between the gradients for each pair of 1. Introduction tasks in Figure 1b. Several approaches were proposed for mitigating task in- Multi-task learning (MTL) is commonly employed to terference in MTNs, including loss/gradient balancing [17, improve learning efficiency and performance of multiple 21, 22, 34, 52], parameter partitioning [2, 28, 30, 37] and ar- tasks by using supervised signals from other related tasks chitectural design [8, 18, 29]. Despite the diversity of these [6, 33, 49]. These models have led to impressive results approaches, they share two common characteristics, (i) all across numerous tasks. However, there is well-documented parameters are learned, either for a pre-trained task or for evidence [18,28,41,53] that these models are suffering from the multiple tasks at hand, (ii) the learned parameters are task interference [53], thereby limiting multi-task networks either fully shared across all tasks or are shared across a par- (MTNs) from realizing their full potential.. tial set of tasks through implicit partitioning, i.e., with no di- *Work done as a visiting scholar at Michigan State University. rect control over which parameters are shared across which  Corresponding author tasks. Both of these features limit the flexibility of existing",
    "6 W. BARRERA, A. CANO, J.P. NAVARRETE, AND J. SEADE 1.5. The control group. We refer to [8] for a discussion about this section. Con- sider I c PSL(3, C) a (discrete or not) subgroup which acts on P? with a point p which is fixed by all of I. Choose an arbitrary line l in P2\\{p}, and notice we have a canonical projection: T=p,e:P\\{p}>l, given by (x) = ,pnl. It is clear that this map is holomorphic and it allows us to define a group homomorphism: II = IIp,e : I > Bihol(l)  PSL(2, C), by H(g)(x) = (g(x)). If we choose another line, say l', one gets similarly a projection t' = p.e' : P? \\{p} > l' , and a group homomorphism II' = IIp.e' : I -> PSL(2, C). It is an exercise to see that II and II' are equivalent in the sense that there is a biholomorphism h : l -> l' inducing an automorphism H of PSL(2, C) such that H o II = II'. As before, the line l is called the horizon. This leads to the following definition: Definition 1.7. Let I c PSL(3, C) be a discrete group as above. We call II = IIp,e the control morphism (or map) and its image II(r) C PSL(2, C), is the control group. These are well-defined and independent of l up to an automorphism of PSL(2, C). The control map and the control group allow us to get information about the dynamics of I by looking at a subgroup of PSL(2, C), which is far easier to handle. The prize we pay is that the control group in PSL(2, C) may not be discrete. 2. PURELY PARABOLIC GROUPS We now follow [5] and look at the discrete subgroups in PSL(3, C) that, besides the identity, have only parabolic elements. These are called purely parabolic and there are five families of such groups; three of them split into various subfamilies elementary. The simplest purely parabolic groups are cyclic, generated by a parabolic ele ment. As described above, there are three types of such elements in PSL(3, C), described by the Jordan normal form of their lifts to SL(3, C). Each of these be- longs to a different type of the families we describe below. The first type generates torus groups (see definitions below), the second generates Abelian Kodaira groups and the ellipto-parabolic elements generate elliptic groups. (i) Elliptic groups. These are the only purely parabolic groups that are not conjugate to subgroups of the Heisenberg group Heis(3, C) and they are subgroups of fundamental groups of elliptic surfaces. These have limit set a single line. Up to conjugation these groups are of the form: (w) (w)w 0 Ell(W, ) 0 (w) 0 M3n 0 u(w)-2 where W C C is an additive discrete subgroup and  : W -> S1 is a group morphism.",
    "Topportunities at the LHC: Rare Top Decays with Light Singlets. Henning Bahl* , Seth Koren' , and Lian-Tao Wang. Department of Physics and Enrico Fermi Institute, University of Chicago,. 5720 South Ellis Avenue, Chicago, IL 60637 USA. yet known, has given us a distinct window into investigating the physics of the Standard Model and Beyond. With a plethora of top quarks to be produced in the High Luminosity era of the LHC, the exploration of its rare decays holds great promise in revealing potential new physics phenomena.. We consider higher-dimensional operators contributing to top decays in the SMEFT and its extension by a light singlet species of spin 0, 1/2, or 1, and exhibit that the HL-LHC may observe many exotic top decays in a variety of channels. Light singlets which primarily talk to the SM through such a top interaction may also lead to distinctive long-lived particle signals. Searching for such long-lived particles in top-quark decays has the additional advantage that the SM decay of the other top quark in the same event provides a natural trigger. *hbahl@uchicago.edu tsethk@uchicago.edu #liantaow@uchicago.edu 1",
    "7.3 Computational Performance of the Optimization Proxies. This section presents numerical experiments used to assess the performance of the proposed optimization proxies (Proxies) against the optimization models (GDO) and the greedy heuristic (GH). Optimality Gap:  Table 3 presents the optimality gaps of various approaches, including the results of Model (1) under various time constraints. In the table, the columns under \"Gap of Model (1)\" denote the optimality gaps of for GH and the optimization proxies. In addition, columns Time(s) denote the solving times for GH and Proxies. Table 3: Optimality Gap (%) with respect to the Total Trailer Cost Model (1) GH Proxies Instance 1s 5s 10s 30s 60s 1800s Gap Time (s) Gap Time (s) M 2.59 0.55 0.48 0.48 0.48 0.48 3.84 3.12 1.14 0.33 L 51.15 5.22 2.18 1.71 1.41 1.39 12.85 13.28 3.80 1.10 XL 77.35 14.02 10.41 2.93 2.07 0.93 17.01 121.55 5.21 2.49 Recall that Model (1) produces solutions that exhibit considerable variability when the total commodity volume is perturbed as detailed in Table 4 and 5. As such, it is unlikely to be practical in scenarios with planners in the loop. Hence, the table compares the optimization proxies and the heuristics GH with an \"idealized\" benchmark. With this caveat in place, observe the performance of the optimization proxies under tight time constraints. Proxies generate solutions with low optimality gaps and may be up to 10 to 50 times faster than GH, and around 10 times faster than Model (1) solved with Gurobi. Second, although Model (1) efficiently produces solutions with low optimality gaps, closing the optimizality gap proves to be a significant challenge due to the poor LP relaxation. The performance of GH is also impeded by the inefficiencies of the LP relaxation, as it solves the LP relaxations over many iterations; it takes the GH around 30 iterations for terminal M, 200 iterations for terminal L, and more than 1000 iterations for terminal XL to generate a feasible solution. Consistency: Tables 4 and 5 report the consistency of solutions obtained from different models in terms of the normalized distance to the reference load plan and the total variation of the generated solutions. As GDO requires running Model (1) and Model (2) sequentially, these experiments set the same time limits for the two stages. For example, if a time limit of 30 seconds is set, GDO runs Model (1) for 30 seconds and subsequently runs Model (2) using the best upper bound obtained from Model (1) for another 30 seconds The high-level result is that proxies are ideally suited to produce consistent plans. Table 4 shows that the proxies accurately predict, in a few seconds, the results produced by GDO after an hour. Furthermore, Table 5 25",
    "Table 2: Normal-markdown model: ideal cases Outcome Emp. p10 p25 p50 p90 Panel A: Regions differ in location parameter, initial min. wage is small Mean causal effect -0.011 0.026 0.013 0.007 0.003 Fraction affected -0.013 0.028 0.014 0.008 0.004 (0.000) (0.001) (0.000) (0.000) (0.000) Gap measure -0.010 0.021 0.011 0.006 0.003 (0.000) (0.001) (0.000) (0.000) (0.000) Panel B: Regions differ in location parameter, initial min. wage is large Mean causal effect -0.076 0.155 0.079 0.049 0.025 Fraction affected -0.079 0.112 0.081 0.054 0.031 0.002) (0.014) (0.003) (0.000) (0.001) Gap measure -0.055 0.074 0.058 0.038 0.022 (0.003) (0.012) (0.002) (0.001) (0.000) Panel C: Identical regions receive different location shocks, initial min. wage is small Mean causal effect -0.006 0.015 0.007 0.004 0.002 Effective min. wage -0.006 0.011 0.003 0.000 -0.002 (0.001) (0.001) (0.000) (0.000) (0.000) Effective min. wage, p90 -0.006 0.013 0.005 0.002 0.000 (0.001) (0.001) (0.001) (0.000) (0.000) Panel D: Identical regions receive different location shocks, initial min. wage is large Mean causal effect -0.058 0.129 0.062 0.037 0.018 Effective min. wage -0.059 0.092 0.024 0.000 -0.019 (0.002) (0.001) (0.001) (0.000) (0.001) Effective min. wage, p90 -0.059 0.112 0.043 0.019 0.000 (0.001) (0.002) (0.001) (0.000) (0.000) Notes: In all panels, the national minimum wage increases by 20 log points from the first period to the second. In Panels A and B, regions differ only in the location parameter rt, assumed to be constant over time. In Panels C and D, regions are identical in period one, but differ in r,t in period two. Each panel displays average results for 5,000 simulations, each with 50 regions. For each outcome, the numbers correspond to the mean true ATE across simulations, the mean estimates of causal effects based on the regressions listed on the left, and the average standard error associated with the estimates (in parentheses, clustered at the region level). 12",
    "Lemma 3.4. Under the hypothesis of Theorem 3.1, for every po > 2 there exists a constant C1 such that for all p > po and ( E C(IRn; IR>o) l|V(C||p/2)|I2<C1pll(IVC|+S)ly|p/2ll2 (29) where a = ( + 1)/2. Proof. The proof of this lemma is based on (22) and it follows the proof of (Theorem 5.1 in [0]). Note that (22) becomes useless for p = 2. Agmon works with the stronger inequality (19), which doesn't degenerate at p = 2. By fixing a number po > 2 and looking at numbers p > Po we can reuse Agmon's proof. From (22) and Holder's inequality it follows that (p-2) dx c2|y|P-2|V||2<2Jdx c2||P-2|V||2) dx|VSl2||P i|p|-bzS  Using (26) this can be rewritten as I(a(z/dl+1)ql7|xp]) z/1(alz/dl?lSlz5 xp]) Ez>zlz/d|P|lSlz3 xp] (z-d) dx C2q-(|y|P/2)2 =C Note that by Lemma 3.3 and assumption (13) all integrals are finite. The above inequality is equivalent to Next, we use that p/(p - 2)  po/(po - 2) =: Do for p > po and AB  8A2 + B2/8 for all  > 0: A2< Do 8A2 P DoC B2.+DoC. We choose  = 1 2Do ,so that A2 2D?B2+ DoC Using a + b  a + b it follows that Do A <2D,B + p 10",
    "Table 3: BLEU score for 4 language pair model 1. The rows are the source language and the columns are the target language. Cells in bold represent the translation directions used in training  kn ml te ta kn 7.7 1.0 0.8 ml 8.9 5.7 0.6 te 0.5 3.2 7.4 ta 5.8 4.9 7.4 4.3 4 language pairs A single encoder-decoder model is trained on 4 language pairs. We run experiments with 3 types of language pair combinations: : Model 1: 2 unique language pairs in forward and reverse direction: kn<> ml,te > ta. Results documented in. Table 3 : Model 2: 4 unique language pairs: kn->ml, ml->te, te->ta, ta->kn. Results documented in Table 4 : Model 3: 4 unique language pairs with VOLT: kn->ml, ml-->te, te->ta, ta->kn. Results documented in Table 5 Both techniques expose the model to 1/3 of the total translation directions during training but the first technique is built to test model performance in very low resource conditions; when there are only 2 sources of parallel corpora available. In comparison, the second model is exposed to 1/3 of the total translation directions with each source-target language combination being unique. We ensure that in every model, both the encoder and decoder see each language atleast once during training. We observe that BLEU score for zero-shot translation lags by 5.03 on average compared to the performance of trained language pairs when we train on both directions of 2 language pairs only. In comparison, the zero-shot translation BLEU score lags by 5.98 BLEU on average for the model trained on 4 unique language pairs. The BLEU score for trained translation directions is always in the 6-8 BLEU range. The 4 language pair model trained with VOLT outperforms both from the trained directions. Table 4: BLEU score for 4 language pair model 2. The rows are the source language and the columns are the target language. Cells in bold represent the translation directions used in training  kn ml te ta kn 7.4 0.4 0.5 ml 1.0 7.0 0.4 te 0.8 4.7 7.1 ta 8.9 4.5 0.6 Table 5: BLEU score for 4 language pair model 3. The rows are the source language and the columns are the target. language. Cells in bold represent the translation directions used in training.  kn ml te ta kn 6.5 4.5 0.8 ml 6.8 6.4 5.5 te 0.7 2.4 6.6 ta 8.1 1.7 4.5 4.4 6 language pairs all 6 language pairs. The model now sees 1/2 of all possible translation directions during training. Table 6 shows the results obtained from the 6 language pair model.. We observe that zero-shot translation performance increases drastically. Zero-shot directions now lag by 1.76 BLEU to. the trained translation directions. 5",
    "(a) (c) DC/SFQ Convert er Drive Freque DC/SFQ Conv (~1.42GHz) (~1.42GHz) Readout Frequency (~f) (~f) (b) f (d) f. 30 (srl)ods) 20 20 10 15 15 6.9506.952 6.954 6.9566.958 6.950 6.9526.9546.9566.958 f,(GHz) f.GHz FIG. 8. (a) Pulse sequence applied to measure qubits state after an SFQ pulse train. The transmission of the readout resonator is measured at fr. (b) Qubit readout resonator spectroscopy vs. DC/SFQ converter drive pulse duration tsFq. (c) Pulse sequence applied to measure qubits state with variable delay tdalay after a 25s SFQ pulse train. The transmission of the readout resonator is measured at fr. (d) Qubit readout resonator spectroscopy vs. delay between SFQ circuit operation and readout pulse tdalay. The frequencies corresponding to the readout resonator when the state of qubit is (0), (1), and punch out have been marked. states. As shown in Fig. 8 (c) and (d), the qubit grad 18 ually relaxes to (0) after the SFQ operation. Therefore, 16 tavg= 0 when the  pulse is applied to the qubit immediately af- t=3 S 14 ter the SFQ operation, the qubit cannot be completely =6 S excited to the (1) state. As the recovery time prolongs, 2  12 S the population of (1) after the  pulse also gradually in- 18 s creases to 1. '86' 4 0 2040 60 80100120140160 Appendix C: Extraction of Quasiparticle Density (srl)  Near Qubit FIG. 9. Effect of measurement time on the extracted xQP,qubit evolution To)/C is a kind of average QP density during the T1 measurement, which can be regarded as the average den- sity of QP over a period of time tavg (~ T1) after tR. To Appendix D: Diffusion of Quasiparticles in Superconducting Quantum-Classical Hybrid Circuits tion extracted in this way to analyze the QP propagation Most QPs propagate diffusively when the local QP density is relatively low. The local QP density is surement, and (ii) the xQP,qubit extracted with several xQp = nQp/ncp, where nQp is the QP density and ncp microsecond measurement times (tavg = 3, 6, 12, 18 s) the Cooper pair density. As the local QP density in- in a real experiment. We assume that the gray curve creases, QPs have a greater probability of recombination, (tavg. = 0) in the Fig. 9 below, which is similar to the and phonon-mediated propagation becomes the leading mechanism. We calculated the diffusion equation by fi- text, is the real QP density evolution. The trends and nite element simulation, thereby estimating the contri- bution of QP diffusion to the QP propagation in the vary little over all values of tavg listed. device described in the paper. We set a boundary of.",
    "4 V. Burgin et al. the other cliques, ensuring a fully connected graph. All nodes and edges are associated with information through embeddings, described below. GNN stage The second stage employs a generalized message-passing GNN following [5] to perform several prediction tasks on this graph simultaneously: 1. keypoint association prediction: we model association between body keypoints and their corresponding pedicle keypoints as binary edge classifi- cation on the over-connected k-NN graph. 2. body keypoint level prediction: for body keypoints, we model the spine level prediction as multi-class node classification. 3. keypoint legitimacy prediction: to filter out false-positive keypoints, we additionally compute an binary legitimacy prediction for each node. To perform these task, our message-passing GNN maintains edge and node em-  beddings which are updated in each layer. A message-passing layer performs a node update and edge update operation. Denoting the feature vector of a node v by xy, and the feature vector of a directed edge (u,v) by xuv, the node and edge features are updated as follows: x'u = D Ynode(xu,xx,xuv), xuv = Wedge(xu,xy,xuv) (1) vENU{u} Node update Edge update Here  denotes a symmetric pooling operation (in our case max pooling) over the neighborhood Nu. node and edge are trainable parametric functions: in our case, two distinct two-layer MLPs with ReLU nonlinearities. After N such message-passing layers we obtain an embedding vector for each node and edge. Each node/edge embedding is passed through a linear layer (distinct for nodes and edges) to obtain a vector of node class logits or a single edge prediction logit, respectively. The last entry in the node prediction vector is interpreted as a node legitimacy prediction score: nodes predicted as illegitimate are discarded for the output. The node input features xu E R7 consist of the one-hot encoded keypoint type (body, left or right pedicle) and the segment input information (a pseudo- probability in [0,1] for each of the four spine segments of belonging to that segment, computed by applying a sigmoid to the heatmap network's output channels which represent the different spine segments). The edge input features xuv E R4 consist of the normalized direction vector of the edge and the distance between the two endpoints. The output of the GNN contains finer spine-level classification (i.e. C1-C7 T1-T13, L1-L6, S1-S2), keypoint-level legitimacy (legitimate vs. false-positive detection) and body-pedicle association via edge prediction, implicitly defining the orientation of each vertebra. Prediction scores of corresponding directed edges u, and ,u are symmetrized by taking the mean. In our experiments we consider variations to our architecture: weight sharing between consecutive GNN layers, multiple heads with a shared backbone (jointly trained) and dedicated networks (separately trained) for edge/node prediction.",
    "5 taking  ->  + 0+, where we add infinitesimally small The integral over y can be calculated in terms of the imaginary part as it is required in the retarded Green's complete elliptical integral of the first kind K(x) using. function. Then a = ( + 0+)2 + ... gets small imaginary the identity (3.131.5) from [20] part 2o+ defining the value of csgn. Taking the limit of infinitisimal 0+ we arrive at the following expression dy for the trace of the Green's function V(u3-y)(y-u2)(y-u1) 22 for a2>b2 2 u3-u2 TrG() = dky 13) (16) sgn for a2  b2. u3-u1 u3-u1 b2-a2 where we used the fact that the integrand is an even where u3 > u2 > u1. In Eq. (15) these parameters are function of ky. Here the values a and b are the func- u1 = -1, u2 = yo, u3 = 1 and the result of integration is tions of the variables ky and  and the parameter m as equal to 2K (1  yo)/2]. Then the DOS for |m] = 1 determined by Eqs. (10). The DOS is proportional to the imaginary part of is TrG(), therefore it is nonzero only in the region of  y^g* '6>zU>I J! where P|m|=1() = a2-b20. 0, Otherwise. (14) (17) Outside the region (14) TrG is real and the DOS is equal For convenience, in the Appendix A we provide the def- to zero, i.e., p) = 0. initions of the elliptic integrals. The next step in evaluation of Eq. (13) is to perform integration over ky. It is convenient to replace y = cos ky and dky = -dy(1 - y2)-1/2. The boundaries of the in- 2. Case |m|>1 tegration are -1 < y < 1, where changing the order of To calculate the DOs for all other values of the pa- the integration boundaries results an additional minus sign. The integration over y is performed differently de rameter m we need first to analyze the function in de- pending on the value of the parameter m. Therefore, in nominator of Eq.13).For m| 1 we can write a2-b2 = 4(m2-1)(y-y1)(y-y2). Here the left and right what follows we are considering three cases with |m| = 1, zeros of the function are denoted as y1 = min(y1, 92) and [m| > 1, and m] < 1, separately. y2 = max(y1, 92), respectively, where. 2-1-(m+1)2 1. Case |m|=1 y1= 2(m+1) Calculations are simpler in the special case of |m| = 1. 2-1-(m-1)2 y2= (18) The function in the denominator of the integral (13) can 2(m-1) be written explicitly as a2 - b2 = (2 -1)(2 - 5- 4my). So we have to set y1 = y1, y2 = y2 if the the following It is linear in y and changes the sign only once at the point y = yosgnm, where yo = (2 - 5)/4.  Solving condition is met the condition 14) with respect to  and using the fact that |y|  1 we obtain that DOS is nonzero only for (19) m2 -1 13. The condition (14) considered with respect to y de- and to set y1 = y2, y2 = y1, otherwise.. termines the boundaries of integration in Eq. (13). For Lets consider the case [m| > 1, then factor m? - 1 is m = 1 it is satisfied for yo  y  1.Then the imaginary positive. Rewriting Eq. (13) in terms of variable y and part of Eq. (13) in terms of variable y gives the DOS in substituting it in Eq. (7), we obtain the nonzero DOS in the implicit form the implicit form 2 dy dy =(U)d (15) =(U)d 20 2N2 _ 2m2-1 (1-y2)(y1-y)(y-y2) where the definition (7) is used. The similar expression Here the boundaries of integration are determined by will appears for m = -1: the boundaries of integration Eq.14), which reads y1  y  y2, implying |y| 1. are -1  y  -yo and denominator in the integrand There are two cases, in which these conditions can be is (1 - y?)(-y - yo). The corresponding DOS can be satisfied by the integration variable y:. transformed into the result Eq. (15) by replacing the in- ly1|<1,|y2|>1, tegration variable y  -y. So Eq. (15) is valid for both. ly1|>1,|y2|<1. (21) cases m = 1.",
    "[9] Sun, Y., Wang, Z. J., and Liu, Y., \"Spectral (Finite) Volume Method for Conservation Laws on. Unstructured Grids VI: Extension to Viscous Flow,\" Journal of Computational Physics, Vol. 215, No. 1, 2006, pp. 41-58. [10] Huynh, H. T., \"A Flux Reconstruction Approach to High-Order Schemes Including Discontinu- ous Galerkin Methods,\" AIAA Paper No. 2007-4079, 18th AIAA Computational Fluid Dynamics Conference, Miami, FL, USA, June 2007.. [11] Huynh, H. T., \"A Reconstruction Approach to High-Order Schemes Including Discontinuous Galerkin for Diffusion, AIAA Paper No. 2009-403, 47th AIAA Aerospace Sciences Meeting In- cluding The New Horizons Forum and Aerospace Exposition, Orlando, FL, USA, Jan. 2009. [12] Roe, P. L., \"Characteristic-based schemes for the Euler Equations,\" Annual Review of Fluid Me-. chanics, Vol. 18, 1986, pp. 337-365. [13] Kopriva, D. A. and Kolias, J. H., \"A Conservative Staggered-Grid Chebyshev Multidomain Method. for Compressible Flows,\" Journal of Computational Physics, Vol. 125, 1996, pp. 244-261. [14] Lomax, H., Pulliam, T. H., and Zingg, D. W., Fundamentals of Computational Fluid Dynamics, Springer-Verlag, Heidelberg, 1st ed., 2001, p. 249. [15] Romero, J., Asthana, K., and Jameson, A., \"A Simplified Formulation of the Flux Reconstruction Method,\" Journal of Scientific Computing, Vol. 67, 2016, pp. 351-374.. [16] Hirsch, C., Numerical Computation of Internal and External Flows - Volune 1: Fundamentals of. Numerical Discretization, John Wiley & Sons, Chichester, 1st ed., 1988, p. 515.. [17] Roe, P., \"A Simple Explanation of Superconvergence for Discontinuous Galerkin Solutions to ut + Ux = 0,\" Communications in Computational Physics, Vol. 21, No. 4, 2017, pp. 905-912.. RESPONSIBILITY NOTICE The authors are solely responsible for the printed material included in this paper.. 15",
    "9 further, the time scales becomes sequenced as for |z|> 1 and tc-t<t<tp<tc+t, (48) 2m/2 2+#Vtz+O(z2), where the system enters into the S regime. The scenario Dm(z) = r(-m) r(-) A5 of the adiabatic-impulse approximation is illustrated in Fig. 7. for |z| > 0. ACKNOWLEDGMENTS Furthermore, in numerical simulations, the time- We thank Yan He for useful discussion. This work is dependent parameter should start at a finite value. We. supported by NSFC under Grants No. 11074177. choose a sufficiently large but finite initial transverse field, so the initial conditions of Eqs. (A1) and (A2) can be expanded into a powers of 1/gi, Appendix A: Solution of TDBdG equations We can solve the TDBdG equations given by Eq. (6) exactly by mapping them to the Landau-Zener problem. +O (A6) 4g Then, the time-dependent Bogoliubov coefficients can be vq(ti)2=1-uq(ti). (A7) given by Based on this approximation, the two constants, Ci and Vq(z) =CjD-sg-1(iz)+C2D-sg-1(-iz) (A1) C2, can be expressed as ein/4 uqz)= ) Vq(z) (A2) VQsinq(dz+2) |Ci|2 = uq(ti)2 e-3rq sin? qTQ sin? q (A8) with free complex parameters Ci and C2. Here, |C2l2 = 0, (A9) Dm(z) is the complex parabolic cylinder function, z = 2TQrq duce the above rigorous solution, we need to apply the for |zi|>1, and asymptotes of Dm(z) that are given by [89] Dm(z) = e-z2/4zm, V|arg(z)|<3n/4, (A3) 2 Dm(z) =e-z2/4zm r(-m) V-5/4argz-/4, (A4) for |zi| 1, where zi is defined by Eq. (9) [1] T. W. B. Kibble, Journal of Physics A: Mathematical [10] R. Monaco, J. Mygind, and R. J. Rivers, Phys. Rev. Lett and General 9, 1387 (1976). 89, 080603 (2002) [2] T. W. B. Kibble, Physics Reports 67, 183 (1980) [11] A. Maniv, E. Polturak, and G. Koren, Phys. Rev. Lett. [3] W. H. Zurek, Nature 317, 505 (1985). 91, 197001 (2003). [4] W. H. Zurek, Acta physica polonica. B 24, 1301 (1993) [12] L. E.Sadler, J. M.Higbie, S. R.Leslie, M.Vengalattore, [5] W. Zurek, Physics Reports 276, 177 (1996). and D. M.Stamper-Kurn, Nature 443, 312 (2006). [6] I. Chuang, R. Durrer, N. Turok, and B. Yurke, Science [13] C. N.Weiler, T. W.Neely, D. R.Scherer, A. S.Bradley, 251, 1336 (1991). M. J.Davis, and B. P.Anderson, Nature 455, 948 (2008). [7 M.J.Bowick, L.Chandar,E.A.Schiff, and A.M.Sri- [14] D. Golubchik, E. Polturak, and G. Koren, Phys. Rev.. vastava, Science 263, 943 (1994). Lett. 104, 247002 (2010). [8] V. M. H. Ruutu, V. B. Eltsov, A. J. Gill, T. W. B. Kibble, [15] G. D. Chiara, A. del Campo, G. Morigi, M. B. Plenio, and M.Krusius, Y. G.Makhlin, B.Placais, G. E. Volovik, and A. Retzker, New Journal of Physics 12, 115003 (2010). W. Xu, Nature 382, 334 (1996). [16] S. M. Griffin, M. Lilienblum, K. T. Delaney, Y. Kumagai, [9] C.Bauerle, Y. M.Bunkov, S. N.Fisher, H.Godfrin, and M. Fiebig, and N. A. Spaldin, Phys. Rev. X 2, 041022 G. R.Pickett, Nature 382, 332 (1996). (2012).",
    "Figure 3: Construction of BQ(l, 2k - 1) Figure 4: BQ(2,3), presented two different ways. Proposition 2. Given integers l and k where l,k > 2, the shortest negative cycle of BQ(l, 2k - 1) is of length min{2l, 2k}. Proof. We first present two natural choices for a negative cycle, one of length 2k and another of length 2l. of the two paths using only the negative edges that connect the two layers. This would result in a negative cycle of length 2k. The second negative cycle we consider is by taking a positive edge and connecting each of its ends to the vertex u by a shortest path (all edges negative). One of these paths will be of length l and the other would be of length l - 1. Together with the first chosen edge itself then, they form a negative. cycle of length 2l. It remains to show that the shortest of these two types of cycles gives us the negative girth. To that end. a contradiction, let C be a negative cycle with more than two positive edges. We aim to present a negative cycle C' whose length is at most |C| - 2. We take two positive edges of C that come consecutively on the cyclic order. Assume xy and x'y' are these two edges and that x' is followed by y in the cyclic order of C (that is to say, there is no positive edge in the x' - y path in C). We remove the two positive edges xy and x'y' and the x'y path connecting them in C, but then we add a xy' copy of this path (which also has. no positive edge). The result is a closed walk whose sign is the same as that of C, and whose length is |C| - 2. But then this closed walk must contain a negative cycle, whose length then is also at most |C| - 2, a contradiction.",
    "For a set E, E denotes its interior and E its closure. For E C d, C=[0, oo) denotes the set of continuous functions from [0, oo) to E and Dp[0, oo] denotes the set of cadlag functions from [0, oo) to E For E C d, P(E) denotes the set of probability measures on E. For a stochastic process Z. {F2} denotes the filtration generated by Z, i.e. FZ := o{Z(s), s  t} 2  Formulation of the problem and preliminaries. Let W C d be a piecewise smooth cone with vertex at the origin i.e.. W:=Wj,Wj:={x=rz,zESj,r>0}, (1) where S, is a nonempty domain in the unit sphere Sd-1 with C2 boundary. Clearly. W={x=rz,z ES,r>0}, where S:=S (2) It is supposed that The object of this work is the semimartingale obliquely reflecting Brownian motion (ORBM) in W with drift b, dispersion matrix o and radially constant direction of reflection g' on each face, i.e. for x E QW, -{0}, x = rz, z E 0Sj, g(x) = g(z), (3) for some unit vector field g' defined on dS,. This process can be defined as the solution of the following stochastic differential equation with reflection:. X(t)=X(0)+bt+oW(t)+Jy(s)dX(s), t>0, y(t)EG(X(t)), ly(t)|=1, dX-a.e., t0, (4) X(t) EW, X(t)=f11aw(X(s))dX(s), t0, where G(x)={gg=ujg'(x),u0},J(x)={jxEAWj}xEaW-0, jEJx (5) G(0) := the closed convex cone generated by {g(x), x E (aW, n W) - {0}, j = 1, ..: , m} 4",
    "Lemma 1.1. [0] If G is a graph such that for u, v E V(G), uv  E(G), then p(G) < p(G + uv). Let A be a real symmetric matrix whose rows and columns are indexed by V = {1, 2, .:. , n}. Let {V1, V2, ..: , V} be a partition of V such that the block partition of the matrix A according to {V1, V2,..: , V} can be expressed as [A1 A12 ... Ak A21A22 A2k ... A= : : ::. Ak1 Ak2 ..Akk where A, denotes the block formed by intersection of the rows in V, and the columns in V,. Let qi;(A) denote the average row sum of A;. Then, the quotient matrix of A with respect to the partition {V1, V2, .:. , V} is given by Q(A) =[9ij(A)]. Moreover, if the row sum of each block Ay, is constant then we say that the partition is equitable and Q(A) is called an equitable quotient matrix of A. There is a nice relation between the spectrum of A and that of Q(A), which is stated now as a theorem. Theorem 1.2. [0] Let A be a real symmetric matrix such that it has an equitable quotient matrix Q(A), then, o(QA)) C o(Q(A)).Moreover, if A is nonnegative, then p(A) = p(Q(A)), i.e., the spectral radius of Q(A) is actually the spectral radius of A. A vertex v of a connected graph G is a cut vertex of G if G  v is disconnected. A block of the graph G is a maximal connected subgraph of G that has no cut-vertex. Given two blocks . F and H of graph G are said to be adjacent if they are connected via a cut-vertex. We denote F o H, to represent the induced subgraph on the vertex set of two adjacent blocks F and H. A complete graph is a graph where each vertex is adjacent to every other vertex. A complete. graph on n vertices is denoted by Kn. A connected graph is called a clique tree if each of its blocks is a clique. Let G be a clique tree with d1 blocks of Kn1, d2 blocks of Kn2, so on up to dh blocks the above notation only gives information about the blocks of G, but not about the structure of the graph. But for a special case, if G has a central cut vertex, then all the blocks are adjacent via the central cut vertex and we denote it by G = K(d1) o K(d2) O... O K(ds) A block H of a clique tree G is a pendent block of G if H has exactly one cut-vertex of G. Let v be a cut-vertex of G. If G - v consists of two disjoint graphs W1 and W2 and let G(i = 1,2). be the subgraph of G induced by {v} U V(Wi), then G is called the vertex-sum at v of the two. graphs G1 and G2, and denoted by G = G1 , G2. For a vertex v in a graph G, the block index of v is the number of blocks which share the vertex v and is denoted by big(v). The spectral radius of a graph has been extensively studied subject to various graph theoretic constraints. In spectral graph theory, the maximization and minimization of the spectral radius of a given class of a graph and the problem of determining the extremal graphs find a particular interest among researchers. One such result due to Brualdi and Solheid in [0] is an important motivation for our study. In this article, the authors obtained the graphs that maximize the 2",
    "6 D. Al-Attar et al.. where Pw is the density of water and C the ocean function that equals one where water is present and zero otherwise. In the case of ice. loading, the direct term is given by. =Pi1-CI (2.12) where pi is the density of ice, and I the change in ice thickness. The factor, 1  C, within this expression accounts for the possibility of floating ice (e.g. Crawford et al. 2018, equations 31-34). Consider again a pair of solutions (u, $) and (u, $t) of the loading problem associated, respectively, to with loads  and o'. Here,. however, we assume that these loads are decomposed as in eq.(2.11) into water and direct terms that share a common ocean function. From the above expression for sea level change we can write uV+$=-gSL+g,uV+$=-gSL+ (2.13) and hence eq.(2.8) becomes (-gSL+$t)odS =..(-gSL+$g)o'dS. (2.14) The terms involving the constants g and  vanish due to conservation of mass, and so the identity simplifies to .. ASL' odS = .. ASLo' dS.. (2.15) If we now substitute into the equality the decompositions of the loads,  and o', we find SL(pwCASL+C) dS = SL(PwCASL+g)dS (2.16) and cancelling the terms symmetric in SL and SL we arrive at ASLt C dS = ASLCdS (2.17) am Again, this is a known result, being implied as a special case by the adjoint theory of Crawford et al. (2O18) for sea level change in a viscoelastic earth model. What is new is the explicit statement as a reciprocity theorem along with the more elementary derivation that has been facilitated by restricting attention to the elastic fingerprint problem. 2.4 Symmetry of the Green's function. Because the fingerprint problem is linear, its solution must take the form ASL(x) = G(x,x')C(x) dSx'; (2.18) for an appropriate Green's function, where we have added a subscript to the surface element to make clear which variable it is defined. with respect to. Suppose that, within eq.(2.17), we take",
    "decline in activity on Stack Overflow. We report the estimated effect of our difference-in-differences model in Table 1 and visualize the weekly estimates of the relative change in the Stack Overflow activity in Figure 2. Table 1 indicates that ChatGPT decreased posting activity on Stack Overflow by 15.6% (1 - e-0.17). These results are robust to changes in the controls and starting point of the data time series. We also tested for heterogeneity in subsets of the data: considering only questions (rather than counting both questions and answers) and posts on weekdays. In both subsets our estimates did not deviate significantly from the main result: we estimate a 12% relative decrease in questions and 14% relative decrease in posts on weekdays. (1) (2) 3 Number of posts. Number of questions Weekday posts Stack Overflow  Post-GPT -0.170** -0.112+ -0.149* (0.0607) (0.0619) (0.0636) Observations 1,150 1,150 1,150 R-squared 0.995 0.994 0.993 R-squared within 0.290 0.315 0.232 Outcome mean 16363 7273 13191 Outcome std. dev. 29088 12661 23685 Table 1: Results of a difference-in-differences model, estimating the change in activity observed weekly on Stack Overflow following the release of ChatGPT, relative to activity on four other platforms less likely to have been impacted. All regressions comprise platform fixed effects, week fixed effects, and platform-specific linear time-trends. The standard-error of the estimate clustered on month is reported in parentheses. Significance codes: ***: p < 0.001, **: p < 0.01, *: p < 0.05, +p0.1. Figure 2 shows that the impact of ChatGPT is increasing over time and is by the end of our study greater in magnitude than the average post-ChatGPT effect estimated in Table 1. By the end of April 2023, the estimated effect stabilizes at around 25%. Interestingly, ChatGPT use, in general, peaked around this time.3. 3https://www.similarweb.com/blog/insights/ai-news/chatgpt-bard/",
    ": stellar occultation events by (307261) 2002 MS4 Table 2: Target stars designation and geocentric coordinates at closest approach instant (UT) sorted by occultation date (day-month-. year). Propagated Frnrr Propagated Date Gaia DR3 Frnrr va Ka Spiamb AMS4 right ascension  declination Designation (mas) (mas) (mag) (mag) ..0 (km) (au) (hh mm ss.sssss)  09-07-2019 4253196402592965504 18 45 19.24565 0.15 -06 24 13.0031 0.12 15.00 14.15 0.19 45.62 4253186506987951104 18 44 07.57274 0.54 06 26 40.1240 0.46 26-07-2019 17.78 16.27 0.08 45.67 4253186477047835648 18 44 06.31756 0.13 -06 26 43.8948 II'0 15.45 11.66 0.98 45.68 19-08-2019 4253181804071259648 18 42 43.51905 0.24 -06 32 34.0868 0.19 16.51 16.59 0.05 45.88 26-07-2020 4253244201379441792 18 48 18.07372 0.12 -06 13 31.6134 0.12 14.76 12.61 0.47 45.60  08-08-2020 4253248324549054464 18 47 29.96384 0.12 -06 16 31.4727 0.10 14.62 11.13 1.19 45.70  24-02-2021 4253709191700784896 18 56 35.98731 0.25 -06 30 23.1569 0.23 16.51 12.96 0.53 47.05  14-10-2021 4252495635735083264 18 50 30.76176 0.31 -06 24 13.3375 0.27 15.83 13.44 0.34 46.52 10-06-2022 4253907305577009664 19 00 15.44628 0.23 05 42 42.9960 0.21 15.1 13.00 0.39 45.48 Notes. It is essential to mention that none of the stars have a duplicity flag in the Gaia DR3 catalog. () The magnitudes retrieved from NOMAD catalog and used in SORA to calculate the (b) stellar diameter (SDiam) at the (c) MS4's geocentric distance (ms4). 8 August 2020 dent points at the sky plane to fit the five ellipse parameters. The global elliptical limb is determined by minimizing the classical 400 2 function. The quality of the result is given by the x2 per degree of freedom xpaf = x2/(N - M)  1 for satisfactory fits, where N 200 is the number of points and M is the number of fitted parameters (wy) 6 (Gomes-Junior et al. 2022). A set of empirical tests' assuming 0 topography values between O and 10 km were performed and 200 considered. This result agrees with the theoretical approach pro- posed by Johnson and McGetchin (1973), which gives a lower -400 limit of 6 to 7 km for topography on MS4 (see Sect. 3.4). 500 0 500 f (km) 400 Fig. 1: Chords measured during the 8 August 2020 event show 200 the detection of MS4's limb in blue with 1o error bars (red seg- ments). Six positive chords with large error bars were suppressed (kn) 0 from this plot for better visualization: TAROT, Lleida, Khmel- nytskyi, Fuensanta de Martos, Kharkiv T36, and Marbella. The green lines represent positions compatible with the total target's N flux within the noise (i.e., no secondary occultation). The order 400 of positive chords, from north to south, is the same as in Table 3. E 600 -500-250 0 250 500 7501000 1250 cause the GPS was connected to the computer and it presented f (km) a large offset with respect to all close-by chords; 5) Artemis be- cause its length does not match the length of Catania's chord (at Fig. 2: Thirteen selected chords (blue), where GPS data are pre- 1 level), which probed exactly the same object's profile but is  sented in solid lines and NTP by dashed lines. Gray segments a bit larger. 6) Finally, Caussols, Ariana, and Kuban have larger show the other positive chords not used in limb-fitting. The black uncertainties than other chords that probed the same region. In ellipse shows the best elliptical limb, and the gray region the so- addition to the eight GPS data sets, we selected another five pos- lutions within 3o. The orange segments represent each image itive chords acquired from Meo station, Matraszentistvan, Hvar, acquired from the Montsec station and the light green segments Agerola, and La Palma. The main criteria for selecting the men- show other negative chords. tioned NTP chords were: data acquired with professional tele- scopes, low dispersion in the light curves, and the smallest un- Among the elliptical solutions inside the 3o region, we ex- certainties of the probed limb.. cluded those that crossed or approached the negative grazing Figure 2 presents the 13 selected positive chords (blue) over- chords within the tolerance level of 7 km (radial direction). plotted to the other positives (gray segments). Solid lines repre- Therefore, although the solutions cross the negative chord as sent GPS chords, while dashed lines show NTP data. The se- seen from Montsec (Fig. 2), they are inside the 7 km assumed lected data are ordered from north to south, as follows: Meo range. The area equivalent radius was calculated using the re- station (FRA), Valbonne (FRA), Matraszentistvan (HUN), Cat- lation Requiv = a' 1 - e'. Finally, the limb solution in Table 4 alonia (ESP), Massa (ITA), Rome (ITA), Hvar (HRV), Sassari ITA),Odesa (UKR),Agerola ITA),Algiers DZA),La Palma (ESP), and Canakkale (TUR). They provide N = 26 indepen- tion that considers topography in the limb fitting.. Article number, page 5 of 31",
    "Proposition 5.1 characterizes the slow dynamics of an N-spike quasi-equilibrium solution on the long O (e-: time-scale. We remark that this time-scale is longer than the O(e-2) time-scale of slow spike dynamics for the. GM and Gray-Scott models ([23], [8], [12]), where there are no chemotactic effects. In Appendix H, we show that j, as given in (5.17), can be calculated asymptotically by retaining only the contribution from the sub-inner solution. In particular, in Appendix H we provide the leading order estimate. 2 Bj for Vmax j > 1. (5.26) Vmax j Moreover, in Appendix H we show at the steady-state spike locations that ; = o Vj, with o given in (4.28) To illustrate our results, we now compare the dynamics computed from the DAE system (5.24) with corre- sponding numerical results computed from the full PDE system (1.2) using FLEXPDE7 [14]. In our comparison, we computed the integrals defining ; numerically from (5.17). The results for a one- and two-spike dynamics are shown in Figure 8 for the parameter values in the figure caption. In Figure 8a, where we chose the initial condition x(O) = -0.1, the asymptotic and numerical spike trajectories are favorably compared for a one-spike. quasi-equilibrium pattern. In Figure 8b a similar favorable comparison is shown for the case of two-spike dy- namics starting from the initial condition x (O) = -0.6 and x2(O) = 0.6. Slow motion of one spike Slow motion of two spikes 0.6 location (num) location (asy) 0.4 left location (num) -0.02 right location (num) left location (asy) 0.2 right location (asy) -0.04 -0.06 -0.2 -0.4 0.08 0.6 0.1 0.8 100 200 300 400 500 0 100 200 300 400 500 t t (a) one-spike slow dynamics (b) two-spike slow dynamics Figure 8: 5.1 Computation of Jacobian Matrix for Balancing Conditions In this subsection, and as remarked in $4, we show that when d e Te the matrix M in (4.29) arises from the. linearization of the DAE dynamics (5.24) in Proposition 5.1 about the steady-state spike locations. Our approach below is inspired by a related analysis for the GM model in [58]. To this end, we use the Green's function in (2.24) together with its decomposition in (5.20) to define xx=xgly-xR(x;y)j=k, dx G(xj,xk) := dx dx G(xj;xR) = (5.27) dx;dxzG(xj,xk), j#k. ax 32",
    "Models A and BSW [13] Experimental [78] 276 261 346.2  1.4 341 433  13 FV 384 Table 6. The decay constants of the vector mesons (in MeV) obtained in our work (same result for models A and B), compared against the result obtained using the soft wall model (Sw) [13]. In order to compare with experimental results of [78], we need to identify Fv with gp. where Sn(u) = e-Bssn(u). To get the normalization constant we first consider the asymptotic expansion of the normalizable solution, Sn(u), close to the boundary, Sn(u) = Nsnu3 +..., where Nsn is the normalization constant, which is obtained by plugging Sn(u) in (4.3). Then decay constants of the scalar mesons are given by the following dictionary [40] Fsn =Cu e3As- (4.4) We first investigate the behavior of the scalar meson decay constants as a function of the parameter ao in the chiral limit with the other parameters fixed as in model A. Our. numerical results are displayed on the left panel of Fig. 14. As can be seen from the plot,. the results show a smooth behavior of the decay constants in the region of interest, i.e., ao < ao, where ag ~ 0.0974. However, the behavior of the decay constant increases close to af for the ground state while it decreases for the scalar resonances. 700 j 700 600 600 500 300 400 200 100 300 0.10 0.05 0.15 0.20 500  1000 1500 2000 2500 3000 mq (MeV) Figure 14. Left panel: The decay constants of the scalar mesons as a function of ao in the chiral limit. Right panel: The decay constants of the scalar mesons as a function of the quark mass for  = 27, bo = 1.7 and ao = 0.02. In addition, we calculate the scalar meson decay constants as a function of the quark mass. Our numerical results are displayed on the right panel of Fig. 14. As can be seen from the plot, the decay constant increases in the region of small quark mass until it reaches some. maximum value and then decreases when the quark mass grows. Finally, we calculate the decay constant using the final set of parameters for models A and B displayed in Table 1. 21",
    "Conference'17, July 2017, Washington, DC, USA Hui Miao, Yuanfang Guo, and Yunhong Wang detection methods [9, 15, 29, 37] only focus on coping with presen. : We analyze the frequency spectrum of the real and generated tation attacks, which construct artificial fingers [34] to circumvent fingerprint images and construct a simple yet effective gen- the fingerprint recognition system. To model the physiological dif- eration artifact stream, i.e., a shallow convolutional neural. ferences between the artificial and real fingers, existing liveness network, to extract frequency-domain inconsistencies. detection methods usually rely on collecting the pulse rate, skin : Comprehensive experiments demonstrate that our method odor, finger elasticity, etc., from the sensor of the fingerprint recog is effective, efficient, and robust to the anti-forensic nition system. Unfortunately, the replacement attack, i.e., replacing method [11]. the real fingerprint images with the GAN-generated fingerprint images, usually happens after the fingerprint collection step and RELATED WORK the fake fingerprint images are generated without the defects of artificial fingers. Besides, the GAN-generated fingerprint images 2.1 Fingerprint Image Synthesis also exist some generation artifacts, which are induced by specific Several recent methods have been proposed for generating real- processing operations in GANs and does not exist in the captured istic fingerprint images automatically [3, 4, 12, 17, 35, 39, 44]. [3] impressions. Under such circumstance, the existing fingerprint live- and [35] combine a convolution autoencoder (CAE) and a GAN- ness detection methods can hardly be directly applied to detect the based method (e.g., DCGAN [38], wGAN [18]) directly. [4] presents GAN-generated fingerprint images.. a GAN-based pipeline followed by a stochastic search algorithm To efficiently and effectively identify the GAN-generated fin- over the latent variable space, to search for suitable latent variable gerprint images with decent robustness against the existing anti- and generate DeepMasterPrints which are synthetic fingerprints forensic method [11], in this paper, we propose a Robust deep and can be matched against a large number of fingerprints. These Forgery Detection method for GAN-generated Fingerprint images techniques can be considered as single-staged architectures, whose (RFDforFin). To take full advantage of the fingerprint characteris- input is a random vector and output is a generated image. tics and the generation artifacts of the fake fingerprint images, we To make the synthetic results more realistic and obtain mul- construct a lightweight yet robust two-stream neural network, by tiple impressions for a virtual identity, many multi-staged meth- exploiting the unique features of the fingerprint images and gen ods [12, 17, 39, 44] firstly synthesize a binary masterprint which eration artifacts in frequency domain. Considering the impact of. defines a ridge structure and represents a new identity. After non- sweat on grayscale variations along the ridges of fingerprints [10], linear distortion and cropping, which simulate various pressures we construct a special ridge stream which utilizes this unique fin and different contact regions between the finger and the fingerprint gerprint characteristic. In the generation artifact stream, inspired sensor, the distorted masterprint is fed into another generative neu- by [13], which discovers the obvious generation artifacts in the ral network to generate a realistic fingerprint image. The differences Discrete Cosine Transform (DCT) frequency domain, we transform between these multi-staged methods lie in the way of the master the input fingerprint image into different frequency domains, an-.  print generation scheme, the distortion simulation method, and the alyze the generation artifacts in these spectrum, and construct a final impression (fingerprint) generation approach. [12] utilizes the simple yet effective convolutional neural network to learn more GAN-based methods (e.g., BigGAN [5]) in these three steps. [17] robust generation artifacts between the generated and real images attempts to employ conventional rotation instead of the deep learn from the FFT frequency spectrum. To simultaneously utilize the ing method in the distortion module. [39] adopts StyleGAN2 [22] to features extracted from the ridges and generation artifacts in the fi- synthesize the fingerprint skeletons and CycleGAN [46] to generate nal prediction, we build a simple yet effective fusion module. Since photorealistic fingerprint images. [44] also proposes a CycleGAN- typical CNNs can learn certain frequency information from the input image or its frequency transformed spectrum, by utilizing firstly uses traditional methods (e.g., Anguli [1], Gabor filter) to the unique 1D ridge features jointly with the 2D generation artifact generate masterprints with pores and scratch. Besides, [44] releases features, our method can avoid overfitting to certain frequency a synthetic fingerprint database. information, which can improve the robustness of our method. Our main contributions are summarized as follows: 2.2Deep Forgery Detection Researchers have proposed a series of deep forgery detection approaches to detect the generated images [2, 7, 13, 23, 26- . We propose the first deep forgery detection method for 28, 30, 31, 33, 43]. [31] reveals that the texture statistics is an im- GAN-generated fingerprint images, by jointly exploiting the portant detection clue and global texture features can improve unique 1D ridge features and 2D generation artifact features the robustness of face forgery detection. [13] observes that GAN- via a lightweight two-stream neural network to ensure the generated images contain distinguishable artifacts in the frequency robustness and efficiency of the proposed work. domain due to the upsampling operations in the generator of GAN : We propose to exploit fingerprint-related characteristic and architectures, and these artifacts can be utilized for forgery detec- construct a ridge stream, which exploits the grayscale varia- tion. [28] attempts to explore the discrepancies in Learned Noise tions along the ridges. With this ridge stream, our method Patterns (LNP) to detect forgery. [30] concatenates spatial images can avoid overfitting to certain frequency information, which. and phase spectrums to emphasize the artifacts and proposes a can be easily interfered by existing anti-forensic method [11] Spatial-Phase Shallow Learning method. [26] captures frequency- and thus improves the overall robustness. aware features and merge them with the extracted spatial domain",
    "12 RANA BADREDDINE Remark 2.1. (1) It should be noted that for any potential u, the eigenvalues (vn) of Lu cannot be all simple. For instance, take u(x) = ex , one can easily check that for Lu =D-TuTu, Lu1 = Luex =0. (2) Inequality (2.7) implies that as n >> 0, the lower bound of the distance between two consecutive eigenvalues vn gets closer to 1. Proof. All the presented inequalities are a direct consequence of the max-min principle An=max min{<Luh|h);hEFnH(T),l|h|z2=1 lim F Vn = max min{<Luh|h); h E F-nH(T),|h|z2 =J lim Fr Spectrum of Lu. Let F be any subspace of L?(T) of dimension n, and consider E := C1  S(F), where S is the shift operator, then An+1 min{{Luh|h);l|h|z2 =1, h E En H} Observe that E = S (F) , thus by (2.2), An+1 min{<Lug|g)+1+|<Sg|u)l; l|gl|z2=1, g E Fn H In addition, since |(Sg|u)|2  0, we infer for all n E N>o ; An+1An+1. Spectrum of Lu-Inequality (2.6). let F be any subspace of L?(T) of dimension n, and take G:= C1  S(F) + Cu. Then, Vn+2(u)  min{{Luh|h) ;|h|z2 =1, h E GnH} Since G = S (F-n (S*u)), then Vn+2 min{{LuSg|Sg); l|g|lz2 =1, g E Fn(S*u)n H3(T) Note that g 1 S*u, then by (2.2),. (L)HU(n*S)UI 3 6I= z7|6|| I+{6|6nT)} u!W Z 3+un leading to Vn+2Vn+1.",
    "From embedding Ln-2(Q)  Ln-2(i-o)() and D(A'2) > Ln-2(i+o)(Q), (1.10) and the Young inequality, we conclude. (f1(v1(t),Av2(t))<C [(1+|v1(t)I)|Av2(t)|dx n-2+20 () (4.72) Using (1.7), we derive. l<f(u(t))- f(v1(t),Av2(t))]<C f|(f'(1- )u(t)) + v1(t))|u(t) -v1(t)||Av2(t)|dx (4.73) <C f(1+|u(t)|n-2+|v1(t)|n2) |v2(t)|Av2(t)|dx, where 0 <  < 1. Noticing u(t) = v1(t) + v2(t), it follows that. |u(t)|n=2|v2(t)]|Av2(t)|dx<C f (lv1(t)|n=2 +|v2(t)|n=2) |v2(t)|Av2(t)|dx. (4.74) Hence, from Lemma 2.11, the Cauchy and Young inequalities, we obtain there exists positive constants C4 and C5 such that. |v2(t)|Av2(t)|dx <C4 +Cs||A2\" v2(t)|l2. (4.75) Conducting similar calculations to (4.72), then by Corollary 4.8, we deduce. <C|A2v1(t)||n-2|A't\"v2(t)|2 (4.76) 26",
    "4. TinySiamese Network The proposed TinySiamese neural network takes on a new look and a. new way of working which is different from the standard Siamese network. The difference first appears in the input processing of the network. Instead of having images as input, the input was the output feature vector of a pre- trained CNN model. In other words, all input images would be transformed into feature vectors using a feature extractor (such as a pre-trained CNN model) as illustrated in Fig. 3. Then, the Tiny-Siamese encoded the fea- tures in a small set of layers and finally calculated the distance between two encoded feature vectors and generated similarity score. Using this score, the model was trained from scratch with the Adam optimization algorithm and. binary cross-entropy loss function. Figure 3: The Proposed Architecture Based on TinySiamese Network for Verification. 4.1. Architecture Unlike the standard Siamese, the input of the TinySiamese was the en- coded image as a feature vector. The backbone layers first aimed to extract relevant features using a linear fully-connected layer and a ReLU layer and then amplify them using another linear fully-connected layer and Sigmoid layer. The output size of the first linear layer had the half size of the input. (n, n/2) and was followed by a non-linear ReLU layer. The second linear layer took n/2 features in input and came back to the same first input size in output (n/2, n). This layer was followed by a non-linear Sigmoid layer. The outputs of the TinySiamese sub-networks were encoded into an n-dimensional vector using inputs of a size equal to n. Siamese networks are usually trained. 8",
    "Natural Language is All a Graph Needs Ruosong Ye Caiqi Zhang Runhui Wang Rutgers University University of Cambridge. Rutgers University ruosong.ye@rutgers.edu cz391@cam.ac.uk runhui. wang@rutgers.edu Shuyuan Xu Yongfeng Zhang Rutgers University Rutgers University shuyuan.xu@rutgers.edu yongfeng.zhang@rutgers.edu Abstract The emergence of large-scale pre-trained language models, such as ChatGPT, has revolutionized various research fields in artificial intelligence. Transformers- based large language models (LLMs) have gradually replaced CNNs and RNNs to unify fields of computer vision and natural language processing. Compared with the data that exists relatively independently such as images, videos or texts, graph is a type of data that contains rich structural and relational information. Meanwhile, natural language, as one of the most expressive mediums, excels in describing complex structures. However, existing work on incorporating graph learning problems into the generative language modeling framework re- mains very limited. As the importance of large language models continues to grow, it becomes essential to explore whether LLMs can also replace GNNs as the foundation model for graphs. In this paper, we propose InstructGLM (Instruction-finetuned Graph Language Model), systematically design highly scalable prompts based on natural language instructions, and use natural language to describe the geometric structure and node features of the graph for instruction tuning an LLM to perform learning and inference on graphs in a generative manner. Our method exceeds all competitive GNN baselines on ogbn-arxiv, Cora and PubMed datasets, which demonstrates the effectiveness of our method and sheds light on generative large language models as the foundation model for graph machine learning.. 1Introduction Before the advent of Transformers [1], various artificial intelligence domains with different inductive biases had diverse foundational model architectures. For instance, CNNs [2, 3] were designed with considerations for spatial invariance in images, leading to superior performance in computer vision tasks [4, 5]. Memory-enhanced models like RNNs [6] and LSTM [7, 8] were widely used for handling sequential data such as natural language [9] and audio [10]. Graph Neural Networks (GNNs) excel in capturing topological information by employing message passing and aggregation mechanisms, making them a preferred choice in the field of graph learning for a long time [11-13]. In recent years, the AI community has witnessed the emergence of numerous powerful pre-trained Large Language Models (LLMs) [14-18], which are driving huge advancements and lead to the pursuit of possible Artificial General Intelligence (AGI) [19]. Under this background, there is a trend towards unification in model architectures across different domains. Specifically, pre-trained Transformers have demonstrated remarkable performance on various modalities, such as images [20] and videos [21] in computer vision, text in natural language processing [22], structured data in graph machine learning [23], decision sequences in reinforcement learning [24], and visual-text pairs in multimodal tasks [25]. There has even been Transformers capable of handling twelve modalities [26] Besides model architecture, the unification of processing method in handling multimodal data is also a significant trend worth attention. T5 [15] established a text-to-text framework, unifying all NLP Preprint. Preliminary work..",
    "each root subgroup may be expressed in terms of commutators of other root subgroups. If some commutative unital ring K acts on the root subgroups in a natural way, then the resulting odd form ring (R, ) is an augmented odd form K-algebra and in the last claim of the theorem the maps of the root subgroups are isomorphisms. The Chevalley commutator formula is [Ga,G]II Gia+j ia+jE ij{12} we also assume that G2  G are 2-step nilpotent filtrations for any ultrashort root a. In other words, G is a group with BCe-commutator relations in the sense of [8]. Alternatively, we may assume only that G contains groups indexed by a root system of type Be ando. [Ga,G] II Gia+jB ia+jE ijER+ These formulas turn out to be equivalent (modulo other natural conditions) up to a choice of the nilpotent filtrations G2  Ga. The paper is organized as follows. In section 2 we recall the definitions of odd form rings and associated unitary groups. In sections 3 and 4 we list the precise conditions on G and its subgroups. Namely, the conditions are (C1)-(C5) without using a commutative unital ring K or (C1)-(C8) involving K. In section 4 we also discuss the case l = 3: under additional \"associativity conditions (A1)-(A4) the main results still hold, otherwise there are counterexamples (e.g. Chevalley groups of types E6 and E7). These associativity conditions always hold for l  4 by theorem 1. Sections 5 and 6 contain the proof of the main theorem 2 for groups satisfying (C1)-(C8). In the last section 7 we prove theorem 3 for groups satisfying only (C1)-(C5) Odd form groups and odd form rings 2 In this paper we build a lot of 2-step nilpotent groups with various operations so it is useful to develop some technique to simplify such constructions. The group operation of 2-step nilpotent groups is usually denoted by +. All lemmas in this section may be checked directly or using the machinery of polyquadratic maps [14, $1.3]. We say that (M, H) is a hermitian group if M and H are abelian groups, there is an automorphism. () : H  H of order at most 2, and there is a biadditive pairing (-, =) : M M -> H such that- (m,m') 3",
    "4 ones where there are only a few particles, we opt to first 600 sliced sim- ulated showers the mean value of the spectral parameter and the corre- V shower sponding standard deviation. If a bin contains less than two data points, which can occur because not all showers Decompose trace might contain particles in that slice, we do not consider into GEO/CE it for the parabolic fit. All the other bins are then fed to in every antenna a least-squares fitting routine. We end up with a spectral function describing the spectral parameter value as func- V slice tion of the shower Xmax in a given slice, for a particular Calculate amplitude antenna,  frequency spectrum a(rant,Xslice,Xmax) = p+piXmax + p2Xmax b(rant,Xslice, Xmax) = po+ pi Xmax +p2 Xmax Fit parametrised crant,Xslice,Xmax)=po+piXmax+p2Xmax function to spectra Spectral coefficients In Figure 3 we present a schematic overview of how we extract the spectral functions. These need to be de- termined only once for the air shower geometry under Relate spectral consideration. Generalising them to arbitrary geometries coefficients to Xmax of the shower will be the subject of future work.. C. Construction of the template Fit 2nd de- gree polynomial Spectral functions The final ingredient of template synthesis, is the tem- plate itself. With this object and the spectral functions, we have all the necessary information to synthesise the FIG. 3. Schematic overview of how we extract the spectral emission from an air shower with arbitrary longitudinal functions from our simulation set. In every antenna, we de- profile. compose the emission from every slice in the geomagnetic In order to construct our template, we use a single mi- GEO) and charge-excess (CE) components. These are then croscopic simulation called the origin shower. The origin fitted using Equations (4) and (5) respectively. Finally, we fit is a microscopic simulation, sliced using the same proce- The result of this are the spectral functions. dure as the simulation set that was used to extract the spectral functions. From the origin shower we calculate the amplitude frequency spectrum Aorigin and phase fre- quency spectrum $origin in each antenna and every slice, the spectral coefficients. We can fit this dependency of as shown in Figure 4. Using the spectral functions with the coefficients in order to obtain the spectral functions the Xmax of the origin shower, we can normalise these to obtain the spectra of the template, a(rant, Xslice, Xmax) , b(rant, Xslice, Xmax) , crant,Xslice,Xmax), AtemplateTant, f, Xslice) = Aoriginrant,f, Xslice) . A(rant, f, Xslice Xorigin) in every slice. This procedure is applied to each antenna independently, indicated by the explicit dependency on $template(rant, f, Xslice) = $origin(rant, f, Xslice) the antenna distance. Therefore in the current version of template synthesis rant, as well as Xslice, can only In this equation the parameterised amplitude frequency take values on a fixed grid. We note here that while we spectrum A(f) also depends on Xmax through the spec write the functions as both a function of Xslice and Xmax, tral coefficients, which are calculated using the fitted a more accurate description should probably take some spectral functions. As a result, in the following the fre- combination of the two that could serve as a proxy for quency f is restricted to the range used to fit the spectral shower age in the slice. We come back to this in Section functions VI. The template thus contains a normalised version of the We fit the spectral parameters as a function of Xmax origin shower. It acquires its phase frequency spectrum using a parabola. In order to better deal with the large as is, but the origin amplitude frequency spectrum is cor scatter for some slices, especially the very early and late rected for the longitudinal evolution (particle number in",
    "4.3Effectiveness of different features in the physical world. 4.3.1 Color transfer and texture blurring Figure 4: Patch with different feature changes. (left: original patch; middle: color transfer patch; right: texture blurring patch). In physical-world deployments, attack patches are often affected by color transfer due to lighting conditions or blurring caused by camera focus or smudging. To analyze if these changes will affect the performance of the attack patches, we compare the performance of an original patch, a color-adjusted patch, and a local texture adjusted patch. The color-adjusted patch is applied by adding a value () to all values in RGB channels and making sure & will not lead to an overflow. This color transfer will 3x3 Gaussian blur. Figure 4 demonstrates the two types of feature adjustments applying to a patch with brightness range=0.24.  Table 1: Performance with color transfer and Gaussian blur. Brightness range Original Color transfer Gaussian blur 1(AdvPatch) 89.4% 90.8% 47.8% 0.35 89.5% 87.9% 22.7% 0.24 74.2% 75.3% 10.1% The performances of different patches are shown in Table 1. Regardless of the lightness restriction, the color transfer patch achieves almost the same success rate as the original patch. This performance shows that the patch does not need to maintain a specific color to deceive the target network. On the other hand, the blurred patch exhibits a significant decrease in success rate, suggesting that local texture is the key feature in deceiving target networks. Using these findings, we can apply the proposed hue mapping method to adjust the color of the patch and enhance its integration with the target environment, resulting in further reduced visibility. This process does not require any learning and can be quickly applied when deploying the patch in the physical world.. 4.3.2Random color variations When printing an attack patch, it is important to consider that normal printers are not able to produce a patch with precisely the same color as the digital version. Therefore, the patch's robustness to. random color variations must be evaluated.. To replicate the color drift that commonly occurs during printing, we generate random noise within a. restricted range that corresponds to a percentage of the original value. This approach allows us to simulate different levels of drift, and the results are shown in Table 2.. Table 2: Performance with different color drift Brightness range Original 10% drift 15% drift 20% drift 1 (AdvPatch) 89.4% 87.6% 85.9% 83.3% 0.35 89.5% 84.2% 77.6% 67.2% 0.24 74.2% 68.6% 43.2% 27.3% 6",
    "10 S. Ganguly et al. 102 Crutcher+10 variable 1 variable 2 time [Myr] p-value B  p0.5 exponent=0.470.03 Pthr(MA>1) Pthr(MA 1) 2 6  10-4 3.5 5.2  10-15 V{B2) [G] Table 6. The p-values of the 2-sample KS test for the density distribution of sub-Alfvenic and super-Alfvenic structures. We can see that the p-value is low for both 2 and 3.5 Myr, suggesting that sub-Alfvenic and super-Alfvenic structures (corresponding to bluish and reddish points in Fig. 6, respectively) have statistically significant differences in their density distributions. 50% H2 >50% H2 power of M. While of potential interest, this is unfortunately not 10-20 10-19  demonstrable from the present analysis. Pthr [g cm-3] 6.2 Impact of magnetic fields on the energetics of sub-structures 0.0 log10(MA) We are also interested in assessing the energetic relevance of mag- netic fields over different length scales in the MCs, especially with Figure 6. Relation between the root-mean-square magnetic field and Pthr respect to potentially star-forming structures. For this purpose, we for all MHD clouds at tevol=3.5 Myr. The colour bar shows the Alfvenic compute the volume term of the magnetic energy and compare it Mach number MA. The dash-dotted line represents the B-p relation from with the kinetic and potential energies. Similar work for the same Crutcher et al. (2010), while the dotted line represents a B  p0.5 power simulations has been performed by Ganguly et al. (2022), who as- law. The cyan dashed line represents the best fit power law for all points with. sess the virial balance of the cloud sub-structures. Here, we extend Pthr > 1.1  10-21 g cm-3. the range of our analysis to include the dynamics of lower-density gas (between 10-24 and 10-22 g cm-3; low-den dendrogram analysis, see Table 2). The cyan dashed line represents the linear least-squares best fit The magnetic energy of a given structure is computed as performed on the logarithm of the points for high densities (Pthr > 1.1  10-21 g cm-3). The best fit of k = 0.47  0.03 is consistent EB = |B|2d3r, (21) JV8 with the strong-field limit of B  p0.5. We have already shown in the where the integration is computed over the entire volume V of previous section (Section 5) that our structures are on average highly the structure. The kinetic energy is computed using the following elongated, and magnetic fields clearly help to deform the shape of the forming structures. It is therefore not unexpected that we find a relation: shallower scaling compared to the weak field limit (k = 0.67). EKE = (v - vo)2d3r (22) We see that, while there is no clear transition from the sub- to the super-Alfvenic regime, there is clearly a trend that higher Alfvenic Mach numbers are preferentially obtained at the higher density end. Here, vo is the centre of mass velocity computed from Eq. 17. This is confirmed by a Kolmogorov-Smirnov (KS) two-sample test,. The self-gravitating potential energy of a given structure is obtained. which compares if two distributions belong to the same population. using the following relation: In this case, we compare the Pthr-distributions of structures with MA > 1 and MA  1. We find the p-values' to be very low: (23) y r-r 6  10-4 at 2 Myr and 5.2  10-15 at 3.5 Myr (see Table 6). where G is the gravitational constant. We compute the self-gravity Crutcher et al. (2010) found that the observed magnetic field dis- of each dendrogram structure using a KD-tree algorithm (Bentley tribution is rather flat at low density, in agreement with the idea that 1975) instead of an O(N2) direct computation. denser clouds are swept up along the magnetic field lines on large We show the relative importance of magnetic fields with respect scales, while at higher density there is a power-law increase of the magnetic field strength. If spherical clouds start to collapse and the to potential and kinetic energy in the left and right panel of Fig. 7, magnetic field is not strong enough to stop the collapse, one expects a power-law slope of k = 0.5 - 0.67 (see above). both plots, the x-axis represents the density threshold Pthr, and the In the case of our clouds, we find that the high-density end is well y-axis represents Eb/|EpE| (left) and Eb/|EkE| (right), respectively. consistent with  = 0.5, and the lower-density end clearly shows a The colours of the points represent their morphologies. Here, for the purpose of understanding the dynamics of low-density gas, we also. much shallower slope. Nonetheless, there does not seem to be a clear single density at which there is a sharp change in slope. Simulations include the \"unclassified\" structures (i.e. structures with >5% of their by Li et al. (2015), Mocz et al. (2017), Girichidis et al. (2018), Zhang surface cells touching the edge of the analysis box, see Section 3). et al. (2019) find similarly the lack of a sharp transition density. Auddy The side panels to the right and top of each plot show the marginal et al. (2022) predict that the transition density depends on the fourth distributions of Nx/Ntot for each morphology. Note that, since the definition of Ntot (Eq. 14) does not contain unclassified structures, the fractions in the two side panels add up to greater than unity. The filled symbols are molecular structures, while the open symbols are atomic. 3 1f the p-value is larger than a certain value (typically 0.05), this means that Typically, for low-density structures, which mostly consist of atomic we cannot reject the null hypothesis that the sub-Alfvenic and super-Alfvenic structures have the same underlying density distribution. the potential energy (left panel of Fig. 7). The magnetic energy is. MNRAS 000, 1-21 (2022)",
    "instructions given in the prompt. Past research has feedback topic. Figure 4 presents an overview of shown the importance of stating the actions a model the two different presentations of this taxonomy, can take, such as outputting \"I don't know.\" (Zhou and the mapping between them. et al., 2023). Similarly, how strongly the prompt We motivate this taxonomy to finely categorize encourages a model to incorporate feedback can current approaches to textual feedback that implic- favor overoptimization. itly formulate feedback solely for utility (i.e.,how useful is the feedback for guiding a model toward Introducing Errors  Finally, effective feedback a suitable response). However, they do not cate- may communicate information on where the gorize its content, leaving a conceptual gap about learner is failing, requiring an understanding of the what makes feedback useful. Our taxonomy strati- possible error modes for a given task, and which fies the feedback space, allowing a deliberate and ones the learner is likely in. For example, guessing systematic study of feedback content.. and committing systematic reasoning mistakes are reflections of differing understandings. Exploring 5.1  General Taxonomy the error space and identifying the mistakes made We break down feedback content along ten dimen by a learner is an important extension to the base sions that influence how feedback is formulated: framework directly derived from pedagogical and psychology of education research. 1. length, an indication of how much feed- back feedback is given, possibly measured 4.3Feedback Integration by counting its number of tokens, The method used to transmit the feedback to the 2. granularity, a measure of the level of detail model influences how it is subsequently processed. with which the feedback addresses the original Fernandes et al. (2023) identify three common feed- answer - it is not a measure of how much back integration mechanisms: feedback-based imi- of the answer is being considered, but rather tation learning, joint-feedback modeling, and rein- of the level of detail with which it is being forcement learning. In addition to this, we also con- considered,8 sider feedback use in in-context learning (Brown et al., 2020). The training objective will necessarily 3. applicability of instructions, expressing both influence how the model is processing and incorpo- whether the feedback contains instructions, as well as how applicable those instructions are rating feedback. Typically, the training relies upon for the learner and their current understanding either scalar feedback (a single number encoding how much the model should be rewarded for its out- and approach to solving the task, put) or a ranking (how well a given output did in 4. answer coverage, which registers how much relation to other candidate answers). However, this of the learner's answer is considered to gen- is simple information, and does not leverage the erate the given feedback. The feedback could rich and complex information encoded in natural be independent of the answer, or only relate language feedback. Section 5 therefore comprehen- to parts of the answer (e.g.,, focusing on a par- sively explores the different types of information ticular mistake), or the feedback might take that can be encoded in feedback. the complete answer into consideration, 5Feedback Content Taxonomy 5. criteria, denoting which criteria the answer is being evaluated on: global evaluation, specific In Section 4, we presented an overview of the com- dimensions (e.g., fluency, engagement, etc.), plex ecosystem of feedback, including an expan- or, alternatively, no dimensions (the answer is sion specifically for LLMs (i.e., FELT) that con- not being evaluated), nects various background elements (e.g.,the learner. 6. information novelty,indicating the degree to the task, the error types) to the actual feedback that which learner already had access to the in- must be given. In this section, we expand on our formation provided in the feedback, ranging analysis of the content dimension of feedback in from all information being previously known FELT. Specifically, we present a taxonomy of feed- back content under two different forms: a set of 10 *For an open-answer example task, feedback might range broad axes along which feedback can vary, and a from global learning meta-feedback, to global but task specific, to paragraph-level, to sentence-level, to word-level, more concrete set of nine emergent categories for to token-level feedback.",
    "8 I. Kostyuk et al.. 1.0 individual escape fractions, we select a subsample of galaxies not 0.8 used for the fitting in order to avoid problems due to over-fitting. As 0.6 a measure for this accuracy we use the average relative deviation 0.2 Ntest j=I (15) fesc,i 2.00 with fesc,pred,i and fesc,i being the predicted and modelled escape fraction of the i-th galaxy respectively, and Ntest the number of test 1.50 galaxies. We only used galaxies with fesc > O.01, as this measure 1.00  is not useful for fesc approaching 0. We find a value of r ~ 1.2, i.e. the average estimation error is of the order of a factor of 2, and 0.75 as such the accuracy of predicting the escape fraction of a single 0.50 halo is limited. However, for large scale studies where the statistical distribution of the escape fraction is more important, this model 2.00 performs significantly better. Indeed, the average escape fraction 1.50 the modelled escape fraction being fesc,i = 0.117  0.1334. 1.00  In fig. 9 we show how well the fitting formula is able to reproduce 0.75 the behaviour of the escape fraction in relation to the stellar mass and redshift that we examined in fig. 2. We see that the evolution of the escape fraction with redshift is successfully reproduced. However. the large gradients infesc) that are seen in fig.8 are smoothed out. The reason for this likely lies in the optimization process used 1.0 to find the fitting formula, as the mean squared error was used for 0.8 optimization, and thus large gradients in the fitting function were 0.6 y disfavored because they led to large errors for the outer mass ranges. Fig. 10 shows that the fitting formula is able to successfully predict 0.2 the bimodality in the escape fraction, as seen in fig. 4. However the boundary between the two modes is less pronounced. This is likely .0 caused by the smoothing effect of the optimization process of the 2.00 fitting function discussed above. 1.50 Finally, by comparing fig. 11 to fig. 3, we see that the fitting formula is able to reproduce all important trends, namely, the decrease in 1.00  peak escape fraction with redshift and the approximate locations and values of the peaks. We also reproduce both the minima and maxima 0.75 in the dependence of fesc on Mgas.. .50 As mentioned earlier, it is important to emphasize that our mod- 2.00 eling aims to capture the overall trends of LyC escape with galactic properties. Considering the inherent limitations in resolution and 1.50 simplifications involved in estimating the LyC flux, it is crucial to 1.00  scale the absolute value predicted by the fitting formula using a free parameter, which should be determined based on the specific ioniz- ing photon budget required for reionization. We intend to investigate the large scale implication of these results and to determine scaling parameters in subsequent work.. Figure 6. Galaxies with disk scale heights H > 1021.3cm selected for their high and low SFR, i.e. log(SFR/Myr-1) = 0.14, 0.20 and 0.40 (top) and log(SFR/Myr-1) = -4.34, -4.05 and -4.08 (bottom figure). From top to bottom, the panels in each figure refer to the cell escape fraction, fesc,cell, 5 DISCUSSION AND CONCLUSIONS optical depth of dust, Td, and of gas, THI-. To gain a better understanding of the correlation of LyC escape with galactic properties, we have applied the physically motivated model are likely to be inaccurate. Indeed, the unconstrained estimate fesc for the LyC escape fraction developed in F23 to ~ 600,000 galaxies predicts high escape fraction values in the high stellar mass range and extracted from the TNG50 simulation (Nelson et al. 2019; Pillepich hence does not match our findings in fig. 4. We therefore artificially et al. 2019) in the range 5.2 < z < 20. set the fesc value to 0 for galaxies with x > 8.5, obtaining: Given the large uncertainties in the subgrid modeling of LyC es- cape, attempting a quantitative comparison of our results to those of 0 fesc < 0 or M+,1og < 8.5 previous studies would be impractical. Therefore, we focus our dis- fesc fesc > 1 (14) cussion on qualitative results. Numerous previous numerical studies, fesc otherwise. such as the First Billion Year project (Paardekooper et al. 2015), CODA-II (Lewis et al. 2020), FIRE-II (Ma et al. 2020), THE In order to determine the accuracy of the model in predicting SAN (Yeh et al. 2022), SPHINX (Rosdahl et al. 2022) and TNG50 MNRAS submitted, 000-000 (0000)",
    "B Scene Knowledge LeViLM (ZS): Q The man on the far right of the image is Spider- Man Bruce. A spider is painted on his back. His LeViLM (FT): nemy Brandon is floating in the air across Q from him, wearing sunglasses. Brandon's servant Tom is behind LeViLM (FT): Brandon, holding a cane in his hand. Bruce comes Q+K/ to destroy them today. Q+K + S The cane in Tom's hand The Spider-Man Bruce Brandon's servant Bruce's enemy Brandon (Easy) (Medium) (Hard) (Haad) Figure 5. The illustration of samples from the proposed SK-VG dataset, where a scene story and its four referring expressions are shown with the grounding results from four baseline methods. level accuracy, we can obtain the message that LeViLM (image, scene knowledge, query) triples to perform accu- is not capable of performing complicated (multi-hop) rea- rate reasoning. We propose two approaches to perform this. soning over the scene knowledge and producing accurate new task: Knowledge-embedded Vision-Language Interac- predictions. Besides, the prediction process is black-box and tion and Linguistic-enhanced Vision-Language Matching can not be explainable, which can be further studied in the Experimental results confirm the validity of the proposed future. The answer is that (i) The current baselines can only approaches but also show that there is still substantial room achieve strong results on easy or medium tasks and are un for improvement, e.g., reasoning and interpretability. able to perform well on the hard task; (ii) The interpretability of the baselines is poor.. Acknowledgement 4.5. Case Study This work was supported in part by the Chi- nese Key-Area Research and Development Program To further investigate the effects of knowledge, we per- of Guangdong Province (2020B0101350001), in part form qualitative analysis on four cases in the SK-VG dataset. by the Guangdong Basic and Applied Basic Re- Figure 5 shows the grounding results of four baselines on search Foundation (NO. 2020B1515020048), in part four referring expressions. It is observed that in the first. by the National Natural Science Foundation of China case, all the baselines can ground the \"cane\"' in the image (NO. 61976250), in part by the Shenzhen Science even without the knowledge since there is only one cane and Technology Program (NO. JCYJ20220530141211024, presented. In the second case, the finetuned LeViLM can NO. JCYJ20220818103001002), in part by the Fundamental detect the target object even without knowledge, while it can Research Funds for the Central Universities under Grant not detect the \"Brandon's servant' without knowledge in the 22lgqb25 and in part by the Guangdong Provincial Key Lab third case. In the last case, all the baselines can not ground oratory of Big Data Computing, The Chinese University of the referred object correctly, and the last three baselines all Hong Kong, Shenzhen. This work was also sponsored by treat the \"Spider-Man' as the \"enemy\". This shows that the Tencent CCF Open Fund (NO. RBFR2022009). baseline models can not perform accurate reasoning in some complicated cases, demonstrating the challenges.. 5. Concluding Remarks The visual grounding field has emerged as a prominent attractive research direction, where the models are required to reason over vision and language to ground the target ob- jects. Yet, the language part of the existing VG benchmarks is only simple description texts, which can not evaluate the reasoning capability of the models comprehensively. To take a step in this direction, we propose a new benchmark dataset called SK-VG, which requires models to reason over the",
    "Springer Nature 2021 LATEX template Unique continuation for an elliptic interface problem using unfitted isoparametric finite elements Erikl and Janosch1* 1Department of Mathematics, University College London, Gower. Street, London, WC1E 6BT, United Kingdom.. *Corresponding author(s). E-mail(s): j.preuss@ucl.ac.uk; Contributing authors: e.burman@ucl.ac.uk; Abstract We study unique continuation over an interface using a stabilized unfitted finite element method tailored to the conditional stability of the problem. The interface is approximated using an isoparametric transformation of. the background mesh and the corresponding geometrical error is included in our error analysis. To counter possible destabilizing effects caused by. non-conformity of the discretization and cope with the interface condi- tions, we introduce adapted regularization terms. This allows to derive error estimates based on conditional stability. Numerical experiments. suggest that the presence of an interface seems to be of minor impor-. tance for the continuation of the solution beyond the data domain. On the other hand, certain convexity properties of the geometry are crucial as has already been observed for many other problems without interfaces. Keywords: unfitted finite element method, unique continuation, interface problems, isoparametric finite element method, geometry errors, conditional Holder stability MSC Classification:35J15,65N1265N2065N3086-08 1 Introduction 1.1 Motivation 1"
  ],
  "mmd": [
    "In Figure 9, we show the Leavitt laws for a sample of Cepheids in the LMC (Persson et al. 2004) and in NGC 7250 (Owens et al. 2023). The scatter in the _ JWST_  F115W data for NGC 7250 is a factor of two smaller than in the SHoES F160W data; i.e., the improved resolution and higher signal-to-noise ratio of the _ JWST_  data results in a lower variance ( \\(\\sigma^{2}\\)) for the F115W relation by almost a factor of four. This is all the more remarkable since the \\(J\\)-band data are single-phase observations only, while the _ HST_  observations have been corrected to mean light. The _ HST_  data exhibit more than three times the scatter of the \\(H\\)-band data for the LMC, the latter of which reflects the expected scatter for that band, as exemplified by the LMC data. \n\n## 12.  SUMMARY \n\nThe accuracy of the Cepheid distance scale has continued to improve over the century during which it has been used to measure the distances to nearby galaxies and set the scale for the determination of H \u2080. Still, challenges remain in overcoming systematic uncertainties. Many of these challenges will be overcome with new capabilities provided by the _JWST_ . \n\nNew _ JWST_  data for the nearby galaxy NGC 7250 already demonstrate that (1) many of the Cepheids observed with _HST/WFC3_  are significantly crowded (and biased to brighter apparent magnitudes) by nearby neighbors. A re-analysis of the SH0ES optical data, then coupled with the new high-resolution and higher signal-to-noise _ JWST_  F115W data, leads to significantly reduced effects of crowding and smaller photometric uncertainties. (2) These improvements result in a factor of two lower scatter in the near-infrared Leavitt law for _ JWST_  F115W compared with _ HST_  F160W, even with single-epoch F115W _ JWST_  photometry. \n\nThe galaxies in our _ JWST_  CCHP program sample have all been selected to have with distances \\(\\lesssim\\)20 Mpc, close enough to minimize crowding effects. As for the case of NGC 7250 presented here, these data will be combined with a re-analysis of the SH0ES _ HST_  optical data for the Cepheids. TRGB, carbon star, and Cepheid distances to the same sample of galaxies being observed as part of the CCHP will allow measurement of three independent distances to each \n\n**Figure 8.**  Four Cepheids in NGC 7250 discovered as part of the SH0ES project (bottom row: _ HST_  F160W/ \\(H\\)-band exposures; top row: _ JWST_  F115W/ \\(J\\)band). Each postage-stamp image is\n \\(2\\times 2\\)arcsec on a side. The red circles are centered at the\n position of the Cepheid determined from the _ HST_  optical (F350LP white light) photometry. It is immediately evident that the crowding for these Cepheids is quite severe and the signal-to-noise ratio (SNR) for the \\(H\\)-band data tends to be low, ranging from 1 to 23. In contrast, the SNR for the \\(J\\)-band data ranges from 36 to 121. On average, the _ JWST_  data have almost an order of magnitude greater SNR, and a four times better angular resolution, allowing the Cepheids to be distinguished clearly from the background. ",
    "as follows: \n\n\\[\\alpha_{\\text{eff}}=\\beta_{\\text{eff}}\\] (50) \\[\\implies \\alpha\\frac{N_{1}}{L}=\\beta\\bigg{(}1-\\frac{N_{2}}{L}\\bigg{)}\\] (51)  \n\n\\[\\bigg{(}{\\frac{1+k_{20}}{2}+\\frac{k_{10}+k_{20}}{2\\alpha}}\\bigg{)}\\] \\[-\\bigg{[}\\bigg{(}{\\frac{1+k_{20}}{2}+\\frac{k_{10}+k_{20}}{2\\alpha }}\\bigg{)}^{2}-\\mu k_{20}\\bigg{]}^{\\frac{1}{2}}\\] \\[=\\bigg{(}\\frac{1}{2}+\\frac{k_{10}}{2\\alpha}+\\frac{k_{20}}{2\\beta} \\bigg{)}-\\bigg{[}\\bigg{(}\\frac{1}{2}+\\frac{k_{10}}{2\\alpha}+\\frac{k_{20}}{2 \\beta}\\bigg{)}^{2}-k_{20}\\bigg{]}^{\\frac{1}{2}}.\\] (58)  \n\n\n\n\n\nBelow we obtain the exact location \\(x_{w}\\)\\(\\Delta\\)of\n the LDW in terms of the control parameters. \n\n\n\nIn the DW phase, particle number in \\(T\\)\\(T\\)In the DW phase, particle number in T can be expressed as\n \n\n\\[N_{T}=L\\int_{0}^{1}\\rho(x)dx,\\] (52)  \n\nThe LD-DW boundary equation ( 58 ) can be simplified further (detailed calculation is given in Appendix) after which it reduces to a form which we will obtain later in subsection  V E . We find \n\nwhere a multiplicative factor \\(L\\)\\(L\\)where a multiplicative factor L is introduced in the righthand side to rescale the integration limit of the position\n \n\n\\[\\frac{N_{1}}{L}\\bigg{(}1+\\alpha-\\frac{\\alpha}{\\beta}\\bigg{)}=\\mu-1\\] (59)  \n\nvariable \\(x\\). Using ( 48 ) and ( 51 ) in ( 52 ), we get: \n\n\n\nas the LD-DW phase boundary, where \\(N_{1}/L\\) is given by \n\n\\[N_{T}=L\\bigg{[}\\alpha\\frac{N_{1}}{L}(2x_{w}-1)+1-x_{w}\\bigg{]}.\\] (53)  \n\n\\[\\begin{split}\\frac{N_{1}}{L}&=\\bigg{(}\\frac{1}{2\\alpha}+\\frac{k_{ 10}}{2\\alpha^{2}}+\\frac{k_{20}}{2\\alpha\\beta}\\bigg{)}\\\\ &\\quad-\\bigg{[}\\bigg{(}\\frac{1}{2\\alpha}+\\frac{k_{10}}{2\\alpha^{2}}+\\frac{k_{2 0}}{2\\alpha\\beta}\\bigg{)}^{2}-\\frac{k_{20}}{\\alpha^{2}}\\bigg{]}^{\\frac{1}{2}}. \\end{split}\\] (60)  \n\nIdentifying the steady state TASEP current in the DW phase as \\(J_{T}=\\rho_{\\text{LD}}(1-\\rho_{\\text{LD}})\\)expressions\n or\n \\(J_{T}=\\rho_{\\text{HD}}(1-\\rho_{\\text{HD}})\\)53\n and\n substituting the expressions of \\(N_{T}\\) [see eq. ( 53 )] and \\(J_{T}\\)in eq. ( 17a ) together with PNC, we obtain the following two equations coupled in \\(N_{1}/L\\) and \\(x_{w}\\): \n\nTherefore, the acceptable solution of \\(N_{1}/L\\) is the one \n\n\\[\\frac{N_{1}}{L}\\bigg{[}1-\\frac{\\alpha}{\\beta}+\\alpha(2x_{w}-1) \\bigg{]}-x_{w}+1=\\mu-1,\\] (54) \\[\\begin{split}\\frac{N_{1}}{L}&=\\frac{k_{2}}{k_{1}+k_{2}}\\bigg{[} \\mu-\\alpha\\frac{N_{1}}{L}(2x_{w}-1)-1+x_{w}\\bigg{]}\\\\ &\\quad-\\frac{1}{L(k_{1}+k_{2})}\\alpha\\frac{N_{1}}{L}\\bigg{(}1-\\alpha\\frac{N_{1 }}{L}\\bigg{)}.\\end{split}\\] (55)  \n\nwith a negative discriminant; see eq. ( 60 ). Next, the \n\n\n\nexpression for \\(N_{2}\\) can be obtained using eq. ( 51 ). One finds \n\n\\[\\frac{N_{1}}{L}\\bigg{[}1-\\frac{\\alpha}{\\beta}+\\alpha(2x_{w}-1) \\bigg{]}-x_{w}+1=\\mu-1,\\] (54) \\[\\begin{split}\\frac{N_{1}}{L}&=\\frac{k_{2}}{k_{1}+k_{2}}\\bigg{[} \\mu-\\alpha\\frac{N_{1}}{L}(2x_{w}-1)-1+x_{w}\\bigg{]}\\\\ &\\quad-\\frac{1}{L(k_{1}+k_{2})}\\alpha\\frac{N_{1}}{L}\\bigg{(}1-\\alpha\\frac{N_{1 }}{L}\\bigg{)}.\\end{split}\\] (55)  \n\n\\[\\frac{N_{2}}{L} =1-\\frac{\\alpha}{\\beta}\\frac{N_{1}}{L}\\] \\[=1-\\bigg{(}\\frac{1}{2\\beta}+\\frac{k_{10}}{2\\alpha\\beta}+\\frac{k_{ 20}}{2\\beta^{2}}\\bigg{)}\\] \\[\\quad+\\bigg{[}\\bigg{(}\\frac{1}{2\\beta}+\\frac{k_{10}}{2\\alpha\\beta }+\\frac{k_{20}}{2\\beta^{2}}\\bigg{)}^{2}-\\frac{k_{20}}{\\beta^{2}}\\bigg{]}^{ \\frac{1}{2}},\\] (61)  \n\n\n\n\n\n\n\n\n\n\n\n\n\nWhile solving eqs. ( 54 ) and ( 55 ) for \\(N_{1}/L\\) and \\(x_{w}\\), we get a qudratic equation for \\(N_{1}/L\\) with two solutions: \n\n\n\n\\[\\begin{split}\\bigg{(}\\frac{N_{1}}{L}\\bigg{)}^{\\pm}&=\\bigg{(}\\frac {1}{2\\alpha}+\\frac{k_{10}}{2\\alpha^{2}}+\\frac{k_{20}}{2\\alpha\\beta}\\bigg{)}\\\\ &\\quad\\pm\\bigg{[}\\bigg{(}\\frac{1}{2\\alpha}+\\frac{k_{10}}{2\\alpha^{2}}+\\frac{k_ {20}}{2\\alpha\\beta}\\bigg{)}^{2}-\\frac{k_{20}}{\\alpha^{2}}\\bigg{]}^{\\frac{1}{2} }.\\end{split}\\] (56)  \n\nOnce we obtain the expression for \\(N_{1}/L\\) in eq. ( 60 ), the position \\(x_{w}\\) of the domain wall can be obtained using eq. ( 54 ). We find: \n\n\n\nThe density in the LD part of the DW is thus \n\n\\[x_{w}=\\frac{\\bigg{(}1-\\alpha-\\frac{\\alpha}{\\beta}\\bigg{)}\\frac{N_{1}}{L}-\\mu+2 }{1-2\\alpha\\frac{N_{1}}{L}}.\\] (62)  \n\n\\[\\rho_{\\text{LD}}=\\alpha\\frac{N_{1}}{L}=\\bigg{(}\\frac{1}{2}+\\frac{k_{10}}{2 \\alpha}+\\frac{k_{20}}{2\\beta}\\bigg{)}\\pm\\\\ \\bigg{[}\\bigg{(}\\frac{1}{2}+\\frac{k_{10}}{2\\alpha}+\\frac{k_{20}}{2\\beta}\\bigg{ )}^{2}-k_{20}\\bigg{]}^{\\frac{1}{2}}.\\] (57)  \n\n\n\n\n\nAt the boundary between the LD and the DW phases, \n\nHaving the expression of \\(N_{1}/L\\), it is straightforward to obtain the low and high densities in the DW phase: \n\n\\[\\rho_{\\text{LD}} =\\left(\\frac{1}{2}+\\frac{k_{10}}{2\\alpha}+\\frac{k_{20}}{2\\beta} \\right)-\\left[\\left(\\frac{1}{2}+\\frac{k_{10}}{2\\alpha}+\\frac{k_{20}}{2\\beta} \\right)^{2}-k_{20}\\right]^{\\frac{1}{2}},\\] (63)  \n\nMFT must predict identical (low) density in the bulk of \\(T\\). We now argue that in ( 57 \\(T\\)T. We now argue that in (57) the solution with a negative discriminant is actually the physically acceptable solution. Equating the density in LD phase [eq. (25)] and\n 25 )] and density in the LD domain of DW phase [eq. ( 57 ) with negative discriminant], we obtain the LD-DW boundary \n\n",
    "For our experiments, ondemand mode with baseload cores 3 has an optimum energy usage when calculating same number of samples compared to other baseload and samples per second combinations. \n\n## IV. C ONCLUSION AND  F UTURE  W ORK Recent research studies have focused on energy-efficient and \n\ncarbon-efficient FL scheduling and client selection. However, most of the research assumes simplistic energy consumption models for underlying FL clients. In this work, we showed that how energy per sample values under real-world scenarios such as different power modes and non-FL baseloads at CPU cores can vary and exhibit complex operational behavior patterns. \n\nFor future work, following open research questions and possibilities could be explored further, \n\n_\u2022_  How do current FL systems communicate FL clients\u2019 \n\nenergy related information? How to collect energy per sample, throughput per second and uncertainty related information at runtime? \n\n_\u2022_  How can we predict the power-performance characteristics, what are the relevant metrics? With more data about real-world impact factors affecting energy footprint of edge devices, can we build predictive models for forecasting? _\u2022_  How often do we need to measure before we can be certain? Can we report the uncertainty to be used in scheduling? FL trainings are usually executed multiple times due to data distribution drifts and hyperparameter search. This repetitive FL training execution could be leveraged to collect more data about power-performance behavior patterns of FL clients. _\u2022_  What\u2019s the impact of hardware accelerated edge devices \n\nof threads/CPU cores. For the FL training we utilized Flower framework 3 . We simulate a computer vision IoT training task using dataset CIFAR-10 4 and the computer vision model SqueezeNet which is light-weight and deemed to be suitable for edge computer visions applications. We assign higher kernel priority to baseload process to ensure the FL training doesn\u2019t affect the CPU time of baseload in co-running scenario. For the energy consumption measurement, we utilized WLAN power socket switch 5 . We report mean energy per sample and samples per second values for different powermodes and CPU core baseloads. \n\nsuch as jetson nano on energy related metrics? What are the energy efficiency opportunities in FL and non-FL corunning scenarios? \n\n\\[EPS=\\frac{P_{total}-P_{BL}}{N}\\] (1)  \n* R EFERENCES \n\n\\[EPS :\\text{Energy per Sample}\\] \\[P_{\\text{total}} :\\text{Total power consumption (FL and Baseload)}\\] \\[P_{\\text{BL}} :\\text{Power consumption due to Baseload}\\] \\[N :\\text{Number of Samples}\\]  \n* [1] H. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, \u201cCommunication-efficient learning of deep networks from decentralized data,\u201d in  AISTATS , 2016. \n\n\n* [2] X. Qiu, T. Parcollet, D. J. Beutel, T. Topal, A. Mathur, and N. D. Lane, \u201cA first look into the carbon footprint of federated learning,\u201d  CoRR , vol. abs/2010.06537, 2020. \n\n\n\nEnergy per sample values were calculated using Eq. 1. \n* [3] X. Zhou, J. Zhao, H. Han, and C. Guet, \u201cJoint optimization of energy consumption and completion time in federated learning,\u201d in  ICDCS , IEEE, 2022. \n\nFigure 1a illustrates the mean energy per sample and 95% \n* [4] C. W. Zaw, S. R. Pandey, K. Kim, and C. S. Hong, \u201cEnergy-aware resource management for federated learning in multi-access edge computing systems,\u201d  IEEE Access , vol. 9, pp. 34938\u201334950, 2021. \n* [5] Y. G. Kim and C.-J. Wu, \u201cAutofl: Enabling heterogeneity-aware energy efficient federated learning,\u201d in  IEEE/ACM International Symposium on Microarchitecture (MICRO) , pp. 183\u2013198, 2021. \n* [6] P. Wiesner, R. Khalili, D. Grinwald, P. Agrawal, L. Thamsen, and O. Kao, \u201cFedzero: Leveraging renewable excess energy in federated learning,\u201d arXiv preprint arXiv:2305.15092 , 2023. \n\nconfidence intervals for each powermode, based on 10 repeated measurements. We observe significant difference in energy per sample and samples per second values when there is no nonFL base load (0 baseload cores) compared to a scenario when non-FL baseload is executing and utilizing all CPU cores. We also observe that while samples per second (Figure 1b) doesn\u2019t vary significantly when non-FL baseload is co-running with FL, energy per sample values fluctuate for baseloads 3 and 4. \n* [7] B. G\u00a8 uler and A. Yener, \u201cA framework for sustainable federated learning,\u201d in  International Symposium on Modeling and Optimization in Mobile, Ad hoc, and Wireless Networks (WiOpt) , IEEE, 2021. \n* [8] B. Rupprecht, D. Hujo, and B. Vogel-Heuser, \u201cPerformance evaluation of ai algorithms on heterogeneous edge devices for manufacturing,\u201d in  International Conference on Automation Science and Engineering (CASE) , pp. 2132\u20132139, IEEE, 2022. 3 https://flower.dev 4 https://www.cs.toronto.edu/ kriz/cifar.html 5 https://www.delock.com/produkt/11826/merkmale.html \n\n(a) Energy Per Sample \n\n(b) Samples Per Second \n\nFig. 1: Power-Performance Characteristics for RPI ",
    "In the process of scanning the database, the system identifies all the songs that have the word \u2019good\u2019 either in their titles or in their lyrics. The first song that meets this criterion is \u2019Good Life\u2019 by Kehlani and G-Eazy. This song contains the word \u2019good\u2019 not only in its title but also within its lyrical content. \n\nIt\u2019s important to note that the search doesn\u2019t stop at \u2019Good Life.\u2019 There might be many other songs with the word \u2019good\u2019 in their titles or lyrics within the database. The given information only indicates the first result that the system presents in response to the query \u2019good.\u2019 \n\nTo summarize, the system is a music-centric search tool that uses the provided query to locate songs in its database containing the term \u2019good\u2019 either in their titles or lyrics. The first song it finds is \u2019Good Life\u2019 by Kehlani and G-Eazy, which contains \u2019good\u2019 both in its title and lyrics. The system can provide more results if the user wishes to explore other songs with the word \u2019good.\u2019 \n\nIn Figure 7, the dataset consists of song lyrics from the year 1950 to 2019. This provides a wellspread dataset which allows us to get results from over 60 years, thus making the search engine efficient enough to provide songs from every year. The year 2017 has the most songs amounting upto 660 songs from various different genres and emotions. \n\nIn Figure 8, the dataset has been categorized into 7 major genres namely - pop, country, blues, rock, jazz, reggae and hip hop. There are about 7042 songs under the genre pop. This includes pop \n\nFigure 6: Lyric Query Detection \n\nFigure 7: Distribution of songs throughout the years ",
    "# Dissecting Code Vulnerabilities: Insights from C++ and Java Vulnerability Analysis with ReVeal Model \n\n\\(200\\), batch size\n \\(128\\), maximum number\n \\(10000\\), number of gradient accumulation steps\n \\(8\\),\n \\(50\\)for C++ data and\n \\(20\\)for Java data.\n \n\n## Experiments with C++ data \n\n\\(k\\), and draw conclusions based on the observed dynamics. To make set \\(P_{3}\\) to be independent of \\(k\\), we fixed it to be the complement of \\(P_{1}\\). That is, \\(P_{3}\\) consisted of functions that remained unchanged in the commits where only one function was changed. Also, in order to balance different parts involved in training and testing, we restricted the size of \\(P_{3}\\): \\[|P_{3}|=|P_{1}|+|P_{2}|\\]  \n\nTo answer the first research question, we used the original C++ method-level vulnerability dataset from [ 1 ]. After pars ing, we obtained the following statistics of the input graphs: \n\n11788 train graphs (956 vulnerable), 1667 validation graphs (133 vulnerable), 3385 test graphs (286 vulnerable) \n\nDuring the data cleaning phase, we ensured that in each \n\nTo test each dimension of RQ 1, we performed 10 trials \n\nexperiment, \\(P_{3}\\) did not contain functions that are contained in \\(P_{1}\\cup P_{2}\\). Also, we removed any duplicate functions from each of the parts \\(P_{1},P_{2}\\), and \\(P_{3}\\), and removed methods contained in the training data from the test data. \n\nof training the model. In each trial, the dataset was split into train, validation, and test parts anew. The results can be found in Table  1 . \n\nTable  2  shows the distribution of the collected Java meth ods after stratification by \\(k\\)and cleaning the data: \n\n### Excluding SMOTE and RL \n\nThe model without SMOTE and RL achieves the worst performance with respect to the F1 score and the best performance with respect the ROC AUC measure. \n\n### AST edges \n\nThe model performs slightly better without including AST edges. This is likely due to including too much of fine-grained information or too many nodes. The model becomes more likely to overfit to irrelevant features in the input and fail to generalize. \n\n### Pruning \n\nThe experiments also showed that the model performs better with pruning at operator nodes. Pruning makes a graph simpler and less entangled for the model to understand. \n\n### Research question 2 \n\n### Downsampling \n\nIn this research question, we investigate training on different combinations of sets \\(P_{1}\\), \\(P_{2}\\), and \\(P_{3}\\), and testing on \\(P_{1}\\cup P_{2}\\cup P_{3}\\)be\n found\n or \\(P_{1}\\cup P_{3}\\)Figures\n , which is a stricter test. The results can be found in Figures  2  and  3 . \n\nFigures  2  and  3  allow us to conclude that if the test set \n\nTable  1  shows that the model performs worse with balancing the train set by downsampling non-vulnerable methods. We think that a rough balancing of the train part impacts the score negatively since it turns off SMOTE. \n\n## Experiments with Java data \n\nincludes part \\(P_{3}\\), then the inclusion of part \\(P_{3}\\) into training is critical to achieving a high performance. Overall, parts \\(P_{2}\\)and \\(P_{3}\\) contribute the most to the prediction, as seen by the red and blue lines on Figures  2  and  3 . \n\nAlso, on Figure  3 \\(P_{2}\\cup P_{3}\\)(red line) as\n \\(P_{2}\\cup P_{3}\\)increasing\n  (red line) as \n\nTo answer the rest of research questions, we trained and tested the model on different parts of the Java dataset  ( 1 ) : \\(P_{1}\\), \\(P_{2}\\), and \\(P_{3}\\). In particular, we varied \\(k\\)\\(1\\)to\n \\(14\\). Then, we plotted the resulting ROC AUC scores against\n \n\n\\(k\\)increases. This might indicate the increasing amount of \n\n\\begin{tabular}{c|c c}\nConfiguration & Median F1 & Median ROC AUC \\\\\n\\hline\nBaseline & 27.29 & 0.696 \\\\\nWithout SMOTE \\& RL & 21.45 & 0.730 \\\\\nWithout AST edges & 27.65 & 0.706 \\\\\nWith pruning & 30.83 & 0.724 \\\\\nMajority downsampling & 26.61 & 0.678 \\\\\n\\end{tabular}\n\n\n\\begin{tabular}{|c|c|c|c|c|}\n\\hline\n & \\multicolumn{2}{c|}{P1} & \\multicolumn{2}{c|}{P2} \\\\\n\\hline\nk & train & test & train & test \\\\\n\\hline\n1 & 410 (205) & 135 (68) & 0 (0) & 0 (0) \\\\\n2 & 399 (200) & 145 (73) & 343 (171) & 122 (61) \\\\\n3 & 416 (208) & 132 (66) & 696 (347) & 228 (113) \\\\\n4 & 414 (207) & 128 (65) & 960 (479) & 346 (172) \\\\\n5 & 415 (210) & 129 (64) & 1159 (575) & 433 (217) \\\\\n6 & 414 (208) & 131 (65) & 1393 (692) & 506 (254) \\\\\n7 & 421 (212) & 120 (60) & 1583 (789) & 596 (296) \\\\\n8 & 394 (197) & 151 (75) & 1870 (938) & 572 (284) \\\\\n9 & 410 (207) & 135 (67) & 2027 (1012) & 664 (330) \\\\\n10 & 411 (206) & 131 (66) & 2195 (1089) & 632 (314) \\\\\n11 & 399 (199) & 150 (75) & 2439 (1215) & 708 (353) \\\\\n12 & 400 (202) & 144 (72) & 2545 (1270) & 769 (383) \\\\\n13 & 397 (200) & 143 (72) & 2619 (1303) & 872 (434) \\\\\n14 & 409 (204) & 136 (68) & 2853 (1421) & 845 (419) \\\\ \\hline\n\\end{tabular}\n\n\n\n\n\n\n**Table 1.**  Results of experiments for research question 1 \n\n\n\n\n\n\n\n\n\n**Table 2.** Table 2. Statistics of collected Java methods after stratification by \ud835\udc58and cleaning. Each cell has the format \ud835\udc411(\ud835\udc412),\n \\(k\\)and cleaning. Each cell has the format\n \\(N_{1}(N_{2})\\)\\(k\\)and cleaning. Each cell has the format \\(N_{1}(N_{2})\\), where \\(N_{1}\\) is the total number of methods and \\(N_{2}\\) is the num ber of vulnerable ones. ",
    "\\[4\\cdot\\begin{pmatrix}\\left.\\begin{matrix}2&-1\\\\ 0&-2\\end{matrix}\\right|\\begin{matrix}3&2\\\\ 0&3\\end{matrix}\\end{pmatrix}-0\\cdot\\begin{pmatrix}\\left.\\begin{matrix}2&5\\\\ 0&3\\end{matrix}\\right|\\begin{matrix}3&1\\\\ 0&4\\end{matrix}\\end{pmatrix}+5\\cdot\\begin{pmatrix}\\left.\\begin{matrix}5&-1\\\\ 3&-2\\end{matrix}\\right|\\begin{matrix}0&3\\\\ 2&5\\end{matrix}\\end{pmatrix}-1\\cdot\\begin{pmatrix}\\left.\\begin{matrix}2&-1\\\\ 0&-2\\end{matrix}\\right|\\begin{matrix}-3&3\\\\ -3&5\\end{matrix}\\end{pmatrix}+\\]  \\[0\\cdot\\begin{pmatrix}\\left.\\begin{matrix}2&5\\\\ 0&3\\end{matrix}\\right|\\begin{matrix}-3&0\\\\ -3&2\\end{matrix}\\end{pmatrix}=326.\\]  \n\n_After expanding further the minors of above determinant based on Theorem 1, we see that this result is_ \n\n\n\n_the same as the result of Example 2._ \n\nFor\n \\(i=2\\)_, we have:_ \n\n\\[A=\\begin{pmatrix}\\left.\\begin{matrix}3&0&-4\\\\ 2&5&-1\\\\ 0&3&-2\\end{matrix}\\right|\\begin{matrix}-2&4&0\\\\ -3&0&3\\\\ -3&2&5\\end{matrix}\\left|\\begin{matrix}5&1&0\\\\ 3&1&2\\\\ 0&4&3\\end{matrix}\\right.\\end{pmatrix}\\]  \n\n\\[=2\\cdot\\begin{pmatrix}\\left.\\begin{matrix}4&0\\\\ 2&5\\end{matrix}\\right|\\begin{matrix}1&0\\\\ 4&3\\end{matrix}\\end{pmatrix}-5\\cdot\\begin{pmatrix}\\left.\\begin{matrix}-2&0\\\\ -3&5\\end{matrix}\\right|\\begin{matrix}5&0\\\\ 0&3\\end{matrix}\\end{pmatrix}+(-1)\\cdot\\begin{pmatrix}\\begin{matrix}-2&4\\\\ -3&2\\end{matrix}\\left|\\begin{matrix}5&1\\\\ 0&4\\end{matrix}\\right.\\end{pmatrix}-(-3)\\cdot\\begin{pmatrix}\\begin{matrix}0&-4 \\\\ 3&-2\\end{matrix}\\left|\\begin{matrix}1&0\\\\ 4&3\\end{matrix}\\right.\\end{pmatrix}+\\]  \\[0\\cdot\\begin{pmatrix}\\begin{matrix}3&-4\\\\ 0&-2\\end{matrix}\\left|\\begin{matrix}5&0\\\\ 0&3\\end{matrix}\\right.\\end{pmatrix}-3\\cdot\\begin{pmatrix}\\begin{matrix}3&0\\\\ 0&3\\end{matrix}\\left|\\begin{matrix}5&1\\\\ 0&4\\end{matrix}\\right.\\end{pmatrix}+5\\cdot\\begin{pmatrix}\\begin{matrix}5&-1\\\\ 3&-2\\end{matrix}\\left|\\begin{matrix}0&3\\\\ 2&5\\end{matrix}\\right.\\end{pmatrix}-1\\cdot\\begin{pmatrix}\\begin{matrix}2&-1\\\\ 0&-2\\end{matrix}\\left|\\begin{matrix}-3&3\\\\ -3&5\\end{matrix}\\right.\\end{pmatrix}+\\]  \\[0\\cdot\\begin{pmatrix}\\begin{matrix}2&5\\\\ 0&3\\end{matrix}\\left|\\begin{matrix}-3&0\\\\ -3&2\\end{matrix}\\right.\\end{pmatrix}=326.\\]  \n\n_After expanding further the minors of above determinant based on Theorem 1, we see that this result is_ \n\n\n\n_the same as the result of Example 2._ \n\nFor\n \\(i=3\\)_, we have:_ \n\n\\[A=\\begin{pmatrix}\\left.\\begin{matrix}3&0&-4\\\\ 2&5&-1\\\\ 0&3&-2\\end{matrix}\\right|\\begin{matrix}-2&4&0\\\\ -3&0&3\\\\ -3&2&5\\end{matrix}\\left|\\begin{matrix}5&1&0\\\\ 3&1&2\\\\ 0&4&3\\end{matrix}\\right.\\end{pmatrix}\\]  \n\n\\[=0\\cdot\\begin{pmatrix}\\begin{matrix}4&0\\\\ 0&3\\end{matrix}\\left|\\begin{matrix}1&0\\\\ 1&2\\end{matrix}\\right.\\end{pmatrix}-5\\cdot\\begin{pmatrix}\\begin{matrix}-2&0\\\\ -3&3\\end{matrix}\\left|\\begin{matrix}5&0\\\\ 3&2\\end{matrix}\\right.\\end{pmatrix}+(-2)\\cdot\\begin{pmatrix}\\begin{matrix}-2&4 \\\\ -3&0\\end{matrix}\\left|\\begin{matrix}5&1\\\\ 3&1\\end{matrix}\\right.\\end{pmatrix}-(-3)\\cdot\\begin{pmatrix}\\begin{matrix}0&-4 \\\\ 5&-1\\end{matrix}\\left|\\begin{matrix}1&0\\\\ 1&2\\end{matrix}\\right.\\end{pmatrix}+\\]  \\[2\\cdot\\begin{pmatrix}\\begin{matrix}3&-4\\\\ 2&-1\\end{matrix}\\left|\\begin{matrix}5&0\\\\ 3&2\\end{matrix}\\right.\\end{pmatrix}-5\\cdot\\begin{pmatrix}\\begin{matrix}3&0\\\\ 2&5\\end{matrix}\\left|\\begin{matrix}5&1\\\\ 3&1\\end{matrix}\\right.\\end{pmatrix}+0\\cdot\\begin{pmatrix}\\begin{matrix}5&-1\\\\ 5&-1\\end{matrix}\\left|\\begin{matrix}0&3\\\\ 0&3\\end{matrix}\\right.\\end{pmatrix}-4\\cdot\\begin{pmatrix}\\begin{matrix}2&-1\\\\ 2&-1\\end{matrix}\\left|\\begin{matrix}-3&3\\\\ -3&3\\end{matrix}\\right.\\end{pmatrix}+\\]  \\[3\\cdot\\begin{pmatrix}\\begin{matrix}2&5\\\\ 2&5\\end{matrix}\\left|\\begin{matrix}-3&0\\\\ -3&0\\end{matrix}\\right.\\end{pmatrix}=326.\\]  \n\n_After expanding further the minors of above determinant based on Theorem 1, we see that this result is_ \n\n\n\n_the same as the result of Example 2._ \n\nFor\n \\(j=1\\)_, we have:_ \n\n\\[A=\\begin{pmatrix}\\left.\\begin{matrix}3&0&-4\\\\ 2&5&-1\\\\ 0&3&-2\\end{matrix}\\right|\\begin{matrix}-2&4&0\\\\ -3&0&3\\\\ -3&2&5\\end{matrix}\\left|\\begin{matrix}5&1&0\\\\ 3&1&2\\\\ 0&4&3\\end{matrix}\\right.\\end{pmatrix}\\]  \n\n\\[=3\\cdot\\begin{pmatrix}\\begin{matrix}0&3\\\\ 2&5\\end{matrix}\\left|\\begin{matrix}1&2\\\\ 4&3\\end{matrix}\\right.\\end{pmatrix}-2\\cdot\\begin{pmatrix}\\begin{matrix}4&0\\\\ 2&5\\end{matrix}\\left|\\begin{matrix}1&0\\\\ 4&3\\end{matrix}\\right.\\end{pmatrix}+0\\cdot\\begin{pmatrix}\\begin{matrix}4&0\\\\ 0&3\\end{matrix}\\left|\\begin{matrix}1&0\\\\ 1&2\\end{matrix}\\right.\\end{pmatrix}-(-2)\\cdot\\begin{pmatrix}\\begin{matrix}5&-1 \\\\ 3&-2\\end{matrix}\\left|\\begin{matrix}1&2\\\\ 4&3\\end{matrix}\\right.\\end{pmatrix}+\\]  \\[(-3)\\cdot\\begin{pmatrix}\\begin{matrix}0&-4\\\\ 3&-2\\end{matrix}\\left|\\begin{matrix}1&0\\\\ 4&3\\end{matrix}\\right.\\end{pmatrix}-(-3)\\cdot\\begin{pmatrix}\\begin{matrix}0&-4 \\\\ 5&-1\\end{matrix}\\left|\\begin{matrix}1&0\\\\ 1&2\\end{matrix}\\right.\\end{pmatrix}+5\\cdot\\begin{pmatrix}\\begin{matrix}5&-1\\\\ 3&-2\\end{matrix}\\left|\\begin{matrix}0&3\\\\ 2&5\\end{matrix}\\right.\\end{pmatrix}-3\\cdot\\begin{pmatrix}\\begin{matrix}0&-4\\\\ 3&-2\\end{matrix}\\left|\\begin{matrix}4&0\\\\ 2&5\\end{matrix}\\right.\\end{pmatrix}+\\]  \n\n\n\n",
    "# SHELAH\u2019S MAIN GAP AND THE GENERALIZED BOREL-REDUCIBILITY \n\nLet us denote by \\(\\mathcal{T}=(\\kappa\\times\\omega\\times\\operatorname{acc}(\\kappa)\\times\\gamma \\times\\kappa\\times\\kappa\\times\\kappa\\times\\kappa)^{\\leq\\gamma}\\)\\(\\{\\xi_{i}\\in\\kappa^{\\leq\\omega}\\mathrel{|}\\allowbreak 0<i\\leq 8\\}\\)\\(i\\leq 8\\). For every \\(\\xi\\in\\mathcal{T}\\)there are functions \\(\\{\\xi_{i}\\in\\kappa^{\\leq\\omega}\\mathrel{|}\\allowbreak 0<i\\leq 8\\}\\),\n  such that for all \\(i\\leq 8\\),\n \\(dom(\\xi_{i})=dom(\\xi)\\)and for all \\(n\\in dom(\\xi)\\),\n \\(\\xi(n)=(\\xi_{1}(n),\\xi_{2}(n),\\xi_{3}(n),\\xi_{4}(n),\\xi_{5}(n),\\xi_{6}(n),\\xi_ {7}(n),\\xi_{8}(n))\\).\n For every \\(\\xi\\in\\mathcal{T}\\)let us denote\n \\((\\xi_{4},\\xi_{5},\\xi_{6},\\xi_{7},\\xi_{8})\\)by\n \\(\\overline{\\xi}\\). \n\nDefinition\n  For all \\(\\alpha\\in\\operatorname{acc}(\\kappa)\\)and\n \\(\\eta\\in\\mathcal{T}\\)with \\(\\overline{\\eta}\\in J_{f}\\), \\(dom(\\eta)=m<\\gamma\\)define\n \\(\\Gamma_{\\eta}^{\\alpha}\\)as follows: \n\nIf \\(\\overline{\\eta}\\in J_{f}^{\\alpha}\\), then\n \\(\\Gamma_{\\eta}^{\\alpha}\\)is the set of elements \\(\\xi\\)of \\(\\mathcal{T}\\)such that: \n\n\\(\\xi\\mathbin{\\upharpoonright}m=\\eta,\\)\\(\\overline{\\xi}\\mathbin{\\upharpoonright}dom(\\xi)\\backslash m\\in W^{\\alpha}_{ \\eta},\\)on\n \\(\\xi_{3}\\) is constant on \\(dom(\\xi)\\backslash m,\\)\\(\\xi_{3}(m)=\\alpha\\), (5) for all \\(n\\in dom(\\xi)\\backslash m\\), let \\(\\xi_{2}(n)\\)be the unique\n \\(r<\\omega\\)such that \\(\\sigma_{\\zeta}^{\\alpha}(r)=\\overline{\\xi}(n)\\),\n where \\(\\zeta=\\overline{\\xi}\\mathbin{\\upharpoonright}n\\). \n\nIf \\(\\overline{\\eta}\\notin J_{f}^{\\alpha}\\), then\n \\(\\Gamma_{\\eta}^{\\alpha}=\\emptyset\\). \n\nFor \\(\\eta\\in\\mathcal{T}\\)with \\(\\overline{\\eta}\\in J_{f}\\), \\(dom(\\eta)=m<\\gamma\\)define \\[\\Gamma(\\eta)=\\bigcup_{\\alpha\\in\\operatorname{acc}(\\kappa)}\\Gamma_{\\eta}^{ \\alpha}.\\]  Finally we can define \\(A^{f}\\)by induction. Let \\(T_{f}(0)=\\{\\emptyset\\}\\) and for all \\(n<\\gamma\\), \\[T_{f}(n+1)=T_{f}(n)\\cup\\bigcup_{\\eta\\in T_{f}(n)~{}dom(\\eta)=n}\\Gamma(\\eta).\\]  For \\(n\\leq\\gamma\\)a limit ordinal, \\[\\bar{T}_{f}(n)=\\bigcup_{m<n}T_{f}(m)\\]  \\[\\bar{T}_{f}(n)=\\bigcup_{m<n}T_{f}(m)\\]  and \\[T_{f}(n)=\\bar{T}_{f}(n)\\cup\\{\\eta\\in\\mathcal{T}\\mathrel{|}\\allowbreak dom(\\eta )=n\\ \\&\\ \\forall m<n\\ (\\eta\\mathbin{\\upharpoonright}m\\in\\bar{T}_{f}(n))\\}.\\]  \n\nFor\n \\(0<i\\leq 8\\)let us denote by\n \\(s_{i}(\\eta)=sup\\{\\eta_{i}(n)\\mathrel{|}\\allowbreak n<\\gamma\\}\\) and \\(s_{\\gamma}(\\eta)=max\\{s_{i}(\\eta)\\mathrel{|}\\allowbreak i\\leq 8\\}\\). Finally \\[A^{f}=T_{f}(\\gamma).\\]  \n\nDefine the color function \\(d_{f}\\)by \n\n\\[d_{f}(\\eta)=\\begin{cases}c_{f}(\\overline{\\eta})&\\mbox{if }s_{1}(\\eta)<s_{ \\gamma}(\\eta)\\\\ f(s_{1}(\\eta))&\\mbox{if }s_{1}(\\eta)=s_{\\gamma}(\\eta).\\end{cases}\\]  \n\nIt is clear that \\(A^{f}\\)is closed under initial segments, indeed the relations \\(\\prec\\),\n \\((P_{n})_{n\\leq\\gamma}\\), and \\(\\wedge\\)\n\nNow\n \n\nof Definition 3.11 have a canonical interpretation in \\(A^{f}\\). \n\nNow we finish the construction of \\(A^{f}\\)by using the \\(\\kappa\\)-colorable linear order \\(I\\)of . We have to define\n \\(<\\mathbin{\\upharpoonright}Suc_{A^{f}}(\\eta)\\)for all\n \\(\\eta\\in A^{f}\\)with domain smaller than \\(\\gamma\\). Properly speaking, \\(A^{f}\\)will not be an ordered coloured tree as in Definition 3.11, but it will be isomorphic to an ordered coloured tree as in Definition 3.11. \n\nLet us proceed to define \\(<\\mathbin{\\upharpoonright}Suc_{A^{f}}(\\eta)\\). Let\n \\(F:I\\rightarrow\\kappa\\)be a \\(\\kappa\\)-coloration of \\(I\\). \n\nFor any \\(\\eta\\in A^{f}\\)with domain \\(m+1<\\gamma\\), we will define the order \\(<\\mathbin{\\upharpoonright}Suc_{A^{f}}(\\eta)\\)such that it is isomorphic to \\(I\\)and satisfies the following: \n\n\\((\\ast)\\)_For any set_ \\(B\\subset Suc_{A^{f}}(\\eta)\\)_ of size less than_ \\(\\kappa\\)_,_ \\(p(x)\\)For any set\n \\(B\\subset Suc_{A^{f}}(\\eta)\\)of size less than\n \\(\\kappa\\),\n \\(p(x)\\)(*)\nFor any set \ud835\udc35\u2282\ud835\udc46\ud835\udc62\ud835\udc50\ud835\udc34\ud835\udc53(\ud835\udf02) of size less than \ud835\udf05, \ud835\udc5d(\ud835\udc65) a type of basic formulas over \ud835\udc35in the variable \ud835\udc65, and any tuple (\ud835\udf172, \ud835\udf173) \u2208\ud835\udf14\u00d7 acc(\ud835\udf05) with \ud835\udf173 \u2265\n \\(B\\)in the variable\n \\(x\\), and any tuple\n \\((\\vartheta_{2},\\vartheta_{3})\\in\\omega\\times\\operatorname{acc}(\\kappa)\\)with\n \\(\\vartheta_{3}\\geq\\eta_{3}(m)\\)\\(B\\)_in the variable_ \\(x\\)_, and any tuple_ \\((\\vartheta_{2},\\vartheta_{3})\\in\\omega\\times\\operatorname{acc}(\\kappa)\\)\\(\\kappa\\)_ with_ \\(\\vartheta_{3}\\geq\\eta_{3}(m)\\)that\n _, if_ \\(p(x)\\)_ is realized in_ \\(Suc_{A^{f}}(\\eta)\\)_, then there are_ \\(\\kappa\\)_many_ \\(\\alpha<\\kappa\\)_such that_ \\(\\eta^{\\frown}(\\alpha,\\vartheta_{2},\\vartheta_{3},\\sigma^{\\vartheta_{3}}_{ \\overline{\\eta}}(\\vartheta_{2}))\\models p\\)_._ ",
    "$G$, from a standard SAUR $\\{S'_i\\}${\nof\n }\n:\n  of $G'$, we call the follow ing SAUR a standard one of $G$: \n\nwhenever ${\\rm tr} (\\rho^2) \\le 2/d$\u03c1 )\n/\nmatrices,\n . Secondly, Lemma  7 ${\\rm tr} (\\rho^2) \\le 2/d$whenever tr(\u03c12) \u22642/d. Secondly, Lemma 7 and the vectorization of matrices, Theorem 8 and Theorem 11 give\n  8  and Theorem  11  give hints to the similarity of the role of $\\vartheta(G)$ in quantum contextuality and joint expectation values. \n\n\\begin{equation}       \\mathopen{}\\mathclose\\bgroup\\originalleft(\\bigcup_{k=0}^3 \\{\\sigma_k\\otimes S'_i\\}_{i\\in V_k}\\aftergroup\\egroup\\originalright) \\cup \\{X_{i_0}\\otimes {\\operatorname{id}}, Z_{j_0}\\otimes {\\operatorname{id}}\\}.     \\end{equation}\n\n## SELFADJOINT UNITARY \n\nIf $G$ has no edge, we assign ${\\operatorname{id}}$ or $1$ to all its vertices. \n\n## REPRESENTATIONS The set of operators, where any pair either commutes \n\nIf we take the pentagon $C_5$ in Fig.  2 If we take the pentagon\n $C_5$If we take the pentagon C5 in Fig. 2 as the original graph, and (1, 3) as the edge, then the Pauli-(1, 3)-\n $(1,3)$g\n5\ng\nas the edge, then the Pauli-\n $(1,3)$$(1,3)$ as the edge, then the Pauli- $(1,3)$induced subgraph $G'$ is a triangle. Continually, the Pauli- $(4,5)$-induced subgraph $G''$of $G'$Pauli-\n $(4,5)$g\np\n-induced subgraph\n $G''$of\n $G'$g\np\ng\ny,\nPauli-(4, 5)-induced subgraph G\u2032\u2032 of G\u2032 is just the vertex 2. Hence, the standard SAURs {S\u2032\u2032\ni }, {S\u2032\ni} and {Si}\n $2$( , )\ng\np\n. Hence, the standard SAURs\n $\\{S''_i\\}, \\{S'_i\\}$and\n $\\{S_i\\}$$2$. Hence, the standard SAURs $\\{S''_i\\}, \\{S'_i\\}$ and $\\{S_i\\}$of $G'', G'$and $G$, respectively, are \n\nor anticommutes, plays an important role as exemplified $\\{S_i\\}$can be encoded into\n $\\{S_i\\}$$G$i}\n11\n  can be encoded into a so-called frustration graph $G$ [ 11 ,  12 ], where $i\\sim j$ if $\\{S_i, S_j\\} = 0$, and $i\\not\\sim j$it is\n  if $[S_i, S_j]=0$. By checking extensive examples, it is conjectured in Ref. [ 34 ] that \n\n\\begin{align}     &S''_2 = 1, S'_2 = Y, S'_4 = X, S'_5 = Z,\\\\     &S_1 = X{\\operatorname{id}}, S_2 = {\\operatorname{id}} Y, S_3 = Z{\\operatorname{id}}, S_4 = X X, S_5 = Z Z,  \\end{align}\n\n\\begin{equation}\\label{eq:oldConjecture}     \\sos{\\{S_i\\}} = \\alpha(G). \\end{equation}\n\nwhere we have omitted the symbol of tensor product, \n\nWhether Eq. ( 20 $G$q\n, we\n 25 ]. Conversely, for a given graph $G$, we \n\nand $X{\\operatorname{id}}$ means $X\\otimes {\\operatorname{id}}$ etc. \n\n**Theorem 14**  (Cf. [ 41 ]) **.**  For a given graph $G$ and one SAUR $\\{S_i\\}$$\\{\\bar{S}_i\\}$ of $G$, there is a unitary $U$ and standard SAUR $\\{\\bar{S}_i\\}$ such that $US_iU^\\dagger = \\bar{S}_i \\otimes D_i$i\ni\nunitaries.\n , where $\\{D_i\\}$is a set of commuting selfadjoint unitaries. \n\nThe standard SAUR is succinct, however, it loses the information of the symmetry in the graph. To reflect the structure of the graph, we introduce the edge SAUR. \n\n**Definition 15.**  For a given graph $G$ with $n$ vertices and the edge set $E$, the set of selfadjoint operators $\\{A_i\\}_{i=1}^n$$G${\n,\n with $A_i = \\otimes_{e\\in E} O_{e,i}$if\n $i$e\u2208\nis\n  is called the edge SAUR of $G$, where $O_{e,i} = X$ if $i$ is the start of $e$, and $O_{e,i} = Z$ if $i$ is the end of $e$, otherwise, $O_{e,i} = {\\operatorname{id}}$. \n\ncan consider its representation by a set $\\{S_i\\}$[\n]\ny,\ng\ncan consider its representation by a set\n $\\{S_i\\}$[\n]\ny,\ng\ng\np\n,\ncan consider its representation by a set {Si} of selfadjoint unitaries, in the sense that {Si, Sj} = 0 if i \u223cj\n $\\{S_i,S_j\\} = 0$if\n $i\\sim j$$\\{S_i,S_j\\} = 0$ if $i\\sim j$j\ncalled\n and $[S_i,S_j] = 0$ if $i\\not\\sim j$. This representation is called selfadjoint unitary representation (SAUR) [ 41 ]. By taking the graph-theoretic approach instead of starting from a special set, we denote $\\beta(G,w) = \\sos{\\saur(G),w}$, where $\\saur(G)$ is the set of all SAURs of $G$. The conjecture in ac\nEq.\n is equivalent to\n $\\beta(G) = \\alpha(G)$j\n. In Ref.\n , no\n such an example is known that $\\beta(G) > \\alpha(G)$$\\beta(G) > \\alpha(G)$q (\n)\nq\n\u03b2( )\n( )\n[\n],\nsuch an example is known that \u03b2(G) > \u03b1(G). To continue, we first introduce the standard SAUR of a given\n graph, which is defined deductively. The standard SAUR can help us to reduce the complexity of considerations, since we only need to focus on the standard SAUR to obtain $\\beta(G)$ as we will see later. \n\nFor different SAURs of the same graph $G$, their joint expectation values are related. \n\n**Definition 12.**  For a given graph $G$ and one of its edges $(i_0,j_0)$, other vertices except $i_0$ and $j_0$ can be devided into four groups $V_0, V_1, V_2, V_3$, such that \n\nTheorem\n  For a given graph $G$, $\\sos{\\{S_i\\}} = \\sos{\\{\\bar{S}_i\\}}$a\n where $\\{S_i\\}$ is a SAUR of $G$ and $\\{\\bar{S}_i\\}$ is a standard one. \n\n$i\\not\\sim i_0$ and $i\\not\\sim j_0$ for any $i\\in V_0$; \n\n, we know that we \n\n$i\\not\\sim i_0$ and $i\\sim j_0$ for any $i\\in V_1$; \n\n_Proof._  From the convexity of $\\sum_i \\mathopen{}\\mathclose\\bgroup\\originalleft\\langle S_i \\aftergroup\\egroup\\originalright\\rangle^2$i\nP\ncase\nwith\n \n\n$i\\sim i_0$ and $i\\sim j_0$ for any $i\\in V_2$; \n\nonly need to prove for the case that $\\rho$ is a pure state $|\\psi\\rangle\\langle \\psi|$|\u03c8\u27e9\u27e8\u03c8\nsume\n . Since $D_i$$|\\psi\\rangle\\langle \\psi|$. Since\n $D_i$y\np\n\u03c1\np\n|\u03c8\u27e9\u27e8\u03c8|. Since Di commutes with each other, we can assume Di\u2019s are diagonal matrices. Denote d2 the dimen-\n $D_i$i\n\u2019s are diagonal matrices. Denote\n $d_2$the dimen-\n $D_i$\u2019s are diagonal matrices. Denote $d_2$$D_i$i\n\u2019s are diagonal matrices. Denote\n $d_2$|\u03c8\u27e9\u27e8\u03c8|\ni\n,\nsume Di\u2019s are diagonal matrices. Denote d2 the dimension of Di\u2019s, then we have the decomposition\n $D_i$g\n\u2019s, then we have the decomposition\n $D_i$\u2019s, then we have the decomposition \n\n$i\\sim i_0$ and $i\\not\\sim j_0$ for any $i\\in V_3$. \n\nThe subgraph $G'$of $G$ with vertices in $\\cup_{i=0}^4 V_i$$G$ is said to \n\n\\begin{equation}    U|\\psi\\rangle = \\sum_{i=1}^{d_2} \\sqrt{p_i} |\\phi_i\\rangle \\otimes |i\\rangle,  \\end{equation}\n\nbe a Pauli- $(i_0,j_0)$-induced subgraph of $G$ if \n\n\n\n\n* $i\\in V_{k_1}, j\\in V_{k_2}$$i\\not\\sim j$ where $k_1\\neq k_2 \\in \\{1,2,3\\}$only\n , we \n\nHence, \n\nwhere $p_i \\ge 0$ and $\\sum_i p_i = 1$. \n\nhave $i\\sim j$in\n  (or $i\\not\\sim j$) in $G'$if and only if $i\\not\\sim j$ (or $i\\sim j$) in $G$; \n\n\n\n\n* $i\\sim j$ in $G'$if and only if $i\\sim j$ in $G$. \n\n\\begin{align}    \\mathopen{}\\mathclose\\bgroup\\originalleft\\langle S_i \\aftergroup\\egroup\\originalright\\rangle &%= \\mean{\\bar{S}_i \\otimes D_i}     = \\sum_{kl} \\sqrt{p_ip_j} \\langle \\phi_k|\\bar{S}_i|\\phi_l\\rangle \\langle k|D_i|l\\rangle\\nonumber\\\\    &= \\sum_k p_k \\langle \\phi_k|s_{ik} \\bar{S}_i|\\phi_k\\rangle,  \\end{align}\n\n**Definition 13.**  For a given graph $G$ and one of its edges $(i_0,j_0)$, denote $G'$the Pauli- $(i_0,j_0)$-induced subgraph of \n\n",
    "## Checking SUSY for the Fibered Background \n\nHere we aim to compute how many supercharges are preserved by the the backgrounds presented in this paper. For the un-fibered background in eq.( 2.1 ) we refer the reader to [ 12 ], [ 19 ], where it is shown that this solution preserves 16 Supercharges in an interesting way: the anti-commutator of two supercharges includes the \\(R\\)-Symmetry generators. Now we present the analysis for the fibered background in eq.( 2.3 ). We perform all the analysis in the S-dual system, in terms of NS5 branes, where we only have \\(H_{3}\\) flux. \n\nFirst, note that the dilatino variation is a matrix equation of the form \\(M\\varepsilon=0\\). In order to have\n non-trivial solutions to this equation, we require \\(M\\) to be non-invertible, for which we need to impose \\(\\text{det}(M)=0\\). It is also possible to obtain a matrix equation from the gravitino variation. Noting that\n we can write the gravitino variation as a covariant derivative, for which we define the connection \n\n\\[W_{\\mu}=\\frac{1}{4}\\omega^{\\phantom{\\mu}ab}_{\\mu}\\Gamma_{ab}+\\frac{1}{4\\cdot 2 !}H_{\\mu\\nu\\lambda}\\Gamma^{\\nu\\lambda}\\sigma^{3}+\\frac{e^{\\Phi}}{8}\\left(F_{ \\mu}\\Gamma^{\\mu}(i\\sigma_{2})+\\frac{1}{3!}F_{\\mu\\nu\\lambda}\\Gamma^{\\mu\\nu \\lambda}\\sigma^{1}+\\frac{1}{2\\cdot 5!}F_{\\mu\\nu\\lambda\\rho\\sigma}\\Gamma^{\\mu \\nu\\lambda\\rho\\sigma}(i\\sigma_{2})\\right)\\Gamma_{\\mu},\\  \n\nthen we can write the gravitino variation as \n\n\\[\\delta\\psi_{\\mu}dx^{\\mu}=\\left(\\partial_{\\mu}\\varepsilon+W_{\\mu}\\varepsilon \\right)dx^{\\mu}\\equiv\\mathcal{D}\\varepsilon.\\  \n\nWe can get rid of the partial derivative of the spinor by acting with \\(\\mathcal{D}\\) a second time \n\n\\[\\mathcal{D}\\wedge\\mathcal{D}\\varepsilon=\\left(dW+W\\wedge W\\right)\\varepsilon= \\frac{1}{2}\\Theta_{\\mu\\nu}dx^{\\mu}\\wedge dx^{\\nu}\\varepsilon.\\  \n\nEach of the components of\n \\(\\Theta_{\\mu\\nu}\\)\\(\\Theta_{\\mu\\nu}\\)Each of the components of \u0398\u00b5\u03bd defines a matrix equation, giving a total of 45 independent equations. We need to make sure that det(\u0398\u00b5\u03bd) = 0 for each of the components. The equations\n \\(\\text{det}(\\Theta_{\\mu\\nu})=0\\)for each of the components. The equations\n for each of the components. The equations\n \n\n\\[M\\varepsilon=0,\\quad\\Theta_{\\mu\\nu}\\varepsilon=0,\\  \n\nconstrain the number of independent components of the spinor. After this procedure we use the gravitino variation to solve the dependence of the spinor on the spacetime coordinates. \n\nSpecialising to our background, the determinant of the Dilatino variation for the background in eq.( 2.3 ) reads \n\n\\[\\text{det}(M)\\sim\\left(4(e_{B}Q_{A}-e_{A}Q_{B})^{2}+m^{2}\\right)^{8}\\left(4(e_ {B}Q_{A}+e_{A}Q_{B})^{2}+m^{2}\\right)^{8}.\\  \n\nimpose\n \n\n\n\nconditions\n \n\n\n\nIn order to have non-trivial solutions we need to impose the following BPS conditions on the parameters of the background \n\n\\[e_{A}Q_{B}=\\pm e_{B}Q_{A},\\quad m=0.\\  \n\nWith this conditions it is possible to check that\n \\(\\text{det}(\\Theta_{\\mu\\nu})=0\\)is also satisfied. Solving these matrix\n equations shows that the spinor has 8 independent components. Then, solving for the gravitino variation shows that these components are not independents, and in fact, the total number of independent components its reduced to 4. The solution for the spinor is \n\n\\[\\varepsilon_{1}=\\vec{0}\\  ",
    "The aim of this section is to assess the influence of individual branches on the performance of our proposed method. We evaluate the influence of each branch architecture, including low-level, mid-level, and high-level discriminators. All the ablation studies are carried out utilizing the MIT67 dataset, which is summarized in Table 2. The table shows the performance metrics for different cases. The comparison is as follows: \n\n\n1.** Cases 1-3** : In these cases, only one of the sub-models is utilized for prediction. Case 1, which solely uses low-level features, demonstrates the highest performance, followed by Case 3, which only incorporates the high-level sub-model. On the other hand, Case 2, which considers mid-level features, achieves the lowest performance among all cases. \n2.** Cases 4-6** : In these cases, EnTri incorporates a combination of two levels of sub-models. The highest performance is achieved by Case 5, which utilizes both low-level and high-level sub-models. Following closely is Case 4, which takes into account both low-level and mid-level sub-models. On the other hand, case 6, which uses mid-level and high-level features, demonstrates the weakest performance among the cases. This suggests that low-level and high-level sub-models have a higher impact compared to the mid-level sub-model. \n3.** Case 7** : All three levels of sub-models (low, mid, and high) are incorporated in this case, resulting in the highest performance and demonstrating their complementary roles for the recognition task. \n\nMoreover, these textual explanations present the degree of agreement between the predictions made using the three features through ensemble learning and the final prediction of our framework. \n\n### 5.4. Explanation results and analysis \n\nTo visualize the quality and intelligibility of the explanations produced by the proposed VTEG, we provided illustrative examples of the visual and textual explanations on different MIT67 scenes in Figure 9. It can be seen from the examples that the visual explanations attempt to highlight the most influential attributes of the scene in the prediction process of the recognition model, with the cumulative heatmap highlighting the regions that contributed to the prediction based on low-level feature and the masked segmentation map highlighting the important objects that contributed based on mid-level feature. These visual explanations are complemented by the textual explanation, which not only highlights crucial attributes such as object categories, frequencies, locations, and textural cues but also offers scores that represent the contribution of these objects towards the prediction. This textual explanation increases the certainty and confidence of users in their interpretation of the reasoning behind the prediction. Moreover, the ability to align the textual information with the visual contents allows for a clearer comprehension of the process and facilitates the diagnosis of the system at the modular level. By analyzing the scene and the confidence score of each sub-model, users can gain a deeper understanding of which type of information in the scene has the greatest impact on recognition performance. Such insights can help users identify areas for modification and adjustment and provide guidance in answering questions such as: \n\nTable 2: Ablation studies on the MIT67 dataset demonstrating the effect of different sub-models evaluated in terms of Top@1, Top@2, and Top@5 accuracy. \n\n\\begin{tabular}{c|c|c|c|c|c|c}\n4 **Case** & **Low-level** & **Mid-level** & **High-level** & **Top@1 (\\%)** & **Top@2 (\\%)** & **Top@5 (\\%)** \\\\\n4 1 & \\(\\checkmark\\) & \\(\\times\\) & \\(\\times\\) & 84.47 & 90.75 & 94.18 \\\\\n\\hline\n2 & \\(\\times\\) & \\(\\checkmark\\) & \\(\\times\\) & 66.49 & 76.57 & 85.45 \\\\\n\\hline\n3 & \\(\\times\\) & \\(\\times\\) & \\(\\checkmark\\) & 77.31 & 86.04 & 92.61 \\\\\n\\hline\n4 & \\(\\checkmark\\) & \\(\\checkmark\\) & \\(\\times\\) & 85.52 & 92.24 & 95.52 \\\\\n\\hline\n5 & \\(\\checkmark\\) & \\(\\times\\) & \\(\\checkmark\\) & 86.19 & 92.84 & 95.97 \\\\\n\\hline\n6 & \\(\\times\\) & \\(\\checkmark\\) & \\(\\checkmark\\) & 79.62 & 87.76 & 93.06 \\\\\n\\hline\n**7** & \\(\\checkmark\\) & \\(\\checkmark\\) & \\(\\checkmark\\) & **87.69** & **93.58** & **97.54** \\\\\n4 & \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{} & \\multicolumn{1}{c}{} & \\\\\n\\end{tabular}\n",
    "system diagram presentations. Firstly, we start by creating \n\nDatabase (NVD) by inferring new classes, enriching relations, \n\nthe ontology of the cloud computing stack. Figure 2 depicts \n\nand expanding conceptual coverage. The ontology is used \n\nthe ontology of the three cloud stack: Software as a Service \n\nto search for and query social media threads that contain \n\n(SaaS), Platform as a Service (PaaS), Infrastructure as a \n\ncybersecurity-related information, and natural language pro- \n\nService (IaaS), Function as a Service (FaaS), Communication \n\ncessing techniques are used to relate unstructured information \n\nas a service (CaaS), and Desktop as a service (DaaS). Figure 1 \n\nto concepts in the ontology. The paper highlights the advan- \n\ndepicts the cloud service model. Cloud service has nine layers, \n\ntages of Semantic Web technologies in integrating information \n\ngreen colored layers mean these layers are managed by the \n\nfrom multiple and often heterogeneous sources, without human \n\nclient while the other color refers to layers managed by the \n\nintervention. Rosa et.al. [8] presented a novel ontology-based \n\ncloud providers. \n\napproach to utilize ontology to identify and map threats to assets. With the support of formally sound approaches, this process can be streamlined and made more efficient. From an ontology perspective, the authors introduced ThreMA, an ontology-based approach for automating threat modeling in ICT infrastructures. ThreMA provides a standard meta- model that describes the infrastructure and a set of rules for threat modeling. The meta-model consists of three ontolo- gies modules: ICT ontology for modeling the infrastructure, Data Flow ontology for representing data flow diagrams, and threat ontology for characterizing threats. The use of ontology and inference rules allows for a syntactical representation of the problem, mimicking expert thinking. This approach enhances extensibility, maintainability, and integration in a rapidly changing context. The paper emphasizes the impor- \n\ntance of using ontologies to address the lack of context and low accuracy in threat modeling. Overall, ThreMA offers a comprehensive ontology-based solution for automating threat modeling in ICT infrastructures. \n\n## III. M ETHODOLOGY \n\nThis work presents an ontology for representing various data sources about cloud computing and security. This ontology enables a knowledge presentation framework for all cloud computing and its relationships. The ontology consists of sev- eral modules: Cloud Computing and services, Cloud Service underlying components, and CVE module. \n\n### A. Cloud Computing Stack and Services Ontology Module This section represents our proposed ontology module that covers the cloud computing stack and services. Our extension ontology is provided as a separate ontology, which is an important design criteria in ontology engine engineering [13, 14]. This ontology can be used to unify and provide a primary \n\nbaseline for cloud computing stack, threat understanding, and \n\nFig. 1. Cloud computing stack. The green color depicts the layers managed by the used user. While the orange-colored boxes represent the layers managed by the cloud provider. \n\nFig. 2. Cloud computing stack ontology. ",
    "\\(q\\)-NAGUMO NORMS AND FORMAL SOLUTIONS TO SINGULARLY PERTURBED \\(q\\)-DIFFERENCE EQUATIONS 5 \n\nfor the \\(q\\)-analogue to \\(\\lambda\\), which reduces to \\[[n]_{q}=1+q+\\cdots+q^{n-1},\\qquad\\text{for }n\\in{\\mathbb{N}}^{+}.\\]  We have that\n \\([0]_{q}=0\\)and\n \n\n(162.1) \\[[np]_{q}=\\frac{q^{p}-1}{q-1}\\frac{q^{np}-1}{q^{p}-1}=[p]_{q}\\cdot[n]_{q^{p}}, \\qquad n,p\\in{\\mathbb{N}}^{+}.\\]  \n\nFor future use, we note that \\[|[n]_{q}|\\leqslant[n]_{|q|},\\qquad\\text{ for }n\\in{\\mathbb{N}},\\]  and also that \n\n(164.1) \\[\\lim_{n\\to+\\infty}\\frac{[n]_{q}}{q^{n}}=\\frac{1}{q-1}.\\]  \n\nThese constants appear naturally while considering Jackson\u2019s \\(q\\)-derivative of a function \\(f\\), which is given by \\[d_{q}(f)(x):=\\frac{f(qx)-f(x)}{qx-x}=\\frac{\\sigma_{q}(f)(x)-f(x)}{qx-x},\\]  whenever the expression is defined. As before, \\(\\sigma_{q}(f)(x):=f(qx)\\). For analytic\n functions \\(f\\in\\mathcal{O}(D_{r})\\), we see that\n \n\n(170.1) \\[\\sigma_{q}(f),d_{q}(f)\\in\\mathcal{O}(D_{r/|q|})\\]  \n\nand they can be computed term by term using its power series expansion according to the rules \\[d_{q}(x^{n})=[n]_{q}x^{n-1},\\qquad\\sigma_{q}(x^{n})=q^{n}x^{n},\\qquad n\\in{ \\mathbb{N}}.\\]  On the other hand, this formula allows to consider \\(d_{q},\\sigma_{d}:{\\mathbb{C}}[[x]]\\to{\\mathbb{C}}[[x]]\\), also\n defined term by term. In this setting, Leibniz rule is replaced by \n\n(173.1) \\[d_{q}(fg)(x)=d_{q}(f)(x)g(x)+f(qx)d_{q}(g)(x).\\]  \n\nWe recall the coefficients \n\n(174.1) \\[(a;q)_{n}=\\prod_{j=0}^{n-1}(1-aq^{j}),\\qquad(a;q^{-1})_{\\infty}=\\prod_{j=0}^{ \\infty}(1-aq^{-j}),\\qquad a\\in{\\mathbb{C}}.\\]  \n\nThe second one is convergent as we can compare it with a geometric series. The \\(q\\)-factorial is defined accordingly as \\[[n]_{q}^{!}=[1]_{q}[2]_{q}\\cdots[n]_{q}=\\frac{(q;q)_{n}}{(1-q)^{n}}.\\]  In general, for \\(|q|>1\\), since\n \\(\\lambda\\in{\\mathbb{R}}\\longmapsto[\\lambda]_{|q|}\\) is a strictly increasing function, the same holds for the map \\(n\\in{\\mathbb{N}}\\longmapsto[n]^{!}_{|q|}\\). Therefore, \n\n\\[\\frac{[n-p]_{|q|}}{([n]^{!}_{|q|})^{1/p}}=\\frac{[n-p]_{|q|}}{([n] _{|q|}\\cdots[n-p+1]_{|q|})^{1/p}([n-p]^{!}_{|q|})^{1/p}} \\leqslant\\frac{[n-p]_{|q|}}{[n-p+1]_{|q|}}\\frac{1}{([n-p]^{!}_{|q |})^{1/p}},\\]  \n\nand thus \n\n(181.1) \\[\\frac{[n-p]_{|q|}}{([n]^{!}_{|q|})^{1/p}}\\leqslant\\frac{1}{([n-p]^{!}_{|q|})^{ 1/p}},\\qquad\\text{for integers }n>p>0.\\]  ",
    "\n* K. Zollner, P. E. Faria Junior, and J. Fabian, Phys. Rev. B 100 , 085128 (2019). \n* B. Huang, G. Clark, E. Navarro-Moratalla, D. R. Klein, R. Cheng, K. L. Seyler, D. Zhong, E. Schmidgall, M. A. McGuire, D. H. Cobden, et al., Nature  546 , 270 (2017). \n* C. Gong, L. Li, Z. Li, H. Ji, A. Stern, Y. Xia, T. Cao, W. Bao, C. Wang, Y. Wang, et al., Nature  546 , 265 (2017). \n* Y. Deng, Y. Yu, Y. Song, J. Zhang, N. Z. Wang, Z. Sun, Y. Yi, Y. Z. Wu, S. Wu, J. Zhu, et al., Nature  563 , 94 (2018). \n* O. G\u00a8 oser, W. Paul, and H. Kahle, Journal of Magnetism and Magnetic Materials  92 , 129 (1990). \n* E. J. Telford, A. H. Dismukes, K. Lee, M. Cheng, A. Wieteska, A. K. Bartholomew, Y.-S. Chen, X. Xu, A. N. Pasupathy, X. Zhu, et al., Advanced Materials  32 , 2003240 (2020). \n* Y. Guo, Y. Zhang, S. Yuan, B. Wang, and J. Wang, Nanoscale  10 , 18036 (2018). \n* Z. Jiang, P. Wang, J. Xing, X. Jiang, and J. Zhao, ACS Applied Materials and Interfaces  10 , 39032 (2018). \n* C. Wang, X. Zhou, L. Zhou, N.-H. Tong, Z.-Y. Lu, and W. Ji, Science Bulletin  64 , 293 (2019). \n* N. P. Wilson, K. Lee, J. Cenker, K. Xie, A. H. Dismukes, E. J. Telford, J. Fonseca, S. Sivakumar, C. Dean, T. Cao, et al., Nature Materials  20 , 1657 (2021). \n* J. Klein, B. Pingault, M. Florian, M.-C. Hei\u00dfenb\u00a8 uttel, A. Steinhoff, Z. Song, K. Torres, F. Dirnberger, J. B. Curtis, M. Weile, et al., ACS Nano  17 , 5316 (2023). \n* M. Bianchi, S. Acharya, F. Dirnberger, J. Klein, D. Pashov, K. Mosina, Z. Sofer, A. N. Rudenko, M. I. Katsnelson, M. van Schilfgaarde, et al., Phys. Rev. B  107 , 235107 (2023). \n* A. N. Rudenko, M. R\u00a8 osner, and M. I. Katsnelson, npj Computational Materials  9 , 1 (2023). \n* J. Klein, T. Pham, J. D. Thomsen, J. B. Curtis, T. Denneulin, M. Lorke, M. Florian, A. Steinhoff, R. A. Wiscons, J. Luxa, et al., Nature Communications  13 , 5420 (2022). \n* E. J. Telford, A. H. Dismukes, R. L. Dudley, R. A. Wiscons, K. Lee, D. G. Chica, M. E. Ziebel, M.-G. Han, J. Yu, S. Shabani, et al., Nature Materials  21 , 754 (2022). \n\ndoping. As a result we find the largest angle change in \\(\\delta\\). As the inter-layer distance stays the same, the inner and outer Cr atoms of the bilayer system experience a different change in their local environments, which we \\(\\mu_{B}^{1}\\neq\\mu_{B}^{2}\\)and\n \\(\\mu_{B}^{3}\\neq\\mu_{B}^{4}\\).\n \\(\\mu_{B}^{1}\\neq\\mu_{B}^{2}\\)and \\(\\mu_{B}^{3}\\neq\\mu_{B}^{4}\\). \n* 39 \n* A. Grubi\u02c7 \u02c7 Cabo, M. Michiardi, C. E. Sanders, M. Bianchi, D. Curcio, D. Phuyal, M. H. Berntsen, Q. Guo, and M. Dendzik, Advanced Science (2023). \n* N. D. Mermin and H. Wagner, Phys. Rev. Lett.  17 , 1133 (1966). \n* J. Strasdas, B. Pestka, M. Rybak, A. K. Budniak, N. Leuth, H. Boban, V. Feyer, I. Cojocariu, D. Baranowski, J. Avila, et al., arxiv.2211.05501. \n* S. Chakravarty, B. I. Halperin, and D. R. Nelson, Phys. Rev. B  39 , 2344 (1989). \n* S. V. Hoffmann, C. S\u00f8ndergaard, C. Schultz, Z. Li, and P. Hofmann, Nuclear Instruments and Methods in Physics Research, A  523 , 441 (2004). \n* L. J. de Jongh, ed.,  Magnetic Properties of Layered Transition Metal Compounds  (Springer, 1990). \n* A. I. Liechtenstein, V. I. Anisimov, and J. Zaanen, Physical Review B  52 , R5467 (1995). \n* V. Y. Irkhin, A. A. Katanin, and M. I. Katsnelson, Phys. Rev. B  60 , 1082 (1999). \n* M. Gibertini, M. Koperski, A. F. Morpurgo, and K. S. Novoselov, Nature Nanotechnology  14 , 408 (2019). \n* G. Kresse and J. Furthm\u00a8 uller, Comp. Mat. Sci.  6 , 15 (1996). \n\nFIG. 10. CrSBr bilayer lattice structure indicating analysed angles, distances, and magnetic moments. For values see Tab. I. \n\nTABLE I. CrSBr lattice structure details for undoped and doped bilayers including angles, distances, and magnetic moments as indicated in Fig. 10. \n\n\\begin{tabular}{r r r c}\n & undoped & doped & difference \\\\\n\\hline\nlat. const. \\(a\\) [\u00c5] & 3.483 & 3.496 & -0.013 \\\\\nlat. const. \\(b\\) [\u00c5] & 4.734 & 4.783 & -0.049 \\\\\n\\hline\n\\(\\alpha\\) [\u2218] & 95.84 & 94.77 & 1.07 \\\\\n\\(\\beta\\) [\u2218] & 92.85 & 93.34 & -0.50 \\\\\n\\(\\gamma\\) [\u2218] & 120.01 & 120.54 & -0.53 \\\\\n\\(\\delta\\) [\u2218] & 163.31 & 166.63 & -3.32 \\\\\n\\hline\n\\(\\Delta_{\\text{intra}}\\) [\u00c5] & 2.00 & 1.93 & 0.08 \\\\\n\\(\\Delta_{\\text{inter}}\\) [\u00c5] & 5.21 & 5.21 & 0.00 \\\\\n\\hline\n\\(\\mu_{B}^{1}\\) & 2.77 & 2.87 & -0.11 \\\\\n\\(\\mu_{B}^{2}\\) & 2.77 & 2.78 & -0.01 \\\\\n\\(\\mu_{B}^{3}\\) & -2.77 & -2.78 & 0.01 \\\\\n\\(\\mu_{B}^{4}\\) & -2.77 & -2.87 & 0.11 \\\\\n\\end{tabular}\n\n\n\n\n",
    "describes the traveling-wave microwave photon transporting \n\nand \\[\\hat{c}_{{\\rm{in}}/{\\rm{out}}}=\\pm\\frac{1}{\\sqrt{2\\pi}}\\int d\\omega e^{-i \\omega\\left(t-t^{\\prime}\\right)}c_{0}(\\omega),\\]  \\[\\hat{c}_{{\\rm{in}}/{\\rm{out}}}=\\pm\\frac{1}{\\sqrt{2\\pi}}\\int d\\omega e^{-i \\omega\\left(t-t^{\\prime}\\right)}c_{0}(\\omega),\\]  \n\nalong the transmission line with \\(l=b,c\\) refering to its left, \\([l(\\omega),l^{\\dagger}(\\omega^{\\prime})]=\\delta(\\omega-\\omega^{\\prime})\\). Also, the flux\n \\([l(\\omega),l^{\\dagger}(\\omega^{\\prime})]=\\delta(\\omega-\\omega^{\\prime})\\). Also, the flux operator of the traveling-wave photon reads [14\u201316]: \n\nare the input- and output fields, respectively. After the Fourier\n , for \n\n\\[\\hat{\\phi}_{l}(x)=\\sqrt{\\frac{\\hbar Z_{0}}{4\\pi}}\\int_{0}^{\\infty}\\frac{d \\omega}{\\sqrt{\\omega}}\\left[\\hat{l}(\\omega)e^{ikx}+\\hat{l}^{\\dagger}(\\omega)e^ {-ikx}\\right],\\] (7)  \\[\\hat{\\phi}_{l}(x)=\\sqrt{\\frac{\\hbar Z_{0}}{4\\pi}}\\int_{0}^{\\infty}\\frac{d \\omega}{\\sqrt{\\omega}}\\left[\\hat{l}(\\omega)e^{ikx}+\\hat{l}^{\\dagger}(\\omega)e^ {-ikx}\\right],\\] (7)  \n\ntransformation: \\(x(t)=\\int_{-\\infty}^{+\\infty}e^{-i\\omega\\left(t-t_{0}\\right)}x(\\omega)d\\omega/ \\sqrt{2\\pi}\\),\n \\(b_{\\rm{out}}(t)\\)the\n \n\n\n\n\\(x(t)=a(t)\\), \\(b_{\\rm{in}}(t)\\), \\(c_{\\rm{in}}(t)\\), \\(b_{\\rm{out}}(t)\\), and \\(c_{\\rm{out}}(t)\\), respectively, we have \n\n\n\nwith \\(Z_{0}\\)\\(Z_{0}\\)with Z0 being the characteristic impedance of the transmission line, and thus\n \n\n\\[-i\\omega a(\\omega)= \\left(-i\\omega_{p}-\\frac{\\kappa-\\gamma}{2}\\right)a(\\omega)\\] (12) \\[+\\sqrt{\\kappa_{1}}b_{\\rm{in}}(\\omega)+\\sqrt{\\kappa_{2}}c_{\\rm{in} }(\\omega)\\]  \n\n\n\n\n\n\\[\\dot{\\hat{\\phi}}_{l}(x)=(-i)\\sqrt{\\frac{\\hbar Z_{0}}{4\\pi}}\\int^{ \\infty}_{0}d\\omega\\sqrt{\\omega}\\left[\\hat{l}(\\omega)e^{ikx}-\\hat{l}^{\\dagger}( \\omega)e^{-ikx}\\right].\\] (8)  \\[\\dot{\\hat{\\phi}}_{l}(x)=(-i)\\sqrt{\\frac{\\hbar Z_{0}}{4\\pi}}\\int^{ \\infty}_{0}d\\omega\\sqrt{\\omega}\\left[\\hat{l}(\\omega)e^{ikx}-\\hat{l}^{\\dagger}( \\omega)e^{-ikx}\\right].\\] (8)  \n\nand \n\nUnder the sufficiently low current bias, the CBJJ Hamiltonian reads: \\(\\hat{H}_{CBJJ}\\approx\\hat{H}_{b},\\)\\(\\hat{H}_{CBJJ}\\approx\\hat{H}_{b},\\) shown in Eq. 4. The physical boundary \n\n\n\ncondition at \\(x=0\\), i.e., the location of the device, reads: \n\n\\[-i\\omega a(\\omega)= \\left(-i\\omega_{p}+\\frac{\\kappa+\\gamma}{2}\\right)a(\\omega)\\] (13) \\[-\\sqrt{\\kappa_{1}}b_{\\rm{out}}(\\omega)-\\sqrt{\\kappa_{2}}c_{\\rm{ out}}(\\omega).\\]  \n\n. \n\n\n\n\\(\\hat{I}\\left(0_{b},t\\right)=\\hat{I}\\left(0_{c},t\\right)\\)\\(\\hat{I}\\left(0_{b},t\\right)=\\hat{I}\\left(0_{c},t\\right)\\), \\(V_{J}=\\left({\\Phi_{0}}/{2\\pi}\\right)\\dot{\\delta}+\\left[\\dot{\\phi}(0_{b})-\\dot{ \\phi}(0_{c})\\right]\\)the\n ap-\ni\n \n\nFor the configuration shown in Fig. 3, we can assume that \\(c_{\\rm{in}}(t)=0\\). Consequently, we have \n\nThus, under the low-excitation limit and rotating-wave approximation, i.e., the photon scattering is the desired elastic and any possibly created and annihilated of the photons at \\(x=0\\) is neglected, we have \n\n\\[b_{\\rm{in}}(\\omega)+b_{\\rm{out}}(\\omega)=\\sqrt{\\kappa_{1}}a(\\omega)\\] (14) \\[c_{\\rm{in}}(\\omega)+c_{\\rm{out}}(\\omega)=\\sqrt{\\kappa_{2}}a( \\omega).\\]  \n\n\\[\\hat{H}_{CBJJ-B}= C_{J}{\\hat{p}}_{\\theta}\\left[\\dot{\\phi}(0_{b})-\\dot{\\phi}(0_{c})\\right]\\] \\[= i\\hbar\\sqrt{\\frac{\\kappa_{l}}{2\\pi}}{\\int{d\\omega}}\\left[a^{ \\dagger}l(\\omega)-l^{\\dagger}(\\omega)a\\right],\\]  \\[\\hat{H}_{CBJJ-B}= C_{J}{\\hat{p}}_{\\theta}\\left[\\dot{\\phi}(0_{b})-\\dot{\\phi}(0_{c})\\right]\\] \\[= i\\hbar\\sqrt{\\frac{\\kappa_{l}}{2\\pi}}{\\int{d\\omega}}\\left[a^{ \\dagger}l(\\omega)-l^{\\dagger}(\\omega)a\\right],\\]  \n\nTherefore, the measurable transmitted- and phase shift spectra of the traveling-wave photons can be calculated as \n\nwhere \\(\\kappa_{l}=Z_{0}/4Z_{J}\\,(l=b,c)\\) describes the interaction \n\n\n\nand \n\n\\[T_{B}(\\omega)=\\left|\\frac{c_{\\rm{out}}(\\omega)}{b_{\\rm{in}}(\\omega)}\\right|^{2 }=\\frac{4\\kappa_{1}\\kappa_{2}}{4\\left(\\omega-\\omega_{p}\\right)^{2}+(\\kappa+ \\gamma)^{2}},\\] (15)  \n\nLJ/CJ is the characteristic impedance of the Josephson junction. As a consequence, the Hamiltonian (with \u210f= 1)\nZJ =\np\n \\(\\hbar=1\\)\\(\\hbar=1\\)) between the CBJJ and the left/right traveling-wave photons, \\(Z_{J}=\\sqrt{{L_{J}}/{C_{J}}}\\)junction.\n of the system [16\u201318]: \n\n\\[\\phi_{T_{B}}(\\omega)=\\arctan\\left[-\\frac{2\\left(\\omega-\\omega_{p}\\right)}{ \\kappa+\\gamma}\\right],\\] (16)  \n\n\\[H_{B}= \\left(\\omega_{P}-\\frac{i\\gamma}{2}\\right)a^{\\dagger}a\\] (9) \\[+\\int d\\omega\\left[\\omega b(\\omega)^{\\dagger}b(\\omega)+i\\sqrt{ \\frac{\\kappa_{1}}{2\\pi}}\\left(a^{\\dagger}b(\\omega)-ab(\\omega)^{\\dagger}\\right)\\right]\\] \\[+\\int d\\omega\\left[\\omega c(\\omega)^{\\dagger}c(\\omega)+i\\sqrt{ \\frac{\\kappa_{2}}{2\\pi}}\\left(a^{\\dagger}c(\\omega)-ac(\\omega)^{\\dagger}\\right) \\right],\\]  \n\nrespectively. In Fig. 4 we shows the spectra of the travelingwave microwave photons scattered by a quantized CBJJ device with the typical parameters: Ib = 0, Ic = 0.975 \u00b5A,\n \\(I_{b}=0,I_{c}=0.975{\\rm{~{}\\mu A}}\\)\\(I_{b}=0,I_{c}=0.975{\\rm{~{}\\mu A}}\\), \n\n\n\n\\(C=11.18{\\rm{~{}pF}}\\), and thus \\(\\omega_{p}\\sim 2\\pi\\times 2.595{\\rm{~{}GHz}}\\)\n\n. It is seen \n\n\n\n\n\nwhere \\(\\gamma\\) is decay rate of the cavity, \\(\\kappa_{1}\\) and \\(\\kappa_{2}\\) are the effective \n\nstrengths of the boson coupled to the photons in the left and right sides of the transmission line, respectively. By using the standard input-output theory [18, 19], we get the relations: \n\n\\[\\frac{da}{dt}=\\left(-i\\omega_{p}-\\frac{\\kappa+\\gamma}{2}\\right)a+\\sqrt{\\kappa_ {1}}b_{\\rm{in}}(t)+\\sqrt{\\kappa_{2}}c_{\\rm{in}}(t),\\] (10)  \n\n\n\nand \n\n\\[\\frac{da}{dt}=\\left(-i\\omega_{p}+\\frac{\\kappa-\\gamma}{2}\\right)a-\\sqrt{\\kappa_ {1}}b_{\\rm{out}}(t)-\\sqrt{\\kappa_{2}}c_{\\rm{out}}(t),\\] (11)  \n\nwith \\(\\kappa=\\kappa_{1}+\\kappa_{2}\\), \n\nclearly that, if the CBJJ device works as a boson, the peak of the photon transmission is located as the eigenfrequency of the \n\n\\[\\hat{b}_{{\\rm{in}}/{\\rm{out}}}=\\pm\\frac{1}{\\sqrt{2\\pi}}\\int d\\omega e^{-i \\omega\\left(t-t^{\\prime}\\right)}b_{0}(\\omega),\\]  \\[\\hat{b}_{{\\rm{in}}/{\\rm{out}}}=\\pm\\frac{1}{\\sqrt{2\\pi}}\\int d\\omega e^{-i \\omega\\left(t-t^{\\prime}\\right)}b_{0}(\\omega),\\]  \n\nFIG. 4: The transmitted spectrum (a) and phase shift spectrum (b) \\(\\kappa_{1}=0.004\\),\n \\(\\kappa_{2}=0.008\\),\n \\(\\gamma=0.0008\\), and\n \\(\\kappa_{1}=0.004\\), \\(\\kappa_{2}=0.008\\), \\(\\gamma=0.0008\\), and \\(\\omega_{p}=2\\pi\\times 2.595{\\rm{~{}GHz}}\\). ",
    "# Introduction \n\nVectorlike (VL) fermions are key ingredients in many new physics models beyond the Standard Model (SM) adopted to resolve both theoretical and experimental issues. Since chiral fermions in the fourth family are excluded experimentally [1, 2], these are considered to be vectorlike and their masses are given independently to the Higgs mechanism in the SM. The VL fermions are introduced in, for instance, supersymmetric models [3\u201310], gauge mediated supersymmetry breaking scenario [11\u201316], composite Higgs models [17\u201319], KSVZ axion models [20,21], axionlike particle models [22\u201325], alternative solutions of the strong CP problem [26,27], two Higgs doublet model augmented by VL fermions [28\u201338], and models for gauge coupling unification [39,40]. \n\nAmong the fourth family fermions, VL leptons (VLLs) with nonzero lepton number play unique roles in constructing lepton-philic dark matter (DM) models [41\u201346], mirror sector models [47\u201349], and explanations for the muon anomalies [50\u201365] 1 . Interestingly, the lightest VLL is expected to be in the reach of the Large Hadron Collider (LHC) or High-Luminosity (HL)-LHC. Both ATLAS and CMS collaborations search for the pair production of VLLs each of which dominantly decays to a SM boson and a tau lepton [70\u201372]. For the doublet VLL 2 , the ATLAS search excludes the mass range of\n \\(130<m_{\\mathrm{VLL}}<900~{}\\mathrm{GeV}\\)[72], and the CMS search\n excludes the mass up to 1045 GeV [71]. The singlet VLL is less constrained and the limit is less \\(150~{}\\mathrm{GeV}\\)[71]. Prospects of such VLLs at the future colliders are discussed in Ref. [73].\n The pair productions of the VLLs decaying to a SM boson and a muon (neutrino) are studied by the ATLAS [74] and the theorists [75, 76] using the Run-I data. The limit is obtained for \\(m_{\\rm VLL}\\lesssim 500\\)GeV when the neutral component of the lightest doublet VLL dominantly decays\n to a \\(W\\) boson and a muon [75]. There are also studies for the VLL produced from cascade decays of extra neutral Higgs bosons [28\u201331,35,36], and signals from the VLLs decaying to a DM particle [77] or \\(Z^{\\prime}\\)boson [78]. \n\nIn this paper, we study pair-productions of the VLLs, through the Drell-Yan process, decaying to the second generation lepton, namely _ muon-philic_  VLL. Such VLL is well motivated to explain the experimental anomalies in the muon \\(g-2\\)limits\n [69, 79, 80] and the semi-leptonic\n \\(B\\)decays [81]. 3 In this work, we obtain the current limits using the Run-2 data at\n _ _ \\(\\sqrt{s}=13\\)TeV by simply recasting the ATLAS analyses searching for the triplet lepton in the type-III seesaw [84,85]. We then estimate expected sensitivities at the HL-LHC using the same channels. \n\nThis paper is organized as follows. We briefly explain the VLLs in Sec. 2 and discuss the analysis strategy in Sec. 3. Our main results are shown in Sec. 4. Finally, we summarize the paper in Sec. 5. 1 The latest experimental result [66] confirms the previous results [67,68] which might deviate from the SM prediction [69]. 2 Throughout this work, doublet (singlet) for VLL means iso-doublet (iso-singlet) under the \\(SU(2)_{L}\\) gauge symmetry. 3 The LHCb has recently announced the new result of \\(R_{K^{(*)}}\\) consistent with the SM expectation [82] which requires efforts such as separate measurements of the branching ratio at Belle-II [83]. ",
    "#### Even \\(L\\) with a fermion parity defect \n\nLet us introduce a \\(\\mathsf{G}\\) defect. A concrete Hamiltonian to keep in mind is \n\n\\[H_{\\mathsf{G}}={i\\over 2}\\sum_{\\ell=1}^{L-1}\\chi_{\\ell+1}\\chi_{ \\ell}-{i\\over 2}\\chi_{1}\\chi_{L}\\,,\\  \n\nwhere the defect is in the link connecting \\((L,1)\\). We use the subscript \\(\\mathsf{G}\\) for the Hamiltonian and symmetry operators in the system with a \\(\\mathsf{G}\\) defect. However, we emphasize that for most of our discussion the particular form of the Hamiltonian will not matter. Note that the defect can be moved to other links, e.g., to the link \\((1,2)\\), by conjugating \\(H_{\\mathsf{G}}\\) by a local \\(\\mathsf{G}\\) transformation, \\(\\chi_{1}\\) or \\(\\mathsf{g}_{1}\\). \n\nLet us determine the symmetry operators of the theory with the defect. We use the same fermion parity operator \\(\\mathsf{G}\\) as in ( 3.10 ), because it commutes with \\(H_{\\mathsf{G}}\\). 21 On the other hand, instead of ( 3.5 ), the translation operator now acts on the fermion fields as \n\nT\ud835\udda6:\u03c7\u2113\u2192T\ud835\udda6\u03c7\u2113T\ud835\udda6\u22121=\u2211\u2113\u2032R(T\ud835\udda6)\u2113,\u2113\u2032\u03c7\u2113\u2032={\u03c7\u2113+1\u2113=1,2,\u22ef,L\u22121\u2212\u03c71\u2113=L (486.1)  \n\nThe algebra satisfied by these operators is \n\n\\[R(\\mathsf{G})^{2}=1\\,,~{}~{}~{}~{}R(T_{\\mathsf{G}})^{L}=R( \\mathsf{G})\\,,~{}~{}~{}~{}R(\\mathsf{G})\\,R(T_{\\mathsf{G}})=R(T_{\\mathsf{G}})\\, R(\\mathsf{G})\\,.\\  \n\nIn contrast to the case without the defect ( 3.7 ),now we have \n\n\\[\\det R(T_{\\mathsf{G}})_{\\ell,\\ell^{\\prime}}=+1\\,,\\ \\[\\det R(\\mathsf{G})_{\\ell,\\ell^{\\prime}}=+1\\,.\\]  \n\nThis means that the twisted translation operator is an \\(SO(L)\\) transformation and is constructed out of an even number of fermions, i.e., it is bosonic. \n\nLet us write \\(T_{\\mathsf{G}}\\) in terms of the fermion fields. Again, ( 3.22 ) does not determine its phase normalization, and we will make an arbitrary choice below. Later, in Section  3.3 , we will rescale it to \\(T_{\\text{NSNS}}\\) and compare it to the continuum operators. Its action in ( 3.22 ) means that we should multiply \\(T\\) by an operator that maps \\(\\chi_{1}\\to-\\chi_{1}\\).\n  and leaves the other fermions unchanged, i.e., we should multiply it by \\(\\mathsf{g}_{1}=-\\chi_{2}\\chi_{3}\\cdots\\chi_{L}\\). Therefore, we take [ 81 ] 22 \n\n\\[T_{\\mathsf{G}}=(-1)^{N}\\mathsf{g}_{1}T ={1\\over 2^{L-1\\over 2}}(1-\\chi_{1}\\chi_{2})(1-\\chi_{2}\\chi_{3}) \\cdots(1-\\chi_{L-1}\\chi_{L})\\,.\\  21 We do not write \\(\\mathsf{G}_{\\mathsf{G}}\\) because it is the same as \\(\\mathsf{G}\\). 22 Alternatively, the translation operator for even \\(L\\) with a defect can be written as \n\n\\[T_{\\mathsf{G}}={(-1)^{N}\\over 2^{L-1\\over 2}}(\\chi_{1}-\\chi_{2}) (\\chi_{2}-\\chi_{3})\\cdots(\\chi_{L-1}-\\chi_{L})\\chi_{L}\\,.\\  (Note that in this forms, \\(T_{\\mathsf{G}}\\) does not satisfy the locality condition ( 1.15 ).) ",
    "when measuring the correlation of cities. Although the correlation of cities can be measured from the aspect of POI distribution, the user behavioral transition pattern is a significant factor in the next POI recommendation task, we thus further explore such correlation from the angle of user sequential behaviors. \n\n**Correlation of Cities w.r.t Behavioral Patterns** . We examine the correlation of cities w.r.t. the categories of users\u2019 successive POI visits. In particular, given any two cities, \\(A^{cat}=[A_{1}^{cat},A_{2}^{cat}...A_{\\mathcal{|S|}}^{cat}]\\) and \\(B^{cat}=[B_{1}^{cat},B_{2}^{cat}...B_{\\mathcal{|S|}}^{cat}]\\) re fer to the category transition distributions among \\(\\mathcal{S}\\)within\n  transition types, e.g., \\(A_{1}^{cat}\\)denotes the ratio of transition type \\(FO\\to SS\\) within city A. Analogously, the similarity among different cities can be calculated via the Pearson correlation coefficient, shown in Fig. 2(b). Interestingly, we observe that the correlation of cities w.r.t behavioral patterns is quite different from that w.r.t POI distribution. Specifically, PHO and CAL still keep higher similarity, whereas NYC shows comparably lower similarity with PHO and CAL. To further dig out how the four cities are correlated and different over the behavioral patterns, we compare the two most correlated cities (i.e., CAL and PHO) and the two least correlated cities (i.e., NYC and SIN). For ease of presentation, we select the 10 most frequent category transitions for comparison as shown in Fig. 2(c-d), where the \\(x\\)-axis denotes the category transitions, e.g., \\(AE\\to CU\\)within\n  (AE2CU), and the \\(y-\\)axis shows the proportion of such a transition within a city. We find that the more correlated cities possess consistent distributions over the frequent category transitions and _ vice versa_ . The above observations depict the various correlations between cities, which inspire us to differentiate their influence when transferring knowledge from auxiliary cities to the target city. \n\n## The Proposed MERec This section presents the proposed MERec, which leverages the correlation of behavioral patterns when transferring knowledge from auxiliary cities to the target city, i.e., paying more attention to more correlated knowledge. \n\n**Problem Formulation.**  Each city has its unique user set \\(\\mathcal{U}\\)his\n  and POI set \\(\\mathcal{P}\\)without sharing any common users and POIs. For user \\(u\\), all his check-in records, i.e., \\({r=(p,c,g,t)}\\), are ordered by timestamps as in [22], where \\(p,c,g,t\\) denote POI \\(p\\), category \\(c\\), coordinate \\(g\\) (i.e., longitude and latitude) and timestamp \\(t\\). We then split his historical records into sequences by day and obtain two \n\nFig. 2: (a-b) the correlation of four cities w.r.t POI distribution and behavioral patterns at category level; (c-d) two most correlated and least correlated cities. ",
    "# SCHUR-POSITIVITY OF SHORT CHORDS IN MATCHINGS \n\n### 2.2.  Symmetric and Schur-positive sets As mentioned in Section 1, a set \\(\\mathcal{A}\\) is symmetric with respect to a statistic function \\(D:\\mathcal{A}\\to 2^{[N-1]}\\)if\n if its generating function \\(\\mathcal{Q}_{N,D}(\\mathcal{A})\\)is a symmetric function. Moreover, it is Schur-positive if\n all Schur coefficients are nonnegative integers. \n\nOne of the fundamental constructions of Schur-positive sets, regarding sets of standard Young tableaux (SYT), is due to Gessel [11]. Let\n \\(\\operatorname{SYT}(\\lambda)\\)denote the set of standard Young tableaux of\n shape \\(\\lambda\\). We draw tableaux in English notation, as in Figure 2. The _ descent set_  of \\(T\\in\\operatorname{SYT}(\\lambda)\\)is\n \\[\\operatorname{Des}(T):=\\{i\\in[N-1]\\mid i+1\\text{ appears in a lower row than $ i$ in $T$}\\}.\\]  For example, the descent set of the SYT in Figure 2 is \\(\\{2,4,7,8\\}\\). \n\n\\[\\young(1247,36,58,9)\\]  \n\nThe entry in row \\(i\\) and column \\(j\\) of a tableau \\(T\\in\\operatorname{SYT}(\\lambda)\\)entries\n is denoted as\n \\(T_{i,j}\\). In addition, we define\n \\(\\operatorname{row}_{i}(T):=\\{T_{i,j}\\mid 1\\leq j\\leq\\lambda_{i}\\}\\)in\n Figure\n ,\n  as the set of entries in the \\(i\\)-th row of \\(T\\). For example, if we , then\n \\(T_{3,2}=8\\)and\n \\(\\operatorname{row}_{3}(T)=\\{5,8\\}\\). \n\n**Theorem 2.4**  (Gessel [11]) **.** _ For every_ \\(\\lambda\\vdash N\\)_, the set_ \\(\\operatorname{SYT}(\\lambda)\\)_ is Schur-positive with respect to_ \\(\\operatorname{Des}\\)_._ _Moreover,_ \\(\\mathcal{Q}(\\operatorname{SYT}(\\lambda))=s_{\\lambda}\\)_._ \n\nIn 2015, Adin and Roichman proved the following criterion. \n\n**Theorem 2.5**  ([2, Prop. 9.1]) **.** _ A set_ \\(\\mathcal{A}\\)_ is symmetric with respect to_ \\(D:S\\to 2^{[N-1]}\\)_if and only if_ \\[\\sum_{a\\in\\mathcal{A}}\\bm{t}^{D(a)}=\\sum_{\\lambda\\vdash N}c_{\\lambda}\\sum_{T \\in\\operatorname{SYT}(\\lambda)}\\bm{t}^{\\operatorname{Des}(T)}\\]  _for some values_ \\(c_{\\lambda}\\)_, where_ \\(\\bm{t}^{J}:=\\prod_{j\\in J}t_{j}\\)\n\n  \n\n_ for_ \\(J\\subseteq[N-1]\\)if\n only\n _. The coefficients_ \\(c_{\\lambda}\\)_ are the Schur_ _coefficients of_ \\(\\mathcal{A}\\)_. Moreover,_ \\(\\mathcal{A}\\)_ is Schur-positive if and only if_ \\(c_{\\lambda}\\in\\mathbb{N}_{0}\\)_ for all_ \\(\\lambda\\vdash N\\)_._ \n\nThis criterion implies that proving the Schur-positivity of a set is achievable by establishing a statistic-preserving bijection between the set and SYTs of shapes corresponding to a specific multiset. \n\nIn this paper, we will also apply a recently formulated criterion for symmetry [19]. \n\n**Definition 2.6.**  Let \\(\\mathcal{A}\\) be a finite set with a statistic \\(D:\\mathcal{A}\\to 2^{[N-1]}\\)of the\n . The set of elements that _ respect_ a given composition \\(\\alpha\\vDash N\\), denoted \\(\\mathcal{A}_{D}(\\alpha)\\)to\n , consists of the elements\n \\(a\\in\\mathcal{A}\\)clear\n  such that \\(D(a)\\subseteq S_{\\alpha}\\), where \\(S_{\\alpha}\\) is the set corresponding to the composition \\(\\alpha\\). When \\(D\\) is clear from the context, we may write \\(\\mathcal{A}(\\alpha)\\)instead.\n \n\nLemma\n _ A set_ \\(\\mathcal{A}\\)_ is symmetric if and only if_ \\(|\\mathcal{A}(\\alpha)|=|\\mathcal{A}(\\beta)|\\)_ for all_ \\(\\alpha\\sim\\beta\\vDash N\\)_._ \n\nNote that only sets of permutations are considered in [19]. However, Lemma 2.7 applies to other sets as well. \n\nAnother useful result about symmetric sets and symmetric functions is due to Bloom and Sagan: \n\n**Lemma 2.8**  (Bloom and Sagan [6, Lemma 2.2]) **.** _ For every set_ \\(S\\subseteq[N-1]\\)_, the function_ \\(F_{S}\\)_ is_ _symmetric if and only if_ \\(S=[N-1]\\)_ or_ \\(S=\\emptyset\\)_._ Figure\n  A SYT of shape \\(\\lambda=(4,2,2,1)\\).\n ",
    "where \\(\\delta_{nm}\\) is the Kronecker delta symbol. Such relation leads to the definition of the Laguerre transform of order \\(\\nu\\): \n\n\n\n\\[\\mathcal{T}^{\\nu}[f(x)]=\\left\\{\\int_{0}^{\\infty}e^{-x}x^{\\nu}L_{n }^{\\nu}(x)f(x)dx\\right\\}=\\{c^{\\nu}_{n}\\},\\] (11)  \n\nit must be emphasize that the Laguerre transform is a sequence of numbers in \\(\\mathbb{C}\\). The inverse Laguerre transform is defined by \n\n\\[f(x)=\\mathcal{(T^{\\nu})}^{-1}[\\{c_{n}^{\\nu}\\}]=\\sum_{k=0}^{ \\infty}c^{\\nu}_{n}L_{n}^{\\nu}(x).\\] (12)  \n\n\n\n## Examples of applications \n\n### Applications to the Schr\u00a8 odinger equation \n\nIn this section is consider the equation \n\n\n\n\\[-\\frac{1}{2}\\frac{d^{2}}{dr^{2}}\\psi(r)-(V(r)+E)\\psi(r)=0\\] (13)  \n\nwhich in appropriate units ( \\(\\hbar\\)=M=1) is the steady state Sch\u00a8 odinger equation defined in a one dimensional space, where \\(V(r)\\)is a potential function and\n \\(E\\) is the energy. Under the change of coordinates (see [0]), given by \\(\\lambda^{-1}\\xi(x)=dx/dr\\), where \\(\\lambda\\geq 0\\)has inverse length units, equation (13) becomes\n \n\n\\[\\lambda^{2}\\xi^{2}\\left[\\frac{d^{2}}{dx^{2}}\\psi(x)+\\frac{1}{\\xi} \\frac{d\\xi}{dx}\\frac{d}{dx}\\psi(x)-\\frac{2}{\\lambda^{2}\\xi^{2}}W(x)\\psi(x) \\right]=0,\\] (14)  \n\nwhere \\(W(x)=V(r)-E\\). To obtain a Laguerre-type equation the change of , leads to \\(\\xi(x)=x^{a}e^{bx}\\). coordinates must satisfy \\(x(r)\\geq 0\\)and setting\n \\(\\frac{1}{\\xi}\\frac{d\\xi}{dx}=\\frac{a}{x}\\)\n\nIn this way, equation (14) becomes \n\n\\[\\lambda^{2}\\xi^{2}\\left[\\frac{d^{2}}{dx^{2}}\\psi(x)+\\left(\\frac{a }{x}+b\\right)\\frac{d}{dx}\\psi(x)+\\left(A_{+}+\\frac{A_{-}}{x^{2}}-\\frac{A_{0}}{ x}\\right)\\psi(x)\\right]=0,\\] (15)  \n\n\n\nwhere \\(A_{\\pm},A_{0},a,b\\) are real parameters determined in terms of \\(V(r)\\)and\n \\(E\\). \n\nTo solve equation (15) it is proposed a solution of the form \n\n\\[\\psi(x)=x^{\\alpha}e^{-\\beta x}y(x),\\] (16)  \n\n\\(\\nu\\), and \\(\\alpha,\\beta,\\nu\\) are dimensionless parameters, free for the moment, but to be determined according to the concrete examples to be solved below. where \\(y=\\sum_{k=0}^{\\infty}c_{k}L_{k}^{\\nu}(x)\\), and\n \\(L_{n}^{\\nu}(x)\\)are the Laguerre polynomials of order\n \n\nTo solve (15) the use of the finite Laguerre transform is introduced. Many of the following transforms are known [0] or are obtained by direct calculation by using Laguerre polynomial properties found in [0] or in [0]. ",
    "Andrei Teimurazov 1 , Matthew McCormack 2, \u2217 , Moritz Linkmann 2, \u2020 , and Olga Shishkina 1, \u2021 \n\n##### Abstract\nIn magnetoconvection, the flow of electromagnetically conductive fluid is driven by a combination of buoyancy forces, which create the fluid motion due to thermal expansion and contraction, and Lorentz forces, which distort the convective flow structure in the presence of a magnetic field. The differences in the global flow structures in the buoyancy-dominated and Lorentz-force-dominated regimes lead to different heat transport properties in these regimes, reflected in distinct dimensionless scaling relations Nu) versus the strength of buoyancy (Rayleigh number\n Ra) and\n Ha). Here, we propose a theoretical model for the transition\n between these two regimes for the case of a quasistatic vertical magnetic field applied to a convective fluid layer confined between two isothermal, a lower warmer and an upper colder, horizontal surfaces. The model suggests that the scaling exponents \\(\\gamma\\)in the buoyancy-dominated regime,\n \\(\\mbox{\\rm{Nu}}\\sim\\mbox{\\rm{Ra}}^{\\gamma}\\)and\n , and \\(\\xi\\)in the Lorentz-force-dominated regime,\n \\(\\mbox{\\rm{Nu}}\\sim(\\mbox{\\rm{Ha}}^{-2}\\mbox{\\rm{Ra}})^{\\xi}\\), are related as \\(\\xi=\\gamma/(1-2\\gamma)\\)our\n , and the onset\n of the transition scales with\n \\(\\mbox{\\rm{Ha}}^{-1/\\gamma}\\mbox{\\rm{Ra}}\\). These theoretical results are supported by our Direct Numerical\n Simulations for\n \\(10\\leqslant\\mbox{\\rm{Ha}}\\leqslant 2000\\), Prandtl number\n \\(\\mbox{\\rm{Pr}}=0.025\\)and\n Raup to\n \\(10^{9}\\)and data from the literature. \n\nMagnetoconvection (MC) governs most astro- and geophysical systems and is relevant to various engineering applications [25, 7]. The former include, for instance, outer layers of stars and liquid metal planetary cores [12], examples of the latter comprise liquid-metal batteries, induction heating, casting, liquid-metal cooling for nuclear fusion reactors and semiconductor crystal growth [6]. MC occurs in an electrically conducting fluid that is subjected both to a magnetic field and an imposed temperature gradient. The buoyancy forces induce convective fluid motion due to thermal expansion and contraction, while the magnetic field affects this motion and distorts the global flow structure through the Lorentz force, which eventually influences the heat transport in the system. The resulting main two control parameters, the strength of the imposed thermal driving and that of the external magnetic field, are encoded in independent dimensionless groups, Raand Hartmann number\n Ha, respectively.\n \n\nOne of the key objectives in MC research is to provide scaling relations for the heat transport through the Nu, as a function of\n Raand\n Ha. However,\n the heat transport scaling relations also depend on the flow configuration, including the angle between the magnetic field and gravity, the geometry of the container and the boundary conditions (BCs), and on whether the buoyancy forces dominate over the Lorentz forces in the system or vice versa. This inherent complexity results in the need, at least in principle, to derive separate heat transport scaling relations to describe each specific flow regime itself and transitions between distinct regimes. The considerable difficulty of doing so in a coherent manner is exacerbated by non-universal scaling relations even within specific regimes \u2013 the scaling relations in the buoyancy-dominated and Lorentz-force-dominated regimes themselves change with the control parameters, and transitions between the different regimes are also non-universal. \n\nThe objective of this paper is to offer a unifying heat transport model for the transition between the buoyancy-dominated and Lorentz-force-dominated regimes in quasistatic MC. We focus on Rayleigh\u2013B\u00b4 enard \u2217 A. Teimurazov and M. McCormack contributed equally. \u2020 moritz.linkmann@ed.ac.uk \u2021 olga.shishkina@ds.mpg.de ",
    "### B. Compared Methods The experiment includes a comparison of different models: \n\n_\u2022_ ** I) MHA-LSTM [4]:**  This model only takes as inputs the past trajectories of the agents in the scene and outputs \\(L\\) trajectories with their associated probabilities (see the architecture in the red rectangle in Fig. 1). We use \\(L=6\\)attention heads. _\u2022_ ** II) G-MHA-LSTM [17]:**  We add to the previous \n\ndon\u2019t consider the position of the neighbors at time \\(t_{obs}\\). Instead, we consider their predicted position at time \\(t_{obs}+t_{f}\\) using a Constant velocity model. We assume that before predicting his goal, the target agent first predicts the future positions of his surroundings according to their headings and current velocitites, and then avoids the zones that are expected to be crowded. While training this model, we calculate the \\(occup_{k}\\) function using the grouth truth positions of the neighbors. \n\n### D. Implementation details \n\nmodel a radial grid representation from which we extract potential goals. We predict the goal and then the trajectories conditioned on the predicted goal. (see the architecture in the orange rectangle in Fig. 1). \n\nWe use \\(K=15\\) number of potential goals. Similar to [8], \n\n_\u2022_ ** III) DCM-MHA-LSTM :**  To predict the goal of the target agent, we combine the DCM and the neural network using the LMNL framework [15]. This model is described in Section III and the architecture is illustrated in the blue rectangle in Fig. 1. _\u2022_ ** IV) ODCM-MHA-LSTM :**  This model only uses the DCM to predict the goal of the target agent. \n\n**Goal set representations :**  We also compare different types of radial grids. For the methods II), III) and IV), we compare our results for two types of radial grid : a **dynamic**  grid (d) and a ** fixed**  one (f). Similar to [12], we build the dynamic grid by considering the target agent\u2019s current velocity \\(v_{T}^{t_{obs}}\\). If \\(v_{T}^{t_{obs}}=0\\), we replace it with an arbitrary value equals to \\(0.5\\)\\(m.s^{-1}\\). The fixed grid is built using the value \\(v=5.83m.s^{-1}\\), which corresponds to the mean of the velocities in the INTERACTION training set. \n\nour interaction space is 40 m ahead of the target vehicle, 10 m behind and 25 m on each side. We consider the neighbors situated in the interaction space at \\(t_{obs}\\). We also take into account the neighbors that are susceptible of being in this space from time \\(t_{obs}\\) to \\(t_{f}\\). To do so, we predict the trajectories of all of the neighbors in the scene using a Constant Velocity model and if they have a predicted position in the interaction space, we consider them in our model. We argue that this representation allows to consider neighbors that are not situated in the grid at \\(t_{obs}\\) but that can appear in the grid from time \\(t=t_{obs}+1\\) to \\(t=t_{f}\\). without having to create a bigger interaction space which can be more computationally expensive. We use \\(L+K=6+15\\)parallel attention operations. We use a batch size of 64 and Adam optimizer. The model is implemented using PyTorch [18]. \n\n### C. Compared DCMs \n\n## V. R ESULTS \n\nWe compare two types of DCMs for modelling the \n\n### A. Evaluation metrics Our method for trajectory forecasting is evaluated with the following three error metrics: \n\nbehavior of vehicle motion. For our case, the functions modelling vehicle motion phenomenon which we consider for goal selection in this work are: \n\n_\u2022_ ** Minimum** **Average** **Displacement** **Error** **over** **k** \n\n1) _ occupancy:_  directions containing neighbours in the vicinity are less desirable. 2) _ keep direction:_  vehicles tend to maintain the same \n\n**(** \\(minADE_{k}\\)**)**  : The average of pointwise L2 distances between the predicted trajectory and ground truth over the k most likely predictions. \n\ndirection of motion. \n\n_\u2022_ ** Minimum** **Final** **Displacement** **Error** **over** **k** \n\n3) _ collision_ _avoidance:_ when a neighbour vehicle\u2019s trajectory is head-on towards a potential goal, this goal becomes less desirable due to the chance of a collision. \n\n**(** \\(minFDE_{k}\\)**)**  : The final displacement error (FDE) is the L2 distance between the final points of the prediction and ground truth. We take the minimum FDE over the k most likely predictions and average over all agents. \n\n_\u2022_ ** 1) DCM 1 :**  For the first DCM configuration, we use a utility function defined as: \n\n_\u2022_ ** Collision II - Groundtruth collision (Col-II)**  [19]: \n\n\\[u_{k}(\\textbf{X}) =\\beta_{dir}dir_{k}+\\beta_{occ}occ_{k}+\\beta_{col}col_{k}\\] (13)  \n\nWhere the functions \\(dir_{k}\\), \\(occ_{k}\\), and \\(col_{k}\\) correspond \n\nThis metric calculates the percentage of collision between the primary vehicle\u2019s prediction and the neighbors in the groundtruth future scene. \n\n### B. Comparison of Methods \n\nrespectively to _ keep direction_ , _ occupancy_  and _ collision_ _avoidance_ . These functions are defined in [2] and [6]. _\u2022_ ** 2) DCM 2 :**  For the second DCM, the utility function is defined as : \n\nWe compare the methods described in Section IV-B. \n\nThe results are reported in Table I. DCM 1 and DCM 2 \n\n\\[u_{k}(\\textbf{X}) =\\beta_{dir}dir_{k}+\\beta_{occup}occup_{k}\\] (14)  \n\nWhere the function \\(dir_{k}\\) is the same as in (IV-C). For \\(occup_{k}\\), we use the same mathematical formula as the occupancy function in (IV-C), however, we \n\nrefers to the first (resp the second) type of DCM described in IV-C. (f) and (d) correspond to respectively, the fixed and the dynamic radial grid representation for the extraction of potential goals. We can see that adding the DCM module decrease the percentage of collisions. We can see that the models using a fixed grid perform slightly better than when ",
    "sured density-density correlation function _ \u2261\u27e8_ _n_ + _\u03b1_ shown in Fig. (b), is expected to exhibit pronounced peaks. Indeed, as can be seen in Fig.  3 (c), the peak at  =  extrapolates to finite values in the TDL while other signals vanish, indicative of long-range order. $S_{\\mathrm{C}}(\\mathbf{q})$where the same type of symmetry breaking order\nt\n1/6\nd\nd t t\ni\nit\n \n\nthat local interactions play a subordinate role and the hard-core constraint is largely inactive. As a result, the $V_1$behavior of the system is dominated by the\n $V_1$hopping processes, which naturally result in the formation of a Fermi surface similar to the one in graphene at\n $V_1=10^8$gr\n \n\n## ons to this pure Fermi-gas behavior. By measuring\n the lattice Green\u2019s function \n\nground state wave function as ) =  _e_ _i,j_ (3) = X \n\npreva\nl ti\n  = 1 6 and ground state energies per site are \n\n\\begin{equation} \t\t\\label{eq:correlation_function} \t\tC_{i}^{\\alpha,\\beta}(a) \\equiv \\langle n_i^{\\alpha} n_{i+a}^{\\beta} \\rangle, \\quad \\mathrm{where} \\quad \\alpha=A,B, \t\\end{equation}\n\n_\u00d7_ potentially more general instability towards charge order above some critical filling in the dilute fermion regime. \n\nFor non-interacting fermions on the honeycomb lattice, \n\n**ZERO-ENERGY STATE WINDOW** _ \u2264_  \u2272 Starting from _ \u03bd_  = 1 4, i.e. one fermion per two unit \n\ni.e. without density-density interactions or the hard-core constraint, ( $G^{\\alpha,\\beta}_{i,j}\\equiv\\langle c^{\\dagger}_{\\beta,j} c^{\\phantom{\\dagger}}_{\\alpha,i} \\rangle$nction of\n nction of\n the graphene dispersion ). Fig. $n(\\mathbf{k})$splays\nfilli\n a step-like behavior for the occupation at lower fillings \n\n\\begin{equation} \t\tn(\\mathbf{k}) = \\frac{1}{N} \\sum_{\\alpha=A,B} \\sum_{i,j} e^{i \\mathbf{k}\\cdot(\\mathbf{r}_i-\\mathbf{r}_j)} G^{\\alpha,\\alpha}_{i,j}. \t\\end{equation}\n\n_ \u03bd_ Interestingly, we find that the Fermi liquid regime is \n\n$\\nu\\leq 1/6$/ ,\np\nound state of the SUSY model on the honey-\n $\\nu=1/8$g\ny\nttice from Eq. (2) has exactly zero energy for a\n ) has _ exactly_  zero energy for a $2\\times 2$y\ngy\ns illustrated in Fig. 4, w\n , we find robust zero-energy states for (almost ) all rational fillings 1 _/_  \u2272 292 within our finite-size simulations. \n\n## st to the finite-energy Fermi-liquid and c\ndi\nd i\nS\nII d\nh\n $1/4 \\leq \\nu \\lesssim 0.292$\n\n For the two rational fillings accessible to us in _ \u2208_ 286 292), we suspect zero-energy states emerge for appropriate geometries but were unable to identify them in our study. \n\n$n(\\mathbf{k})$charge ordered phase at filling \u03bd =\n _/_ $Z$aneously polarizes\n into either the  or $\\epsilon_{\\mathrm{G}}(\\mathbf{k})$tice. The expected six-fold\n ground state degeneracy in the many-body spectrum as $\\nu \\lesssim 0.2$well as the clear energetic preference of simulation clusters supporting this form of order strongly points at spontaneous symmetry breaking as the root of this incompressible phase. Additionally, the static structure factor\n _S_ $\\nu \\gtrsim 0.25$i\n \n\nFIG. 3. ** Fermi liquids and charge order at low filling.**  (a) The momentum-space occupation number $n(\\mathbf{k})$from ED as\n a function of the graphene dispersion $\\epsilon_{\\mathrm{G}}(\\mathbf{k})$exhibits a (softened) step at fillings\n $\\nu < 1/4$, indicative of a Fermi liquid. (b)\n At $\\nu=1/6$, the connected density-density correlation function relative to the site marked in green shows clear signatures\n of sublattice polarized CO with a tripled unit cell. (c) The long-range character is substantiated by the finite value of the extrapolation of the static charge structure factor peak at $\\mathbf{q}=\\mathbf{K}$ to the TDL. For fillings with solid lines in (a), the ground state is completely unique, while for dashed ones it is only unique in its symmetry sector. Red/blue outlined circles in (b) correspond to sites on the $A$/ $B$ sublattice. The clusters used are $\\mathbf{u}_1=(1,4),\\mathbf{u}_2=(5,-4),N=48$for (a), and\n $\\mathbf{u}_1=(3,3),\\mathbf{u}_2=(3,-6),N=54$for (b). ",
    "(Thailand). URL:www.e-science.in.th. The Computational Materials Physics (CMP) Project, SLRI, Thailand, University, Thailand. We acknowledge the supporting computing infrastructure provided by NSTDA, CU, is acknowledged for providing computational resource. CUAASC, NSRF via PMUB [B05F650021, B37G660013] \n* Machine-learning x-ray absorption spectra to quantitative accuracy, Phys. Rev. Lett.  124 , 156401 (2020). \n* [1] R. J. Needs and C. J. Pickard, Perspective: Role of structure prediction in materials discovery and design, APL Materials  4 , 053210 (2016). \n* [17] Z. Liang, M. R. Carbone, W. Chen, F. Meng, E. Stavitski, D. Lu, M. S. Hybertsen, and X. Qu, Decoding structure-spectrum relationships with physically organized latent spaces, Phys. Rev. Mater.  7 , 053802 (2023). \n* [2] W. Kohn and L. J. Sham, Phys. Rev.  140 , A1133 (1965). [3] A. R. Oganov and C. W. Glass, Crystal structure prediction using ab initio evolutionary techniques: Principles and applications, The Journal of Chemical Physics  124 , 244704 (2006). \n* [4] Y. Wang, J. Lv, L. Zhu, and Y. Ma, Crystal structure prediction via particle-swarm optimization, Phys. Rev. B  82 , 094116 (2010). \n* [18] Y. Song and S. Ermon, Generative modeling by estimating gradients of the data distribution, in  Advances in Neural Information Processing Systems , Vol. 32, edited by H. Wallach, H. Larochelle, A. Beygelzimer, F. d ' Alch\u00b4 eBuc, E. Fox, and R. Garnett (Curran Associates, Inc., 2019). \n* [5] C. J. Pickard and R. J. Needs, Ab initio random structure searching, Journal of Physics: Condensed Matter 23 , 053201 (2011). \n* [19] Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, and B. Poole, Score-based generative modeling through stochastic differential equations, in  International Conference on Learning Representations  (2021). \n* [6] A. R. Oganov, C. J. Pickard, Q. Zhu, and R. J. Needs, Structure prediction drives materials discovery, Nature Reviews Materials  4 , 331 (2019). \n* [20] J. Ho, A. Jain, and P. Abbeel, Denoising diffusion probabilistic models, in  Advances in Neural Information Processing Systems , Vol. 33, edited by H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and H. Lin (Curran Associates, Inc., 2020) pp. 6840\u20136851. \n* [7] J. C. Sch\u00a8 on, K. Doll, and M. Jansen, Predicting solid compounds via global exploration of the energy landscape of solids on the ab initio level without recourse to experimental information, physica status solidi (b)  247 , 23 (2010). \n* [21] M. M. Bronstein, J. Bruna, T. Cohen, and P. Velickovic, Geometric deep learning: Grids, groups, graphs, geodesics, and gauges, CoRR  abs/2104.13478  (2021), 2104.13478. \n* [8] T. Xie, X. Fu, O.-E. Ganea, R. Barzilay, and T. S. Jaakkola, Crystal diffusion variational autoencoder for periodic material generation, in  International Conference on Learning Representations  (2022). \n* [22] T. S. Cohen, M. Geiger, J. K\u00a8 ohler, and M. Welling, Spherical CNNs, in  International Conference on Learning Representations  (2018). \n* [9] C. Shi, S. Luo, M. Xu, and J. Tang, Learning gradient fields for molecular conformation generation, in  Proceedings of the 38th International Conference on Machine Learning , Proceedings of Machine Learning Research, Vol. 139, edited by M. Meila and T. Zhang (PMLR, 2021) pp. 9558\u20139568. \n* [23] N. Thomas, T. Smidt, S. Kearnes, L. Yang, L. Li, K. Kohlhoff, and P. Riley, for 3d point clouds (2018). \n* [24] D. P. Kingma and M. Welling, Auto-encoding variational bayes, in  International Conference on Learning Representations  (2014). \n* [10] M. Xu, L. Yu, Y. Song, C. Shi, S. Ermon, and J. Tang, Geodiff: A geometric diffusion model for molecular conformation generation, in  International Conference on Learning Representations  (2022). \n* [11] J. Guan, W. W. Qian, X. Peng, Y. Su, J. Peng, and J. Ma, 3d equivariant diffusion for target-aware molecule generation and affinity prediction, in  The Eleventh International Conference on Learning Representations  (2023). \n* [25] R. Jiao, W. Huang, P. Lin, J. Han, P. Chen, Y. Lu, and Y. Liu, Crystal structure prediction by joint equivariant diffusion on lattices and fractional coordinates, in diffusion on lattices and fractional coordinates, in Work-\n (2023). \n* [12] S. Kang and K. Cho, Conditional molecular design with deep generative models, Journal of Chemical Information and Modeling  59 , 43 (2019), pMID: 30016587. \n* [26] A. Okhotin, D. Molchanov, V. Arkhipkin, G. Bartosh, A. Alanov, and D. Vetrov, Star-shaped denoising diffusion probabilistic models (2023), arXiv:2302.05259 [stat.ML]. \n* [27] J. Gasteiger, S. Giri, J. T. Margraf, and S. G\u00a8 unnemann, Fast and uncertainty-aware directional message passing for non-equilibrium molecules (2022), arXiv:2011.14115 [cs.LG]. \n* [13] J. Lim, S. Ryu, J. W. Kim, and W. Y. Kim, Molecular generative model based on conditional variational autoencoder for de novo molecular design, Journal of Cheminformatics  10 , 31 (2018). [14] Y. Song, L. Shen, L. Xing, and S. Ermon, Solving inverse problems in medical imaging with score-based generative models, in  International Conference on Learning Representations  (2022). \n* [28] W. Hu*, B. Liu*, J. Gomes, M. Zitnik, P. Liang, V. Pande, and J. Leskovec, Strategies for pre-training graph neural networks, in  International Conference on Learning Representations  (2020). \n* [15] A. Cui, K. Jiang, M. Jiang, L. Shang, L. Zhu, Z. Hu, G. Xu, and J. Chu, Decoding phases of matter by machine-learning raman spectroscopy, Phys. Rev. Appl. 12 , 054049 (2019). \n* [16] M. R. Carbone, M. Topsakal, D. Lu, and S. Yoo, \n* [29] K. Sch\u00a8 utt, P.-J. Kindermans, H. E. Sauceda Felix, S. Chmiela, A. Tkatchenko, and K.-R. M\u00a8 uller, Schnet: A continuous-filter convolutional neural network for modeling quantum interactions, in  Advances in Neural Infor- ",
    "which is precisely ( 1.3 ) for \\(p=1\\)due to (\n 3.12 ); the non-normalized case follows in a standard way. \n\nSince the Sobolev inequality ( 1.3 ) for \\(p=1\\)is equivalent to the isoperimetric inequality\n \n\n\\[n(\\omega_{n}{\\sf AVR}_{g})^{\\frac{1}{n}}{\\rm Vol}_{g}(\\Omega)^{\\frac{n-1}{n}} \\leq\\mathcal{P}_{g}(\\partial\\Omega)\\  \n\nfor every bounded open domain\n \\(\\Omega\\subset M\\)ly\n  with smooth boundary ( \\(\\mathcal{P}_{g}\\)out\n  being the perimeter), and ( 3.15 ) is sharp, see Balogh and Krist\u00b4 aly [ 2 ] and Brendle [ 4 ], it turns out that ( 1.3 ) is also sharp. \\(\\square\\)\n\n## 4.  Proof of the sharp \\(L^{p}\\)-logarithmic Sobolev inequality (Theorem  1.2 ) \n\n4.1. \n\n###  The case \\(p>1\\)\n\n**.**  Let \\(p>1\\)and fix\n \\(f\\in C_{0}^{\\infty}(M)\\)arbitrarily; we may assume that\n \\(f\\) is nonnegative and \\[\\int_{M}f^{p}{\\rm d}v_{g}=1.\\]  As before, let\n \\(\\Omega=\\{x\\in M:f(x)>0\\}\\)\n\nevery\n \n\n\n\n\\(k\\in\\mathbb{N}\\)\n\n; since \\(f\\in C_{0}^{\\infty}(M)\\), then\n \\(\\overline{\\Omega}\\)is compact.\n \n\nLet \\(x_{0}\\in\\Omega.\\)given\n  For every \\(\\lambda>0\\)and\n \\(k\\in\\mathbb{N}\\), we introduce the truncated Gaussian bubble \\(G_{\\lambda,k}:M\\to\\mathbb{R}\\) given by \\[G_{\\lambda,k}(x)=P_{k}(d_{g}(x_{0},x))e^{-\\lambda d_{g}^{p^{\\prime}}(x_{0},x)},\\]  where \\(P_{k}\\) is defined in ( 3.2 ). We observe that the support of \\(G_{\\lambda,k}\\) is the ball \\(\\overline{B_{x_{0}}(k+1)}\\). Let\n \\[\\mathcal{J}_{\\lambda,k}=\\int_{M}G_{\\lambda,k}(y){\\rm d}v_{g}(y);\\]  clearly,\n \\(0<\\mathcal{J}_{\\lambda,k}<\\infty\\)for every \\(\\lambda>0\\)and\n \\(k\\in\\mathbb{N}\\)\n\n\n\n. \n\nLet\n \\({\\rm d}\\mu(x)=f^{p}(x){\\rm d}v_{g}(x)\\)and\n \\({\\rm d}\\nu(y)=\\frac{G_{\\lambda,k}(y)}{\\mathcal{J}_{\\lambda,k}}{\\rm d}v_{g}(y)\\)be two probability measures on\n \\((M,g)\\)with\n compact supports; by the theory of OMT one can find a unique map \\(T:\\overline{\\Omega}\\to\\overline{B_{x_{0}}(k+1)}\\subset M\\)pushing \\(\\mu\\) forward to \\(\\nu\\) having the form \\(T(x)=\\exp_{x}(-\\nabla_{g}u(x))\\)for a.e.\n \\(x\\in\\overline{\\Omega},\\) for some \\(c=d_{g}^{2}/2\\)concave function \\(u:\\overline{\\Omega}\\to\\mathbb{R}\\). The associated Monge-Amp` ere equation is \n\n\\[f^{p}(x)=\\frac{G_{\\lambda,k}(T(x))}{\\mathcal{J}_{\\lambda,k}}{\\rm det}DT(x)\\ { \\rm for\\ a.e.}\\ x\\in\\Omega.\\  \n\nAccordingly, by ( 4.1 ), a change of variables, Jensen\u2019s inequality and Propositions  2.1  and  2.2 , we \n\n\n\nhave \n\n\\[\\int_{M}f^{p}\\log f^{p}{\\rm d}v_{g} = \\int_{\\Omega}f^{p}(x)\\log\\left(\\frac{G_{\\lambda,k}(T(x))}{ \\mathcal{J}_{\\lambda,k}}{\\rm det}DT(x)\\right){\\rm d}v_{g}(x)\\] \\[= \\int_{\\Omega}f^{p}(x)\\log\\left({G_{\\lambda,k}(T(x))}\\right){\\rm d }v_{g}(x)+n\\int_{\\Omega}f^{p}(x)\\log\\left(\\frac{{\\rm det}^{\\frac{1}{n}}DT(x)}{ \\mathcal{J}^{\\frac{1}{n}}_{\\lambda,k}}\\right){\\rm d}v_{g}(x)\\] \\[\\leq \\int_{\\Omega}\\frac{G_{\\lambda,k}(T(x))}{\\mathcal{J}_{\\lambda,k}} \\log\\left({G_{\\lambda,k}(T(x))}\\right){\\rm det}DT(x){\\rm d}v_{g}(x)\\] \\[+n\\log\\left(\\int_{\\Omega}f^{p}(x)\\frac{{\\rm det}^{\\frac{1}{n}}DT( x)}{\\mathcal{J}^{\\frac{1}{n}}_{\\lambda,k}}{\\rm d}v_{g}(x)\\right)\\] \\[\\leq \\frac{1}{{\\mathcal{J}_{\\lambda,k}}}\\int_{M}{G_{\\lambda,k}(y)}\\log \\left({G_{\\lambda,k}(y)}\\right){\\rm d}v_{g}(y)\\] \\[+n\\log\\left(\\int_{\\Omega}\\frac{f^{p}(x)}{\\mathcal{J}^{\\frac{1}{n} }_{\\lambda,k}}\\left(1-\\frac{\\Delta_{g}u(x)}{n}\\right){\\rm d}v_{g}(x)\\right)\\] \\[\\leq \\frac{1}{{\\mathcal{J}_{\\lambda,k}}}\\int_{M}{G_{\\lambda,k}}\\log \\left({G_{\\lambda,k}}\\right){\\rm d}v_{g}+n\\log\\left(\\int_{\\Omega}\\frac{f^{p}(x )}{\\mathcal{J}^{\\frac{1}{n}}_{\\lambda,k}}\\left(1-\\frac{\\Delta_{g,\\mathcal{D}^{ \\prime}}u(x)}{n}\\right){\\rm d}v_{g}(x)\\right).\\]  ",
    "J. Orell-Miquel\n \n\n# et al.: Confirmation of He\n  i  in HD 235088 b\u2019s atmosphere \n\n2.\n \n\n## Observations and data analysis\n \n\n2.1.\n \n\n### CARMENES observations and analysis\n \n\nA single transit of the planet candidate 23.01 was observed with the CARMENES 1 ( Quirrenbach et al. 2014 ,  2020 ) spectrograph located at the Calar Alto Observatory, Almer\u00eda, Spain, on the night of 6 August 2022. CARMENES has two spectral channels: the optical channel (VIS), which covers the wavelength range of 0.52\u20130.96 \\(\\mu\\)m with a resolving power of \\(\\mathcal{R}\\)0.96\u2013\n  =  94 600, and the near-infrared channel (NIR), which covers 0.96\u20131.71 \\(\\mu\\)m with a resolving power of \\(\\mathcal{R}\\) =  80 400. We observed the target with both channels simultaneously and collected a total of 44 spectra of 5 min exposure time, with 28 of them between the first ( \\(T_{1}\\)) and fourth ( \\(T_{4}\\)) transit contacts. We obtained a median S / N of 72 around the H \\(\\alpha\\) line and of 86 around the He  i  triplet. \n\nFiber A was used to observe the target star, while fiber B was placed on sky, separated by 88 arcsec in the east-west direction. The observations were reduced using the CARMENES pipeline caracal \n\n ( Caballero et al. 2016 \n\n) and both fibers were extracted with the flat-optimized extraction algorithm ( Zechmeister et al. 2014 ). We also processed the spectra with  serval 2 \n\n( \n\nZechmeister et al. 2018 ), which is the standard CARMENES pipeline to derive the radial velocities (RVs) and several activity indicators: the chromatic radial velocity index (CRX) and the di ff \\(\\alpha\\)(\n)f\n, Na i D1 and D2, and\n \\(\\alpha\\), Na \n\n i \n\n D1 and D2, and \n\nCa  ii \n\n IRT line indices. \n\nWe corrected the VIS and NIR spectra from telluric absorptions with  molecfit  ( Smette et al. 2015 \n\n;  Kausch et al. \n\n2015 ). We analyzed the spectroscopic observations via the wellestablished transmission spectroscopy technique (e.g.  Wyttenbach et al. 2015 \n\n;  Casasayas-Barris et al. 2017 \n\n). We computed the H \\(\\alpha\\) transmission spectra (TS) following the standard procedure. However, because there are OH emission lines from the Earth\u2019s atmosphere close to the He \n\n i \n\n triplet lines, we applied an extra step before computing the He \n\n i \n\n TS. First, we planned the observations to avoid a complete overlap or superposition of the OH telluric lines and the He \n\n i \n\n planetary trace. We corrected the fiber A spectra from OH telluric emission using fiber B information, which is used to generate an OH emission model for correcting the science spectra. This methodology is based in previous \n\nHe  i \n\n studies with CARMENES ( Nortmann et al. 2018 \n\n;  Salz et al. 2018 ;  Alonso-Floriano et al. 2019 ;  Palle et al. 2020a ;  CasasayasBarris et al. 2021 ;  Czesla et al. 2022 \n\n). In particular, we followed the procedure previously applied in  Orell-Miquel et al. \n\n ( 2022 \n\n). Figure  D.1  compares our prediction for the telluric contamination of the He \n\n i \n\n triplet lines with the real observations. \n\n2.2.\n \n\n### X-ray observations and planetary irradiation\n \n\nWe used XMM-Newton archival observations of 23 (PI M. Zhang) to calculate the X-ray luminosity of the star. The star was observed on 7 July 2021. We reduced the data following standard procedures and used the three EPIC detectors to extract a spectrum for each of them, simultaneously fitting them with a two-temperatures coronal model, using the ISIS package ( Houck & Denicola 2000 ) and the Astrophysics Plasma Emission Database (APED,  Foster et al. 2012 \\(\\times\\)10\n \u00b9\u2079cm\n _-3_was adopted, con-\n \\(\\times\\)overall\n  10 \u00b9\u2079 cm _-3_\\(\\times\\)10\n \u00b9\u2079cm\n _-3_tion H column density of 1 \u00d7 1019 cm\u22123 was adopted, consistent with the fit to the overall spectrum, and the distance\n 1  Calar Alto high-Resolution search for M dwarfs with Exoearths with Near-infrared and optical \u00c9chelle Spectrographs. \n\nwe confirm the previous detection of He  i  and, by analysing this He(2 3 S) signal, we study the hydrodynamical escape of this planet and derive the temperature and mass-loss rate of its upper atmosphere. \n\nTable 1: Stellar parameters of 23. \n\n\\begin{tabular}{l c l}\n\\hline \\hline\nParameter & Value & Reference \\\\\n\\hline\nName & HD\u2009235088 & HD \\\\\n & TIC 293954617 & _TESS_ \\\\\n & TOI-1430 & TOI \\\\\n & HIP 98668 & HIP \\\\\n\\hline\n\\multicolumn{3}{c}{_Coordinates and spectral types_} \\\\\n\\(\\alpha\\)\u2009(J2000) & 20h\u200902m\u200927\\({}^{\\mathrm{s}}\\!\\).4 & _Gaia_ EDR3 \\\\\n\\(\\delta\\)\u2009(J2000) & \\(+\\)53\u00ba\u200922_\u2032_\u200936\\(\"\\!\\).5 & _Gaia_ EDR3 \\\\\nSpectral type & K2\u2009V & Sect.\u2009 \\\\\n\\multicolumn{3}{c}{_Parallax and kinematics_} \\\\\n\\(\\pi\\) [mas] & 24.25\u2009\\(\\pm\\)\u20090.01 & _Gaia_ EDR3 \\\\\n\\(d\\) [pc] & \\(41.24\\pm 0.02\\) & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\alpha}\\cos{\\delta}\\) [mas\u2009yr_-1_] & 165.05\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\delta}\\) [mas\u2009yr_-1_] & 145.17\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\gamma\\)\u2009_(a)_ [km\u2009s_-1_] & \\(-\\)27.370\\(\\pm\\)\u20090.002 & _Gaia_ DR2 \\\\\n\\(U\\) [km\u2009s_-1_] & \\(-\\)41.75\u2009\\(\\pm\\)\u20090.02 & This work \\\\\n\\(V\\) [km\u2009s_-1_] & \\(-\\)22.16\u2009\\(\\pm\\)\u20090.01 & This work \\\\\n\\(W\\) [km\u2009s_-1_] & \\(-\\)19.03\u2009\\(\\pm\\)\u20090.02 & This work \\\\\nRUWE & \\(0.966\\) & _Gaia_ DR3 \\\\\n\\multicolumn{3}{c}{_Magnitudes_} \\\\\n\\(B\\) [mag] & 10.129 \\(\\pm\\) 0.038 & TYC \\\\\n\\(V\\) [mag] & 9.19 \\(\\pm\\) 0.03 & HIP \\\\\n\\(J\\) [mag] & 7.646 \\(\\pm\\) 0.03 & 2MASS \\\\\n\\hline\n\\multicolumn{3}{c}{_Stellar parameters_} \\\\\n\\(L_{\\rm X}\\) [\\(\\times 10^{28}\\) erg s_-1_] & \\(1.89\\pm 0.07\\) & Sect.\u2009 \\\\\n\\(L_{\\star}\\) [\\(L_{\\odot}\\)] & 0.3609 \\(\\pm\\) 0.0052 & Sect.\u2009 \\\\\n\\(T_{\\mathrm{eff}}\\) [K] & 5037\\(\\pm\\)14 & Sect.\u2009 \\\\\nlog(g[cm\u2009s]\u22122) & 4.63 \\(\\pm\\) 0.02 & Sect.\u2009 \\\\\n\\(\\rm[Fe/H]\\) & \\(-\\)0.01\\(\\pm\\)0.02 & Sect.\u2009 \\\\\n & \\(-\\)0.08\\(\\pm\\)0.13 & B18 \\\\\n\\(R_{\\star}\\) [R_\u2299_] & 0.789\\({}^{+0.022}_{-0.021}\\) & Sect.\u2009 \\\\\n\\(M_{\\star}\\) [M_\u2299_] & 0.843\\({}^{+0.033}_{-0.056}\\) & Sect.\u2009 \\\\\n\\(V_{\\rm broad}\\) [km\u2009s_-1_] & 2.89 \\(\\pm\\) 0.03 & Sect.\u2009 \\\\\n\\(v\\,\\sin{i}\\) [km\u2009s_-1_] & \\(<\\)2.90 & Sect.\u2009 \\\\\n\\(P_{\\mathrm{rot}}\\) [d] & 12.0 \\(\\pm\\) 0.4 & Sect.\u2009 \\\\\nlog(R)H\u2062K\u2032 & \\(-\\)4.242 \\(\\pm\\) 0.016 & M22 \\\\\nAge [Myr] & 600\u2013800 & Sect.\u2009 \\\\ \\hline\n\\end{tabular}\n\n\n\\begin{tabular}{l c l}\n\\hline \\hline\nParameter & Value & Reference \\\\\n\\hline\nName & HD\u2009235088 & HD \\\\\n & TIC 293954617 & _TESS_ \\\\\n & TOI-1430 & TOI \\\\\n & HIP 98668 & HIP \\\\\n\\hline\n\\multicolumn{3}{c}{_Coordinates and spectral types_} \\\\\n\\(\\alpha\\)\u2009(J2000) & 20h\u200902m\u200927\\({}^{\\mathrm{s}}\\!\\).4 & _Gaia_ EDR3 \\\\\n\\(\\delta\\)\u2009(J2000) & \\(+\\)53\u00ba\u200922_\u2032_\u200936\\(\"\\!\\).5 & _Gaia_ EDR3 \\\\\nSpectral type & K2\u2009V & Sect.\u2009 \\\\\n\\multicolumn{3}{c}{_Parallax and kinematics_} \\\\\n\\(\\pi\\) [mas] & 24.25\u2009\\(\\pm\\)\u20090.01 & _Gaia_ EDR3 \\\\\n\\(d\\) [pc] & \\(41.24\\pm 0.02\\) & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\alpha}\\cos{\\delta}\\) [mas\u2009yr_-1_] & 165.05\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\delta}\\) [mas\u2009yr_-1_] & 145.17\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\gamma\\)\u2009_(a)_ [km\u2009s_-1_] & \\(-\\)27.370\\(\\pm\\)\u20090.002 & _Gaia_ DR2 \\\\\n\\(U\\) [km\u2009s_-1_] & \\(-\\)41.75\u2009\\(\\pm\\)\u20090.02 & This work \\\\\n\\(V\\) [km\u2009s_-1_] & \\(-\\)22.16\u2009\\(\\pm\\)\u20090.01 & This work \\\\\n\\(W\\) [km\u2009s_-1_] & \\(-\\)19.03\u2009\\(\\pm\\)\u20090.02 & This work \\\\\nRUWE & \\(0.966\\) & _Gaia_ DR3 \\\\\n\\multicolumn{3}{c}{_Magnitudes_} \\\\\n\\(B\\) [mag] & 10.129 \\(\\pm\\) 0.038 & TYC \\\\\n\\(V\\) [mag] & 9.19 \\(\\pm\\) 0.03 & HIP \\\\\n\\(J\\) [mag] & 7.646 \\(\\pm\\) 0.03 & 2MASS \\\\\n\\hline\n\\multicolumn{3}{c}{_Stellar parameters_} \\\\\n\\(L_{\\rm X}\\) [\\(\\times 10^{28}\\) erg s_-1_] & \\(1.89\\pm 0.07\\) & Sect.\u2009 \\\\\n\\(L_{\\star}\\) [\\(L_{\\odot}\\)] & 0.3609 \\(\\pm\\) 0.0052 & Sect.\u2009 \\\\\n\\(T_{\\mathrm{eff}}\\) [K] & 5037\\(\\pm\\)14 & Sect.\u2009 \\\\\nlog(g[cm\u2009s]\u22122) & 4.63 \\(\\pm\\) 0.02 & Sect.\u2009 \\\\\n\\(\\rm[Fe/H]\\) & \\(-\\)0.01\\(\\pm\\)0.02 & Sect.\u2009 \\\\\n & \\(-\\)0.08\\(\\pm\\)0.13 & B18 \\\\\n\\(R_{\\star}\\) [R_\u2299_] & 0.789\\({}^{+0.022}_{-0.021}\\) & Sect.\u2009 \\\\\n\\(M_{\\star}\\) [M_\u2299_] & 0.843\\({}^{+0.033}_{-0.056}\\) & Sect.\u2009 \\\\\n\\(V_{\\rm broad}\\) [km\u2009s_-1_] & 2.89 \\(\\pm\\) 0.03 & Sect.\u2009 \\\\\n\\(v\\,\\sin{i}\\) [km\u2009s_-1_] & \\(<\\)2.90 & Sect.\u2009 \\\\\n\\(P_{\\mathrm{rot}}\\) [d] & 12.0 \\(\\pm\\) 0.4 & Sect.\u2009 \\\\\nlog(R)H\u2062K\u2032 & \\(-\\)4.242 \\(\\pm\\) 0.016 & M22 \\\\\nAge [Myr] & 600\u2013800 & Sect.\u2009 \\\\ \\hline\n\\end{tabular}\n\\begin{tabular}{l c l}\n\\hline \\hline\nParameter & Value & Reference \\\\\n\\hline\nName & HD\u2009235088 & HD \\\\\n & TIC 293954617 & _TESS_ \\\\\n & TOI-1430 & TOI \\\\\n & HIP 98668 & HIP \\\\\n\\hline\n\\multicolumn{3}{c}{_Coordinates and spectral types_} \\\\\n\\(\\alpha\\)\u2009(J2000) & 20h\u200902m\u200927\\({}^{\\mathrm{s}}\\!\\).4 & _Gaia_ EDR3 \\\\\n\\(\\delta\\)\u2009(J2000) & \\(+\\)53\u00ba\u200922_\u2032_\u200936\\(\"\\!\\).5 & _Gaia_ EDR3 \\\\\nSpectral type & K2\u2009V & Sect.\u2009 \\\\\n\\multicolumn{3}{c}{_Parallax and kinematics_} \\\\\n\\(\\pi\\) [mas] & 24.25\u2009\\(\\pm\\)\u20090.01 & _Gaia_ EDR3 \\\\\n\\(d\\) [pc] & \\(41.24\\pm 0.02\\) & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\alpha}\\cos{\\delta}\\) [mas\u2009yr_-1_] & 165.05\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\delta}\\) [mas\u2009yr_-1_] & 145.17\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\gamma\\)\u2009_(a)_ [km\u2009s_-1_] & \\(-\\)27.370\\(\\pm\\)\u20090.002 & _Gaia_ DR2 \\\\\n\\(U\\) [km\u2009s_-1_] & \\(-\\)41.75\u2009\\(\\pm\\)\u20090.02 & This work \\\\\n\\(V\\) [km\u2009s_-1_] & \\(-\\)22.16\u2009\\(\\pm\\)\u20090.01 & This work \\\\\n\\(W\\) [km\u2009s_-1_] & \\(-\\)19.03\u2009\\(\\pm\\)\u20090.02 & This work \\\\\nRUWE & \\(0.966\\) & _Gaia_ DR3 \\\\\n\\multicolumn{3}{c}{_Magnitudes_} \\\\\n\\(B\\) [mag] & 10.129 \\(\\pm\\) 0.038 & TYC \\\\\n\\(V\\) [mag] & 9.19 \\(\\pm\\) 0.03 & HIP \\\\\n\\(J\\) [mag] & 7.646 \\(\\pm\\) 0.03 & 2MASS \\\\\n\\hline\n\\multicolumn{3}{c}{_Stellar parameters_} \\\\\n\\(L_{\\rm X}\\) [\\(\\times 10^{28}\\) erg s_-1_] & \\(1.89\\pm 0.07\\) & Sect.\u2009 \\\\\n\\(L_{\\star}\\) [\\(L_{\\odot}\\)] & 0.3609 \\(\\pm\\) 0.0052 & Sect.\u2009 \\\\\n\\(T_{\\mathrm{eff}}\\) [K] & 5037\\(\\pm\\)14 & Sect.\u2009 \\\\\nlog(g[cm\u2009s]\u22122) & 4.63 \\(\\pm\\) 0.02 & Sect.\u2009 \\\\\n\\(\\rm[Fe/H]\\) & \\(-\\)0.01\\(\\pm\\)0.02 & Sect.\u2009 \\\\\n & \\(-\\)0.08\\(\\pm\\)0.13 & B18 \\\\\n\\(R_{\\star}\\) [R_\u2299_] & 0.789\\({}^{+0.022}_{-0.021}\\) & Sect.\u2009 \\\\\n\\(M_{\\star}\\) [M_\u2299_] & 0.843\\({}^{+0.033}_{-0.056}\\) & Sect.\u2009 \\\\\n\\(V_{\\rm broad}\\) [km\u2009s_-1_] & 2.89 \\(\\pm\\) 0.03 & Sect.\u2009 \\\\\n\\(v\\,\\sin{i}\\) [km\u2009s_-1_] & \\(<\\)2.90 & Sect.\u2009 \\\\\n\\(P_{\\mathrm{rot}}\\) [d] & 12.0 \\(\\pm\\) 0.4 & Sect.\u2009 \\\\\nlog(R)H\u2062K\u2032 & \\(-\\)4.242 \\(\\pm\\) 0.016 & M22 \\\\\nAge [Myr] & 600\u2013800 & Sect.\u2009 \\\\ \\hline\n\\end{tabular}\n\\begin{tabular}{l c l}\n\\hline \\hline\nParameter & Value & Reference \\\\\n\\hline\nName & HD\u2009235088 & HD \\\\\n & TIC 293954617 & _TESS_ \\\\\n & TOI-1430 & TOI \\\\\n & HIP 98668 & HIP \\\\\n\\hline\n\\multicolumn{3}{c}{_Coordinates and spectral types_} \\\\\n\\(\\alpha\\)\u2009(J2000) & 20h\u200902m\u200927\\({}^{\\mathrm{s}}\\!\\).4 & _Gaia_ EDR3 \\\\\n\\(\\delta\\)\u2009(J2000) & \\(+\\)53\u00ba\u200922_\u2032_\u200936\\(\"\\!\\).5 & _Gaia_ EDR3 \\\\\nSpectral type & K2\u2009V & Sect.\u2009 \\\\\n\\multicolumn{3}{c}{_Parallax and kinematics_} \\\\\n\\(\\pi\\) [mas] & 24.25\u2009\\(\\pm\\)\u20090.01 & _Gaia_ EDR3 \\\\\n\\(d\\) [pc] & \\(41.24\\pm 0.02\\) & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\alpha}\\cos{\\delta}\\) [mas\u2009yr_-1_] & 165.05\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\delta}\\) [mas\u2009yr_-1_] & 145.17\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\gamma\\)\u2009_(a)_ [km\u2009s_-1_] & \\(-\\)27.370\\(\\pm\\)\u20090.002 & _Gaia_ DR2 \\\\\n\\(U\\) [km\u2009s_-1_] & \\(-\\)41.75\u2009\\(\\pm\\)\u20090.02 & This work \\\\\n\\(V\\) [km\u2009s_-1_] & \\(-\\)22.16\u2009\\(\\pm\\)\u20090.01 & This work \\\\\n\\(W\\) [km\u2009s_-1_] & \\(-\\)19.03\u2009\\(\\pm\\)\u20090.02 & This work \\\\\nRUWE & \\(0.966\\) & _Gaia_ DR3 \\\\\n\\multicolumn{3}{c}{_Magnitudes_} \\\\\n\\(B\\) [mag] & 10.129 \\(\\pm\\) 0.038 & TYC \\\\\n\\(V\\) [mag] & 9.19 \\(\\pm\\) 0.03 & HIP \\\\\n\\(J\\) [mag] & 7.646 \\(\\pm\\) 0.03 & 2MASS \\\\\n\\hline\n\\multicolumn{3}{c}{_Stellar parameters_} \\\\\n\\(L_{\\rm X}\\) [\\(\\times 10^{28}\\) erg s_-1_] & \\(1.89\\pm 0.07\\) & Sect.\u2009 \\\\\n\\(L_{\\star}\\) [\\(L_{\\odot}\\)] & 0.3609 \\(\\pm\\) 0.0052 & Sect.\u2009 \\\\\n\\(T_{\\mathrm{eff}}\\) [K] & 5037\\(\\pm\\)14 & Sect.\u2009 \\\\\nlog(g[cm\u2009s]\u22122) & 4.63 \\(\\pm\\) 0.02 & Sect.\u2009 \\\\\n\\(\\rm[Fe/H]\\) & \\(-\\)0.01\\(\\pm\\)0.02 & Sect.\u2009 \\\\\n & \\(-\\)0.08\\(\\pm\\)0.13 & B18 \\\\\n\\(R_{\\star}\\) [R_\u2299_] & 0.789\\({}^{+0.022}_{-0.021}\\) & Sect.\u2009 \\\\\n\\(M_{\\star}\\) [M_\u2299_] & 0.843\\({}^{+0.033}_{-0.056}\\) & Sect.\u2009 \\\\\n\\(V_{\\rm broad}\\) [km\u2009s_-1_] & 2.89 \\(\\pm\\) 0.03 & Sect.\u2009 \\\\\n\\(v\\,\\sin{i}\\) [km\u2009s_-1_] & \\(<\\)2.90 & Sect.\u2009 \\\\\n\\(P_{\\mathrm{rot}}\\) [d] & 12.0 \\(\\pm\\) 0.4 & Sect.\u2009 \\\\\nlog(R)H\u2062K\u2032 & \\(-\\)4.242 \\(\\pm\\) 0.016 & M22 \\\\\nAge [Myr] & 600\u2013800 & Sect.\u2009 \\\\ \\hline\n\\end{tabular}\n\\begin{tabular}{l c l}\n\\hline \\hline\nParameter & Value & Reference \\\\\n\\hline\nName & HD\u2009235088 & HD \\\\\n & TIC 293954617 & _TESS_ \\\\\n & TOI-1430 & TOI \\\\\n & HIP 98668 & HIP \\\\\n\\hline\n\\multicolumn{3}{c}{_Coordinates and spectral types_} \\\\\n\\(\\alpha\\)\u2009(J2000) & 20h\u200902m\u200927\\({}^{\\mathrm{s}}\\!\\).4 & _Gaia_ EDR3 \\\\\n\\(\\delta\\)\u2009(J2000) & \\(+\\)53\u00ba\u200922_\u2032_\u200936\\(\"\\!\\).5 & _Gaia_ EDR3 \\\\\nSpectral type & K2\u2009V & Sect.\u2009 \\\\\n\\multicolumn{3}{c}{_Parallax and kinematics_} \\\\\n\\(\\pi\\) [mas] & 24.25\u2009\\(\\pm\\)\u20090.01 & _Gaia_ EDR3 \\\\\n\\(d\\) [pc] & \\(41.24\\pm 0.02\\) & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\alpha}\\cos{\\delta}\\) [mas\u2009yr_-1_] & 165.05\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\delta}\\) [mas\u2009yr_-1_] & 145.17\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\gamma\\)\u2009_(a)_ [km\u2009s_-1_] & \\(-\\)27.370\\(\\pm\\)\u20090.002 & _Gaia_ DR2 \\\\\n\\(U\\) [km\u2009s_-1_] & \\(-\\)41.75\u2009\\(\\pm\\)\u20090.02 & This work \\\\\n\\(V\\) [km\u2009s_-1_] & \\(-\\)22.16\u2009\\(\\pm\\)\u20090.01 & This work \\\\\n\\(W\\) [km\u2009s_-1_] & \\(-\\)19.03\u2009\\(\\pm\\)\u20090.02 & This work \\\\\nRUWE & \\(0.966\\) & _Gaia_ DR3 \\\\\n\\multicolumn{3}{c}{_Magnitudes_} \\\\\n\\(B\\) [mag] & 10.129 \\(\\pm\\) 0.038 & TYC \\\\\n\\(V\\) [mag] & 9.19 \\(\\pm\\) 0.03 & HIP \\\\\n\\(J\\) [mag] & 7.646 \\(\\pm\\) 0.03 & 2MASS \\\\\n\\hline\n\\multicolumn{3}{c}{_Stellar parameters_} \\\\\n\\(L_{\\rm X}\\) [\\(\\times 10^{28}\\) erg s_-1_] & \\(1.89\\pm 0.07\\) & Sect.\u2009 \\\\\n\\(L_{\\star}\\) [\\(L_{\\odot}\\)] & 0.3609 \\(\\pm\\) 0.0052 & Sect.\u2009 \\\\\n\\(T_{\\mathrm{eff}}\\) [K] & 5037\\(\\pm\\)14 & Sect.\u2009 \\\\\nlog(g[cm\u2009s]\u22122) & 4.63 \\(\\pm\\) 0.02 & Sect.\u2009 \\\\\n\\(\\rm[Fe/H]\\) & \\(-\\)0.01\\(\\pm\\)0.02 & Sect.\u2009 \\\\\n & \\(-\\)0.08\\(\\pm\\)0.13 & B18 \\\\\n\\(R_{\\star}\\) [R_\u2299_] & 0.789\\({}^{+0.022}_{-0.021}\\) & Sect.\u2009 \\\\\n\\(M_{\\star}\\) [M_\u2299_] & 0.843\\({}^{+0.033}_{-0.056}\\) & Sect.\u2009 \\\\\n\\(V_{\\rm broad}\\) [km\u2009s_-1_] & 2.89 \\(\\pm\\) 0.03 & Sect.\u2009 \\\\\n\\(v\\,\\sin{i}\\) [km\u2009s_-1_] & \\(<\\)2.90 & Sect.\u2009 \\\\\n\\(P_{\\mathrm{rot}}\\) [d] & 12.0 \\(\\pm\\) 0.4 & Sect.\u2009 \\\\\nlog(R)H\u2062K\u2032 & \\(-\\)4.242 \\(\\pm\\) 0.016 & M22 \\\\\nAge [Myr] & 600\u2013800 & Sect.\u2009 \\\\ \\hline\n\\end{tabular}\n\\begin{tabular}{l c l}\n\\hline \\hline\nParameter & Value & Reference \\\\\n\\hline\nName & HD\u2009235088 & HD \\\\\n & TIC 293954617 & _TESS_ \\\\\n & TOI-1430 & TOI \\\\\n & HIP 98668 & HIP \\\\\n\\hline\n\\multicolumn{3}{c}{_Coordinates and spectral types_} \\\\\n\\(\\alpha\\)\u2009(J2000) & 20h\u200902m\u200927\\({}^{\\mathrm{s}}\\!\\).4 & _Gaia_ EDR3 \\\\\n\\(\\delta\\)\u2009(J2000) & \\(+\\)53\u00ba\u200922_\u2032_\u200936\\(\"\\!\\).5 & _Gaia_ EDR3 \\\\\nSpectral type & K2\u2009V & Sect.\u2009 \\\\\n\\multicolumn{3}{c}{_Parallax and kinematics_} \\\\\n\\(\\pi\\) [mas] & 24.25\u2009\\(\\pm\\)\u20090.01 & _Gaia_ EDR3 \\\\\n\\(d\\) [pc] & \\(41.24\\pm 0.02\\) & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\alpha}\\cos{\\delta}\\) [mas\u2009yr_-1_] & 165.05\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\delta}\\) [mas\u2009yr_-1_] & 145.17\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\gamma\\)\u2009_(a)_ [km\u2009s_-1_] & \\(-\\)27.370\\(\\pm\\)\u20090.002 & _Gaia_ DR2 \\\\\n\\(U\\) [km\u2009s_-1_] & \\(-\\)41.75\u2009\\(\\pm\\)\u20090.02 & This work \\\\\n\\(V\\) [km\u2009s_-1_] & \\(-\\)22.16\u2009\\(\\pm\\)\u20090.01 & This work \\\\\n\\(W\\) [km\u2009s_-1_] & \\(-\\)19.03\u2009\\(\\pm\\)\u20090.02 & This work \\\\\nRUWE & \\(0.966\\) & _Gaia_ DR3 \\\\\n\\multicolumn{3}{c}{_Magnitudes_} \\\\\n\\(B\\) [mag] & 10.129 \\(\\pm\\) 0.038 & TYC \\\\\n\\(V\\) [mag] & 9.19 \\(\\pm\\) 0.03 & HIP \\\\\n\\(J\\) [mag] & 7.646 \\(\\pm\\) 0.03 & 2MASS \\\\\n\\hline\n\\multicolumn{3}{c}{_Stellar parameters_} \\\\\n\\(L_{\\rm X}\\) [\\(\\times 10^{28}\\) erg s_-1_] & \\(1.89\\pm 0.07\\) & Sect.\u2009 \\\\\n\\(L_{\\star}\\) [\\(L_{\\odot}\\)] & 0.3609 \\(\\pm\\) 0.0052 & Sect.\u2009 \\\\\n\\(T_{\\mathrm{eff}}\\) [K] & 5037\\(\\pm\\)14 & Sect.\u2009 \\\\\nlog(g[cm\u2009s]\u22122) & 4.63 \\(\\pm\\) 0.02 & Sect.\u2009 \\\\\n\\(\\rm[Fe/H]\\) & \\(-\\)0.01\\(\\pm\\)0.02 & Sect.\u2009 \\\\\n & \\(-\\)0.08\\(\\pm\\)0.13 & B18 \\\\\n\\(R_{\\star}\\) [R_\u2299_] & 0.789\\({}^{+0.022}_{-0.021}\\) & Sect.\u2009 \\\\\n\\(M_{\\star}\\) [M_\u2299_] & 0.843\\({}^{+0.033}_{-0.056}\\) & Sect.\u2009 \\\\\n\\(V_{\\rm broad}\\) [km\u2009s_-1_] & 2.89 \\(\\pm\\) 0.03 & Sect.\u2009 \\\\\n\\(v\\,\\sin{i}\\) [km\u2009s_-1_] & \\(<\\)2.90 & Sect.\u2009 \\\\\n\\(P_{\\mathrm{rot}}\\) [d] & 12.0 \\(\\pm\\) 0.4 & Sect.\u2009 \\\\\nlog(R)H\u2062K\u2032 & \\(-\\)4.242 \\(\\pm\\) 0.016 & M22 \\\\\nAge [Myr] & 600\u2013800 & Sect.\u2009 \\\\ \\hline\n\\end{tabular}\n\\begin{tabular}{l c l}\n\\hline \\hline\nParameter & Value & Reference \\\\\n\\hline\nName & HD\u2009235088 & HD \\\\\n & TIC 293954617 & _TESS_ \\\\\n & TOI-1430 & TOI \\\\\n & HIP 98668 & HIP \\\\\n\\hline\n\\multicolumn{3}{c}{_Coordinates and spectral types_} \\\\\n\\(\\alpha\\)\u2009(J2000) & 20h\u200902m\u200927\\({}^{\\mathrm{s}}\\!\\).4 & _Gaia_ EDR3 \\\\\n\\(\\delta\\)\u2009(J2000) & \\(+\\)53\u00ba\u200922_\u2032_\u200936\\(\"\\!\\).5 & _Gaia_ EDR3 \\\\\nSpectral type & K2\u2009V & Sect.\u2009 \\\\\n\\multicolumn{3}{c}{_Parallax and kinematics_} \\\\\n\\(\\pi\\) [mas] & 24.25\u2009\\(\\pm\\)\u20090.01 & _Gaia_ EDR3 \\\\\n\\(d\\) [pc] & \\(41.24\\pm 0.02\\) & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\alpha}\\cos{\\delta}\\) [mas\u2009yr_-1_] & 165.05\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\delta}\\) [mas\u2009yr_-1_] & 145.17\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\gamma\\)\u2009_(a)_ [km\u2009s_-1_] & \\(-\\)27.370\\(\\pm\\)\u20090.002 & _Gaia_ DR2 \\\\\n\\(U\\) [km\u2009s_-1_] & \\(-\\)41.75\u2009\\(\\pm\\)\u20090.02 & This work \\\\\n\\(V\\) [km\u2009s_-1_] & \\(-\\)22.16\u2009\\(\\pm\\)\u20090.01 & This work \\\\\n\\(W\\) [km\u2009s_-1_] & \\(-\\)19.03\u2009\\(\\pm\\)\u20090.02 & This work \\\\\nRUWE & \\(0.966\\) & _Gaia_ DR3 \\\\\n\\multicolumn{3}{c}{_Magnitudes_} \\\\\n\\(B\\) [mag] & 10.129 \\(\\pm\\) 0.038 & TYC \\\\\n\\(V\\) [mag] & 9.19 \\(\\pm\\) 0.03 & HIP \\\\\n\\(J\\) [mag] & 7.646 \\(\\pm\\) 0.03 & 2MASS \\\\\n\\hline\n\\multicolumn{3}{c}{_Stellar parameters_} \\\\\n\\(L_{\\rm X}\\) [\\(\\times 10^{28}\\) erg s_-1_] & \\(1.89\\pm 0.07\\) & Sect.\u2009 \\\\\n\\(L_{\\star}\\) [\\(L_{\\odot}\\)] & 0.3609 \\(\\pm\\) 0.0052 & Sect.\u2009 \\\\\n\\(T_{\\mathrm{eff}}\\) [K] & 5037\\(\\pm\\)14 & Sect.\u2009 \\\\\nlog(g[cm\u2009s]\u22122) & 4.63 \\(\\pm\\) 0.02 & Sect.\u2009 \\\\\n\\(\\rm[Fe/H]\\) & \\(-\\)0.01\\(\\pm\\)0.02 & Sect.\u2009 \\\\\n & \\(-\\)0.08\\(\\pm\\)0.13 & B18 \\\\\n\\(R_{\\star}\\) [R_\u2299_] & 0.789\\({}^{+0.022}_{-0.021}\\) & Sect.\u2009 \\\\\n\\(M_{\\star}\\) [M_\u2299_] & 0.843\\({}^{+0.033}_{-0.056}\\) & Sect.\u2009 \\\\\n\\(V_{\\rm broad}\\) [km\u2009s_-1_] & 2.89 \\(\\pm\\) 0.03 & Sect.\u2009 \\\\\n\\(v\\,\\sin{i}\\) [km\u2009s_-1_] & \\(<\\)2.90 & Sect.\u2009 \\\\\n\\(P_{\\mathrm{rot}}\\) [d] & 12.0 \\(\\pm\\) 0.4 & Sect.\u2009 \\\\\nlog(R)H\u2062K\u2032 & \\(-\\)4.242 \\(\\pm\\) 0.016 & M22 \\\\\nAge [Myr] & 600\u2013800 & Sect.\u2009 \\\\ \\hline\n\\end{tabular}\n\\begin{tabular}{l c l}\n\\hline \\hline\nParameter & Value & Reference \\\\\n\\hline\nName & HD\u2009235088 & HD \\\\\n & TIC 293954617 & _TESS_ \\\\\n & TOI-1430 & TOI \\\\\n & HIP 98668 & HIP \\\\\n\\hline\n\\multicolumn{3}{c}{_Coordinates and spectral types_} \\\\\n\\(\\alpha\\)\u2009(J2000) & 20h\u200902m\u200927\\({}^{\\mathrm{s}}\\!\\).4 & _Gaia_ EDR3 \\\\\n\\(\\delta\\)\u2009(J2000) & \\(+\\)53\u00ba\u200922_\u2032_\u200936\\(\"\\!\\).5 & _Gaia_ EDR3 \\\\\nSpectral type & K2\u2009V & Sect.\u2009 \\\\\n\\multicolumn{3}{c}{_Parallax and kinematics_} \\\\\n\\(\\pi\\) [mas] & 24.25\u2009\\(\\pm\\)\u20090.01 & _Gaia_ EDR3 \\\\\n\\(d\\) [pc] & \\(41.24\\pm 0.02\\) & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\alpha}\\cos{\\delta}\\) [mas\u2009yr_-1_] & 165.05\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\delta}\\) [mas\u2009yr_-1_] & 145.17\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\gamma\\)\u2009_(a)_ [km\u2009s_-1_] & \\(-\\)27.370\\(\\pm\\)\u20090.002 & _Gaia_ DR2 \\\\\n\\(U\\) [km\u2009s_-1_] & \\(-\\)41.75\u2009\\(\\pm\\)\u20090.02 & This work \\\\\n\\(V\\) [km\u2009s_-1_] & \\(-\\)22.16\u2009\\(\\pm\\)\u20090.01 & This work \\\\\n\\(W\\) [km\u2009s_-1_] & \\(-\\)19.03\u2009\\(\\pm\\)\u20090.02 & This work \\\\\nRUWE & \\(0.966\\) & _Gaia_ DR3 \\\\\n\\multicolumn{3}{c}{_Magnitudes_} \\\\\n\\(B\\) [mag] & 10.129 \\(\\pm\\) 0.038 & TYC \\\\\n\\(V\\) [mag] & 9.19 \\(\\pm\\) 0.03 & HIP \\\\\n\\(J\\) [mag] & 7.646 \\(\\pm\\) 0.03 & 2MASS \\\\\n\\hline\n\\multicolumn{3}{c}{_Stellar parameters_} \\\\\n\\(L_{\\rm X}\\) [\\(\\times 10^{28}\\) erg s_-1_] & \\(1.89\\pm 0.07\\) & Sect.\u2009 \\\\\n\\(L_{\\star}\\) [\\(L_{\\odot}\\)] & 0.3609 \\(\\pm\\) 0.0052 & Sect.\u2009 \\\\\n\\(T_{\\mathrm{eff}}\\) [K] & 5037\\(\\pm\\)14 & Sect.\u2009 \\\\\nlog(g[cm\u2009s]\u22122) & 4.63 \\(\\pm\\) 0.02 & Sect.\u2009 \\\\\n\\(\\rm[Fe/H]\\) & \\(-\\)0.01\\(\\pm\\)0.02 & Sect.\u2009 \\\\\n & \\(-\\)0.08\\(\\pm\\)0.13 & B18 \\\\\n\\(R_{\\star}\\) [R_\u2299_] & 0.789\\({}^{+0.022}_{-0.021}\\) & Sect.\u2009 \\\\\n\\(M_{\\star}\\) [M_\u2299_] & 0.843\\({}^{+0.033}_{-0.056}\\) & Sect.\u2009 \\\\\n\\(V_{\\rm broad}\\) [km\u2009s_-1_] & 2.89 \\(\\pm\\) 0.03 & Sect.\u2009 \\\\\n\\(v\\,\\sin{i}\\) [km\u2009s_-1_] & \\(<\\)2.90 & Sect.\u2009 \\\\\n\\(P_{\\mathrm{rot}}\\) [d] & 12.0 \\(\\pm\\) 0.4 & Sect.\u2009 \\\\\nlog(R)H\u2062K\u2032 & \\(-\\)4.242 \\(\\pm\\) 0.016 & M22 \\\\\nAge [Myr] & 600\u2013800 & Sect.\u2009 \\\\ \\hline\n\\end{tabular}\n\\begin{tabular}{l c l}\n\\hline \\hline\nParameter & Value & Reference \\\\\n\\hline\nName & HD\u2009235088 & HD \\\\\n & TIC 293954617 & _TESS_ \\\\\n & TOI-1430 & TOI \\\\\n & HIP 98668 & HIP \\\\\n\\hline\n\\multicolumn{3}{c}{_Coordinates and spectral types_} \\\\\n\\(\\alpha\\)\u2009(J2000) & 20h\u200902m\u200927\\({}^{\\mathrm{s}}\\!\\).4 & _Gaia_ EDR3 \\\\\n\\(\\delta\\)\u2009(J2000) & \\(+\\)53\u00ba\u200922_\u2032_\u200936\\(\"\\!\\).5 & _Gaia_ EDR3 \\\\\nSpectral type & K2\u2009V & Sect.\u2009 \\\\\n\\multicolumn{3}{c}{_Parallax and kinematics_} \\\\\n\\(\\pi\\) [mas] & 24.25\u2009\\(\\pm\\)\u20090.01 & _Gaia_ EDR3 \\\\\n\\(d\\) [pc] & \\(41.24\\pm 0.02\\) & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\alpha}\\cos{\\delta}\\) [mas\u2009yr_-1_] & 165.05\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\delta}\\) [mas\u2009yr_-1_] & 145.17\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\gamma\\)\u2009_(a)_ [km\u2009s_-1_] & \\(-\\)27.370\\(\\pm\\)\u20090.002 & _Gaia_ DR2 \\\\\n\\(U\\) [km\u2009s_-1_] & \\(-\\)41.75\u2009\\(\\pm\\)\u20090.02 & This work \\\\\n\\(V\\) [km\u2009s_-1_] & \\(-\\)22.16\u2009\\(\\pm\\)\u20090.01 & This work \\\\\n\\(W\\) [km\u2009s_-1_] & \\(-\\)19.03\u2009\\(\\pm\\)\u20090.02 & This work \\\\\nRUWE & \\(0.966\\) & _Gaia_ DR3 \\\\\n\\multicolumn{3}{c}{_Magnitudes_} \\\\\n\\(B\\) [mag] & 10.129 \\(\\pm\\) 0.038 & TYC \\\\\n\\(V\\) [mag] & 9.19 \\(\\pm\\) 0.03 & HIP \\\\\n\\(J\\) [mag] & 7.646 \\(\\pm\\) 0.03 & 2MASS \\\\\n\\hline\n\\multicolumn{3}{c}{_Stellar parameters_} \\\\\n\\(L_{\\rm X}\\) [\\(\\times 10^{28}\\) erg s_-1_] & \\(1.89\\pm 0.07\\) & Sect.\u2009 \\\\\n\\(L_{\\star}\\) [\\(L_{\\odot}\\)] & 0.3609 \\(\\pm\\) 0.0052 & Sect.\u2009 \\\\\n\\(T_{\\mathrm{eff}}\\) [K] & 5037\\(\\pm\\)14 & Sect.\u2009 \\\\\nlog(g[cm\u2009s]\u22122) & 4.63 \\(\\pm\\) 0.02 & Sect.\u2009 \\\\\n\\(\\rm[Fe/H]\\) & \\(-\\)0.01\\(\\pm\\)0.02 & Sect.\u2009 \\\\\n & \\(-\\)0.08\\(\\pm\\)0.13 & B18 \\\\\n\\(R_{\\star}\\) [R_\u2299_] & 0.789\\({}^{+0.022}_{-0.021}\\) & Sect.\u2009 \\\\\n\\(M_{\\star}\\) [M_\u2299_] & 0.843\\({}^{+0.033}_{-0.056}\\) & Sect.\u2009 \\\\\n\\(V_{\\rm broad}\\) [km\u2009s_-1_] & 2.89 \\(\\pm\\) 0.03 & Sect.\u2009 \\\\\n\\(v\\,\\sin{i}\\) [km\u2009s_-1_] & \\(<\\)2.90 & Sect.\u2009 \\\\\n\\(P_{\\mathrm{rot}}\\) [d] & 12.0 \\(\\pm\\) 0.4 & Sect.\u2009 \\\\\nlog(R)H\u2062K\u2032 & \\(-\\)4.242 \\(\\pm\\) 0.016 & M22 \\\\\nAge [Myr] & 600\u2013800 & Sect.\u2009 \\\\ \\hline\n\\end{tabular}\n\\begin{tabular}{l c l}\n\\hline \\hline\nParameter & Value & Reference \\\\\n\\hline\nName & HD\u2009235088 & HD \\\\\n & TIC 293954617 & _TESS_ \\\\\n & TOI-1430 & TOI \\\\\n & HIP 98668 & HIP \\\\\n\\hline\n\\multicolumn{3}{c}{_Coordinates and spectral types_} \\\\\n\\(\\alpha\\)\u2009(J2000) & 20h\u200902m\u200927\\({}^{\\mathrm{s}}\\!\\).4 & _Gaia_ EDR3 \\\\\n\\(\\delta\\)\u2009(J2000) & \\(+\\)53\u00ba\u200922_\u2032_\u200936\\(\"\\!\\).5 & _Gaia_ EDR3 \\\\\nSpectral type & K2\u2009V & Sect.\u2009 \\\\\n\\multicolumn{3}{c}{_Parallax and kinematics_} \\\\\n\\(\\pi\\) [mas] & 24.25\u2009\\(\\pm\\)\u20090.01 & _Gaia_ EDR3 \\\\\n\\(d\\) [pc] & \\(41.24\\pm 0.02\\) & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\alpha}\\cos{\\delta}\\) [mas\u2009yr_-1_] & 165.05\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\delta}\\) [mas\u2009yr_-1_] & 145.17\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\gamma\\)\u2009_(a)_ [km\u2009s_-1_] & \\(-\\)27.370\\(\\pm\\)\u20090.002 & _Gaia_ DR2 \\\\\n\\(U\\) [km\u2009s_-1_] & \\(-\\)41.75\u2009\\(\\pm\\)\u20090.02 & This work \\\\\n\\(V\\) [km\u2009s_-1_] & \\(-\\)22.16\u2009\\(\\pm\\)\u20090.01 & This work \\\\\n\\(W\\) [km\u2009s_-1_] & \\(-\\)19.03\u2009\\(\\pm\\)\u20090.02 & This work \\\\\nRUWE & \\(0.966\\) & _Gaia_ DR3 \\\\\n\\multicolumn{3}{c}{_Magnitudes_} \\\\\n\\(B\\) [mag] & 10.129 \\(\\pm\\) 0.038 & TYC \\\\\n\\(V\\) [mag] & 9.19 \\(\\pm\\) 0.03 & HIP \\\\\n\\(J\\) [mag] & 7.646 \\(\\pm\\) 0.03 & 2MASS \\\\\n\\hline\n\\multicolumn{3}{c}{_Stellar parameters_} \\\\\n\\(L_{\\rm X}\\) [\\(\\times 10^{28}\\) erg s_-1_] & \\(1.89\\pm 0.07\\) & Sect.\u2009 \\\\\n\\(L_{\\star}\\) [\\(L_{\\odot}\\)] & 0.3609 \\(\\pm\\) 0.0052 & Sect.\u2009 \\\\\n\\(T_{\\mathrm{eff}}\\) [K] & 5037\\(\\pm\\)14 & Sect.\u2009 \\\\\nlog(g[cm\u2009s]\u22122) & 4.63 \\(\\pm\\) 0.02 & Sect.\u2009 \\\\\n\\(\\rm[Fe/H]\\) & \\(-\\)0.01\\(\\pm\\)0.02 & Sect.\u2009 \\\\\n & \\(-\\)0.08\\(\\pm\\)0.13 & B18 \\\\\n\\(R_{\\star}\\) [R_\u2299_] & 0.789\\({}^{+0.022}_{-0.021}\\) & Sect.\u2009 \\\\\n\\(M_{\\star}\\) [M_\u2299_] & 0.843\\({}^{+0.033}_{-0.056}\\) & Sect.\u2009 \\\\\n\\(V_{\\rm broad}\\) [km\u2009s_-1_] & 2.89 \\(\\pm\\) 0.03 & Sect.\u2009 \\\\\n\\(v\\,\\sin{i}\\) [km\u2009s_-1_] & \\(<\\)2.90 & Sect.\u2009 \\\\\n\\(P_{\\mathrm{rot}}\\) [d] & 12.0 \\(\\pm\\) 0.4 & Sect.\u2009 \\\\\nlog(R)H\u2062K\u2032 & \\(-\\)4.242 \\(\\pm\\) 0.016 & M22 \\\\\nAge [Myr] & 600\u2013800 & Sect.\u2009 \\\\ \\hline\n\\end{tabular}\n\\begin{tabular}{l c l}\n\\hline \\hline\nParameter & Value & Reference \\\\\n\\hline\nName & HD\u2009235088 & HD \\\\\n & TIC 293954617 & _TESS_ \\\\\n & TOI-1430 & TOI \\\\\n & HIP 98668 & HIP \\\\\n\\hline\n\\multicolumn{3}{c}{_Coordinates and spectral types_} \\\\\n\\(\\alpha\\)\u2009(J2000) & 20h\u200902m\u200927\\({}^{\\mathrm{s}}\\!\\).4 & _Gaia_ EDR3 \\\\\n\\(\\delta\\)\u2009(J2000) & \\(+\\)53\u00ba\u200922_\u2032_\u200936\\(\"\\!\\).5 & _Gaia_ EDR3 \\\\\nSpectral type & K2\u2009V & Sect.\u2009 \\\\\n\\multicolumn{3}{c}{_Parallax and kinematics_} \\\\\n\\(\\pi\\) [mas] & 24.25\u2009\\(\\pm\\)\u20090.01 & _Gaia_ EDR3 \\\\\n\\(d\\) [pc] & \\(41.24\\pm 0.02\\) & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\alpha}\\cos{\\delta}\\) [mas\u2009yr_-1_] & 165.05\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\delta}\\) [mas\u2009yr_-1_] & 145.17\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\gamma\\)\u2009_(a)_ [km\u2009s_-1_] & \\(-\\)27.370\\(\\pm\\)\u20090.002 & _Gaia_ DR2 \\\\\n\\(U\\) [km\u2009s_-1_] & \\(-\\)41.75\u2009\\(\\pm\\)\u20090.02 & This work \\\\\n\\(V\\) [km\u2009s_-1_] & \\(-\\)22.16\u2009\\(\\pm\\)\u20090.01 & This work \\\\\n\\(W\\) [km\u2009s_-1_] & \\(-\\)19.03\u2009\\(\\pm\\)\u20090.02 & This work \\\\\nRUWE & \\(0.966\\) & _Gaia_ DR3 \\\\\n\\multicolumn{3}{c}{_Magnitudes_} \\\\\n\\(B\\) [mag] & 10.129 \\(\\pm\\) 0.038 & TYC \\\\\n\\(V\\) [mag] & 9.19 \\(\\pm\\) 0.03 & HIP \\\\\n\\(J\\) [mag] & 7.646 \\(\\pm\\) 0.03 & 2MASS \\\\\n\\hline\n\\multicolumn{3}{c}{_Stellar parameters_} \\\\\n\\(L_{\\rm X}\\) [\\(\\times 10^{28}\\) erg s_-1_] & \\(1.89\\pm 0.07\\) & Sect.\u2009 \\\\\n\\(L_{\\star}\\) [\\(L_{\\odot}\\)] & 0.3609 \\(\\pm\\) 0.0052 & Sect.\u2009 \\\\\n\\(T_{\\mathrm{eff}}\\) [K] & 5037\\(\\pm\\)14 & Sect.\u2009 \\\\\nlog(g[cm\u2009s]\u22122) & 4.63 \\(\\pm\\) 0.02 & Sect.\u2009 \\\\\n\\(\\rm[Fe/H]\\) & \\(-\\)0.01\\(\\pm\\)0.02 & Sect.\u2009 \\\\\n & \\(-\\)0.08\\(\\pm\\)0.13 & B18 \\\\\n\\(R_{\\star}\\) [R_\u2299_] & 0.789\\({}^{+0.022}_{-0.021}\\) & Sect.\u2009 \\\\\n\\(M_{\\star}\\) [M_\u2299_] & 0.843\\({}^{+0.033}_{-0.056}\\) & Sect.\u2009 \\\\\n\\(V_{\\rm broad}\\) [km\u2009s_-1_] & 2.89 \\(\\pm\\) 0.03 & Sect.\u2009 \\\\\n\\(v\\,\\sin{i}\\) [km\u2009s_-1_] & \\(<\\)2.90 & Sect.\u2009 \\\\\n\\(P_{\\mathrm{rot}}\\) [d] & 12.0 \\(\\pm\\) 0.4 & Sect.\u2009 \\\\\nlog(R)H\u2062K\u2032 & \\(-\\)4.242 \\(\\pm\\) 0.016 & M22 \\\\\nAge [Myr] & 600\u2013800 & Sect.\u2009 \\\\ \\hline\n\\end{tabular}\n\\begin{tabular}{l c l}\n\\hline \\hline\nParameter & Value & Reference \\\\\n\\hline\nName & HD\u2009235088 & HD \\\\\n & TIC 293954617 & _TESS_ \\\\\n & TOI-1430 & TOI \\\\\n & HIP 98668 & HIP \\\\\n\\hline\n\\multicolumn{3}{c}{_Coordinates and spectral types_} \\\\\n\\(\\alpha\\)\u2009(J2000) & 20h\u200902m\u200927\\({}^{\\mathrm{s}}\\!\\).4 & _Gaia_ EDR3 \\\\\n\\(\\delta\\)\u2009(J2000) & \\(+\\)53\u00ba\u200922_\u2032_\u200936\\(\"\\!\\).5 & _Gaia_ EDR3 \\\\\nSpectral type & K2\u2009V & Sect.\u2009 \\\\\n\\multicolumn{3}{c}{_Parallax and kinematics_} \\\\\n\\(\\pi\\) [mas] & 24.25\u2009\\(\\pm\\)\u20090.01 & _Gaia_ EDR3 \\\\\n\\(d\\) [pc] & \\(41.24\\pm 0.02\\) & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\alpha}\\cos{\\delta}\\) [mas\u2009yr_-1_] & 165.05\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\delta}\\) [mas\u2009yr_-1_] & 145.17\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\gamma\\)\u2009_(a)_ [km\u2009s_-1_] & \\(-\\)27.370\\(\\pm\\)\u20090.002 & _Gaia_ DR2 \\\\\n\\(U\\) [km\u2009s_-1_] & \\(-\\)41.75\u2009\\(\\pm\\)\u20090.02 & This work \\\\\n\\(V\\) [km\u2009s_-1_] & \\(-\\)22.16\u2009\\(\\pm\\)\u20090.01 & This work \\\\\n\\(W\\) [km\u2009s_-1_] & \\(-\\)19.03\u2009\\(\\pm\\)\u20090.02 & This work \\\\\nRUWE & \\(0.966\\) & _Gaia_ DR3 \\\\\n\\multicolumn{3}{c}{_Magnitudes_} \\\\\n\\(B\\) [mag] & 10.129 \\(\\pm\\) 0.038 & TYC \\\\\n\\(V\\) [mag] & 9.19 \\(\\pm\\) 0.03 & HIP \\\\\n\\(J\\) [mag] & 7.646 \\(\\pm\\) 0.03 & 2MASS \\\\\n\\hline\n\\multicolumn{3}{c}{_Stellar parameters_} \\\\\n\\(L_{\\rm X}\\) [\\(\\times 10^{28}\\) erg s_-1_] & \\(1.89\\pm 0.07\\) & Sect.\u2009 \\\\\n\\(L_{\\star}\\) [\\(L_{\\odot}\\)] & 0.3609 \\(\\pm\\) 0.0052 & Sect.\u2009 \\\\\n\\(T_{\\mathrm{eff}}\\) [K] & 5037\\(\\pm\\)14 & Sect.\u2009 \\\\\nlog(g[cm\u2009s]\u22122) & 4.63 \\(\\pm\\) 0.02 & Sect.\u2009 \\\\\n\\(\\rm[Fe/H]\\) & \\(-\\)0.01\\(\\pm\\)0.02 & Sect.\u2009 \\\\\n & \\(-\\)0.08\\(\\pm\\)0.13 & B18 \\\\\n\\(R_{\\star}\\) [R_\u2299_] & 0.789\\({}^{+0.022}_{-0.021}\\) & Sect.\u2009 \\\\\n\\(M_{\\star}\\) [M_\u2299_] & 0.843\\({}^{+0.033}_{-0.056}\\) & Sect.\u2009 \\\\\n\\(V_{\\rm broad}\\) [km\u2009s_-1_] & 2.89 \\(\\pm\\) 0.03 & Sect.\u2009 \\\\\n\\(v\\,\\sin{i}\\) [km\u2009s_-1_] & \\(<\\)2.90 & Sect.\u2009 \\\\\n\\(P_{\\mathrm{rot}}\\) [d] & 12.0 \\(\\pm\\) 0.4 & Sect.\u2009 \\\\\nlog(R)H\u2062K\u2032 & \\(-\\)4.242 \\(\\pm\\) 0.016 & M22 \\\\\nAge [Myr] & 600\u2013800 & Sect.\u2009 \\\\ \\hline\n\\end{tabular}\n\n\n\\begin{tabular}{l c l}\n\\hline \\hline\nParameter & Value & Reference \\\\\n\\hline\nName & HD\u2009235088 & HD \\\\\n & TIC 293954617 & _TESS_ \\\\\n & TOI-1430 & TOI \\\\\n & HIP 98668 & HIP \\\\\n\\hline\n\\multicolumn{3}{c}{_Coordinates and spectral types_} \\\\\n\\(\\alpha\\)\u2009(J2000) & 20h\u200902m\u200927\\({}^{\\mathrm{s}}\\!\\).4 & _Gaia_ EDR3 \\\\\n\\(\\delta\\)\u2009(J2000) & \\(+\\)53\u00ba\u200922_\u2032_\u200936\\(\"\\!\\).5 & _Gaia_ EDR3 \\\\\nSpectral type & K2\u2009V & Sect.\u2009 \\\\\n\\multicolumn{3}{c}{_Parallax and kinematics_} \\\\\n\\(\\pi\\) [mas] & 24.25\u2009\\(\\pm\\)\u20090.01 & _Gaia_ EDR3 \\\\\n\\(d\\) [pc] & \\(41.24\\pm 0.02\\) & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\alpha}\\cos{\\delta}\\) [mas\u2009yr_-1_] & 165.05\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\mu_{\\delta}\\) [mas\u2009yr_-1_] & 145.17\u2009\\(\\pm\\)\u20090.02 & _Gaia_ EDR3 \\\\\n\\(\\gamma\\)\u2009_(a)_ [km\u2009s_-1_] & \\(-\\)27.370\\(\\pm\\)\u20090.002 & _Gaia_ DR2 \\\\\n\\(U\\) [km\u2009s_-1_] & \\(-\\)41.75\u2009\\(\\pm\\)\u20090.02 & This work \\\\\n\\(V\\) [km\u2009s_-1_] & \\(-\\)22.16\u2009\\(\\pm\\)\u20090.01 & This work \\\\\n\\(W\\) [km\u2009s_-1_] & \\(-\\)19.03\u2009\\(\\pm\\)\u20090.02 & This work \\\\\nRUWE & \\(0.966\\) & _Gaia_ DR3 \\\\\n\\multicolumn{3}{c}{_Magnitudes_} \\\\\n\\(B\\) [mag] & 10.129 \\(\\pm\\) 0.038 & TYC \\\\\n\\(V\\) [mag] & 9.19 \\(\\pm\\) 0.03 & HIP \\\\\n\\(J\\) [mag] & 7.646 \\(\\pm\\) 0.03 & 2MASS \\\\\n\\hline\n\\multicolumn{3}{c}{_Stellar parameters_} \\\\\n\\(L_{\\rm X}\\) [\\(\\times 10^{28}\\) erg s_-1_] & \\(1.89\\pm 0.07\\) & Sect.\u2009 \\\\\n\\(L_{\\star}\\) [\\(L_{\\odot}\\)] & 0.3609 \\(\\pm\\) 0.0052 & Sect.\u2009 \\\\\n\\(T_{\\mathrm{eff}}\\) [K] & 5037\\(\\pm\\)14 & Sect.\u2009 \\\\\nlog(g[cm\u2009s]\u22122) & 4.63 \\(\\pm\\) 0.02 & Sect.\u2009 \\\\\n\\(\\rm[Fe/H]\\) & \\(-\\)0.01\\(\\pm\\)0.02 & Sect.\u2009 \\\\\n & \\(-\\)0.08\\(\\pm\\)0.13 & B18 \\\\\n\\(R_{\\star}\\) [R_\u2299_] & 0.789\\({}^{+0.022}_{-0.021}\\) & Sect.\u2009 \\\\\n\\(M_{\\star}\\) [M_\u2299_] & 0.843\\({}^{+0.033}_{-0.056}\\) & Sect.\u2009 \\\\\n\\(V_{\\rm broad}\\) [km\u2009s_-1_] & 2.89 \\(\\pm\\) 0.03 & Sect.\u2009 \\\\\n\\(v\\,\\sin{i}\\) [km\u2009s_-1_] & \\(<\\)2.90 & Sect.\u2009 \\\\\n\\(P_{\\mathrm{rot}}\\) [d] & 12.0 \\(\\pm\\) 0.4 & Sect.\u2009 \\\\\nlog(R)H\u2062K\u2032 & \\(-\\)4.242 \\(\\pm\\) 0.016 & M22 \\\\\nAge [Myr] & 600\u2013800 & Sect.\u2009 \\\\ \\hline\n\\end{tabular}\n",
    "## 9.  Zeros It is well known that the zeros of orthogonal polynomials with respect to a positive definite linear functional are real, simple, and located in the interior of the convex hull of the support [ 15 ,  20 ]. With this in mind, let \\(\\{x_{n,k}(z)\\}_{k=1}^{n}\\)be the the zeros of \\(P_{n}(x)\\) in an increasing order, i. e., \n\n\\[P_{n}(x_{n,k}(z),z)=0\\  \n\nwith \\[x_{n,1}(z)<x_{n,2}(z)<\\cdots<x_{n,n}(z).\\]  \n\nNext we will focus our attention on an electrostatic interpretation of the zeros of the polynomial \\(P_{n}(x;z)\\) in terms of the energy associated with a logarithmic potential and next we will study the dynamics of them in terms of the parameter \\(z.\\)\n\n9.1. \n\n### Electrostatic interpretation\n \n\n.\n  Evaluating the operator \\(D_{n+1}\\) defined in ( 5.6 ) at \\(x=x_{n+1,k},\\) we get \n\n\\[\\left.\\dfrac{\\partial_{x}^{2}P_{n+1}}{\\partial_{x}P_{n+1}}\\right|_{x=x_{n+1,k} }=-\\dfrac{(2x_{n+1,k}-z)}{\\phi(x_{n+1,k})}+\\dfrac{a_{n+1}}{C_{n}(x_{n+1,k})}\\\\ +\\dfrac{(x_{n,k}-b_{n})C_{n-1}(x_{n,k};z)}{a_{n}\\phi(x_{n,k};z)}+\\dfrac{\\delta _{n}(x_{n,k};z)+\\delta_{n-1}(x_{n,k};z)}{\\phi(x_{n,k};z)},\\]  \n\nwhere \\(C_{n}(x;z)\\) and \\(\\delta_{n}(x;z)\\) were defined in Proposition . Taking into account ( 5.4 ) the above expression reads \n\n\\[\\left.\\dfrac{\\partial_{x}^{2}P_{n+1}}{\\partial_{x}P_{n+1}}\\right| _{x=x_{n+1,k}} =-\\dfrac{1}{x_{n+1,k}-z}-\\dfrac{1}{x_{n+1,k}}+\\dfrac{1}{x_{n+1,k} -\\beta_{n}}+1-\\dfrac{\\alpha}{x_{n+1,k}},\\]  \n\nwhere \\(\\beta_{n}=-b_{n+1}+(2n+\\alpha+z+3)\\)\\(w(x)=x^{\\alpha}e^{-x}=e^{-x+\\alpha\\ln x}.\\). Observe that the weight function associated with \\(\\boldsymbol{\\ell}\\)is \\(w(x)=x^{\\alpha}e^{-x}=e^{-x+\\alpha\\ln x}.\\)),\n  If we define \\(v(x)=x-\\alpha\\ln x,\\) (the external potential [ 22 , Section 3.5]), then \n\n\\[\\left.\\dfrac{\\partial_{x}^{2}P_{n+1}}{\\partial_{x}P_{n+1}}\\right| _{x=x_{n+1,k}}=-\\dfrac{1}{x_{n+1,k}-z}-\\dfrac{1}{x_{n+1,k}}+\\dfrac{1}{x_{n+1,k }-\\beta_{n}}+v^{\\prime}(x_{n+1,k}).\\  \n\nRemark\n _ If_ \\(\\{\\widetilde{x}_{n+1,k}(z)\\}_{k=1}^{n+1}\\)_are the zeros of_ \\(Q_{n+1}(x)\\)_ in an increasing order, i.e._ \n\n\\[\\left.\\dfrac{\\partial_{x}^{2}Q_{n+1}}{\\partial_{x}Q_{n+1}}\\right| _{x=\\widetilde{x}_{n+1,k}}=-\\dfrac{1}{\\widetilde{x}_{n+1,k}-z}-\\dfrac{1}{ \\widetilde{x}_{n+1,k}}+\\dfrac{1}{\\widetilde{x}_{n+1,k}-\\widetilde{\\beta}_{n}}+ 1-\\dfrac{\\alpha+1}{\\widetilde{x}_{n+1,k}},\\  \n\n\\(\\widetilde{x}_{n+1,1}<\\widetilde{x}_{n+1,2}<\\cdots<\\widetilde{x}_{n+1,n+1}\\)\\(\\widetilde{x}_{n+1,1}<\\widetilde{x}_{n+1,2}<\\cdots<\\widetilde{x}_{n+1,n+1}\\)\n\n\n\n_, then we have_ \n\n\n\n_where_ \\(\\widetilde{\\beta}_{n}=-d_{n+1}+(2n+\\alpha+z+4)\\)_._ \n\nTheorem\n _ The zeros of_ \\(P_{n+1}(x;z)\\)_ are the equilibrium points of_ \\(n+1\\)_ unit_ _charged particles located in the interval_ \\((0,z)\\)_ under the influence of the external_ _potential_ \\[V_{P}(x)=\\ln\\dfrac{1}{|x-z|}+\\ln\\dfrac{1}{|x|}-\\ln\\dfrac{1}{|x-\\beta_{n}|}+v(x ),\\quad 0<x<z.\\]  ",
    "for all \\(t\\in[0,\\delta)\\) almost surely. Furthermore, for \\(p\\geqslant 4\\), using Ito\u2019s formula for \\(\\|u\\|_{1,2}^{p}\\), we have \n\n\\[\\|w^{\\varepsilon}(t)\\|_{1,2}^{p}-\\|w_{0}\\|_{1,2}^{p}=p\\sum_{k} \\lambda_{k}\\int_{0}^{t}\\|w^{\\varepsilon}(s)\\|_{1,2}^{p-2}(\\partial_{x}(\\Psi_{k }w^{\\varepsilon}(s)),w^{\\varepsilon}(s))_{1,2}\\,d\\beta^{k}(s)\\ \\[+ p\\sum_{k}\\gamma_{k}\\int_{0}^{t}\\|w^{\\varepsilon}(s)\\|_{1,2}^{p-2 }(\\Psi_{k}f(w^{\\varepsilon}(s)),w^{\\varepsilon}(s))_{1,2}d\\beta_{1}^{k}(s)\\] \\[+ \\frac{p}{2}\\int_{0}^{t}\\|w^{\\varepsilon}(s)\\|_{1,2}^{p-2}(2 \\langle\\langle A^{\\varepsilon}w^{\\varepsilon}(s),w^{\\varepsilon}(s)\\rangle \\rangle+\\|B(w^{\\varepsilon}(s))\\|_{L_{2}}^{2})\\,ds\\] \\[+ \\frac{p(p-2)}{2}\\sum_{k}\\lambda_{k}^{2}\\int_{0}^{t}\\|w^{ \\varepsilon}(s)\\|_{1,2}^{p-4}(\\partial_{x}(\\Psi_{k}w^{\\varepsilon}(s)),w^{ \\varepsilon}(s))^{2}_{1,2}\\,ds\\] \\[+ \\frac{p(p-2)}{2}\\sum_{k}\\gamma_{k}^{2}\\int_{0}^{t}\\|w^{ \\varepsilon}(s)\\|_{1,2}^{p-4}(\\Psi_{k}f(w^{\\varepsilon}(s)),w^{\\varepsilon}(s) )^{2}_{1,2}\\,ds\\]  \n\n\n\nwhere we used the definition of the norm \\(\\|B(u)\\|_{L_{2}}\\). Next, using Burkholder-Davis-Gundy inequality: \n\n\\[\\mbox{\\bf E}\\sup_{t^{\\prime}\\in[0,t)}\\left|\\int_{0}^{t^{\\prime}} \\|w^{\\varepsilon}(s)\\|_{1,2}^{p-2}(\\partial_{x}(\\Psi_{k}w^{\\varepsilon}(s)),w^ {\\varepsilon})_{1,2}\\,d\\beta^{k}(s)\\right|\\ \\[\\leqslant 3\\mbox{\\bf E}\\left(\\int_{0}^{t}\\|w^{\\varepsilon}(s)\\|_{1,2}^{2p- 4}\\partial_{x}(\\Psi_{k}w^{\\varepsilon}(s),w^{\\varepsilon}(s))_{1,2}^{2}\\,ds \\right)^{\\frac{1}{2}}\\] \\[\\leqslant C\\mbox{\\bf E}\\left(\\int_{0}^{t}\\|w^{\\varepsilon}(s)\\|_{1,2}^{2p} \\right)^{\\frac{1}{2}}\\leqslant C\\mbox{\\bf E}\\sqrt{\\sup_{s\\in[0,t]}\\|w^{ \\varepsilon}(s)\\|_{1,2}^{p}\\,\\int_{0}^{t}\\|w^{\\varepsilon}(s)\\|_{1,2}^{p}\\,ds}\\] \\[\\leqslant \\nu\\mbox{\\bf E}\\sup_{s\\in[0,t]}\\|w^{\\varepsilon}(s)\\|_{1,2}^{p}+ \\frac{C}{\\nu}\\mbox{\\bf E}\\int_{0}^{t}\\|w^{\\varepsilon}(s)\\|_{1,2}^{p}\\,ds,\\]  \n\n\n\nwhere \\(\\nu>0\\) can be chosen arbitrarily small, and \\(C\\) is independent of \\(\\nu\\). Note that the expected values in (4.26) are finite due to (4.8). \n\nIn a similar way, we get \n\n\\[\\mbox{\\bf E}\\sup_{\\tau\\in[0,t]}\\left|\\int_{0}^{\\tau}\\|w^{\\varepsilon}(s)\\|_{1, 2}^{p-2}(\\Psi_{k}f(w^{\\varepsilon}(s)),w^{\\varepsilon}(s))_{1,2}d\\beta_{1}^{k} (s)\\right|\\\\ \\leqslant 3\\mbox{\\bf E}\\left(\\int_{0}^{t}\\|w^{\\varepsilon}(s)\\|_{1,2}^{2p-4}( \\Psi_{k}f(w^{\\varepsilon}(s)),w^{\\varepsilon}(s))_{1,2}\\,ds\\right)^{\\frac{1}{2 }}.\\  \n\nBut \n\n\\[(\\Psi_{k}f(w^{\\varepsilon}(s)),w^{\\varepsilon}(s))_{1,2}=\\int_{0}^{L}\\Psi_{k}f (w^{\\varepsilon}(s))w^{\\varepsilon}(s)\\,ds\\\\ +\\int_{0}^{L}\\partial_{x}(\\Psi_{k}f(w^{\\varepsilon}(s)))\\partial_{x}w^{ \\varepsilon}(s)\\,ds:=I_{1}+I_{2}.\\  \n\nThe estimate for \\(I_{1}\\) follows from the conditions imposed on \\(f\\), namely \\[|I_{1}|\\leqslant C\\|w^{\\varepsilon}(s)\\|_{2}^{2}.\\]  ",
    "To simplify the analysis, a narrow frequency band was selected between 24 and 61 Hz, with the fourth and fifth bending modes of the blades dominating the response in this band. Although other modes appear to have a small influence in this band, a 2DOF assumption was imposed. (This assumption results in smoothing of the FRF over the band, and might result in some loss of interpretability, but is acceptable for these preliminary analyses). The real part was modelled as a probabilistic FRF, using the FRF estimate from Eq. (13) as the mean of the likelihood function, as described in Case 1, presented in Section 6 of this paper. The real parts of the averaged FRFs for each blade, at the second accelerometer from the blade root (corresponding to the drive-point location), are shown in Figures 5a and 5b. Figure 5a shows the full measured bandwidth, and Figure 5b shows the FRF in the bandwidth of interest, between 24 and 61 Hz. \n\nFigures 5a and 5b show increasing variability with respect to frequency, which is an expected result, given that higher-frequency modes are more sensitive to small physical changes than lower-frequency modes. For modes less than 80 Hz, the maximum frequency difference among the blades was approximately 2.5 Hz; for modes greater than 80 Hz, the maximum frequency difference was approximately 6.3 Hz. Note the grouping visible at several of the peaks, where Blades 1 and 2 appear closely aligned in frequency while Blades 3 and 4 appear closely aligned. These results are quite relevant for PBSHM. All of the helicopter blades are healthy, and represent a normal-condition state of the population. Consider a situation where only FRFs from one of the groupings are available for training a model (or FRFs from the other groups are missing data). The normal condition could be heavily biased towards the training set, and incoming FRFs could be flagged as damaged, even if they are healthy. Further details regarding the data collection and processing for these tests can be found in [27]. ",
    "## Appendix B. Derivation of  E 1 VV [\u2206 H ]  in  (19) According to [8], for the harmonic oscillator with the Hamiltonian (A.1) and the equations of motion (A.2), the expected energy error produced by a \\(k\\)-stage palindromic splitting integrator \\(\\Psi_{h}\\) applied for \\(L\\) integration steps is given by \n\n\\[\\mathbb{E}[\\Delta H]=\\sin^{2}\\left(L\\Theta^{\\bm{z}}_{h}\\right)\\rho(h,\\bm{z}),\\] (43)  \n\nwhere \\(\\Theta^{\\bm{z}}_{h}=\\arccos A^{\\bm{z}}_{h}\\), and \\(A^{\\bm{z}}_{h}\\). For\n \\(L=1\\) and \\(\\rho(h,\\bm{z})\\)defined in (A.4), (B.1) yields \n\n\\[\\mathbb{E}[\\Delta H]=\\frac{\\left(B^{\\bm{z}}_{h}+C^{\\bm{z}}_{h}\\right)^{2}}{2}.\\] (44)  \n\nFigure 14: Musk BLR: The effect of the scaling approaches \\(S\\) and \\(S_{\\omega}\\) (28) with (30) (in green) and with (29) (in purple) respectively. Metrics are plotted against the 1-stage dimensionless stability interval \\((0,2)\\) for comparison. Using \\(S_{\\omega}\\) (in purple) helps to shift the best performance of both adaptive schemes towards the center of the stability interval. Moreover, \\(\\max\\text{PSRF}\\)confirms that the stability limit is estimated better with\n \\(S_{\\omega}\\). ",
    "[5] and the references there for some of the algorithmic developments. A particular feature of numerical approximations of PDE solutions based on DNNs as approximation architectures that was observed in practice was the apparent insensitivity of the DNN approximation quality to the so-called \u201ccurse of dimensionality\u201d (CoD for short). This is particularly relevant for approximating maps \n\n\\[\\mathcal{G}:\\mathcal{X}\\to\\mathcal{Y}\\] (1)  \n\nbetween (in general, infinite-dimensional) separable Hilbert spaces 1 \\(\\mathcal{X}\\)PDEs\n  and \\(\\mathcal{Y}\\)within\n . Operators \\(\\mathcal{G}\\) as in (1) emerge for example as parameter-to-solution mappings for parametric PDEs within the field of Uncertainty Quantification (see, e.g., [48] and the references there), or in so-called digital twins of complex, physical systems governed by partial differential equations (PDEs) (see [32] and the references there). Owing to the infinite dimension of \\(\\mathcal{X}\\) and \\(\\mathcal{Y}\\) in (1), efficient numerical approximations of maps \\(\\mathcal{G}\\) are to overcome the CoD. \n\nSeveral (intrinsically different) mechanisms for overcoming the CoD in DNN emulations have been identified and mathematically justified recently. This includes the seminal work of A. _ Barron_  [3], _ MonteCarlo path simulation_  type arguments (e.g. [20, 29] and the references there), and the emulation of sparse (generalized) _ polynomial chaos expansions_  (e.g. [2, 17]) by DNNs (e.g. [56, 51, 57]). \n\nSpecifically, in [56, 51, 57], a parametric representation of inputs \\(x\\in\\mathcal{X}\\)whose\n  of \\(\\mathcal{G}\\)depth\n  was used to prove DNN emulation rates for approximating \\(\\mathcal{G}\\). The construction used DNNs whose depth scales polylogarithmic in the parameter dimension, and polynomially in the DNN expression accuracy (i.e., emulation fidelity). Key in the proofs of these results is the _ holomorphic_  dependence of \\(\\mathcal{G}(x)\\)feedforward\n on the input\n \\(x\\). The related DNN emulation results were obtained with sparsely connected, deep feedforward NNs with ReLU or smooth (e.g. sigmoidal or\n \\(\\tanh(\\cdot)\\)) activation. DNN emulation rate results that are free from the CoD for\n _ low regularity_ _maps_ \\(\\mathcal{G}\\) between function spaces were obtained e.g. using the so-called Feynman-Kac representation of solutions of Kolmogorov PDEs in (jump-)diffusion models. These results used ReLU DNNs of moderate depth [20, 29], but the error bounds hold in a mean-square sense or only with high probability. \n\nWhile quantified, parametric holomorphy of solution families of parametric PDEs has been verified in many settings (particularly in elliptic and parabolic PDEs, e.g. [27, 66, 31, 12, 23]), there are broad classes of applications where relevant maps are H\u00a8 older or Lipschitz, but not holomorphic. One purpose of the present paper is to obtain mean-square DNN expression rate bounds for _ Operator Network_  (ONet) emulations with architecture (2) below, of Lipschitz (and, more generally, H\u00a8 older smooth) maps \\(\\mathcal{G}\\) between separable Hilbert spaces. \n\n### Previous work for operator networks A rather recent line of research uses so-called _ Operator Networks_ \\(\\mathcal{G}\\), such as for example the coefficient-to-solution map in linear, elliptic divergence form\n \\(\\mathcal{G}\\)second\n , such as for example the coefficient-to-solution map in linear, elliptic divergence form PDEs of second order. A variety of DNN architectures has been put forward recently with the aim of efficient operator emulation, with distinct architectures tailored to the emulation of particular operators. A number of acronyms labelling these DNN classes has been coined (\u201cdeepONets\u201d [45], Fourier Neural Operators \u201cFNOs\u201d [35, 41], UNet architectures combined with FNOs \u201cU-FNOs\u201d [62], encoders based on transformers, etc.). We refer to [35, 38, 21, 49, 42, 6] and the references there. \n\nIn this paper, we discuss an architecture that belongs to the same general category as those proposed in, for instance, [25, 45, 24]. It reduces the task of approximating \\(\\mathcal{G}\\)an\n  to that of emulating (components of) _countably-parametric maps_ \\(G:\\ell^{2}(\\mathbb{N})\\to\\ell^{2}(\\mathbb{N})\\)\\(\\mathcal{G}\\)with DNNs: using an appropriate\n _ encoder_ \\(\\mathcal{E}_{\\mathcal{X}}:\\mathcal{X}\\to\\ell^{2}(\\mathbb{N})\\)and _ decoder_ \\(\\mathcal{D}_{\\mathcal{Y}}:\\ell^{2}(\\mathbb{N})\\to\\mathcal{Y}\\), the map \\(\\mathcal{G}\\) in (1) allows the structural representation \n\n\\[\\mathcal{G}=\\mathcal{D}_{\\mathcal{Y}}\\circ G\\circ\\mathcal{E}_{\\mathcal{X}}.\\] (2)  1 More generally, separably-valued maps \\(\\mathcal{G}\\) into an otherwise nonseparable target space \\(\\mathcal{Y}\\) may be considered. In [35, Section 9, App. B] additional conditions on separable Banach spaces \\(\\mathcal{X}\\) and \\(\\mathcal{Y}\\) necessary to extend the present arguments to this more general setting are discussed. ",
    "Let $y \\in W_4$. Then $y = [b_k,\\,d_0,\\,d_1,\\,d_2]$for\n $k = 0$or 1. The corresponding equation in\n reads\n \n\n\\begin{align*}         &t_0^{b_k, d_0,d_1,d_2} a_{[b_k, \\, d_0]}a_{[d_1, \\, d_2]}          + t_1^{b_k, d_0,d_1,d_2} a_{[b_k, \\, d_1]}a_{[d_0, \\, d_2]}          + t_2^{b_k, d_0,d_1,d_2} a_{[b_k, \\, d_2]}a_{[d_0, \\, d_1]} = 0\\\\         &t_0 = \\begin{cases}             -1 \\quad \\text{if} \\quad d_0<d_1<b_k<d_2\\\\             +1 \\quad \\text{otherwise}         \\end{cases}\\\\         &t_1 = \\begin{cases}             -1 \\quad \\text{if} \\quad b_k<d_0<d_1<d_2 \\quad \\text{or} \\quad d_0 < d_1<d_2<b_k\\\\             +1 \\quad \\text{otherwise}         \\end{cases}\\\\         &t_2 = \\begin{cases}             -1 \\quad \\text{if} \\quad d_0<b_k<d_1<d_2\\\\             +1 \\quad \\text{otherwise}         \\end{cases}     \\end{align*}\n\nEach of $a_{[d_1, \\, d_2]}, a_{[d_0, \\, d_2]} \\,\\&\\, a_{[d_0, \\, d_1]}$are fixed by Equation\n . Substituting in, (multiplying out\n $a_{[b_0,\\,b_1]}$[\n1,\n2]\n[\n0,\n2]\n[\n0,\n1\n), the equation now reads\n \n\n\\begin{multline}         t_0^{b_k, d_0,d_1,d_2}a_{[b_k, \\, d_0]} \\bigl(         s_0^{b_0,b_1,d_1,d_2} a_{[b_0,\\, d_1]}a_{[b_1,\\, d_2]} +          s_1^{b_0,b_1,d_1,d_2} a_{[b_0,\\, d_2]}a_{[b_1,\\, d_1]}         \\bigr)\\\\         +          t_1^{b_k, d_0,d_1,d_2}a_{[b_k, \\, d_1]} \\bigl(         s_0^{b_0,b_1,d_0,d_2} a_{[b_0,\\, d_0]}a_{[b_1,\\, d_2]} +          s_1^{b_0,b_1,d_0,d_2} a_{[b_0,\\, d_2]}a_{[b_1,\\, d_0]}         \\bigr)\\\\         +         t_2^{b_k, d_0,d_1,d_2}a_{[b_k, \\, d_0]} \\bigl(         s_0^{b_0,b_1,d_0,d_1} a_{[b_0,\\, d_0]}a_{[b_1,\\, d_1]} +          s_1^{b_0,b_1,d_0,d_1} a_{[b_0,\\, d_1]}a_{[b_1,\\, d_0]}         \\bigr) = 0 \\label{eq:w4_equation}     \\end{multline}\n\n25\n \n\n\n\nLabelling the terms of Equation ( 25 ) in order 1 to 6, we can pair them off as follows. If $k = 0$,\n pair\n $(1,3),\\,(2,5)\\, \\& \\, (4,6)$. If\n $k=1$(\n)\n, instead pair\n $(1,6),\\,(2,4)\\,\\&\\,(3,5)$. Then it can be shown that\n each pair sums to 0. For example, for $k = 0$(\n)\n, we have:\n \n\n\\begin{align*}         (1) + (3) \\quad &\\propto \\quad           t_0^{b_0, d_0,d_1,d_2}s_0^{b_0,b_1,d_1,d_2}          + t_1^{b_0, d_0,d_1,d_2}s_0^{b_0,b_1,d_0,d_2} \\\\         (2) + (5) \\quad &\\propto \\quad           t_0^{b_0, d_0,d_1,d_2}s_1^{b_0,b_1,d_1,d_2} +          t_2^{b_0, d_0,d_1,d_2}s_0^{b_0,b_1,d_0,d_1} \\\\         (4) + (6) \\quad &\\propto \\quad           t_1^{b_0, d_0,d_1,d_2}s_1^{b_0,b_1,d_0,d_2}          + t_2^{b_0, d_0,d_1,d_2}s_1^{b_0,b_1,d_0,d_1}      \\end{align*}\n\nFor example, note that $t_0$ and $t_1$ have the same sign only if $d_0 < b_0 < d_1 < d_2$. If this is the case, then $s_0^{b_0,b_1,d_1,d_2}$and $s_0^{b_0,b_1,d_0,d_2}$have different signs, as can be seen from checking the 3 possible relative locations of $b_1$$(1) + (3) = 0$g\ng\n. Similarly for the other pairs. The remaining cases can\n all be checked similarly. \n\nA similar argument holds for $y = [d_0,\\,d_1,\\,d_2,\\,d_3] \\in W_6$. \n\nFor each $j \\in \\mathcal{A}_n$, define the regions $$ S_j = \\biggl\\{ \\ket{\\psi} = \\sum_{j' \\in \\mathcal{A}_n}c_{j'} \\ket{j'} \\in G: | c_j| \\geq | c_{j'}| \\quad \\forall \\, j' \\in \\mathcal{A}_n \\biggr\\} $$Clearly, the union over $j$ gives all of $G$. In each region $S_j$, Gaussian states may be defined by the set of amplitudes with labels within distance 2 of $j$, given by the set $C = \\{ c_k : d(j, k) \\leq 2 \\}$. For these amplitudes, we have \n\n\\begin{align*}     | c_j| &\\in [2^{\\frac{1-n}{2}}, \\, 1] \\\\     | c_k| &\\in [0, \\, | c_j|] \\quad \\ \\forall \\, c_k \\in C \\setminus \\{ c_j \\} \\end{align*}\n\nLet $\\mathcal{N}_j = \\{\\ket{\\psi_i} \\} \\subset S_j$ be a maximal set of pure states satisfying $$ \\forall \\, \\ket{\\psi_i}, \\ket{\\psi_{i'}} \\in \\mathcal{N}_j, \\ \\exists \\ x \\in \\mathcal{A}_n \\text{ s.t. } d(j, x) \\leq 2  \\quad | \\braket{x}{\\psi_i} - \\braket{x}{\\psi_{i'}}| \\geq \\eta $$Let $\\mathcal{N} = \\cup_j \\mathcal{N}_j$. We wish to find a suitable $\\eta$ so that $\\mathcal{N}$ is an $\\epsilon$-net. We require the 2 following lemmas: ",
    "one obtains from (3.75) \n\n\\[y_{0}^{(2)}=1-kz_{0}(v^{(2)})=1-\\frac{1}{2}k^{1/2}+\\frac{1}{4}k\\ln k^{-1}+O(k)\\] (94)  \n\nand due to (3.79) \n\ny1(2)=\u2212kz1(v(2))=\u2212A(\u03b60)k1/22\u2062J0\u22c5(1+O(k1/2))+O(k\u22125/2). (95)  \n\nThen, using the Taylor formula with respect to \\(\\mu\\), we shift initial conditions (3.92) to the point \\(y=y_{0}^{(2)}\\)as follows: \n\n\\[v_{0}(y_{0}^{(2)})=v_{0}^{(2)},\\quad v_{1}(y_{0}^{(2)})=-\\frac{ dv_{0}}{dy}(y_{0}^{(2)})\\cdot y_{1}^{(2)},\\] \\[\\zeta_{1}(y_{0}^{(2)})=\\zeta_{1}^{(2)},\\quad\\zeta_{2}(y_{0}^{(2)} )=\\zeta_{2}^{(2)}-\\frac{d\\zeta_{1}}{dy}(y_{0}^{(2)})\\cdot y_{1}^{(2)},\\] (96) \\[J_{1}(y_{0}^{(2)})=J_{1}^{(2)},\\quad J_{2}(y_{0}^{(2)})=J_{2}^{( 2)}-\\frac{dJ_{1}}{dy}(y_{0}^{(2)})\\cdot y_{1}^{(2)}.\\]  \n\nSubstituting (3.93) into (3.91) and expanding with respect to \\(\\mu\\), one obtains equations for the \\(i\\)-th approximations \\(\\zeta_{i}\\) and \\(J_{i}\\): \n\n\\[\\frac{d\\zeta_{i}}{dy} = \\mathcal{R}_{i}^{(\\zeta)}(y),\\] (97) \\[\\frac{dJ_{i}}{dy} = \\mathcal{R}_{i}^{(J)}(y).\\]  \n\n\\[\\frac{d\\zeta_{i}}{dy} = \\mathcal{R}_{i}^{(\\zeta)}(y),\\] (97) \\[\\frac{dJ_{i}}{dy} = \\mathcal{R}_{i}^{(J)}(y).\\]  \n\nThe solution of this system is \n\n\n\n\\[\\zeta_{i}(y) = \\zeta_{i}(y_{0}^{(2)})+\\int_{y_{0}^{(2)}}^{y}\\mathcal{R}_{i}^{( \\zeta)}(s)\\,{\\rm d}s,\\] (98) \\[J_{i}(v) = J_{i}(y_{0}^{(2)})+\\int_{y_{0}^{(2)}}^{y}\\mathcal{R}_{i}^{(J)}(s )\\,{\\rm d}s.\\]  \\[\\zeta_{i}(y) = \\zeta_{i}(y_{0}^{(2)})+\\int_{y_{0}^{(2)}}^{y}\\mathcal{R}_{i}^{( \\zeta)}(s)\\,{\\rm d}s,\\] (98) \\[J_{i}(v) = J_{i}(y_{0}^{(2)})+\\int_{y_{0}^{(2)}}^{y}\\mathcal{R}_{i}^{(J)}(s )\\,{\\rm d}s.\\]  \n\nFor \\(i=1\\)one has\n \n\n\\[\\mathcal{R}_{1}^{(\\zeta)}(y) = k^{1/2}\\frac{f_{3}}{y^{2}-1-k(v_{0}(y)-1)},\\] (99) \\[\\mathcal{R}_{1}^{(J)}(y) = J_{0}k^{1/2}\\frac{f_{4}}{y^{2}-1-k(v_{0}(y)-1)}{\\rm e}^{-v_{0}(y )},\\]  \n\n\\[\\mathcal{R}_{1}^{(\\zeta)}(y) = k^{1/2}\\frac{f_{3}}{y^{2}-1-k(v_{0}(y)-1)},\\] (99) \\[\\mathcal{R}_{1}^{(J)}(y) = J_{0}k^{1/2}\\frac{f_{4}}{y^{2}-1-k(v_{0}(y)-1)}{\\rm e}^{-v_{0}(y )},\\]  ",
    "Notice that at the optimal dual solution \\(\\lambda^{\\mathrm{opt}}\\)and \\(\\{\\mu_{k}^{\\mathrm{opt}}\\}\\), it must follow that \\(\\lambda^{\\mathrm{opt}}>0\\) and \\(\\boldsymbol{A}(\\lambda^{\\mathrm{opt}},\\{\\mu_{k}^{\\mathrm{opt}}\\})\\) is of full rank (i.e., \\(\\mathrm{rank}(\\boldsymbol{A}(\\lambda^{\\mathrm{opt}},\\{\\mu_{k}^{\\mathrm{opt}}\\} ))=N_{t}\\)), since otherwise, the maximum transmit power constraint in (22b) cannot be satisfied. Then, Proposition 1 follows directly from Lemma 3. This completes the proof. \n\n## P ROOF OF  L EMMA  3 \n\nFirst, we have \\(\\mathrm{tr}(\\boldsymbol{A}(\\lambda,\\{\\mu_{k}\\})\\boldsymbol{S}_{x})=\\mathrm{tr} (\\boldsymbol{\\Lambda}\\boldsymbol{U}^{H}\\boldsymbol{S}_{x}\\boldsymbol{U})\\). Let \\(\\tilde{\\boldsymbol{S}_{x}}=\\boldsymbol{U}^{H}\\boldsymbol{S}_{x}\\boldsymbol{U}\\)\\(\\tilde{\\boldsymbol{S}_{x}}=\\boldsymbol{U}^{H}\\boldsymbol{S}_{x}\\boldsymbol{U}\\). It is easy to figure out that \\(\\mathrm{tr}(\\boldsymbol{S}_{x}^{-1})=\\mathrm{tr}(\\tilde{\\boldsymbol{S}_{x}}^{- 1})\\). Recall that \\(\\boldsymbol{S}_{x}\\) is positive semi-definite. We denote \\((\\tau_{1},\\dots,\\tau_{N_{t}})\\) as introduce the following lemma to find the minimum of \\(\\mathrm{tr}(\\tilde{\\boldsymbol{S}_{x}}^{-1})\\) w.r.t. \\((\\tau_{1},\\dots,\\tau_{N_{t}})\\), for which the diagonal entries of \\(\\tilde{\\boldsymbol{S}_{x}}\\)\\(\\tilde{\\boldsymbol{S}_{x}}\\) to be determined. Note that \\(\\mathrm{tr}(\\boldsymbol{A}(\\lambda,\\{\\mu_{k}\\})\\boldsymbol{S}_{x})=\\sum_{i=1}^ {N}\\alpha_{i}\\tau_{i}\\). Here, we the proof can be found in [43, Appendix A] and thus is omitted. \n\nHence, \\(\\tilde{\\boldsymbol{S}_{x}}\\)\\(\\tilde{\\boldsymbol{S}_{x}}\\) must be diagonal and we obtain \n\n\\[\\mathrm{tr}(\\boldsymbol{A}(\\lambda,\\{\\mu_{k}\\})\\boldsymbol{S}_{x} )+\\mathrm{tr}(\\boldsymbol{S}_{x}^{-1}) = \\mathrm{tr}(\\boldsymbol{\\Lambda}\\tilde{\\boldsymbol{S}_{x}})+ \\mathrm{tr}(\\tilde{\\boldsymbol{S}_{x}}^{-1})=\\sum_{i=1}^{N}\\alpha_{i}\\tau_{i}+ \\sum_{i=1}^{N_{t}}\\frac{1}{\\tau_{i}}.\\] (57)  \n\n\n\nIn this case, when \\(N<N_{t},\\) for \\(i>N\\), \\(\\tau_{i}\\) must approach infinity to achieve the minimum value 0, i.e., for \\(i>N\\), \\(\\tau_{i}\\rightarrow+\\infty\\). As for \\(i\\leq N\\), by checking the first order differentiation, we have \\(\\tau_{i}=\\alpha_{i}^{-1/2}\\). Then, we obtain \\(\\boldsymbol{S}_{x}^{*}\\)as \n\n\\[\\boldsymbol{S}_{x}^{*}=\\boldsymbol{U}{\\boldsymbol{\\Sigma}}\\boldsymbol{U}^{H},\\] (58)  \n\nwhere \\({\\boldsymbol{\\Sigma}}=\\mathrm{diag}(\\tau_{1},\\dots,\\tau_{N_{t}})\\) with \\(\\tau_{i}\\rightarrow+\\infty\\), for \\(i>N\\), and \\(\\tau_{i}=\\alpha_{i}^{-1/2},\\) for \\(i\\leq N\\). \n\nWhen \\(\\boldsymbol{A}(\\lambda,\\{\\mu_{k}\\})\\) is full-rank, we have \n\n\\[\\mathrm{tr}(\\boldsymbol{A}(\\lambda,\\{\\mu_{k}\\})\\boldsymbol{S}_{x} )+\\mathrm{tr}(\\boldsymbol{S}_{x}^{-1}) = \\mathrm{tr}(\\boldsymbol{\\Lambda}\\tilde{\\boldsymbol{S}_{x}})+ \\mathrm{tr}(\\tilde{\\boldsymbol{S}_{x}}^{-1})=\\sum_{i=1}^{N_{t}}\\alpha_{i}\\tau_ {i}+\\sum_{i=1}^{N_{t}}\\frac{1}{\\tau_{i}}.\\] (59)  \n\n\n\nFor any \\(i\\leq N_{t}\\), we need to set \\(\\tau_{i}=\\alpha_{i}^{-1/2}\\)to achieve the minimum value. Then, the \\(\\boldsymbol{S}_{x}^{*}\\)is given by \\(\\boldsymbol{S}_{x}^{*}=\\boldsymbol{U}^{H}{\\boldsymbol{\\Sigma}}\\boldsymbol{U},\\) where \\(\\tilde{\\boldsymbol{\\Lambda}}=\\mathrm{diag}(\\tau_{1},\\dots,\\tau_{N_{t}})\\)\\(\\tilde{\\boldsymbol{\\Lambda}}=\\mathrm{diag}(\\tau_{1},\\dots,\\tau_{N_{t}})\\) with \\(\\tau_{i}=\\alpha_{i}^{-1/2},\\) for \\(i\\leq N_{t}\\). ",
    "# Proof.  The proof is an adaptation of the proof of [ Kye08 , Lemma 4.6]. Since \\(\\omega_{H}^{g}(\\chi(u))=\\tau_{H}^{g}(u)\\),\n \\(\\lambda_{H}^{g}\\circ\\chi\\) extends to an isometric embedding \\[L^{2}(Rep(G),\\tau_{H}^{g})\\to l^{2}_{g}(\\hat{H})\\cong L^{2}(\\mathcal{O}(G), \\omega_{H}^{g}).\\]  The image \\(\\lambda_{H}^{g}\\circ\\chi(\\mathcal{O}(G))\\)is a\n \\(*\\)-algebra that maps \\(L^{2}(Rep(G),\\tau_{H}^{g})\\)into itself\n and hence maps \\(L^{2}(Rep(G),\\tau_{H}^{g})^{\\perp}\\)into itself. Therefore \\(\\lambda_{H}^{g}(\\chi(u))\\)has the\n form \n\n\\[\\begin{bmatrix}\\lambda_{H}^{g}(\\chi(u))|_{L^{2}(Rep(G),\\tau_{H}^{ g})}&0\\\\ 0&\\lambda_{H}^{g}(\\chi(u))|_{L^{2}(Rep(G),\\tau_{H}^{g})^{\\perp}}\\end{bmatrix}.\\]  \n\n# Hence \n\n\\[||\\lambda_{H}^{g}(\\chi(u))||\\] =max{||\u03bbHg(\u03c7(u))|L2\u2062(R\u2062e\u2062p\u2062(G),\u03c4Hg)||,||\u03bbHg(\u03c7(u))|L2\u2062(R\u2062e\u2062p\u2062(G),\u03c4Hg)\u27c2||} \u2265||\u03bbHg(\u03c7(u))|L2\u2062(R\u2062e\u2062p\u2062(G),\u03c4Hg)|| \\[=||\\pi_{\\tau_{H}^{g}}(u)||.\\]  \n\n# This proves that the map \u03ba:\u03bbHg\u2218\u03c7(\ud835\udcaa(G))\u2192\u03c0\u03c4Hg(\u2102[Rep(G)]),\u03bbHg(\u03c7(u)))\u21a6\u03c0\u03c4Hg(u)  is bounded and therefore extends to a contractive \\(*\\)-homomorphism \\[\\kappa:\\overline{\\lambda_{H}^{g}\\circ\\chi(\\mathcal{O}(G))}\\to C^{*}_{\\tau_{H}^ {g}}(Rep(G)).\\]  To finish the proof, we claim \\(\\kappa\\) is injective. This easily follows from the observation \\[\\omega_{H}^{g}(\\chi(u)^{*}\\chi(v))=\\omega_{H}^{g}(\\chi(\\overline{u}\\cdot v))= \\tau_{H}^{g}(\\overline{u}\\cdot v).\\]  \n\n# For \\(\\alpha\\in Irr(H)\\)is\n let\n \\(P_{\\alpha}\\in l^{\\infty}(\\hat{H})\\)than\n denote the orthogonal projection onto\n \\(H_{\\alpha}\\) which is nothing more than the identity operator in \\(M_{n_{\\alpha}}\\subset l^{\\infty}(\\hat{H})\\)isomorphism\n . It is\n easily observed that the map \\(\\alpha\\mapsto P_{\\alpha}\\) induces a unitary isomorphism \\[l^{2}(Irr(H))\\cong\\overline{span\\{\\eta_{\\hat{H}}(P_{\\alpha}):\\alpha\\in Irr(H) \\}}\\subset l^{2}_{g}(\\hat{H}).\\]  From this and the duality it is also easy to check that \\[L^{2}(\\chi(\\mathcal{O}(G)),\\omega_{H}^{g})=\\overline{span\\{\\eta_{H}(q_{H}(\\chi (u))):u\\in Rep(G)\\}}\\subset l^{2}_{g}(Irr(H))\\]  ",
    "##### Abstract.\nAbstract.  This paper quantitatively investigates the structure of non-compactness of the optimal weighted Sobolev-Lorentz embedding with homogeneous weights in an open convex cone. We prove the optimal embedding in question and obtain the exact values of all injective strict _ s_ -numbers (in particular, the Bernstein numbers) of the embedding. Opposite to the earlier results in this direction, the non-compactness in this case does not occur uniformly over all sub-domains of the underlying domain. Despite that, we find an infinitely dimensional subspace restricted onto which the embedding is isomorphic, proving that the embedding is not strictly singular. \n\n## 1.  Introduction It is a truth generally acknowledged that Sobolev embeddings hold a prominent position in various areas of mathematics, making comprehensive understanding of their internal structure and behavior essential. One of their oft-studied aspects is their compactness and its quality. Quite often the quality of compactness is analyzed through the decay rate of different \\(s\\)-numbers. Various \\(s\\)-numbers are closely related to the spectral theory of the corresponding differential operators associated with Sobolev-type embeddings and provide estimates for the growth of their eigenvalues (see [ 14 ]). There is quite extensive literature in which the quality of compactness of Sobolev embeddings is investigated. However, significantly less attention has been devoted to studying the structure of non compact Sobolev embeddings, where the measure of non-compactness may be related to the shape of the essential spectrum (see [12]). \n\nNaturally, there are several ways which Sobolev embeddings can become non-compact, such as: \n\n(a) when the underlying domain is unbounded (see [1], cf. [15]); (b)  when the boundary of the underlying domain is excessively irregular (see [ 20  21  25 26]; (c)  when the target function norm is overly strong\u2014in other words, the target function space is too close to the optimal one (see [19, 24] and references therein). \n\nAmong these possibilities, the last one is particularly intriguing because it has not been explored quantitatively nearly as much as the others, despite the interest in optimal Sobolev embeddings (e.g., see [ 10 ] and references therein). Previous works investigating the case (c) (see [ 4  18  22  23 ]) dealt with Sobolev embeddings that are non-compact \n\n##### Key words and phrases.\n_Key words and phrases._  Sobolev spaces, Sobolev-Lorentz embeddings, homogeneous weights, compact ness, Bernstein numbers, measure of non-compactness. This research was supported by the grant GA23-04720S of the Czech Science Foundation. ",
    "which we call the limit equations of ( 1.2 ). Here unknown functions are the tangential velocity field \\(v\\) and the pressure \\(q\\). Also, \\(f\\) is a given external force. We write \\(P\\), \\(\\nabla_{\\Gamma}\\),\n \\(\\mathrm{div}_{\\Gamma}\\), \\(D_{\\Gamma}(v)\\), and\n \\(\\overline{\\nabla}_{v}v\\) for the orthogonal \\(\\Gamma\\), the tangential gradient, the surface divergence, the surface strain\n rate tensor, and the covariant derivative of \\(v\\) along itself, respectively. Also, \\(\\gamma^{0}\\)and \\(\\gamma^{1}\\)are nonnegative constants which stands for the friction coefficients. For details of notations, see Section  2 . Note that, when \\(g\\equiv 1\\)on\n \\(\\Gamma\\)and\n \\(\\gamma^{0}=\\gamma^{1}=0\\), the limit equations (\n 1.4 ) reduce to the surface Navier\u2013Stokes equations with Boussinesq\u2013Scriven surface stress tensor (see [ 4 ,  52 ,  2 ]) \n\n(57.1) {\u22122\u2062\u03bd\u2062P\u2062div\u0393\u2062[D\u0393\u2062(v)]+\u2207\u00afv\u2062v+\u2207\u0393q=fon\u0393,div\u0393\u2062v=0on\u0393.  \n\nMoreover, the equations ( 1.5 ) are equivalent to the Navier\u2013Stokes equations on an abstract Riemannian manifold (see [ 14 ,  56 ,  10 ]) \n\n(58.1) {\u2212\u03bd\u2062{\u0394B\u2062v+Ric\u2062(v)}+\u2207\u00afv\u2062v+\u2207\u0393q=fon\u0393,div\u0393\u2062v=0on\u0393,  \n\nwhere\n \\(\\Delta_{B}\\)\\(\\Gamma\\)and\n \\(\\mathrm{Ric}\\)is the Ricci curvature of\n \\(\\Gamma\\)(see e.g. [\n 34 , Lemma C.11] for the equivalence of the above equations). \n\nIn the nonstationary setting, we rigorously derived the limit equations ( 1.4 ) from the bulk equations ( 1.2 ) by the thin-film limit in our previous work [ 34 ]. There we proved under suitable assumptions that, for an \\(L^{2}\\)-strong solution \\(u^{\\varepsilon}\\)to the nonstationary Navier\u2013Stokes equations in\n \\(\\Omega_{\\varepsilon}\\), its average \n\n\\[Mu^{\\varepsilon}(y)=\\frac{1}{\\varepsilon g(y)}\\int_{\\varepsilon g _{0}(y)}^{\\varepsilon g_{1}(y)}u^{\\varepsilon}(y+rn(y))\\,dr,\\quad y\\in\\Gamma\\]  \n\nconverges weakly to a tangential vector field \\(v\\)\\(\\Gamma\\)in an appropriate function space as\n \\(\\varepsilon\\to 0\\), and\n \\(\\Gamma\\)by characterizing\n \\(v\\) as a unique \\(L^{2}\\)-weak solution to the limit equations. We also obtained some estimates for the difference of \\(u^{\\varepsilon}\\)and \\(v\\) which show that \\(v\\)approximates \\(u^{\\varepsilon}\\)in the \\(L^{2}\\)sense when \\(\\varepsilon\\) is small. \n\nAs in the nonstationary case [ 34 ], we can derive ( 1.4 ) from ( 1.2 ) by means of convergence of a solution and characterization of the limit, but the procedure is the same so we omit it here. In this paper, we focus on difference estimates for the solutions \\(u^{\\varepsilon}\\)to ( 1.2 ) and \\(v\\) to ( 1.4 ). Let us fix some notations and formally state our main results (see Section  2  for details). Let \\(\\mathbb{P}_{\\varepsilon}\\) be the orthogonal projection from \\(L^{2}(\\Omega_{\\varepsilon})^{3}\\)onto a function space \\(\\mathcal{H}_{\\varepsilon}\\)on\n  given in ( 2.14 ), which is the standard \\(L^{2}\\)solenoidal space on\n \\(\\Omega_{\\varepsilon}\\) or its subspace. For a vector field \\(u\\)on\n \\(\\Omega_{\\varepsilon}\\), let \\(M_{\\tau}u\\) be the tangential component of the average \\(Mu\\)\\(\\Gamma\\). Let\n \n\n\\[H^{1}(\\Gamma,T\\Gamma)=\\{v\\in H^{1}(\\Gamma)^{3}\\mid\\text{$v\\cdot n =0$ on $\\Gamma$}\\}\\]  \n\nand \\(H^{-1}(\\Gamma,T\\Gamma)\\)be the dual space of\n \\(H^{1}(\\Gamma,T\\Gamma)\\). Formally speaking, our main results are as follows (see\n Theorems  2.5  and  2.6  for the precise statements). \n\nTheorem\n _ Let_ \\(f^{\\varepsilon}\\in L^{2}(\\Omega_{\\varepsilon})^{3}\\)_ _ _,_ \\(f\\in H^{-1}(\\Gamma,T\\Gamma)\\)_, and_ \\(u^{\\varepsilon}\\)_and_ \\(v\\)_ be weak solutions to_ _ and_ _,_ _respectively. Under suitable assumptions, suppose that there exist_ \\(c_{1},c_{2}>0\\)_ and_ \\(\\alpha\\in(0,1]\\)_ independent of_ \\(\\varepsilon\\)_ such that_ \n\n(101.1) \\[\\|\\mathbb{P}_{\\varepsilon}f^{\\varepsilon}\\|_{L^{2}(\\Omega_{ \\varepsilon})}^{2}\\leqslant c_{1}\\varepsilon^{-1+\\alpha},\\quad\\|M_{\\tau} \\mathbb{P}_{\\varepsilon}f^{\\varepsilon}\\|_{H^{-1}(\\Gamma,T\\Gamma)}^{2} \\leqslant c_{2}\\]  \n\n_for all_ \\(\\varepsilon>0\\)_ sufficiently small. Then there exist_ \\(c,\\rho>0\\)_ independent of_ \\(\\varepsilon\\)_ such that_ \n\n(105.1) \\[\\|M_{\\tau}u^{\\varepsilon}-v\\|_{H^{1}(\\Gamma)}\\leqslant c\\Bigl{(} \\delta(\\varepsilon)+\\|M_{\\tau}\\mathbb{P}_{\\varepsilon}f^{\\varepsilon}-f\\|_{H^{ -1}(\\Gamma,T\\Gamma)}\\Bigr{)}\\]  \n\n_for all_ \\(\\varepsilon>0\\)_ sufficiently small provided that_ \\(\\|v\\|_{H^{1}(\\Gamma)}\\leqslant\\rho\\)_, where_ \n\n\\[\\delta(\\varepsilon)=\\varepsilon^{\\alpha/4}+\\sum_{i=0,1}\\left| \\frac{\\gamma_{\\varepsilon}^{i}}{\\varepsilon}-\\gamma^{i}\\right|.\\]  \n\n_Moreover, we have the following difference estimate in_ \\(\\Omega_{\\varepsilon}\\)_:_ \n\n\n\n(110.1) \\[\\varepsilon^{-1/2}\\|u^{\\varepsilon}-\\bar{v}\\|_{L^{2}(\\Omega_{ \\varepsilon})}\\leqslant c\\Bigl{(}\\delta(\\varepsilon)+\\|M_{\\tau}\\mathbb{P}_{ \\varepsilon}f^{\\varepsilon}-f\\|_{H^{-1}(\\Gamma,T\\Gamma)}\\Bigr{)}.\\]  \n\nnormal\n \n\n\n\n_Here_ \\(\\bar{v}\\)\\(\\bar{v}\\)_ is the constant extension of_ \\(v\\)_ in the normal direction of_ \\(\\Gamma\\)_._ \n\nNote that the left-hand side of ( 1.9 ) is divided by \\(\\varepsilon^{1/2}\\)since the \\(L^{2}(\\Omega_{\\varepsilon})\\)-norm involves the square root\n of the thickness of\n \\(\\Omega_{\\varepsilon}\\). By ( 1.9 ), we can say that the solution \\(v\\) to the limit equations ( 1.4 ) approximates the solution \\(u^{\\varepsilon}\\)to the bulk equations ( 1.2 ) when \\(\\varepsilon\\) is small. We also have an approximation result for \\(\\nabla u^{\\varepsilon}\\)Theorem\n in\n \\(\\Omega_{\\varepsilon}\\)\\(\\Gamma\\). For details, see Theorem\n 2.6 . We further note that the difference estimate ( 1.8 ) also holds if we replace the tangential component \\(M_{\\tau}u^{\\varepsilon}\\)by the average \\(Mu^{\\varepsilon}\\)itself (see Remark  6.8 ). ",
    "for all \\(\\tau\\in\\mathcal{S}_{0}\\)convex\n , where E\u22c5denotes the expectation. In this context, the functions\n \\(\\tau\\in\\mathcal{S}_{0}\\)Let\n  are named _weakly convex_ . Moreover, [TV97, Lemma 6] gives a weaker version of Theorem 3: Let \\(\\tau\\in\\mathcal{S}_{0}\\). For \\(a,b\\in[0,\\infty)\\)with\n \\(a\\geq b\\), it was shown that \\(\\tau(a+b)+\\tau(a-b)\\leq 2\\tau(a)+2\\tau(b)\\).\n \n\n#### Statistics Theorem 1 can be applied to prove rates of convergence for certain kinds of means [Sch19]: We may want to calculate a mean value of some sample points in a metric spaces. One candidate for this is the _echet mean_  [Fr\u00b4 e48], also called _ barycenter_ . It is the (set of) minimizer(s) of the squared distance to the sample points. If \\(Y\\)is a random variable with values in a metric space\n \\((\\mathcal{Q},d)\\), the\n Fr\u00b4\nechet mean is\n \\(\\argmin_{q\\in\\mathcal{Q}}\\mathbb{E}\\expectarg{\\overline{Y,q}^{2}}\\), where we assume\n \\(\\mathbb{E}\\expectarg{\\overline{Y,q}^{2}}<\\infty\\)for all \\(q\\in\\mathcal{Q}\\). Similarly, one can define the Fr\u00b4 Fr\u00b4\nechet median [FVJ09] as\n \\(\\argmin_{q\\in\\mathcal{Q}}\\mathbb{E}\\expectarg{\\overline{Y,q}}\\), or a more general\n \\(\\tau\\)echet mean [Sch22] as\n \\(\\argmin_{q\\in\\mathcal{Q}}\\mathbb{E}\\expectarg{\\tau(\\overline{Y,q})}\\)for functions\n \\(\\tau\\colon[0,\\infty)\\to\\mathbb{R}\\)as\n . Given a sequence of independent random variables \\(Y_{1},Y_{2},\\dots\\) with the same distribution as \\(Y\\) , a standard task in statistics is to bound the distance between the sample statistics and its corresponding population version. In our case, assume the \\(\\tau\\)echet mean is unique and define \n\nm &:= _q\u2208QE_\u03c4_(\u00afY,q)\u2009 , ^m_n := _q\u2208Q 1n \u2211_i=1^n _\u03c4_(\u00afY_i,q)\u2009 .\n\nWe want to bound\n \\(\\overline{\\hat{m}_{n},m}\\)\\(\\overline{\\hat{m}_{n},m}\\) depending on \\(n\\). One can employ quadruple inequalities such as (3) to obtain a suitable upper bound [Sch19, Theorem 1]. This approach is particularly useful, if we do not want to make the assumption that the diameter of the metric space\n \\(\\sup_{q,p\\in\\mathcal{Q}}\\overline{q,p}\\) is finite. With Theorem 1, one can obtain such a bound for \\(\\tau\\)echet means with \\(\\tau\\in\\mathcal{S}\\) (under some conditions). We emphasize that this is only possible with (3) and not with (8). Noteworthy examples of \\(\\tau\\in\\mathcal{S}\\)\\(\\tau_{\\mathsf{pH},\\delta}\\)in this context, aside from \\(\\tau=\\tau_{\\alpha}\\), are the Huber loss \\(\\tau_{\\mathsf{H},\\delta}\\) [Hub64] and the Pseudo-Huber loss \\(\\tau_{\\mathsf{pH},\\delta}\\)[Cha+94] for \\(\\delta\\in(0,\\infty)\\),\n \n\n_\u03c4__H,_\u03b4_(x) &:= {12 x^2 for x \u2264_\u03b4_\u2009 , _\u03b4_(x - 12 _\u03b4_) for x \u00bf _\u03b4_\u2009 , _\u03c4__pH,_\u03b4_(x) := _\u03b4_^2 ( 1 + x2_\u03b4_2 - 1 ) \u2009 ,\n\nas well as \\(x\\mapsto\\ln(\\cosh(x))\\)[Gre90]. These functions are of great interest in robust statistics and\n image processing as their respective minimizers combine properties of the classical mean ( \\(\\tau_{2}\\)echet mean) and the median ( \\(\\tau_{1}\\)echet mean). \n\n### Outline In the remaining sections, we first discuss the set \\(\\mathcal{T}\\) , i.e., the set of quadruple transformations, see section 2. We continue with a discussion of the set \\(\\mathcal{S}\\), i.e., nondecresing, convex functions with concave derivative, in section 3. Thereafter, we prove our main result, i.e., \\(\\mathcal{S}\\subseteq\\mathcal{T}\\)The\n  . The basic ideas of the proof and variations of the main result are presented in section 4. The technical details can be found in appendix B and C. The proof of Theorem 3 can be found in appendix A. In section 5 we discuss implications of the main results and open questions. \n\n## Quadruple Transformations We explore some properties of quadruple functions \\(\\tau\\in\\mathcal{T}\\) and their quadruple constant \\(L_{\\tau}^{*}\\). \n\n### Properties \n\n(i) For \\(c\\in\\mathbb{R}\\), let \\(\\tau_{c}:=(x\\mapsto c)\\). Then\n \\(\\tau_{c}\\in\\mathcal{T}\\) with \\(L_{\\tau}^{*}=0\\).\n ",
    "The above assumptions are fundamental to our approximate calculation, and a further mild technical assumption allows us to avoid tedious consideration of uninteresting cases: \n\n\n*  The time scales of relaxation of flagellar force and orientation are comparable: \n\n\\[\\gamma_{F}/\\gamma_{\\Theta}\\sim\\operatorname{ord}(1).\\] (25)  \n\nIndeed, we find this condition satisfied by the parameters we inferred from experimental observations in Table 1. \n\nUnder the assumptions described above, we obtain the following approximation for the translational diffusivity: \n\n\\[\\lim\\limits_{t\\rightarrow\\infty}\\frac{\\langle\\mathbf{X}^{(\\mathrm {c})}(t)\\odot\\mathbf{X}^{(\\mathrm{c})}(t)\\rangle}{2t} =D_{\\mathrm{t}}^{\\ast}\\mathit{\\mathsf{I}},\\] \\[D_{\\mathrm{t}}^{\\ast}\\] \u2261Dt+V\u221722\u2062Dr\u2217Dr\u2217+2\u03a9r\u22172+Dt~ (26)  \n\nwhere V\u22172is the mean-square velocity coarse-grained over the flagellar time scale (19), and \n\nDt~\u2261a\u2062\u03a9r\u22172\u03b3t2\u03b3r(\u03a9r\u2217+2Dr\u2217)2[2\u2062\u03c3F2\u03b3F\u2211j,j\u2032=1NFj(0)in\u0398j\u2032(0)cos(\u0398j(0)\u2212\u0398j\u2032(0)+2\u2062\u03c0N(j\u2212j\u2032+Sj\u2212Sj\u2032l)) +\u03c3\u03982\u03b3\u0398\u2211j,j\u2032=1NFj(0)Fj\u2032(0)(Fj\u2032(0)cos(\u0398j\u2032(0))\u2212Fj(0)cos(\u0398j(0)))in(\u0398j(0)\u2212\u0398j\u2032(0)+2\u2062\u03c0N(j\u2212j\u2032+Sj\u2212Sj\u2032l))]  Dt~\u2261a\u2062\u03a9r\u22172\u03b3t2\u03b3r(\u03a9r\u2217+2Dr\u2217)2[2\u2062\u03c3F2\u03b3F\u2211j,j\u2032=1NFj(0)in\u0398j\u2032(0)cos(\u0398j(0)\u2212\u0398j\u2032(0)+2\u2062\u03c0N(j\u2212j\u2032+Sj\u2212Sj\u2032l)) +\u03c3\u03982\u03b3\u0398\u2211j,j\u2032=1NFj(0)Fj\u2032(0)(Fj\u2032(0)cos(\u0398j\u2032(0))\u2212Fj(0)cos(\u0398j(0)))in(\u0398j(0)\u2212\u0398j\u2032(0)+2\u2062\u03c0N(j\u2212j\u2032+Sj\u2212Sj\u2032l))]  \n\nHere\n \\(\\Omega^{\\ast}_{\\mathrm{r}}\\)is the effective rotational drift coefficient and \\(D_{\\mathrm{r}}^{\\ast}\\)is the effective rotational diffusion coefficient given in (8) and (10) respectively. As shown in Subsection 4.2, the error in our calculation is essentially fourth order in the small parameters \\(\\sigma_{\\Theta}\\) and \\(\\sigma_{F}\\) . \n\nThe first two terms of the expression in Eq.  (26)  are exactly the translational diffusion for a colony with thermal diffusivity \\(D_{\\mathrm{t}}\\), moving at a constant speed \\(V^{\\ast}\\)along an orientation with constant rotational drift\n \\(\\Omega^{\\ast}_{\\mathrm{r}}\\)and constant rotational diffusion \\(D_{\\mathrm{r}}^{\\ast}\\). As we shall shortly explain, the complicated terms in \\(\\tilde{D_{\\mathrm{t}}}\\)\\(\\tilde{D_{\\mathrm{t}}}\\) are included for completeness and consistency with the results presented for general geometries in Subsection 5.2, but should typically be considerably smaller than the simpler terms presented in Eq.  (26)  for disclike geometries. \n\nDue to the nonpolynomial dependence of the translational diffusion on the effective rotational statistics, a rigorous computation of the demographic mean is complicated. We therefore content ourselves with an estimate for the demographic mean by averaging separately the numerator and denominator, neglecting demographic correlations between the colony speed and rotational characteristics, and dropping the small contribution from  \\(\\tilde{D_{\\mathrm{t}}}\\)\\(\\tilde{D_{\\mathrm{t}}}\\): \n\n\ud835\udd3c[Dt\u2217]\u2248\ud835\udd3c[V\u2217]2\ud835\udd3c\u2062[Dr\u2217]2\u2062(Var\u2062[Dr\u2217]+(\ud835\udd3c\u2062[Dr\u2217])2+Var\u2062[\u03a9r\u2217])+Dt. (27)  \n\nAll component demographic averages have been reported above, other than \ud835\udd3c[V\u2217]2which is clearly\n representable as a linear combination of \\(\\mathbb{E}[\\langle|\\mathbf{V}^{(\\mathrm{c})}|^{2}\\rangle]\\)and\n \\(\\mathbb{E}[(F_{j}^{(0)})^{2}]\\). We do not report a demographic\n standard deviation because it is cumbersome, and in any case is simply a compounding of the demographic fluctuations from the mean-square speed (21) and the the rate of velocity decorrelation induced by the effective rotational drift (9) and rotational diffusion (13) of the colony. ",
    "# QUENCHED DECAY OF CORRELATIONS FOR RANDOM CONTRACTING LORENZ MAPS ANDREW LARKIN AND MARKS RUZIBOEV \n\n##### Abstract.\nAbstract.  In this work we consider i.i.d. random perturbations of contracting Lorenz maps sufficiently close to a Rovella parameter. We prove that the quenched correlations of the random dynamical system decays exponentially. \n\n## 1.  Introduction The Lorenz system was introduced in [30] as a simplified model for atmospheric convection. Numerical simulations have shown that the Lorenz system admits a strange attractor, called the Lorenz attractor, which became one of the most iconic examples in the field. \n\nA rigorous mathematical approach was developed with the introduction of the so called geometric Lorenz flow by [1, 26], which mimicks simulation of the dynamics of the Lorenz flow, and which has a robust strange attractor under \\(C^{1}\\)perturbations. Later in [37, 38] it was shown that the actual Lorenz attractor is indeed a singular hyperbolic attractor, further showing that the geometric Lorenz attractor represents the Lorenz attractor well. Moreover, it admits the so called Sinai-Ruelle-Bowen (SRB) measure, which is ergodic [11]. Its statistical properties, such as mixing rates, limit theorems and their stability under various perturbations, were studied intensively (see for example, [31, 10, 9, 7, 14, 13, 24]). \n\nAnother class of systems with similar properties was introduced in [35] called the _contracting Lorenz flow_ . A fundamental difference between these is that the attractor of the system introduced by Rovella is not robust under perturbations, but still abundant in a measure theoretic sense. The set of measures for which the system is chaotic is called Rovella parameters and satisfies strong chaotic properties [8]; moreover, restricted to this set the system is stochastically stable [32, 33]. In [34] the authors addressed thermodynamic formalism for it. Up to now, the contracting Lorenz flow and one dimensional maps with critical points remain a profound example of a truly nonuniformly hyperbolic systems, which is studied via construction of induced schemes. We refer to [3] for a comprehensive account of these constructions. \n\nRecently, there has been increased interest in studying statistical properties of random dynamical systems, especially quenched (path-wise) properties. When the system has good uniformly hyperbolic properties, spectral techniques are still applicable and imply strong statistical properties; we refer to [19, 20, 21, 23, 22] and references therein for results on quenched decay of correlations, limit theorems and stability results in this case. \n\nFor the non-uniformly expanding (or non-uniformly hyperbolic) case, spectral techniques are not applicable directly. In this regards, it is customary to employ inducing techniques, in particular randomised version of Young Tower [39] construction called random Young towers. This was first carried out in [15] for random ",
    "though our model exhibits a larger variance in the estimated elasticity values compared to the BLP model. \n\nWe further estimate the average own-elasticity for high-priced, medium-priced, and lowpriced cars and construct a confidence interval for each category using our inference procedure. We present our result in Table  14 . \n\n## Conclusion Choice models are fundamental in understanding consumer behavior and informing business decisions. Over the years, various methods, both parametric and non-parametric, have been developed to represent consumer behavior. While parametric methods, such as logit or probit-based models, are favored for their simplicity and interpretability, their restrictive assumptions can limit their ability to fully capture consumer preferences\u2019 intricacies. On the other hand, non-parametric methods offer a more flexible approach, but they often suffer from the \u201ccurse of dimensionality\u201d, where the complexity of estimating choice functions escalates exponentially with an increase in the number of products. \n\nIn this paper, we propose a fundamental characterization of choice models that combines the tractability of traditional choice models and the flexibility of non-parametric estimators. This characterization specifically tackles the challenge of high dimensionality in choice systems and facilitates flexible estimation of choice functions. Through extensive simulations, we validate the efficacy of our model, demonstrating its superior ability to capture a range of consumer behaviors that traditional choice models fail to capture. We also show how to \n\n(a) Own-Elasticity Estimation (Our Model vs. BLP Model) \n\n(b) Cross-Elasticity Estimation (Our Model vs. BLP Model) \n\nFigure 4: Elasticity Estimation Comparison ",
    "## Data Availability The original data analysed in this work are part of the Guaranteed Time Observation (GTO) program 1282 (PI: Th. Henning) with number 66 and will become public on 2 August 2023 on the MAST database ( https://mast.stsci.edu ). The portion of the spectrum presented in Fig.  3  is available on Zenodo at  https://zenodo.org/record/7991022 . The spectroscopic data for water can be downloaded from the HITRAN database ( https://hitran.org ). The Spitzer-IRS spectrum plotted in Fig.  1  is part of the Spitzer-IRS GTO program 40679 (PI: G. Rieke). The spectrum was extracted and calibrated using private codes 56 , 64 and is available on Zenodo at  https://zenodo.org/record/7991022 . The optical constants of the dust species considered in the fitting procedure for the dust continuum can be downloaded from the HJPDOC database ( https://www2.mpia-hd.mpg.de/HJPDOC ). \n\n## Code Availability The slab model used in this work is a private code developed by B.T. and collaborators. It can be obtained from B.T. upon request. The synthetic spectra presented in this work can be reproduced using the slabspec code, which can be found at  https://doi.org/10.5281/zenodo.4037306 . The fitting procedure for the dust continuum uses the publicly available MultiNest Bayesian fitting algo rithm ( https://github.com/JohannesBuchner/MultiNest ) and the PyMultiNest package ( https://github.com/JohannesBuchner/PyMultiNest ). Figures were made with Mat plotlib version 3.5.1. under the Matplotlib license at  https://matplotlib.org/ . \n\n## Acknowledgements The MINDS team would like to thank the entire MIRI European and US instrument team. Support from STScI is also appreciated. The following National and International Funding Agencies funded and supported the MIRI development: NASA; ESA; Belgian Science Policy Office (BELSPO); Centre Nationale d\u2019Etudes Spatiales (CNES); Danish National Space Centre; Deutsches Zentrum fur L\u00fcft- und Raumfahrt (DLR); Enterprise Ireland; Ministerio De Economi\u00e1 y Competividad; Netherlands Research School for Astronomy (NOVA); Netherlands Organisation for Scientific Research (NWO); Science and Technology Facilities Council; Swiss Space Office; Swedish National Space Agency; and UK Space Agency. G.P. would like to thank B. Bitsch and E. Gaidos for fruitful discussions and P. Hausschildt for kindly providing the model atmosphere. V.C. and O.A. acknowledge funding from the Belgian F.R.S. FNRS. Th.H., R.F. and K.S. acknowledge support from the European Research Council under the Horizon 2020 Framework Program via the ERC Advanced Grant Origins 83 24 28. B.T. is a Laureate of the Paris Region fellowship program, which is supported by the Ile-de-France Region and has received funding under the Horizon 2020 innovation framework program and Marie Sklodowska-Curie grant agreement No. 945298. B.T. acknowledges support from the Programme National \u2018Physique et Chimie du Milieu Interstellaire\u2019 (PCMI) of CNRS/INSU with INC/INP cofunded by CNES. D.G. would like to thank the Research Foundation Flanders for co-financing the present research (grant number V435622N). D.G. and I.A. thank the European Space Agency (ESA) and the Belgian Federal Science Policy Office (BELSPO) for their support in the framework of the PRODEX Programme. I.K., A.M.A., and E.v.D. acknowledge support from grant TOP-1614.001.751 from the Dutch Research Council (NWO). I.K. and J.K. acknowledge funding from H2020-MSCA-ITN-2019, grant no. 860470 (CHAMELEON). E.F.v.D. acknowledges support from the ERC grant 101019751 MOLDISK and the Danish National Research Foundation through the Center of Excellence \u201cInterCat\u201d (DNRF150). T.P.R acknowledges support from ERC grant 743029 EASY. D.B. has been funded by Spanish MCIN/AEI/10.13039/501100011033 grants PID2019- ",
    "coupled WGM resonators to achieve multi-band UR of photons through modulation of the intermode backscatterings of resonators[ 41 ]. In the \n\ntem parameters, we demonstrate the simultaneous realization of UR and unidirectional transmissionlessness (UT). Moreover, the conversion between UR and UT can be achieved by adjusting the coupling strength between WGM resonators and optical fiber. Additionally, a one-to-one correspondence is established between the resonant frequencies of QDs energy levels and the positions of UR and UT peaks. \n\nreciprocal system that the equivalent transmission in both directions was exhibited. Obviously, these systems previously mentioned only investigated the transmission or reflection characteristics, without considering achieving complete nonreciprocity in both channels, whereas directional transport in both channels is vital to enhance the controllability of photons. \n\n## Model and calculations \n\nTo this end, we propose a non-reciprocal system consisting of two WGM resonators that are individually embedded with a Zeeman split quantum dot (QD)[ 42 \u2013 44 ] and indirectly coupled through an optical fiber. By optimizing some sys- \n\nThe schematic of system is shown in Fig. 1  (a) and energy levels of QD is shown in Fig. 1  (b). Assuming that the WGM resonators and QDs have the same loss rates \\(\\gamma\\), then the Hamiltonian of the system can be written as (assuming \\(\\hbar=1\\)\\(\\hbar=1\\)) \n\n\\[H=\\] \u222bdx{[\u2212ivgCR\u2020(x)\u2202\u2202xCR(x)+ivgCL\u2020(x)\u2202\u2202xCL(x)]  \n\n+\u2211j=1,2Gj\u03b4[x\u2212(j\u22121)d](CR\u2020Caj+CL\u2020Cbj+H.c.)}  \n\n+\u2211j=1,2{[gj(Caj\u03c3R\u2062j\u2020+Cbj\u03c3L\u2062j\u2020)+hjCaj\u2020Cbj+H.c.]  \n\n\\[+(\\omega_{0}-\\omega_{j}-i\\gamma)\\sigma^{{\\dagger}}_{Rj}\\sigma_{Rj }+(\\omega_{0}+\\omega_{j}-i\\gamma)\\sigma^{{\\dagger}}_{Lj}\\sigma_{Lj}\\]  \n\n+(\u03c9aj\u2212i\u03b3)Caj\u2020Caj+(\u03c9bj\u2212i\u03b3)Cbj\u2020Cbj}, (1)  \n\nwhere \\(C^{{\\dagger}}_{R}(x)\\leavevmode\\nobreak\\ (C_{R}(x))\\) and \\(C^{{\\dagger}}_{L}(x)\\leavevmode\\nobreak\\ (C_{L}(x))\\) are cre ation (annihilation) operators at \\(x\\) for forward strength between the \\(j\\)th WGM resonator and fiber ( \\(j\\)th QD), and \\(h_{j}\\)fiber (\n \\(j\\)th QD), and\n \\(h_{j}\\)fiber (jth QD), and hj is transition rate between bj and aj.\nWe set up \u03c9a1 = \u03c9a2 = \u03c9a,\n \\(b_{j}\\)and\n \\(a_{j}\\).\nWe set up\n \\(\\omega_{a1}=\\omega_{a2}=\\omega_{a}\\)\\(b_{j}\\) and \\(a_{j}\\). We set up \\(\\omega_{a1}=\\omega_{a2}=\\omega_{a}\\), and backward propagating photon along fiber, respectively. \\(C^{{\\dagger}}_{b_{j}}\\leavevmode\\nobreak\\ (C_{b_{j}})\\) and \\(C^{{\\dagger}}_{a_{j}}\\leavevmode\\nobreak\\ (C_{a_{j}})\\) are cre ation (annihilation) operators of CW mode \\(b_{j}\\) and \\(\\omega_{b1}=\\omega_{b2}=\\omega_{b}\\), \\(G_{1}=G_{2}=G\\), \\(g_{1}=g_{2}=g\\) and \\(h_{1}=h_{2}=h\\) for the sake of simplicity in the following discussions. CCW mode \\(a_{j}\\) with resonance frequencies \\(\\omega_{bj}\\)and \\(\\omega_{aj}\\), respectively. \\(\\sigma^{{\\dagger}}_{Lj}\\leavevmode\\nobreak\\ (\\sigma_{Lj})\\) and \\(\\sigma^{{\\dagger}}_{Rj}\\leavevmode\\nobreak\\ (\\sigma_{Rj})\\)\\(|g_{j}\\rangle\\leavevmode\\nobreak\\ (|e_{Lj}\\rangle)\\)to\n \\(|e_{Lj}\\rangle\\leavevmode\\nobreak\\ (|g_{j}\\rangle)\\)and\n \\(|g_{j}\\rangle\\leavevmode\\nobreak\\ (|e_{Lj}\\rangle)\\),\n  to \\(|e_{Lj}\\rangle\\leavevmode\\nobreak\\ (|g_{j}\\rangle)\\) and \\(|g_{j}\\rangle\\leavevmode\\nobreak\\ (|e_{Rj}\\rangle)\\)group\n  to \\(|e_{Rj}\\rangle\\leavevmode\\nobreak\\ (|g_{j}\\rangle)\\), respectively. \\(v_{g}\\) is group velocity of photon. \\(G_{j}\\leavevmode\\nobreak\\ (g_{j})\\) is coupling \n\nAssuming that photon with energy \\(E_{k}=\\omega=v_{g}k\\) is incident along the forward direction, where \\(\\omega\\) and \\(k\\) are frequency and wave vector of the incident photon, and state of system is (assume \\(\\omega_{a}=\\omega_{b}=\\omega\\) and system is originally prepared in ",
    "with a step size of 0.01. The final weights are used in our OWAF technique. Table 3 illustrates the effects of various fusion strategies. For fare comparison, we use both MRI and DTI data in all cases. The experimental results in the table 3 clearly reveal that the proposed OWAF outperforms other fusion strategies. \n\nAc, Pr, Re, M, F, A, AE, EL, - Indicates Accuracy, Precision, Recall, Male, Female, Average, Auto Encoder, Ensemble Learning & _ data_  not available respectively. All the values are in %. \n\n### Comparisons with State-of-the-art Approaches We compare our method with ten state-of-the-art approaches. There are no results available for a direct 3-class PD classification. So, we compare our results with those papers that have addressed the PD classification on the PPMI database using single or multiple modalities and with three or fewer two-class classifications. The results of comparisons are shown in Table 4. Out of the ten methods we have considered, five are based on machine learning (ML) and the rest five are based on deep learning (DL). Further, in four out of five DL based approaches, only a single modality, namely, MRI is used for classification. Also note that eight of these ten techniques have only addressed a single two-class classification problem between PD and HC and did not consider the challenging SWEDD class at all. The remaining two approaches did consider SWEDD as a third class but have divided the three-class classification problem into multiple binary classes [2,10]. However, Li at al. [10] did not report the classification results for PD vs. SWEDD in their paper. In order to have fair comparisons, we have also included three binary classifications as obtained from our method in this table. Our direct three-class classification accuracy turns out to be superior than two-class classification accuracy of at least eight out of 10 methods. It is also higher than two out of three binary classification accuracy of [2]. Note that in [2], the authors used a somewhat different experimental protocol by considering two publicly available databases of ADNI and PPMI. In our work, we explicitly consider data with both MRI and DTI for the same individual \n\nTable 4: Comparisons of the proposed method with State-of-the-art Approaches \n\n\\begin{tabular}{|c|c|c|c|c|c|c|c|c|}\n\\hline\n\\multirow{2}{*}{Approach} & \\multirow{2}{*}{ML/DL} & \\multirow{2}{*}{MODALITY} & \\multicolumn{3}{c|}{PD vs HC} & PD vs. SWEDD & HC vs. SWEDD & PD vs. HC vs SWEDD \\\\\n\\cline{4-9}\n & & & Ac & Pr & Re & Ac & Ac & Ac \\\\\n\\hline\nAdeli 2016 [] & ML & MRI & 81.9 & - & - & - & - & - \\\\\n\\hline\nCigdem 2018 [] & ML & MRI & 93.7 & - & 95 & - & - & - \\\\\n\\hline\nPrashanth 2018 [] & ML & SPECT & 95 & - & 96.7 & - & - & - \\\\\n\\hline\nSingh 2018 [] & ML & MRI & 95.37 & - & - & 96.04 & 93.03 & - \\\\\n\\hline\nGabriel 2021 [] & ML & MRI & \\begin{tabular}{c} 99.01(M) \\\\ 87.10(F) \\\\ 93.05 (A) \\\\ \\end{tabular} & \\begin{tabular}{c} 100(M) \\\\ 97.2(F) \\\\ - \\\\ \\end{tabular} & \\begin{tabular}{c} 99.3(M) \\\\ 100(F) \\\\ - \\\\ \\end{tabular} & - & - & - \\\\\n\\hline\nLi 2019 [] & DL (AE) & MRI + DTI & 85.24 & 95.8 & 68.1 & - & 89.67 & - \\\\\n\\hline\nTremblay 2020 [] & DL & MRI & 88.3 & 88.2 & 88.4 & - & - & - \\\\\n\\hline\nChakraborty 2020 [] & DL & MRI & 95.3 & 92.7 & 91.4 & - & - & - \\\\\n\\hline\nSivaranjini 2020 [] & DL & MRI & 88.9 & - & 89.3 & - & - & - \\\\\n\\hline\nRajanbabu 2022 [] & DL (EL) & MRI & 97.5 & 97.9 & 97.1 & - & - & - \\\\\n\\hline\nProposed method & DL & MRI + DTI & 97.8 & 97.2 & 97.6 & 94.5 & 95.7 & \\begin{tabular}{c} 95.53 \\\\ Pr: 93.64 \\\\ Re: 91.99 \\\\ \\end{tabular} \\\\ \\hline\n\\end{tabular}\n",
    "We then define the damped mode: \n\n(21.1) W~\u03b5:=\u2207(P\u2062(\u03f1~\u03b5))\u03f1~\u03b5+v~\u03b5+\u2207(\u2212\u0394)\u22121(\u03f1~\u03b5\u2212\u03f1\u00af).  (21.1) W~\u03b5:=\u2207(P\u2062(\u03f1~\u03b5))\u03f1~\u03b5+v~\u03b5+\u2207(\u2212\u0394)\u22121(\u03f1~\u03b5\u2212\u03f1\u00af).  \n\nAs the first equation of (1.3) can be rewritten as \u2202t\u03f1~\u03b5\u2212\u0394(P(\u03f1~\u03b5))\u2212div(\u03f1~\u03b5\u2207(\u2212\u0394)\u22121(\u03f1~\u03b5\u2212\u03f1\u00af))=div(\u03f1~\u03b5W~\u03b5),  we expect the limit density \\(N\\) to satisfy the following _ parabolic-elliptic Keller-Segel system_  : \n\n(24.3) \\[\\left\\{\\begin{array}[]{l}\\partial_{t}N-\\Delta\\left(P(N)\\right)= \\operatorname{div}\\left(N\\ \\nabla V\\right)\\\\ -\\Delta V=N-\\overline{\\varrho}\\end{array}\\right.\\]  \n\nsupplemented with the initial data \\(\\underset{\\varepsilon\\to 0}{\\lim}\\,\\tilde{\\varrho}_{0}^{\\varepsilon}\\). \n\nOur second aim is to justify the passage to the limit when \\(\\varepsilon\\to 0\\) of the Euler-Poisson system towards the parabolic-elliptic Keller-Segel system. \n\nRecall that (1.5) is a model for describing the evolution of density \\(N=N(t,x)\\in\\mathsf{R}_{+}\\).\n  of a biological population under the influence of a chemical agent with concentration \\(V=V(t,x)\\in\\mathsf{R}^{d}\\). Chemotaxis are an important means of cell communication. How cells are arranged and organized is determined by communication by chemical signals. Studying such a biological process is important because it has repercussions in many branches of medicine such as cancer [0], [0], embryonic development [0] or vascular networks [0], [0]. The previous system is famous in biology and comes from E.F Keller and L.A Segel in [0]. This basic model was used to describe the collective movement of bacteria possibly leading to cell aggregation by chemotactic effect. We refer to the articles [0] and [0] for more details and information about the different Keller-Segel models studied since the 1970s. \n\nOur aim here is to demonstrate that (1.5) may be obtained from the Euler-Poisson system with damping when the parameter \\(\\varepsilon\\) tends to \\(0.\\) This question has been addressed in [0] on the torus case and Sobolev spaces in a situation where the potential satisfies a less singular equation : the author justifies the passage to the limit for regular periodic solutions. A lot of articles justify another limit: the passage from the parabolic-parabolic Keller-Segel system to the parabolic-elliptic Keller-Segel system (see e.g. the paper [0] by P-G. Lemari\u00e9-Rieusset for the case of Morrey spaces). \n\nIn the same spirit as this article, T. Crin-Barat, Q. He and L. Shou in [0] justified the high relaxation asymptotics for the (less singular) parabolic-parabolic Keller-Segel system (the potential satisfies the equation \\(-\\Delta V+bV=aN\\) with \\(a,b>0\\)\\(-\\Delta V+bV=aN\\)with\n \\(a,b>0\\)\u2212\u2206V + bV = aN with a, b > 0) : this other system comes from the system (HPC) (hyperbolic-parabolicchemotaxis) which is a damped isentropic compressible Euler system with a potential satisfying an elliptical\n equation. In comparison with what is done here, T. Crin-Barat _ et al_  used a parabolic approach to justify their passage to the limit. Here, we have to handle the more singular case where the limit system is parabolicelliptic. \n\n## 2.  Main results and sketch of the proof In this section, we will first present and motivate the functional spaces used. Secondly we will state the results and the sketch of the proofs about the well-posedness behavior of Euler-Poisson system and the justification of the passage to the limit to parabolic-elliptic Keller-Segel system. 2.1.  Functional spaces. Before describing the main results of this article, we introduce the different notations and definitions used throughout this document. We will designate by \\(C>0\\) an independent constant of \\(\\varepsilon\\) and time, and \\(f\\lesssim g\\)will mean \\(f\\leq Cg\\). For any Banach space \\(X\\) and all functions \\(f,g\\in X\\), we denote \\(\\|(f,g)\\|_{X}\\mathrel{\\mathop{:}=}\\|f\\|_{X}+\\|g\\|_{X}\\)\\(t\\mapsto\\|f(t)\\|_{X}\\). We designate by \\(L^{2}(\\mathsf{R}_{+};X)\\) the set of measurable functions f:[0,+\u221e[\u2192X such that \\(t\\mapsto\\|f(t)\\|_{X}\\) belongs to \\(L^{2}(\\mathsf{R}_{+})\\) and write \u2225\u22c5\u2225L2\u2062(\ud835\uddb1+;X):=\u2225\u22c5\u2225L2\u2062(X)\n\nwill\n \n\n\n\n)\n(\n)\ndecomposition\n \n\n. \n\nIn this article we will use a decomposition in Fourier space, called the _ homogeneous Littlewood-Paley_ _decomposition_ . To this end, we introduce a regular non-negative function \\(\\varphi\\) on \\(\\mathsf{R}^{d}\\)with support in the ",
    "**4.5. Corollary.** _ Let_ \\(P\\)_ be a polyhedron of dimension_ \\(n\\)_ with abelian_ \\(\\pi_{1}(P)\\)_ and_ _finitely generated_ \\(H_{i}(\\tilde{P})\\)_, for_ \\(i\\geq 2\\)direct\n _. Then_ \\(D(P)\\leq\\sum_{i=1}^{n}n_{i}\\)in\n the\n _, where_ \\(n_{1}\\)_ and_ \\(n_{i}\\;(i\\geq 2)\\)and\n _ are the number of nonzero direct summands in the canonical form of_ \\(\\pi_{1}(P)\\)_ and_ \\(H_{i}(\\tilde{P})\\)_, respectively._ \n\n_the number of nonzero direct summands in the canonical form of_ \\(H_{i}(\\tilde{P})\\)_._ **4.6. Corollary.** _ Let_ \\(P\\)_ be a polyhedron of dimension_ \\(n\\)_ with free_ \\(\\pi_{1}(P)\\)_ and finitely_ _generated_ \\(H_{i}(\\tilde{P})\\)_, for_ \\(i\\geq 2\\)_. Then_ \\(D(P)\\leq rank(\\pi_{1}(P))+\\sum_{i=2}^{n}n_{i}\\)  _, where_ \\(n_{i}\\)_ is_ \n\n**4.7. Corollary.** _ Let_ \\(P\\)_ be a polyhedron of dimension_ \\(n\\)_ with elementary amenable_ \\(\\pi_{1}(P)\\)_ of finite cohomological dimension and finitely generated_ \\(H_{i}(\\tilde{P})\\)_, for_ \\(i\\geq 2\\)\\(\\pi_{1}(P)\\)_._ _and_ \\(n_{i}\\)_ is the number of nonzero direct summands in the canonical form of_ \\(H_{i}(\\tilde{P})\\)_._ _Then_ \\(D(P)\\leq h(\\pi_{1}(P))+\\sum_{i=2}^{n}n_{i}\\)nonzero\n _, where_ \\(h(\\pi_{1}(P))\\)_ is the Hirsch length of_ \\(\\pi_{1}(P)\\)\n\nRecently, in [14], Ko  lodziejczyk proved that 2-dimensional polyhedra whose fundamental groups are elementary amenable with finite cohomological dimension have finite depth. In the sequel, we are going to present upper bounds for such polyhedra. \n\nRecall that if \\(P\\) is a polyhedron of dimension \\(n\\), then \\(H_{n}(P)\\)is free abelian (see,\n for example, [18, Theorem 7.24]). Now we state our second main result. \n\n_._ \n\n_Proof._  Consider the following chain of CW-complexes: \n\n4.8.\n \n\n_ If_ \\(P\\)_ is a 2-dimensional polyhedron and_ \\(sl(\\pi_{1}(P))<\\infty\\)_, then_ \\(D(P)\\leq sl\\big{(}\\pi_{1}(P)\\big{)}+rank\\big{(}H_{2}(P)\\big{)}\\)\n\n\n\nthe\n \n\na\n \n\n\\[\\cdots<X_{i+1}<X_{i}<\\cdots<X_{3}<X_{2}<X_{1}<X_{0}=P.\\]  Let \\(d_{X_{i+1}}:X_{i}\\to X_{i+1}\\)converse\n  and \\(u_{X_{i+1}}:X_{i+1}\\to X_{i}\\) be the domination of \\(X_{i}\\) over \\(X_{i+1}\\) and the converse map, i.e., \\(d_{X_{i+1}}u_{X_{i+1}}\\simeq id_{X_{i+1}}\\). Then \\(\\pi_{1}(d_{X_{i+1}})\\pi_{1}(u_{X_{i+1}})=id_{\\pi_{1}(X_{i+1})}\\) and \\(H_{2}(d_{X_{i+1}})H_{2}(u_{X_{i+1}})=id_{H_{2}(X_{i+1})}\\). As a result,\n \\({\\rm im}\\pi_{1}(u_{X_{i+1}})\\)and\n \\({\\rm im}H_{2}(u_{X_{i+1}})\\)are retracts of\n \\(\\pi_{1}(X_{i})\\)and\n \\(H_{2}(X_{i})\\).\n \n\nAssume that\n \\({\\rm im}\\big{(}\\pi_{1}(u_{X_{i+1}})\\big{)}=\\pi_{1}(X_{i})\\)and\n \\({\\rm im}\\big{(}H_{2}(u_{X_{i+1}})\\big{)}=H_{2}(X_{i})\\). Then\n \\(\\pi_{1}(u_{X_{i+1}})\\)and\n \\(H_{2}(u_{X_{i+1}})\\)are isomorphisms. Accordingly,\n \\(\\pi_{1}(d_{X_{i+1}})\\)and\n \\(H_{2}(u_{X_{i+1}})\\)are isomorphisms. Accordingly,\n \\(\\pi_{1}(d_{X_{i+1}})\\)\u03c01(uXi+1) and H2(uXi+1) are isomorphisms. Accordingly, \u03c01(dXi+1) is an isomorphism and H2(Xi) \u223c\n= H2(Xi+1). since \u03c01(Xi) \u223c\n= \u03c01(Xi+1), we have H1(Xi) \u223c\n=\n \\(H_{2}(X_{i})\\cong H_{2}(X_{i+1})\\). since\n \\(\\pi_{1}(X_{i})\\cong\\pi_{1}(X_{i+1})\\), we have\n \\(H_{1}(X_{i})\\cong H_{1}(X_{i+1})\\)\\(H_{2}(X_{i})\\cong H_{2}(X_{i+1})\\). since\n \\(\\pi_{1}(X_{i})\\cong\\pi_{1}(X_{i+1})\\), we have\n \\(H_{1}(X_{i})\\cong H_{1}(X_{i+1})\\)_ _ by the Hurewicz Theorem (see\n ).\n This fact and is a proper retract of \\(H_{2}(X_{i})\\).\n \\(H_{2}(X_{i})\\cong H_{2}(X_{i+1})\\)imply that\n \\(\\chi(X_{i})=\\chi(X_{i+1})\\), where\n \\(\\chi(X)\\)imply that\n \\(\\chi(X_{i})=\\chi(X_{i+1})\\), where\n \\(\\chi(X)\\)H2(Xi) \u223c\n= H2(Xi+1) imply that \u03c7(Xi) = \u03c7(Xi+1), where \u03c7(X) denotes the EulerPoincare characteristic of polyhedron X of dimension m.\nNow since dXi+1 :\n \\(X\\)of dimension\n \\(m\\).\nNow since\n \\(d_{X_{i+1}}:X_{i}\\to X_{i+1}\\)\\(X\\) of dimension \\(m\\). Now since \\(d_{X_{i+1}}:X_{i}\\to X_{i+1}\\) is a homotopy domination between \\(X_{i}\\) and \\(X_{i+1}\\) that induces an isomorphism on the fundamental groups, it is a homotopy equivalence (by [14, Theorems 2]) which contradicts \\(X_{i+1}<X_{i}\\). Therefore, either\n \\({\\rm im}\\big{(}\\pi_{1}(u_{X_{i+1}})\\big{)}\\).\n is a proper retract of \\(\\pi_{1}(X_{i})\\)or\n \\({\\rm im}\\big{(}H_{2}(u_{X_{i+1}})\\big{)}\\), So by Lemma 3.3, \\(sl\\Big{(}{\\rm im}\\big{(}\\pi_{1}(u_{X_{i+1}})\\big{)}\\Big{)}<sl\\big{(}\\pi_{1}(X_ {i})\\big{)}\\)\\(\\pi_{1}(X_{i+1})\\cong{\\rm im}\\big{(}\\pi_{1}(u_{X_{i+1}})\\big{)}\\)or \\(rank\\Big{(}{\\rm im}\\big{(}H_{2}(u_{X_{i+1}})\\big{)}\\Big{)}<rank\\big{(}H_{2}(X_ {i})\\big{)}\\)have\n . Since \\(\\pi_{1}(X_{i+1})\\cong{\\rm im}\\big{(}\\pi_{1}(u_{X_{i+1}})\\big{)}\\)and \\(H_{2}(X_{i+1})\\cong{\\rm im}\\big{(}H_{2}(u_{X_{i+1}})\\big{)}\\), we have \\(sl(\\pi_{1}(X_{i_{0}}))=0\\)we have by Lemma 3.4 that \\(sl\\big{(}\\pi_{1}(X_{i+1})\\big{)}<sl\\big{(}\\pi_{1}(X_{i})\\big{)}\\)or \\(rank\\big{(}H_{2}(X_{i+1})\\big{)}<rank\\big{(}H_{2}(X_{i})\\big{)}\\)\\(sl(\\pi_{1}(X_{i_{0}}))=0\\). Thus for \\(i_{0}:=sl\\big{(}\\pi_{1}(P)\\big{)}+rank\\big{(}H_{2}(P)\\big{)}\\)Lemma\n and \\(rank(H_{2}(X_{i_{0}}))=0\\)which means by Lemma\n that\n \\(\\pi_{1}(X_{i_{0}})=1\\)and\n \\(H_{2}(X_{i_{0}})=0\\), Hence,\n \\(X_{i_{0}}\\) is homotopically trivial and so the proof is finished. ",
    "We use Fenichel\u2019s reduction to regularize the singular perturbation in existence and eigenvalue problem in Section 2. In Section 4, we study the resulting regularized traveling wave problem using functional-analytic methods, using methods developed in [2, 4, 3] to find pulled and pushed front profiles as well as the transition curve. Section 5 establishes marginal spectral stability of these fronts thus justifying the pushed and pulled terminology. In Section 6, we briefly compare the expansions obtained in Theorem 1.2 to those obtained using numerical continuation. The appendix contains the construction and properties of traveling fronts at \\(\\delta=0\\).\n \n\n# Regularization via geometric singular perturbation theory \n\n## Reduction of existence problem We express (1.5) as a dynamical system in the variable \\(x\\) by choosing coordinates \\(U,W=U^{\\prime},H=\\frac{V-U}{\\delta^{2}},Z=\\delta H^{\\prime}\\), obtaining \n\n\\[U^{\\prime} =W\\] \\[W^{\\prime} =-\\frac{1}{d_{1}}\\Gamma(U,W,H,Z)\\] \\[\\delta H^{\\prime} =Z\\] \\[\\delta Z^{\\prime} =H+\\frac{1}{d_{1}}\\Gamma(U,W,H,Z),\\  \n\nwhere \n\n\\[\\Gamma(U,W,H,Z)=cW+W^{2}+\\delta WZ+UH+U(1-U).\\  \n\nWhen \\(\\delta=0\\)the system (2.1) reduces to two algebraic equations coupled to two differential\n equations. One identifies the following reduced slow manifold comprised of solutions of the algebraic of equations in the singular limit \\(\\delta=0\\),\n \n\n\\[\\mathcal{M}_{0}=\\left\\{\\left(U,W,H,Z\\right)\\ |\\ Z=0,\\ H=-\\frac{cW +W^{2}+U-U^{2}}{d_{1}+U}\\right\\}.\\  \n\nThe linearization of (2.1) at any such fixed point has two zero eigenvalues and two hyperbolic for \\(U\\geq 0\\). The eigenspaces of the non-zero eigenvalues are traverse to\n \\(\\mathcal{M}_{0}\\)and therefore the reduced manifold is normally hyperbolic. Fenichel\u2019s Persistence Theorem [5] eigenvalues \\(\\pm\\sqrt{1+\\frac{U}{d_{1}}}\\)implies that \\(\\mathcal{M}_{0}\\) persists as an invariant manifold \\(\\mathcal{M}_{\\delta}\\) with the following properties. \n\nProposition\n _ Fix_ \\(0<\\underline{d}<\\overline{d}\\)_,_ \\(M>1\\)_, and an integer_ \\(k\\geq 2\\)_. There exists a_ \\(\\overline{\\delta}>0\\)_ such that all trajectories of_ _ with_ \\(|\\delta|<\\overline{\\delta}\\)_,_ \\(\\underline{d}<d_{1}<\\overline{d}\\)_ satisfying_ \\(-\\frac{d_{1}}{2}<U<M\\)_ and_ \\(|W|\\leq M\\)_ lie in a slow manifold_ \\(\\mathcal{M}_{\\delta}\\)_, which is normally hyperbolic and invariant_ _under the flow of_  (2.1) _, and may be written as a graph_ \\(\\mathcal{M}_{\\delta}=\\{(U,W,H,Z):H=\\psi_{H}(U,W;\\delta),Z=\\psi_{Z}(U,W;\\delta)\\}\\)_, where_ \n\n\\[H =\\psi_{H}(U,W;\\delta)=\\psi_{H}^{0}(U,W)+\\delta\\psi_{H}^{1}(U,W)+ \\delta^{2}\\psi_{H}^{2}(U,W)+\\mathrm{O}(\\delta^{4}),\\] \\[Z =\\psi_{Z}(U,W;\\delta)=\\delta\\psi_{Z}^{1}(U,W)+\\mathrm{O}(\\delta^{ 2}),\\  ",
    "the input data dimension. Figure 4a shows the memory size (in MB) of the 4 shallow classifiers considered in our experiments, based on the input size in terms of the percentage of PCA explained variance. As expected, the size of most of the classifiers increases according to the input dimension, except for Random Forest (RF), whose size remains nearly constant at around 1 MB (between 0.98 and 1.11). Logistic Regression (LR), the simplest classifier, is also the one with the lowest memory footprint in all the experiments, starting from less than 1 KB (i.e., 922 Bytes), up to 3.64 KB with 99% of PCA explained variance. On the other hand, AdaBoost (AB) results to be the most demanding model in terms of memory, with an overall size that ranges from just 5.74 MB with 60% of PCA, up to 185.05 MB with the full dimension of the input. Finally, SVM has an intermediate memory footprint among the other classifiers, ranging from 42.6 KB up to 1.88 MB. \n\nOn the other hand, when the deep audio models are fine-tuned, the size of the additional fully-connected layers should be considered to estimate the overall memory footprint. Figure 4b shows the average size of the fine-tuned models, highlighting both the size of the original pre-trained models, and the size of the additional layers for classification. We can note that, in general, \n\n(b) Fine-tuned models \n\n(a) Shallow classifiers \n\nFigure 4: Memory footprint of (a) the considered shallow classifiers based on different input sizes (i.e., percentage of PCA explained variance), and (b) the fine-tuned deep learning models. Please, consider that in (a) the overall memory footprint is given by taking into account also the size of the deep embedding models to extract the input features from the raw audio sample. ",
    "be e ff ective for support vector machines (SVM) [ 79 ] and large language models [ 25 ]. Another line of work called transductive learning uses test data to add constraints to the margin of SVMs [ 31 ,  11 ,  66 ]. The principle of transduction, as stated by Vapnik, also emphasizes locality [ 18 ,  67 ]: \"Try to get the answer that you really need but not a more general one.\" \n\nIn computer vision, the idea of training at test time has been well explored for specific applica tions [ 30 ,  57 ,  46 ,  73 ], especially depth estimation [ 62 ,  63 ,  82 ,  84 ,  43 ]. Our paper extends TTT-MAE [ 19 ], detailed in Section  3 . TTT-MAE, in turn, is inspired by the work Sun et al. [ 61 ], which proposed the general framework for test-time training with self-supervision, regardless of application. The particular self-supervised task used in [ 61 ] is rotation prediction [ 21 ]. Many other papers have followed this framework since then [ 24 ,  60 ,  40 ,  77 ], including [ 69 ] on videos discussed in Section  1 , and [ 5 ] which we discuss next. \n\nIn [ 5 ], each video is treated as a dataset of unordered frames instead of a stream. In particular, there is no concept of past vs. future frames. The same model is used on the entire video. In contrast, our paper emphasizes locality. We have access to only the current and past frames, and our model keeps learning over time. In addition, all of our results are on real world videos, while [ 5 ] experiment on videos with artificial corruptions. These corruptions are also i.i.d. across frames. \n\nOur paper is very much inspired by [ 45 ]. To make video segmentation more e ffi cient, [ 45 ] makes predictions frame-by-frame using a small student model. If the student is not confident, it queries an expensive teacher model, and then trains the student to fit the prediction from the teacher online. Thanks to temporal smoothness, the student can generalize confidently across many frames without querying the teacher, so learning and predicting combined is still faster than naively using the teacher at every frame. Our method only consists of one model, which learns from a self-supervised task instead of a teacher model. Rather than focusing on computational e ffi ciency as in [ 45 ], the main goal of our paper is to improve inference quality. Behind their particular algorithm, however, we see the shared idea of locality, regardless of the form of supervision. \n\n## Background: TTT-MAE Our paper extends the work of _ Test-Time Training with Masked Autoencoders_  (TTT-MAE) [ 19 ], and uses TTT-MAE as the inner loop when updating the model for each frame. This section briefly describes TTT-MAE, as background for our extension. Figure  3  illustrates the process of TTT-MAE. \n\nThe architecture for TTT with self-supervision [ 61 ] is Y-shaped with a stem and two heads: a prediction head \\(g\\) for the self-supervised task, a prediction head \\(h\\) for the main task, and a feature extractor \\(f\\) as the stem. The output features of \\(f\\) are shared between \\(g\\) and \\(h\\) as input. For TTT-MAE, the self-supervised task is masked image reconstruction [ 27 ]. Following standard terminology for autoencoders, \\(f\\) is also called the encoder, and \\(g\\) the decoder. \n\nEach input image \\(x\\) is first split into many non-overlapping patches. To produce the autoencoder input \\(\\tilde{x}\\)\\(\\tilde{x}\\), we mask out majority, e.g. 80%, of the patches in \\(x\\) at random. The self-supervised objective \\(\\ell_{s}(g\\circ f(\\tilde{x}),x)\\)computes\n compares the reconstructed patches from\n \\(g\\circ f(\\tilde{x})\\)to the masked patches in\n \\(x\\), and computes the pixel-wise mean squared error. For the main task, e.g. segmentation, all patches in the original \\(x\\) are given as input to \\(h\\circ f\\) , during both training and testing. \n\n### Training-Time Training There are three widely accepted ways to optimize the model components ( \\(f\\) , \\(g\\), \\(h\\)) at training time: joint training, probing, and fine-tuning. Fine-tuning is unsuitable for TTT, because it makes \\(h\\) rely too much on features that are used by the main task. Our paper uses joint training, described in Section  4 . In contrast, [ 19 ] uses probing, which we describe next for completeness. \n\nTo prepare for probing, the common practice is to first train \\(f\\) and \\(g\\) with \\(\\ell_{s}\\) on the training set without ground truth. This preparation stage is also called self-supervised pre-training. TTT- ",
    "the temperature feature to evaluate its impact on the clustering algorithm\u2019s efficiency in identifying locations of interest. _3.3.1_ Obtaining Historical Temperature Data\n .\n  However, such tem perature analysis is only feasible when temperature data is avail able. Certain studies concerning elephant movement (Tsalyuk et al. [ 23 ]; Wall et al. [ 24 ]) lack a temperature feature. Therefore, we explored methods to approximate temperature data from other data sources. Using the meteostat python package and API, we identified weather stations proximate to the study site. The historical data was queried and appended to the study data, enabling calculation of Temperature-influenced centroids that would have been impossible to calculate otherwise. \n\nThe procedure entailed three key steps: (1) Identifying a nearby weather station, (2) Matching timestamps with the queried data, and (3) Evaluating the capability of the appended historical temperature data in calculating temperature-influenced centroids. \n\nFor the first step, the median latitude and longitude of the given \n\nelephant\u2019s movement data was computed, which was then used to query a nearby station. The second step involved normalizing and interpolating the time series data from the station, provided by meteostat, to ensure a higher temporal granularity that matches the given data. In the third step, the correlation between the historical station data and Kruger temperature data was evaluated using the coefficient of determination, R-squared. \n\nbalance between data retention and accuracy should be maintained while deciding the value of \\(\\delta\\). \n\nOur results indicate a moderate correlation between the study \n\nThe integration of weather station temperature data with animal \n\ndata and the station data. This correlation, combined with the per formance of the Temperature-influenced centroids with the weather data, gives us confidence to extend this technique to datasets that lack temperature data. Based on our experiment with elephant AM306 (See Figure 1) from the Kruger dataset, we found that the Temperature-influenced feature space aided in revealing more nu anced locations of interest within the larger clusters identified by the Without Temperature influence feature space. _3.3.2_ Fuzzy Timestamp Matching\n .\n  Fuzzy timestamp matching is an \n\nmovement datasets presented a significant challenge due to the relatively low percentage of matching timestamps. For instance, in the case of AM189 from Etosha, a mere 19.662% of timestamps corresponded. This limited overlap signifies a considerable loss of data, which undermines the analysis. To address this issue, we utilized \"fuzzy\" timestamp matching. This method extends the cri teria of a match beyond exact timestamp equality, incorporating a pre-defined threshold for the discrepancy between two timestamps that still qualifies them as a match. The mathematical formulation \n\nof this concept is as follows: Given two timestamps t1 and t2, and \n\nadvanced data processing technique that matches timestamps not based on exact equality but within a certain tolerance level. This tolerance level, or fuzzy threshold, is usually calculated by taking half of the median of the difference of timestamps in the dataset. The mathematical representation of the fuzzy timestamp matching process could be described as follows: Given two timestamps, \\(t1\\)and\n \\(t2\\), and a tolerance level\n \\(\\delta\\), the times tamps \\(t1\\)and\n \\(t2\\)are said to match if:\n \n\n(2) \\[|t1-t2|\\leqslant\\delta\\]  \n\nwhere \\(|t1-t2|\\)\\(t1\\) denotes the absolute difference between the times tamps \\(t1\\)and\n \\(t2\\). In this case,\n \\(\\delta\\)is calculated as: \n\n(3) \\[\\delta=0.5*median(|t[i+1]-t[i]|),\\forall i\\;1\\;to\\;N-1\\]  \n\nwhere N is the total number of timestamps, and t[i] represents \n\na tolerance level (or fuzzy threshold) \\(\\delta\\), the timestamps t1 and t2 are said to match if the absolute difference between them, denoted as |t1 - t2|, does not exceed \\(\\delta\\). The fuzzy threshold \\(\\delta\\)is calculated as half the median of the differences between all sequential pairs of timestamps in the dataset. \n\nBy employing fuzzy timestamp matching, the percentage of \n\nthe ith timestamp in the ordered sequence. This fuzzy matching approach increases the likelihood of matches and can help to mit igate data loss when aligning data from different sources or with different temporal resolutions. However, it is important to note that this technique may also introduce some uncertainty into the analysis due to the mismatched timestamps. Hence, an appropriate \n\nmatched data can be substantially increased. For example, in the case of AG191 from Etosha, conventional timestamp matching re sulted in a match percentage of 41.85%. With the application of fuzzy matching, this percentage rose to 74.50%. Notably, these ad \n\nditional matches, achieved through fuzzy matching, are proximal \n\n**Figure 1: Comparing feature spaces with and without tem** **perature on elephant AM306 from the Kruger dataset. Black** **Xs represent centroids calculated with temperature included** **in the feature space. Large colored dots represent centroids** **of clusters calculated solely on location data. Parameters:** **Without temp-influenced epsilon=0.1, minPts=35. Temp** **influenced epsilon=0.2, minPts=50** \n\n\\begin{tabular}{l r}\n\\hline \\hline\n**Metric** & **Value** \\\\\n\\hline\nR-squared (zero-centered) & 0.6871044690549571 \\\\\nOffset (study \u2013 station) & 9.840106696689293 \\\\\n\\% of timestamps found & 61.6\\% \\\\ \\hline \\hline\n\\end{tabular}\n\n\n**Table 1: Statistics for Figure 2** ",
    "marking a quantity evaluated at the stationary expansion point $({U ^ \\circ}, {\\vec{r} ^ \\circledast})$ as ${X ^ \\circledast}$. We will use this notation throughout this work. **c** Equation 7 yields an alternative formulation of Equation 4 using the exchanged second mixed derivative (Eq. 1). \n\n**Grand canonical energy of a stationary point** We can now insert the just derived potential- dependent geometric shift of a stationary point ${\\vec{\\Delta r} ^ {\\ast}}(\\Delta U)$${\\vec{\\Delta r} ^ {\\ast}}(\\Delta U)$${\\vec{\\Delta r} ^ {\\ast}}(\\Delta U)$) into the second-order expansion of\n the gcPES (Eq. 6) around a known stationary point $({U ^ \\circ}, {\\vec{r} ^ \\circledast})$, eliminating the spatial dependence and returning the potential-dependent grand canonical energy $ {\\mathcal{E} ^ {\\ast}}(U)$ of a stationary point accurate to second order: \n\n\\begin{align}         {\\mathcal{E} ^ {\\ast}}(U) = &\\mathcal{E}({U ^ \\circ} + \\Delta U, {\\vec{r} ^ \\circledast} + {\\vec{\\Delta r} ^ {\\ast}}(\\Delta U)) \\nonumber\\\\         = &{\\mathcal{E}({U ^ \\circ},{\\vec{r} ^ \\circledast} )}         - {q ^ \\circledast} \\Delta U \\nonumber\\\\         + &\\tfrac{1}{2} \\Biggl ( \\sum_{i,j,k,l} \\mathopen{}\\mathclose\\bgroup\\originalleft({\\mathcal{H}_{j,k} ^ \\circledast}^{-1} {\\mathopen{}\\mathclose\\bgroup\\originalleft(\\tfrac{\\partial q}{\\partial r_k}\\aftergroup\\egroup\\originalright) ^ \\circledast} \\Delta U\\aftergroup\\egroup\\originalright)         {\\mathcal{H}_{i,j} ^ \\circledast}         \\mathopen{}\\mathclose\\bgroup\\originalleft({\\mathcal{H}_{i,l} ^ \\circledast}^{-1} {\\mathopen{}\\mathclose\\bgroup\\originalleft(\\tfrac{\\partial q}{\\partial r_l}\\aftergroup\\egroup\\originalright) ^ \\circledast} \\Delta U \\aftergroup\\egroup\\originalright)\\nonumber \\\\         - &2 \\sum_{i,j} {\\mathopen{}\\mathclose\\bgroup\\originalleft(\\tfrac{\\partial q}{\\partial r_i}\\aftergroup\\egroup\\originalright) ^ \\circledast}          \\mathopen{}\\mathclose\\bgroup\\originalleft({\\mathcal{H}_{i,j} ^ \\circledast}^{-1} {\\mathopen{}\\mathclose\\bgroup\\originalleft(\\tfrac{\\partial q}{\\partial r_j}\\aftergroup\\egroup\\originalright) ^ \\circledast} \\Delta U\\aftergroup\\egroup\\originalright) \\Delta U          - {C_{\\rm el} ^ \\circledast} \\,  \\Delta U^2 \\Biggr) + \\mathcal{O}(\\Delta U^3) \\quad ,\\nonumber     \\end{align}\n\nwhere we dropped the force-contribution, since ${\\mathcal{F}_{i} ^ \\circledast} = 0$. Rearranging and using $\\sum_i {\\mathcal{H}_{k,i} ^ \\circledast}^{-1}{\\mathcal{H}_{i,j} ^ \\circledast} = \\delta_{k,j}$ then yields the energy ${\\mathcal{E} ^ {\\ast}}$of the stationary point at potential $U = {U ^ \\circ} + \\Delta U$: \n\n\\begin{align}         {\\mathcal{E} ^ {\\ast}}(U)          = &{\\mathcal{E} ^ \\circledast}         - {q ^ \\circledast} \\Delta U          - \\tfrac{1}{2} \\underbrace{\\mathopen{}\\mathclose\\bgroup\\originalleft({C_{\\rm el} ^ \\circledast} + \\overbrace{\\sum_{i,j}  {\\mathcal{H}_{i,j} ^ \\circledast}^{-1} {\\mathopen{}\\mathclose\\bgroup\\originalleft(\\tfrac{\\partial q}{\\partial r_i}\\aftergroup\\egroup\\originalright) ^ \\circledast}                  {\\mathopen{}\\mathclose\\bgroup\\originalleft(\\tfrac{\\partial q}{\\partial r_j}\\aftergroup\\egroup\\originalright) ^ \\circledast}}^{{C_{\\rm geom} ^ \\circledast}}\\aftergroup\\egroup\\originalright)}_{{C_{\\rm total} ^ \\circledast}} \\Delta U^2 + \\mathcal{O}(\\Delta U^3)\\quad .         \\label{eq:2ndO_TE_gc_x}     \\end{align}\n\nThis expression is essentially the (double-)integrated form of Equation 5. We could equally obtain it by integrating Equation 5 twice from the potential ${U ^ \\circ}$where all required properties are known **c** As a further clarification on the difference between ${X ^ {\\ast}}$and ${X ^ \\circledast}$: ${X ^ {\\ast}}(U)$ essentially is a shortcut for writing $X(U, {\\vec{r} ^ {\\ast}}(U))$, i.e. for denoting quantities evaluated at the stationary point at the desired potential. The additional circle in ${X ^ \\circledast}$indicates a property evaluated at a stationary expansion point. Essentially, we derive quantities ${Y ^ {\\ast}}$at a desired potential $U$ based on quantities ${X ^ \\circledast}$evaluated at a stationary expansion point $({U ^ \\circ}, {\\vec{r} ^ {\\ast}}({U ^ \\circ}))$, i.e. at a different potential ${U ^ \\circ}$. ",
    "and scales like \\(m_{\\nu}^{4}\\)such that the dynamical friction effect is dominated by the most massive neutrino eigenstate. We may then assume a single neutrino species for simplicity, or explicitly write the total dynamical friction force as a sum of individual contribution from different eigenstates. \n\nIn order to connect Eq. ( 3.19 ) with the results of future sections, it is convenient to rewrite it in terms of a quantity with dimension of inverse time. Since \\(F=Mdv_{\\textrm{H}}/dt\\), we can define: \n\n\\[\\tau^{-1}=-\\frac{\\vec{F}\\cdot\\vec{v}_{\\textrm{H}}}{Mv_{\\textrm{H}}^{2}}=\\frac{ 2}{3\\pi}\\log\\Lambda G^{2}Mm_{\\nu}^{4}=3.4\\times 10^{-5}\\frac{\\log\\Lambda}{\\log 1 00}\\frac{M}{10^{13}M_{\\bigodot}}\\left(\\frac{m_{\\nu}}{0.1\\textrm{eV}}\\right)^{4 }H_{0}\\,,\\] (27)  \n\nwhich is the characteristic time scale for an order one fractional decrease in the halo velocity due to the dynamical friction effect. Note that\n \\(1/\\tau H_{0}=\\Delta v/v\\) is the overall relative decrease in the halo velocity over the age of the Universe \\(t\\sim 1/H_{0}\\). We obtain a numerical value of\n \\(\\Delta v/v=3.4\\times 10^{-5}\\)for a halo mass \\(M=10^{13}M_{\\bigodot}\\)and individual neutrino mass \\(m_{\\nu}=0.1\\)eV, when also assuming\n \\(\\Lambda=100\\).\n This already suggests that the dynamical friction effect is quite small, although it can pick up some significant contributions from the clustering of nearby halos as we will see in Sec.  5 . \n\n### Limitations to the 1-halo approach \n\nThus far we have determined the anisotropic clustering of massive neutrinos behind moving point mass halos and the corresponding dynamical friction force. A more realistic calculation would have to account for both the finite extent of the halo and the presence of large-scale structure. Indeed, the Eq. ( 3.20 \\(\\log\\Lambda\\), where in typical applications of the\n \\(\\Lambda\\)can be estimated as the ratio of maximum and minimum\n impact parameters,\n \\(\\Lambda\\sim b_{\\textrm{max}}/b_{\\textrm{min}}\\). Here\n \\(b_{\\textrm{min}}\\sim R_{\\rm halo}\\) is the halo radius, and \\(b_{\\textrm{max}}\\sim\\lambda_{\\textrm{coh}}\\sim 0.1\\)sufficiently\n Mpc _-1_is the CDM velocity coherence scale. The CDM bulk flow is only coherent over sufficiently small scales and hence our analysis based on a single moving halo is expected to break down at scales \\(\\lambda\\gtrsim\\lambda_{\\textrm{coh}}\\). 3 This point will be made more clear in the next section, where we also provide a precise definition for the velocity coherence scale. 3 We should also impose a cutoff corresponding to the distance traveled by free-streaming neutrinos, which sets the scale where neutrino inhomogeneities are coherent with CDM. As we shall see the neutrino free-streaming scale \n\n**Figure 2** . Suppression of Chandrasekhar\u2019s formula for the dynamical friction force \\(F/F_{\\Lambda\\to\\infty}\\)for finite values \\(\\Lambda\\)in the simple case of a halo subject to Hubble drag. The solid black curve corresponds to a\n choice of halo formation redshift of \\(z_{\\textrm{i}}=1\\), and the dashed blue curve to\n \\(z_{\\textrm{i}}=2\\). In realistic applications we\n might expect\n \\(\\Lambda\\approx\\lambda_{\\rm{coh}}/R_{\\rm halo}\\approx 10-1000\\)as we will see in Sec.\n . ",
    "# Branches Mutual Promotion for End-to-End Weakly Supervised Semantic Segmentation \n\nLei Zhu, Hangzhou He, Xinliang Zhang, Qian Chen, Shuang Zeng, Qiushi Ren, Yanye Lu* \n\n**A: Multi-Stage WSSS** **B: E2E-WSSS with Unidirectional Supervision** Classification Stage 1 Classification Branch Network \n\n##### Abstract\n**Abstract** **\u2014 End-to-end weakly supervised semantic segmentation aims at optimizing a segmentation model in a singlestage training process based on only image annotations. Existing** \n\n##### Abstract\n**methods adopt an online-trained classification branch to provide** **pseudo annotations for supervising the segmentation branch.** **However, this strategy makes the classification branch dominate** **the whole concurrent training process, hindering these two** **branches from assisting each other. In our work, we treat** **these two branches equally by viewing them as diverse ways** **to generate the segmentation map, and add interactions on both** **their supervision and operation to achieve mutual promotion. For** **this purpose, a bidirectional supervision mechanism is elaborated** **to force the consistency between the outputs of these two** **branches. Thus, the segmentation branch can also give feedback** **to the classification branch to enhance the quality of localization** **seeds. Moreover, our method also designs interaction operations** **between these two branches to exchange their knowledge to assist** **each other. Experiments indicate our work outperforms existing** **end-to-end weakly supervised segmentation methods.** \n\n##### Abstract\n**Index Terms** **\u2014 Weakly Supervised Learning, Image Segmentation, Object Localization** \n\n## I. I NTRODUCTION \n\nEMANTIC segmentation is a primary vision task, aiming \n\nSto annotate pixels in an image as target objects or backgrounds. However, training a segmentation model in a fullysupervised manner requires annotating all pixels in training\n \n\nor determining reliable regions on the pseudo annotations [9], [10]. \n\nIn our work, we argue that current E2E-WSSS methods \n\nimages, costing extensive human resources. To solve this problem, weakly supervised semantic segmentation (WSSS) appears and attracts extensive attention, which adopts only image-level annotation for the training process. However, as shown in Fig. 1  A , WSSS methods usually require multiple training stages, _ e.g._ , tuning a classification network with image annotations to produce localization seeds [1]\u2013[3], deriving pseudo annotations after refining the seeds [4]\u2013[6], and finally training the segmentation network with the pseudo annotations [7], [8]. \n\nRecently, some end-to-end weakly supervised semantic \n\nmay fall into a trap, following the multi-stage WSSS to unidirectionally supervise the segmentation branch based on the prediction of the classification branch, without considering the feedback of the segmentation branch. In this way, the classification branch will dominate the whole training process, even if it may perform worse than the segmentation branch, as visualized in Fig. 2. Thus, the classification branch will converge to a similar optimum as the offline trained classification network but cannot stably provide pseudo annotations for the segmentation branch, which causes the large performance gap between current E2E-WSSS and multi-stage WSSS methods. \n\nActually, in the E2E-WSSS setting, these two branches \n\nsegmentation (E2E-WSSS) methods arose to simplify the heavy multi-stage training process into a single stage [9]\u2013 [12]. As shown in Fig. 1  B , these methods train a twobranch network in only a single stage, where the classification branch supervised by image-level annotation can online provide pseudo annotations for the segmentation branch. Compared with multi-stage WSSS, the concurrently-trained classification branch cannot stably provide seed to derive accurate pseudo annotations for supervising the segmentation branch. So, existing E2E-WSSS methods focus on improving the classification branch to provide better supervision by refining the localization seed with online spatial propagation [11]\u2013[13] \n\nare basically at equal status because they are concurrently optimized during training. From another perspective, the segmentation branch can also assist the concurrently-trained classification branch in generating better localization seeds, which is a crucial trait of E2E-WSSS and yet to be explored by existing methods. Based on this perspective, our work treats these two branches equally by viewing them as diverse ways to achieve the same goal, generating the segmentation map of input images. Thus, as shown in Fig. 1  C , interactions are \n\nComparison of WSSS strategies:  A . Multi-stage WSSS contains \n\nmultiple training stages.  B . Existing E2E-WSSS unidirectionally supervises the segmentation branch with pseudo annotations online provided by the classification branch.  C . Our proposed E2E-WSSS strategy interacts both the supervision and operation between these two branches to achieve mutual promotion. ",
    "easier function that only depends on the pairwise shortest path lengths between miners. Importantly, our MDP reward function captures the property that a miner\u2019s mining gains depends on how small the shortest path lengths between the agent and other miners are relative to the shortest path lengths between other miners. Experimentally we show Cobalt outperforms or matches heuristics on diverse network settings. \n\n## II. R ELATED  W ORK \n\nP2P network design for optimizing mining rewards has \n\nshown that the dependence of mining rewards on propagation latency is more intricate than this [35]. Specifically, an honest miner that is well connected with other miners inadvertently creates efficient, low latency paths for other miners by acting as a centrally located bridge between the miners. However, to maximize the marginal gains in reward due to the network, it is important for a miner to have paths to other miners that are, on average, of a lower delay _ relative_  to the delays of paths between other miners. For example, if miners are arranged as a star topology with links of unit delay and uniform compute power across nodes, the central node receives a higher reward compared to the leaf nodes by including more blocks on the blockchain. On the other hand, on a complete graph topology with unit delay links and uniform compute power as before, all nodes receive the same reward. A node identically connected to other nodes in the two cases (i.e., the central node in the star topology and any arbitrary node in the complete graph topology: both have direct links to all other nodes) receives different rewards, as rewards depend not only on the node\u2019s own connections but also on how other nodes\u2019 connections. Thus, there is an inherent tension for a miner in increasing her own connectivity to the rest of the network while simultaneously ensuring that the connectivity between other miners do not significantly increase. A systematic research of this tension, and efficient connection policies to maximize marginal mining reward gain due to the network, have not been done to our best knowledge. \n\nremained a relatively under-explored topic in the community. The work that is closest to our is Perigee [34] which proposes an adaptive peer-selection algorithm for minimizing block propagation latency in the network. However, Perigee does not model the game-theoretic competition between miners. Subsequent works [11], [43] consider optimizing the network to maximize extractable value (MEV) from transactions. A number of prior works have exposed the impact of the network on mining [12], [26], [28], [37], [40], [47], [48]. While these works generally suggest that better network connectivity translates to higher mining rewards earned, the competitive effects of network connectivity and methods to optimize them have not been discussed. Other related works include KadCast [38] which proposes a Kadmila-based structured overlay for efficient block broadcast, and relay networks such as BloXroute [29] for transports blocks quickly across vast geographic distances. \n\nIn this work, we formalize the p2p topology construction \n\nThe idea of network coordinates for p2p networks has been prominently explored in the network systems literature since the turn of the millenium, including distributed approaches to learn them [19], [32], [36]. More recently, a number of theoretical works have studied using low-distortion embeddings in finite metrics (i.e., over finite graphs) for various applications, e.g., sparse spanner construction [10], [13], [16], [21]. \n\nGame theory of blockchains, especially at the consensus layer, has received considerable attention. For example, \n\nproblem as a game between miners and present Cobalt, a decentralized policy for optimizing reward. We consider a simplified setting where only a single node chooses its connections, while the rest of the network\u2019s topology is fixed. We assume that the global topology of the p2p network is unknown to miners. We thus model the problem of optimizing rewards by the connections-deciding miner node as a Markov decision process (MDP) with no state and an action set with a combinatorial number of actions. \n\nWe derive the optimal neighbor selection policy using \n\nLewenberg et al. [33] use game theory to study how mining rewards can be shared across members of a mining pool. On the other hand, prior works have considered various network games outside the context of blockchains [24], [39]. Our work is the first (to our best knowledge) to consider network games in blockchains. \n\n## III. P ROBLEM  F ORMULATION Let us consider a complete directed graph \\(\\ALP G=(\\ALP V,\\ALP E)\\)edges.\n , where \\(\\ALP V\\)node\n  is the set of nodes and \\(\\ALP E\\) is the set of directed edges. Each node in the graph represents a mining server. The hash rate of the mining server \\(v\\) is denoted by \\(H_{v}\\). We use \\(\\VEC H\\) to denote the hash rate vector \\(\\VEC H:=(H_{v})_{v\\in\\ALP V}\\). A directed edge \\((v_{1},v_{2})\\in\\mathcal{E}\\)directed\n  represents a (TCP) link between the nodes \\(v_{1},v_{2}\\). 1 \n\na combinatorial multi-armed bandit (MAB) approach [14]. In the MAB algorithm, the agent (miner) explores various candidate connection configurations, and gradually adapts its connections based on past experience to gain the most mining rewards. A key contribution of our work is a network coordinates based model for efficiently learning the MAB environment [19]. In this model, miners are assigned realvalued vectors from an Euclidean space, which capture the relative location of miners with respect to each other in the network. The coodinates are continuously updated based upon the reward feedback the agent receives from the environment. Thus, despite not having global knowledge of the network initially, we show that it is possible for an agent to learn about the network by just using the observed reward information. \n\nTo enable the deployment of MAB algorithm, we have \n\nThe directed edge represents that node \\(v_{1}\\) can send messages (e.g., transactions, blocks etc.) to \\(v_{2}\\) as and when required by the protocol. The time take for a message sent from \\(v_{1}\\) to reach \\(v_{2}\\) along the link \\((v_{1},v_{2})\\) is denoted by \\(l(v_{1},v_{2})\\geq 0\\). \n\nbuilt a simulator. To simplify the reward computation in the simulator, rather than simulating the actual mining process at each step of the MDP, we consider a computationally 1 We assume if \\((v_{1},v_{2})\\in\\mathcal{E}\\) then \\((v_{2},v_{1})\\in\\mathcal{E}\\) for all \\(v_{1},v_{2}\\in\\mathcal{V}\\). ",
    "**COMO-ViT.** Given the input feature \\(\\mathbf{F}_{l-1}\\in\\mathbb{R}^{H\\times W\\times c}\\)of COMO-ViT, we conduct two branches of operations. In the first branch, we uniformly split it into \\(n\\) non-overlapping windows \\(\\mathcal{P}=[\\mathbf{P}^{1},\\mathbf{P}^{2},\\cdots,\\mathbf{P}^{n}]\\in\\mathbb{R} ^{n\\times w\\times w\\times c}\\), where \\((w,w)\\) is the window resolution. SNR [ 43 ] and STAR [ 52 ] downsample images, losing local structures and some important pixel-level information. Instead, the proposed \n\nCOMO-ViT completely models the dependencies among all \\(\\mathbf{P}^{i}\\)is regarded as\n \\(\\mathbf{P}^{i}\\) is regarded as an individual, we thus reshape \\(\\mathbf{P}^{i}\\)as follows: \n\n\\[\\mathbf{P}^{i}\\to[p^{i,1},p^{i,2},\\cdots,p^{i,m}],\\] (10)  \n\nwhere \\(p^{i,j}\\in\\mathbb{R}^{1\\times 1\\times c}\\), \\(m=w^{2}\\)\\(p^{i,j}\\in\\mathbb{R}^{1\\times 1\\times c}\\),\n \\(m=w^{2}\\)where pi,j \u2208R1\u00d71\u00d7c, m = w2 is the number of pixels in Pi.\nWith a linear projection, we then transform\n \\(\\mathbf{P}^{i}\\).\nWith a linear projection, we then transform\n \\(\\mathbf{P}^{i}\\). With a linear projection, we then transform \n\nthe pixels into a sequence of pixel embeddings \\(\\mathbf{X}^{i}=[x^{i,1},x^{i,2},\\cdots,x^{i,m}]\\)\\(c1\\), where \\(x^{i,j}\\in\\mathbb{R}^{c1}\\)is the \\(j\\)-th pixel embedding, \\(c1\\) is the embedding dimension. For \\(\\mathbf{X}^{i}\\), we utilize a local Transformer module to extract deep features as follows: \n\nGlobal pixel dependencies are explored by calculating \n\n\\[{\\mathbf{Y}^{{}^{\\prime}}}^{i} =\\mathbf{X}^{i}+\\operatorname{MSA}(\\operatorname{LN}(\\mathbf{X}^{ i})),\\] (11) \\[\\mathbf{Y}^{i} ={\\mathbf{Y}^{{}^{\\prime}}}^{i}+\\operatorname{MLP}(\\operatorname{ LN}({\\mathbf{Y}^{{}^{\\prime}}}^{i})),\\]  \n\nwindow attention via a global attention module. Firstly, \\(\\mathcal{C}\\)is transformed into a sequence of window embedding: \n\n\n\n\\[\\mathbf{U}=[u^{1},u^{2},\\cdots,u^{n}],\\quad u^{i}=\\operatorname{ FC}(\\operatorname{Vec}(\\mathbf{C}^{i})),\\] (15)  \n\nwhere \\(\\mathbf{Y}^{i}\\)\\(\\mathbf{Y}^{i}\\)where Yi is the feature learned by the local Transformer module, MSA(\u00b7) is the Multi-head Self-Attention\n \\(\\operatorname{MSA}(\\cdot)\\)is the Multi-head Self-Attention\n \\(\\operatorname{MSA}(\\cdot)\\) is the Multi-head Self-Attention \n\nwhere \\(\\operatorname{Vec}(\\cdot)\\) is vectorization operation. Then, we utilize \n\n[ 35 ], \\(\\operatorname{LN}(\\cdot)\\) is layer normalization [ 1 ] for stable training and faster convergence, \\(\\operatorname{MLP}(\\cdot)\\) is multi-layer perceptron for feature transformation at channel dimension and nonlinearity. In such a process, we adopt 1D learnable location embedding to encode the spatial information of pixels. \n\n\\(\\mathbf{F}_{l}\\in\\mathbb{R}^{H\\times W\\times c}\\), where\n \\(\\mathbf{F}_{l}\\in\\mathbb{R}^{H\\times W\\times c}\\)COMO-ViT\n , where \\(l\\in\\{1,2,\\cdots,L\\}\\), and \\(L\\) is the COMO-ViT number. When \\(l=1\\), \\(\\mathbf{F}_{l-1}\\) is the fused feature \\(\\mathbf{F}_{f}\\)in Eq.\n .\n \n\nThe result of the second stage is obtained by decoding \n\nTo complement the non-overlapping window attention, \n\n\\(\\mathbf{F}_{L}\\) with a convolutional layer ( \\(\\mathcal{D}(\\cdot)\\)): \n\n\\[\\mathbf{R}_{s2}=\\operatorname{Conv}(\\mathbf{F}_{L}).\\] (16)  \n\nin the second branch which is parallel with local attention, we use a CNN module to model local pixel dependencies in \\(\\mathbf{F}_{l-1}\\) via an overlapped sliding kernel to recover image details, in which a SE block [ 11 ] is used to explore channel relationship to boost representative power: \n\nWe visually show \\(\\mathbf{R}_{s2}\\) in Fig.  4 \\(\\mathbf{R}_{s2}\\)We visually show Rs2 in Fig. 4, observing that the illumination is enhanced and image details are also recovered.\n \n\n\\[\\mathbf{F}^{{}^{\\prime}}=\\operatorname{Conv}(\\operatorname{LN}( \\mathbf{F}_{l-1})),\\quad\\mathbf{F}_{conv}=\\mathbf{F}^{{}^{\\prime}}\\odot \\operatorname{SE}(\\mathbf{F}^{{}^{\\prime}}).\\] (12)  \n\nEspecially, the noise is well removed by our COMO-ViT. \n\n**LGCM.** LGCM takes \\(\\mathbf{R}_{s2}\\) as input, and learns local deep \n\n\\(\\mathbf{F}_{conv}\\) is then split into \\(n\\) non-overlapping windows \\(\\mathcal{Q}=[\\mathbf{Q}^{1},\\mathbf{Q}^{2},\\cdots,\\mathbf{Q}^{n}]\\in\\mathbb{R} ^{n\\times w\\times w\\times c}\\)reshaped:\n , and each \\(\\mathbf{Q}^{i}\\)is reshaped: \n\n\\[\\mathbf{Q}^{i}\\to[q^{i,1},q^{i,2},\\cdots,q^{i,m}].\\] (13)  \n\nfeatures to perceive illumination gap between \\(\\mathbf{R}_{s2}\\) and ground truth and elaborately enhances illumination to reduce local color deviation: \n\nWe combine the features from both branches as: \n\n\\[\\mathbf{\\Gamma}_{l}=\\varphi(\\operatorname{Conv}_{3}(\\mathbf{R}_{s 2})),\\quad\\mathbf{R}_{s3}=\\mathbf{R}_{s2}^{\\mathbf{\\Gamma}_{l}}.\\] (17)  \n\n\\[\\mathcal{C}=[\\mathbf{C}^{1},\\mathbf{C}^{2},\\cdots,\\mathbf{C}^{n}] ,\\quad\\mathbf{C}^{i}=\\mathbf{Q}^{i}+\\mathbf{Y}^{i}\\] (14)  \n\n\\begin{tabular}{c c c c c c c c c c c c}\n\\hline \\hline\nEpoches & Optimizer & \\begin{tabular}{c} Batch \\\\ size \\\\ \\end{tabular} & \\begin{tabular}{c} Learning \\\\ rate \\\\ \\end{tabular} & \\begin{tabular}{c} LR \\\\ decay \\\\ \\end{tabular} & \\begin{tabular}{c} Weight \\\\ decay \\\\ \\end{tabular} & \\begin{tabular}{c} Drop \\\\ path \\\\ \\end{tabular} & \\begin{tabular}{c} Embedding \\\\ dim \\\\ \\end{tabular} & Head & \\(L\\) & \\begin{tabular}{c} Window \\\\ size \\\\ \\end{tabular} & \\begin{tabular}{c} Patch \\\\ size \\\\ \\end{tabular} \\\\\n\\hline\n300 & Adam[] & 8 & 4e-4 & cosine & 1e-7 & \\(0.1\\) & \\(15\\) & \\(5\\) & \\(2\\) & \\(16\\) & 512 \\\\ \\hline \\hline\n\\end{tabular}\n\\begin{tabular}{c c c c c c c c c c c c}\n\\hline \\hline\nEpoches & Optimizer & \\begin{tabular}{c} Batch \\\\ size \\\\ \\end{tabular} & \\begin{tabular}{c} Learning \\\\ rate \\\\ \\end{tabular} & \\begin{tabular}{c} LR \\\\ decay \\\\ \\end{tabular} & \\begin{tabular}{c} Weight \\\\ decay \\\\ \\end{tabular} & \\begin{tabular}{c} Drop \\\\ path \\\\ \\end{tabular} & \\begin{tabular}{c} Embedding \\\\ dim \\\\ \\end{tabular} & Head & \\(L\\) & \\begin{tabular}{c} Window \\\\ size \\\\ \\end{tabular} & \\begin{tabular}{c} Patch \\\\ size \\\\ \\end{tabular} \\\\\n\\hline\n300 & Adam[] & 8 & 4e-4 & cosine & 1e-7 & \\(0.1\\) & \\(15\\) & \\(5\\) & \\(2\\) & \\(16\\) & 512 \\\\ \\hline \\hline\n\\end{tabular}\n\n\nTable 1. Default training and network hyper-parameters used in our method, unless stated otherwise. \n\nFigure 4. We observe that \\(\\mathbf{R}_{s3}\\) keeps higher illumination than \\(\\mathbf{R}_{s2}\\), illustrating the effectiveness of our LGCM. \\(\\mathbf{\\Gamma}_{l}\\) is corresponding pixel-wise local gamma map. ",
    "of \\(10^{3}\\)G (Reiners & Christensen 2010), we get a magnetic field strength of 4.5 \\(\\times 10^{1}\\)G at the eclipse edge ( \\(\\phi_{b}=0.31\\)). A magnetosphere field strength of 10 G is sufficient to trap and dominate plasma (assuming protons and electrons) of number density \\(<3\\times 10^{13}\\)cm _-3_and velocity \\(\\sim V_{\\rm orb}\\). \n\nThompson et al. (1994) suggests that, at the edge of the magnetosphere of the brown dwarf, the magnetic pressure should balance the pulsar wind pressure, while the pulsar wind energy density is \\(U_{E}=\\frac{\\dot{E}}{4{\\pi}ca^{2}}\\) and the magnetic pressure is \\(\\frac{B_{E}^{2}}{8{\\pi}}\\). The \\(\\dot{E}\\)\\(\\dot{E}\\) is the spin-down luminosity, c is the speed of light, \\(a\\) is the orbital separation, and \\(B_{E}\\) is the magnetic field of the eclipse medium. From this, the magnetic field strength of \\(B_{E}\\) should be \\(\\approx 8~{}\\).\n \n\nInterestingly, the derived theoretical magnetic field strength (45 G) is more than sufficient for the re- quired field strength (8 G) at the eclipsing edge. However, these field strengths are more than three orders of magnitude higher than the value observed in our egress (10 mG). \n\n### Pulsar wind \n\nThe third scenario (Fig. 7 c) supplements the second one with pulsar wind and a shock boundary, and fixes the inconsistency mentioned above. Such a picture was proposed by Phinney et al. (1988) as one of the early models. In this picture, a shock boundary exists between the magnetosphere and the pulsar wind. Outside of the shock boundary are high-speed, low-density pulsar wind particles traveling with a low magnetic field, and inside, the slow-moving, high-density plasma trapped by the companion\u2019s magnetic fields. This is similar to the boundary shock observed from the Solar wind and the Earth magnetosphere (Sckopke et al. 1983) where both the electron density and magnetic field rose suddenly as the ISEE-1 8 probe traveled downstream of the Solar wind into the Earth magnetosphere. \n\nThe majority of energy in the pulsar wind is carried by relativistic particles. The magnetic fields in the pulsar wind could be much smaller than the magnetic field of the companion at the orbital distance. After all, the pulsar\u2019s magnetic field is only 1.6 \\(\\times 10^{8}\\)G at its 10 km radius surface (Tab. 1). The pulsar wind is almost transparent to the pulsar emission. This is because of the low density and the high Lorenz factor of the wind particles. The wind particles have motion masses far exceeding their rest masses, causing their Faraday rotation effect to be negligible (Quataert & Gruzinov 2000; Wang et al. 2011). When a moderate amount of slow-moving ionized materials from the companion\u2019s magnetosphere flow out of the boundary and come to the pulsar wind side, the combination of the extra slow electrons and a reasonably low magnetic field (10 mG) environment leads to the incomplete depolarization and the Faraday rotation. As we mentioned in the previous section, such a condition is rarely met (only be observed in MJD 59214). In most of the ingresses and egresses of this pulsar, the out-flowing electrons are either too dense or too variable and often completely depolarize the pulsar signal. \n\nThompson et al. (1994) predicted that the pulsar wind could contain an oscillating part around the eclipsing edge with an oscillation length of \\(cP/2\\simeq 500\\) km, where \\(c\\) is the speed of light and \\(P\\) is the spin period of the pulsar. It should be noted that such reciprocating magnetic fields in the pulsar wind was already illustrated in the model of Phinney et al. (1988). But such field was never observed until now. We 8  International Sun-Earth Explorer 1 ",
    "between these works and ours is that they assume the buyer is _ fully strategic_  and processes fully how their actions today affect the seller\u2019s decisions tomorrow (whereas we instead model buyers as no-regret learners). \n\nThe most related work to ours is in the [BMSW18] model itself. Here we provide a brief summary of the main results in [BMSW18] and their connection to our main results. [BMSW18] studies the one seller one buyer scenario, where the buyer employs a mean-based no-regret algorithm. The authors present three results, each obtained under different assumptions regarding the behavior of the buyers. Firstly (as we have already mentioned earlier in the introduction), [BMSW18] shows that for vanilla mean-based no-regret buyers, [BMSW18] can extract revenue that is an arbitrarily large fraction of the bidder\u2019s expected value. Our Theorem 4 extends this result to the multiple buyer setting, overcoming novel technical and conceptual challenges. Second, [BMSW18] designs a novel (not mean-based) learning algorithm against which the optimal mechanism for the seller is simply Myerson\u2019s auction in each round. Their proof of this result naturally accommodates multiple buyers. Finally, [BMSW18] shows that if the buyer is clever and mean-based no regret (where they do not overbid their value), then the optimal auction has a clean tractable format (pay-your-bid with declining reserve over time). As we have discussed in the \u201cNo Overbidding\u201d section of the introduction, our work shows several formal barriers in extending these results to multiple buyers. In summary, our main result extends their first main result to multiple bidders. Their second result already holds for multiple bidders (so there is nothing for us to extend). Our secondary results establish formal barriers to extending their final main result to multiple bidders. \n\nTwo recent follow-ups have extended the setting in [BMSW18] in a different direction. First, [DSS19b] considers the problem of playing a two-player game against a no-regret learner. While technically not an auctions problem, there is thematic overlap with our main result. [DSS19a] extends the single-buyer results in [BMSW18] to be _ prior-free_ . Specifically, they show how to design auctions achieving the same guarantees as those in [BMSW18] but where the buyer\u2019s values are chosen adversarially. In comparison to these works, ours is the first to extend the model to consider multiple buyers. \n\nFinally, recent work of [CHJ20] considers interaction between a learning buyer and a _ learning_ seller. Their seller does not have a prior against which to optimize, and instead itself targets a noregret guarantee. In comparison, our seller (like the seller in all previously cited works) optimizes expected revenue with respect to a prior. \n\n## Preliminaries We consider the same setting as [BMSW18], extended to multiple buyers. Specifically, there are \\(n\\) buyers and \\(T\\) rounds. In each round, there is a single item for sale. Each buyer \\(i\\) has value \\(v_{i,t}\\)for the item during round \\(t\\), and each \\(v_{i,t}\\) is drawn from \\(\\mathcal{D}\\) independently (that is, the buyers are i.i.d., and the rounds are i.i.d. as well). For simplicity of exposition (and to match prior work), we assume \\(\\mathcal{D}\\)has finite support\n \\(0\\leq w_{1}<w_{2}<\\ldots<w_{m}\\leq 1\\)and we define\n \\(q_{j}\\) to be the probability \\(w_{j}\\) is drawn from \\(\\mathcal{D}\\). \n\nEach round, the seller presents \\(K\\) arms for the buyers. Each arm is labeled with a bid, and we \\(0\\)(to represent a bid of \u201cdon\u2019t participate\u201d). Note that\n the same set of arms is presented to all buyers, and the same set of arms is presented in each round. \n\nIn each round \\(t\\), the seller defines an anonymous auction. Specifically, for all \\(i,t\\), the seller defines ",
    "but consistent with a model where only the gravitational potential of the gas is considered. \n\nTo investigate the impact of the SMBH on the kinematics of J0109\u20133047 further, we construct a simple \n\npared to the model without a gap. Moreover, a central gap in the gas distribution would be at odds with simulations and observations where the central \u223c400\u2212500 pc\n \\(\\sim 400-500\\ \\rm{pc}\\)\\(\\sim 400-500\\ \\rm{pc}\\)the\n region contains up to \\(\\sim 10\\)2022\n times the mass of the BH in\n gas (e.g.,  Lupi et al. 2022 ;  Walter et al. 2022 ). \n\nIn summary, the flat velocity dispersion profile implies a flat radial mass density profile. The constant \n\n\u201cdispersion\u2013dominated + SMBH\u201d model in _ QUBEFit_ . In this model the velocity dispersion is the sum of the SMBH component of Eq.  1 the SMBH component of Eq. 1 and a constant dispersion value throughout the quasar host (\u03c32\nCII tot =\n \\(\\sigma_{\\rm{CII,tot}}^{2}=\\sigma_{\\rm{CII},SMBH}(r)^{2}+\\sigma_{\\rm{const}}^{2}\\)\\(\\sigma_{\\rm{CII,tot}}^{2}=\\sigma_{\\rm{CII},SMBH}(r)^{2}+\\sigma_{\\rm{const}}^{2}\\)). The intensity profile is assumed to be exponentially declining as in the constant dispersion model (see Section  3 ). We note that any additional contribution (besides the central SMBH) to the kinematics as a constant is in agreement with the inferred gas mass profile (see Fig.  4 ). \n\nIn Fig. 5  we show the best-fit dispersion fields for \n\ndispersion implies that the underlying mass distribution is not centrally peaked, consistent with the expectations of the gas mass distribution derived from the far-infrared continuum emission under standard assumptions. This leaves only few alternatives to explain the absence of a central peak in the velocity dispersion. One possibility is that the gas mass decreases in the central\n \\(200\\)is that the gas mass decreases in the central 200 pc in order to compensate the presence of a 0.6 \u22121.1 \u00d7 109 M\u2299\n \\(0.6-1.1\\times 10^{9}\\ M_{\\odot}\\)profile.\n black hole and produce a flat mass profile. However, \n\ndifferent SMBH masses from\n \\(10^{8}\\ M_{\\odot}\\)to\n \\(10^{9}\\ M_{\\odot}\\). We find that the [C  II ] kinematics of J0109\u20133047 are clearly incompatible with a \\(\\sim 10^{9}\\ M_{\\odot}\\)the\n SMBH. A full MCMC fit of the model to the data yields an upper limit of \\(M_{\\rm{SMBH}}<6.5\\times 10^{8}\\ M_{\\odot}(2\\sigma)\\)(see Appendix\n  for the full posterior distribution of the model parameters). However, even for the maximum-likelihood model (MBH =\n \\(M_{\\rm{BH}}=2.4\\times 10^{8}\\ M_{\\odot}\\)\\(M_{\\rm{BH}}=2.4\\times 10^{8}\\ M_{\\odot}\\)model\n ), the BIC is slightly higher than for a model without a black hole (\n \\(\\Delta\\rm{BIC}=5.2\\)), showing that\n any SMBH contribution to the dispersion velocity field is disfavored by the observations. \n\nwe have previously excluded the presence of a central gap in the [C  II ]\u2013emitting gas, and the FIR continuum shows no sign of a central gap either. A decrease in the central gas mass would imply fine-tuning of the physical properties of the ISM at the center of J0109\u20133047 (to \u2018offset\u2019 the mass of the SMBH). If such a conspiracy is excluded, the black hole mass is either smaller than expected, as discussed in this section, or the black hole is not located at the center of the galaxy as traced by the dust continuum, as discussed in the next section. \n\nIf confirmed, and applicable to the larger population \n\nOne way to alleviate the tension with the rest-frame UV mass measurement could be to change the radial [C  II ]\u2013emitting gas profile. By definition, the observed [C  II ] kinematics are a luminosity\u2013weighted, beam\u2013 convolved realisation of the intrinsic kinematics. Following Eq.  1 , the velocity dispersion increases exponentially close to the black hole, and due to the exponential intensity profile, these inner regions will contribute more to the beam\u2013convolved velocity dispersion measurement in the center. As a result, the observed velocity dispersion could be reduced, if the [C  II ] intensity profile is not increasing close to the black hole (for example due to feedback). \n\nTo address this further, we have used a toy model where the gas density profile follows an exponentially declining profile with a central gap where the [C  II ] emission is null. As in the fiducial model, the velocity dispersion is composed of the SMBH component and \n\nof \\(z>6\\)luminous quasars, a mass of\n \\(\\sim 10^{8}M_{\\odot}\\)for the SMBH in J0109\u20133047 would have several interesting implications for early SMBH growth and formation. First, it would alleviate the need for massive seeds and/or super\u2013Eddington accretion events at z > 7 (e.g., Ba\u02dc\nnados\n \\(z>7\\)\\(z>7\\)et al. 2018 ;  Wang et al. 2021 ;  Volonteri et al. 2021 ). Second, a SMBH mass of\n \\(10^{8}M_{\\odot}\\)\\(10^{8}M_{\\odot}\\)Second, a SMBH mass of 108M\u2299for a total galaxy (dynamical) mass of 2.34 \u00d7 1010 M\u2299(see Section 4) would\n \\(2.34\\times 10^{10}\\,M_{\\odot}\\)(see Section\n ) would\n (see Section ) would place it on the local relation, meaning that J0109\u20133047 is not part of an overmassive SMBH population at \\(z>6\\)( Pensabene et al. 2020 ;  Neeleman et al. 2021 ), and the offset from the local relation seen in the \\(z>6\\)luminous\n quasar sample could be due to systematic overestimation of black hole masses. Third, the accreting BH at the heart of J0109\u20133047 would be definitive evidence for super\u2013Eddington accretion at \\(z>6\\)with an Eddington\n ratio \\(\\lambda_{\\rm{Edd}}\\gtrsim 5\\).\n \n\n## 6.  AN OFFSET OR RECOILING SMBH AT REDSHIFT Z=6.79? The previous section relied on the assumption that \n\na constant. We use this simple model to calculate the size of the central gap necessary to \u201chide\u201d the SMBH impact on the [C  II ] kinematics tracer. We find that, for a SMBH with a fixed mass \\(M_{\\rm{BH}}=1.1\\times 10^{9}M_{\\odot}\\), the best-fit central gap is constrained to be \\(r<22\\ \\rm{pc}\\)(\n \\(2\\sigma\\)) to reproduce the [C  II ] profile and kinematics. The best-fit model has \\(r_{\\rm{pc}}=0.015^{+0.015}_{-0.010}\\ \\rm{pc}\\)(see Appendix\n ), and is formally ruled out with an increased\n \\(\\Delta\\rm{BIC}=10.42\\)com-\n \n\nthe black hole is located at the center of the host FIR continuum emission. However, if the accreting SMBH is not located at the center of the host galaxy, the [C  II ] kinematics are not expected to be strongly influenced ",
    "**The particular case of a Lie group. In what follows, we will show the previous reduction process in** **the particular case when the initial manifold** \\(Q\\)** is a Lie group** \\(G.\\)** In such a case, one may use the left** **trivialization of the cotangent bundle** \\(T^{*}G\\)** in order to identify** \\(T^{*}G\\)** with the product manifold** \\(G\\times{\\mathfrak{g}}^{*}\\)**,** **where** \\(({\\mathfrak{g}},[\\cdot,\\cdot]_{\\mathfrak{g}})\\)first\n ** is the Lie algebra of** \\(G\\)**, in such a way that the canonical projection** \\(\\tau_{G}^{*}:T^{*}G\\to G\\)by\n ** is** **just the first projection** \\(p_{1}:G\\times{\\mathfrak{g}}^{*}\\to G.\\)** The left action** \\(\\Phi:G\\times G\\to G\\)** on** \\(G\\)** is the one defined by the** **group operation of** \\(G\\)**. We take the left invariant vector field** \\(Y=\\overleftarrow{\\xi}\\)** on** \\(G\\)** induced by an element** \\(\\xi\\)**of** \\({\\mathfrak{g}}.\\)** In the first reduction with the cotangent lift of** \\(\\Phi\\)**, the reduced space is** \\((T^{*}G-0_{G})/G\\cong{\\mathfrak{g}}^{*}-\\{0\\}\\)**and the reduced function induced by** \\(Y\\)** is the restriction to** \\({\\mathfrak{g}}^{*}-\\{0\\}\\)** of the linear map** \\({\\xi}^{\\ell}\\)**associated** **with** \\(\\xi\\in{\\mathfrak{g}},\\)** i.e.** \\[{\\xi}^{\\ell}:{\\mathfrak{g}}^{*}-\\{0\\}\\to\\mathbb{R},\\quad{\\xi}^{\\ell}(\\alpha)= \\alpha(\\xi).\\]  **On the other hand, the Lie-Poisson bracket** \\(\\{\\cdot,\\cdot\\}_{{\\mathfrak{g}}^{*}}\\)**on** \\((T^{*}G-0_{G})/G\\cong{\\mathfrak{g}}^{*}-\\{0\\}\\)** is characterized by** \\[\\{{\\xi_{1}}^{\\ell},{\\xi_{2}}^{\\ell}\\}_{{\\mathfrak{g}}^{*}}=-{[\\xi_{1},\\xi_{2}] }^{\\ell}_{{\\mathfrak{g}}},\\quad\\mbox{ for all $\\xi_{1},\\xi_{2}\\in{\\mathfrak{g} }.$}\\]  \n\n**The scaling symmetry on** \\({\\mathfrak{g}}^{*}-\\{0\\}\\)** is just** \n\n(40) \\[\\phi^{G}:(\\mathbb{R}-\\{0\\})\\times({\\mathfrak{g}}^{*}-\\{0\\})\\to({\\mathfrak{g}}^ {*}-\\{0\\}),\\qquad(s,\\alpha)\\to s\\alpha.\\]  \n\n**Now, we apply the second reduction step to the (Lie)-Poisson Hamiltonian system** \\(({\\mathfrak{g}}^{*}-\\{0\\},\\{\\cdot,\\cdot\\}_{{\\mathfrak{g}}^{*}},\\xi^{\\ell})\\)space\n **,** **with respect to the scaling symmetry** \\(\\phi^{G}.\\)** In this case, the reduced space is the projective space** \\({\\mathbb{P}}{\\mathfrak{g}}^{*}\\)**.** **The corresponding line bundle** \\(\\pi_{L}:L:=({\\mathfrak{g}}^{*}-\\{0\\}\\times\\mathbb{R})/(\\mathbb{R}-\\{0\\})\\to{ \\mathbb{P}}{\\mathfrak{g}}^{*}\\)**is defined by the action** \\[\\widetilde{\\phi}^{G}:(\\mathbb{R}-\\{0\\})\\times(({\\mathfrak{g}}^{*}-\\{0\\})\\times \\mathbb{R})\\to({\\mathfrak{g}}^{*}-\\{0\\})\\times\\mathbb{R},\\qquad\\widetilde{\\phi }^{G}_{s}(\\alpha,t)=(s\\alpha,\\frac{t}{s}).\\]  the\n \\[\\widetilde{\\phi}^{G}:(\\mathbb{R}-\\{0\\})\\times(({\\mathfrak{g}}^{*}-\\{0\\})\\times \\mathbb{R})\\to({\\mathfrak{g}}^{*}-\\{0\\})\\times\\mathbb{R},\\qquad\\widetilde{\\phi }^{G}_{s}(\\alpha,t)=(s\\alpha,\\frac{t}{s}).\\]  the\n **The section of the dual line bundle** \\(\\pi_{L^{*}}:L^{*}\\to{\\mathbb{P}}{\\mathfrak{g}}^{*}\\)**associated with the linear map** \\({\\xi}^{\\ell}:{\\mathfrak{g}}^{*}-\\{0\\}\\to\\mathbb{R}\\)** is** \\[h_{\\xi}(p(\\alpha))([(\\alpha,t)])=t\\alpha(\\xi),\\]  **with** \\([(\\alpha,t)]\\in L,\\)** where** \\(p:({\\mathfrak{g}}^{*}-0)\\to{\\mathbb{P}}{\\mathfrak{g}}^{*}\\)**is the quotient projection.** \n\n**The Kirillov bracket on the projective space** \\({\\mathbb{P}}{\\mathfrak{g}}^{*}\\)**is characterized by** \\[\\begin{array}[]{rcl}[h_{\\xi_{1}},h_{\\xi_{2}}]_{{\\mathbb{P}}{\\mathfrak{g}}^{*}} (p(\\alpha))([(\\alpha,t)])&=&-h_{\\{\\xi_{1}^{\\ell},\\xi_{2}^{\\ell}\\}_{{\\mathfrak{ g}}^{*}}}(p(\\alpha))([(\\alpha,t)])=-t\\{\\xi_{1}^{\\ell},\\xi_{2}^{\\ell}\\}_{{ \\mathfrak{g}}^{*}}(\\alpha)\\\\[5.0pt] &=&t\\alpha([\\xi_{1},\\xi_{2}]_{{\\mathfrak{g}}})=h_{[\\xi_{1},\\xi_{2}]_{{ \\mathfrak{g}}}}(p(\\alpha))([(\\alpha,t)]).\\end{array}\\]  \n\n**This structure on the line bundle** \\(L\\to{\\mathbb{P}}{\\mathfrak{g}}^{*}\\)reason\n \\(L\\to{\\mathbb{P}}{\\mathfrak{g}}^{*}\\)This structure on the line bundle L \u2192Pg\u2217may be considered as the Kirillov version of the LiePoisson structure on g\u2217and for this reason we will use the terminology the Lie-Kirillov structure on\n \\({\\mathfrak{g}}^{*}\\)and for this reason we will use the terminology the Lie-Kirillov structure on\n \\({\\mathfrak{g}}^{*}\\)**and for this reason we will use the terminology** _ the Lie-Kirillov structure on_ \\({\\mathbb{P}}{\\mathfrak{g}}^{*}.\\)\n\n**The reduced dynamics is determined by the** \\(p\\)**-projection of the Lie-Poisson Hamiltonian vector** **field associated with the linear function** \\(\\xi^{\\ell}\\in C^{\\infty}({\\mathfrak{g}}^{*}-\\{0\\})\\)**, that is,** \\[X_{{\\xi}^{\\ell}}^{\\{\\cdot,\\cdot\\}_{{\\mathfrak{g}}^{*}}}=\\{\\cdot,{\\xi}^{\\ell}\\} _{{\\mathfrak{g}}^{*}}.\\]  \n\n**Note however, that this** \\(p\\)**-projection of** \\(X_{\\xi^{\\ell}}^{\\{\\cdot,\\cdot\\}_{{\\mathfrak{g}}^{*}}}\\)**is just the vector field** \\(X_{h_{\\xi}}\\in{\\mathfrak{X}}({\\mathbb{P}}{\\mathfrak{g}}^{*})\\)**, which is** **locally characterized by (** **22** **).** \n\n## 5.  Reduction of symplectic Hamiltonian systems using first the scaling symmetry and then the standard symmetries \n\nAs in the previous section, we have a symplectic Hamiltonian system\n \\((S,\\omega,H)\\)with a scaling symmetry\n \\(\\phi^{S}:\\mathbb{R}^{\\times}\\times S\\to S\\)reduction\n  and a symplectic \\(G\\)-symmetry\n \\(\\Phi^{S}:G\\times S\\to S\\)steps,\n  which are compatible. In what follows we describe the reduction process of the system\n \\((S,\\omega,H)\\)in two steps, but in the following order: the first reduction is obtained\n by a scaling symmetry and the second step is done using the standard symmetry. \n\nFirst of all, we will show a reduction process for Kirillov structures in the presence of a standard symmetry. ",
    "_community filtered by Tutorial tag on social media web_ _site?_ ), and acts via planning, summarizing by HTML-T5, and then programming by Flan-U-PaLM. See  Appendix C for the example workflow. We finetune HTML-T5 with traces that are collected using scripted agents by procedu rally generating instructions from human curated templates. This results in 260 episodes on real estate website and 230 episodes on social media website (about 20/10 steps per episode respectively). \n\nWe prepare 20 different natural language instructions, and measure the success rate and score for the evaluation. The score represents the percentage of required attributes covered during the episode [ 81 ]; for instance (1) _ apartments_  for (2) _ corporate housing_  with (3) _ studio bedroom_  and (4) _ 1+ bathroom_ located in (5) _ oroville, ca_ . When the agents could search the housing satisfying (1), (2), (5) and not (3), (4), the score would be 60 ( \\(=100\\times 3/5\\)). When the agents could achieve 100 score, that episode would mark as success. \n\n**Results**  For comparison, we prepare three baselines, con sisting of partial plug-in language models and a single LLM prompting different examplers per role: WebAgent replacing closed-loop planning from HTML-T5 with few shot open-loop planning from Flan-U-PaLM ( **Plan** :  % ), replacing HTML summarization from HTML-T5 with regular-expression-based retrieval ( **Sum** :  % ), and both of them ( **Plan** :  % , ** Sum** :  % ).  Table 2  shows that WebAgent with HTML-T5 for planning and summarization ( **Plan** : \" , ** Sum** :  \" ) achieves best 65% success and 87.6 score on  real-estate  and 70% success and 85.8 score on social-media , significantly outperforming single LLM ( **Plan** :  % , ** Sum** :  % ), that with open-loop planning ( **Plan** : % ), and that with regular-expression retrieval ( **Sum** :  % ) (most of those roughly achieve only 10 - 20% success). This result suggests that closed-loop planning grounded on HTML observations via finetuning of domain language models is much more suitable for open-ended web navigation than open-loop planning with few-shot LLMs, which is remarkable in  real-estate  (even ** Sum** :  % achieves 50% success), where the longer planning horizon is needed to fulfill instructions. We guess enhancing the planning ability to decompose the given instructions adaptively and robustly can help further improve WebAgent. \n\n\\begin{tabular}{l r r r}\n\\hline \\hline\n**Models** & **Data** & **Success** & **Diff.** \\\\\n\\hline\nCC-Net [] & 2.4M & 32.0\\% & \u2013 \\\\\nWebN-T5-XL [] & 12K & 48.4\\% & \u2013 \\\\\n\\hline\nLongT5-Base & \\multirow{3}{*}{12K} & 53.8\\% & 0.0 \\\\\nLongT5-Large & & 56.3\\% & 0.0 \\\\\nLongT5-XL & & 60.4\\% & 0.0 \\\\\n\\hline\nFlan-LongT5-Base & \\multirow{3}{*}{12K} & 54.1\\% & +0.3 \\\\\nFlan-LongT5-Large & & 56.1\\% & -0.2 \\\\\nFlan-LongT5-XL & & 61.1\\% & +0.7 \\\\\n\\hline\nHTML-T5-Base (ours) & \\multirow{3}{*}{12K} & 57.0\\% & +3.2 \\\\\nHTML-T5-Large (ours) & & 60.8\\% & +4.5 \\\\\nHTML-T5-XL (ours) & & **63.3**\\% & +2.9 \\\\\n\\hline\nFlan-T5-XL [] & \\multirow{2}{*}{347K} & 75.5\\% & \u2013 \\\\\nFlan-T5-XXL [] & & 79.0\\% & \u2013 \\\\\n\\hline\nHTML-T5-XL (ours) & 347K & **79.4**\\% & \u2013 \\\\ \\hline \\hline\n\\end{tabular}\n\\begin{tabular}{l r r r}\n\\hline \\hline\n**Models** & **Data** & **Success** & **Diff.** \\\\\n\\hline\nCC-Net [] & 2.4M & 32.0\\% & \u2013 \\\\\nWebN-T5-XL [] & 12K & 48.4\\% & \u2013 \\\\\n\\hline\nLongT5-Base & \\multirow{3}{*}{12K} & 53.8\\% & 0.0 \\\\\nLongT5-Large & & 56.3\\% & 0.0 \\\\\nLongT5-XL & & 60.4\\% & 0.0 \\\\\n\\hline\nFlan-LongT5-Base & \\multirow{3}{*}{12K} & 54.1\\% & +0.3 \\\\\nFlan-LongT5-Large & & 56.1\\% & -0.2 \\\\\nFlan-LongT5-XL & & 61.1\\% & +0.7 \\\\\n\\hline\nHTML-T5-Base (ours) & \\multirow{3}{*}{12K} & 57.0\\% & +3.2 \\\\\nHTML-T5-Large (ours) & & 60.8\\% & +4.5 \\\\\nHTML-T5-XL (ours) & & **63.3**\\% & +2.9 \\\\\n\\hline\nFlan-T5-XL [] & \\multirow{2}{*}{347K} & 75.5\\% & \u2013 \\\\\nFlan-T5-XXL [] & & 79.0\\% & \u2013 \\\\\n\\hline\nHTML-T5-XL (ours) & 347K & **79.4**\\% & \u2013 \\\\ \\hline \\hline\n\\end{tabular}\n\\begin{tabular}{l r r r}\n\\hline \\hline\n**Models** & **Data** & **Success** & **Diff.** \\\\\n\\hline\nCC-Net [] & 2.4M & 32.0\\% & \u2013 \\\\\nWebN-T5-XL [] & 12K & 48.4\\% & \u2013 \\\\\n\\hline\nLongT5-Base & \\multirow{3}{*}{12K} & 53.8\\% & 0.0 \\\\\nLongT5-Large & & 56.3\\% & 0.0 \\\\\nLongT5-XL & & 60.4\\% & 0.0 \\\\\n\\hline\nFlan-LongT5-Base & \\multirow{3}{*}{12K} & 54.1\\% & +0.3 \\\\\nFlan-LongT5-Large & & 56.1\\% & -0.2 \\\\\nFlan-LongT5-XL & & 61.1\\% & +0.7 \\\\\n\\hline\nHTML-T5-Base (ours) & \\multirow{3}{*}{12K} & 57.0\\% & +3.2 \\\\\nHTML-T5-Large (ours) & & 60.8\\% & +4.5 \\\\\nHTML-T5-XL (ours) & & **63.3**\\% & +2.9 \\\\\n\\hline\nFlan-T5-XL [] & \\multirow{2}{*}{347K} & 75.5\\% & \u2013 \\\\\nFlan-T5-XXL [] & & 79.0\\% & \u2013 \\\\\n\\hline\nHTML-T5-XL (ours) & 347K & **79.4**\\% & \u2013 \\\\ \\hline \\hline\n\\end{tabular}\n\\begin{tabular}{l r r r}\n\\hline \\hline\n**Models** & **Data** & **Success** & **Diff.** \\\\\n\\hline\nCC-Net [] & 2.4M & 32.0\\% & \u2013 \\\\\nWebN-T5-XL [] & 12K & 48.4\\% & \u2013 \\\\\n\\hline\nLongT5-Base & \\multirow{3}{*}{12K} & 53.8\\% & 0.0 \\\\\nLongT5-Large & & 56.3\\% & 0.0 \\\\\nLongT5-XL & & 60.4\\% & 0.0 \\\\\n\\hline\nFlan-LongT5-Base & \\multirow{3}{*}{12K} & 54.1\\% & +0.3 \\\\\nFlan-LongT5-Large & & 56.1\\% & -0.2 \\\\\nFlan-LongT5-XL & & 61.1\\% & +0.7 \\\\\n\\hline\nHTML-T5-Base (ours) & \\multirow{3}{*}{12K} & 57.0\\% & +3.2 \\\\\nHTML-T5-Large (ours) & & 60.8\\% & +4.5 \\\\\nHTML-T5-XL (ours) & & **63.3**\\% & +2.9 \\\\\n\\hline\nFlan-T5-XL [] & \\multirow{2}{*}{347K} & 75.5\\% & \u2013 \\\\\nFlan-T5-XXL [] & & 79.0\\% & \u2013 \\\\\n\\hline\nHTML-T5-XL (ours) & 347K & **79.4**\\% & \u2013 \\\\ \\hline \\hline\n\\end{tabular}\n\\begin{tabular}{l r r r}\n\\hline \\hline\n**Models** & **Data** & **Success** & **Diff.** \\\\\n\\hline\nCC-Net [] & 2.4M & 32.0\\% & \u2013 \\\\\nWebN-T5-XL [] & 12K & 48.4\\% & \u2013 \\\\\n\\hline\nLongT5-Base & \\multirow{3}{*}{12K} & 53.8\\% & 0.0 \\\\\nLongT5-Large & & 56.3\\% & 0.0 \\\\\nLongT5-XL & & 60.4\\% & 0.0 \\\\\n\\hline\nFlan-LongT5-Base & \\multirow{3}{*}{12K} & 54.1\\% & +0.3 \\\\\nFlan-LongT5-Large & & 56.1\\% & -0.2 \\\\\nFlan-LongT5-XL & & 61.1\\% & +0.7 \\\\\n\\hline\nHTML-T5-Base (ours) & \\multirow{3}{*}{12K} & 57.0\\% & +3.2 \\\\\nHTML-T5-Large (ours) & & 60.8\\% & +4.5 \\\\\nHTML-T5-XL (ours) & & **63.3**\\% & +2.9 \\\\\n\\hline\nFlan-T5-XL [] & \\multirow{2}{*}{347K} & 75.5\\% & \u2013 \\\\\nFlan-T5-XXL [] & & 79.0\\% & \u2013 \\\\\n\\hline\nHTML-T5-XL (ours) & 347K & **79.4**\\% & \u2013 \\\\ \\hline \\hline\n\\end{tabular}\n\n\nTable 4: Average success rate of MiniWoB++ with 56 tasks. We use 12K demonstrations [ 42 ], and compare HTML-T5 among supervised-finetuned baselines [ 24 ,  28 ]. HTML-T5-XL remarkably outperforms WebN-T5 XL, the prior best method, by 14.9%, and HTML-denoising improves the success rate better than instruction tuning. We also finetune HTML-T5 with 347K expert traces [ 19 ], which performs better than Flan-T5-XXL (11B parameters) even with 3B parameters. See  Appendix H  for the detailed results. ",
    "ZHUCHAO JI, JUNYI XIE, AND GENG-RUI ZHANG \n* [JX23b] Zhuchao Ji and Junyi Xie. Homoclinic orbits, multiplier spectrum and rigidity theorems in complex dynamics.  Forum Math. Pi , 11:Paper No. e11, 37, 2023. \n* [Lev14] A. Levy. Aim workshop postcritically finite maps in complex and arithmetic dynamics, 2014. \n* [McM87] Curt McMullen. Families of rational maps and iterative root-finding algorithms. Ann. of Math. (2) , 125(3):467\u2013493, 1987. \n* [Mil06] John Milnor. On Latt`  Dynamics on the Riemann Sphere: A Bodil Branner Festschrift , page 9, 2006. \n* [MS14] Alice Medvedev and Thomas Scanlon. Invariant varieties for polynomial dynamical systems.  Ann. of Math. (2) , 179(1):81\u2013177, 2014. \n* [Nar04] ladys  l aw Narkiewicz.  Elementary and analytic theory of algebraic numbers . Springer Monographs in Mathematics. Springer-Verlag, Berlin, third edition, 2004. \n* [Pak23] Fedor Pakovich. Invariant curves for endomorphisms of  P 1 \u00d7 P 1 .  Math. Ann. , 385(12):259\u2013307, 2023. \n* [Poo17] Bjorn Poonen.  Rational points on varieties , volume 186 of  Graduate Studies in Mathematics . American Mathematical Society, Providence, RI, 2017. \n* [Sil98] Joseph H. Silverman. The space of rational maps on  P 1 .  Duke Math. J. , 94(1):41\u201377, 1998. \n* [Sil07] Joseph H. Silverman.  The arithmetic of dynamical systems , volume 241 of  Graduate Texts in Mathematics . Springer-Verlag, New York, 2007. \n* [Sil12] Joseph H. Silverman.  Moduli spaces and arithmetic dynamics , volume 30 of  CRM Monograph Series . American Mathematical Society, Providence, RI, 2012. \n* [Tuc14] T. Tucker. Problem 6 in the problem list of the aim workshop postcritically finite maps in complex and arithmetic dynamics, 2014. \n* [Xie17] Junyi Xie. The existence of Zariski dense orbits for polynomial endomorphisms of the affine plane.  Compos. Math. , 153(8):1658\u20131672, 2017. \n* [Xie22] Junyi Xie. The existence of Zariski dense orbits for endomorphisms of projective surfaces (with an appendix in collaboration with T. Tucker).  J. Amer. Math. Soc. , 2022. published online. \n* [Xie23] Junyi Xie. Remarks on algebraic dynamics in positive characteristic.  J. Reine Angew. Math. , 797:117\u2013153, 2023. \n* [XY23] Junyi Xie and Xinyi Yuan. Partial heights and the geometric Bombieri-Lang conjecture. arXiv:2305.14789, 2023. \n* [Yua08] Xinyi Yuan. Big line bundles over arithmetic varieties.  Invent. Math. , 173(3):603\u2013 649, 2008. \n* [Zdu14] Anna Zdunik. Characteristic exponents of rational functions.  Bulletin of the Polish Academy of Sciences. Mathematics , 62(3), 2014. \n* [Zha95] Shou-Wu Zhang. Small points and adelic metrics.  J. Algebraic Geom. , 4(2):281\u2013300, 1995. \n* [Zha98] Shou-Wu Zhang. Equidistribution of small points on abelian varieties.  Ann.of Math. (2), 147(1998) , 147:159\u2013165, 1998. \n\nInstitute for Theoretical Sciences, Westlake University, Hangzhou 310030, China \n\nBeijing International Center for Mathematical Research, Peking University, Beijing 100871, China \n\nSchool of Mathematical Sciences, Peking University, Beijing 100871, China ",
    "some additional components are added to the matter distribution due to which the number of unknowns grow that make more challenging to solve the Einstein field equations analytically. In this regard, such analytical solutions developed via gravitational decoupling (GD) with minimal geometric deformation (MGD) method in both cosmology and astrophysics [21, 22]. \n\nMultiple methods studied to investigate important properties of self-gravitating objects, including the phenomenon of stability and hydrodynamic equilibrium, the upper limit of the mass-to-radius ratio, the upper limit of superficial redshift, and dynamics of matter content under energy conditions, etc. [23]. One of these techniques is MGD approach, which was initially intended as an optional means of deforming Schwarzschild space-time in framework of the Randall-Sundrum braneworld [24, 25]. Recently, there is a lot of interest in developing novel analytic and an anisotropic solutions for Einstein field equations, which is a difficult task as Einstein field equations are non-linear and difficult to handle. In this way, the method of MGD to gain new models representing relativistic objects with well-determined characteristics have been proposed [26]. For a compact spherical distribution, the analytical solution of an anisotropic fluid as well as the braneworld model of Tolman IV solution have been found [27]. Two essential components are required in which first one is dimensionless coupling constant\n \\(``\\alpha\"\\)to incorporate an extra source\n into the stress-energy tensor of seed solution. Second one is MGD method on the metric potentials (often on the radial component of metric) in the context of braneworld model. If the seed solution is assumed to be anisotropic, the inclusion of this additional component combined with a static and spherically-symmetric system gives rise to a complex simultaneous equations. The MGD technique separates Einstein field equations into two systems, namely the \u201cEinstein system\u201d and \u201cquasi-Einstein system\u201d, which in comparison to the original system are easy to solve. At this point, a few observations are appropriate, firstly, the decoupled systems satisfy Bianchi Identities and secondly, the extra source may be a scalar, vector, or tensor field [28\u201332]. Moreover, a number of interesting results on the solutions of black hole with 2+1 and 3+1 decomposition obtained in [33\u201336]. Additionally, the solutions of new hairy black hole have just been explored [37], and a mechanism is created as well to turn any non-rotational black hole into a rotational one [38, 39]. \n\nWhen weak gravitational forces are at work, the hypothesis in GR has effectively aligned with many tests carried out within the solar system, demonstrating its success in cosmology. To get more accurate and dependable results, this theory may need to be modified when dealing with high gravitational fields or while being observed on a big scale. These changes may be very important in explaining the phenomena of accelerated expansion. These modifications are termed as modified theories (see, for instance [40\u201347]) \n\nMany modified theories of gravity [48\u201352] are taken into account by changing the Einstein-Hilbert action that is frequently used to study both the existence of dark energy and dark matter as well as the mystery of universe rapid expansion. Geometrical representation and scalar tensor representation of \\(f(G,T)\\)gravity has been presented to\n establish novel junction condition [53]. \n\nSeveral researchers are interested to explore the gravitational collapse phenomena because it is a prominent case in a strong-field regime [54\u201356]. Jordan [57] developed a full gravitational theory which gave the title of a gravitational scalar field to gravitational constant. Brans and Dicke [58] developed a scalar-tensor field theory named as the BransDicke (BD) theory obtained by substituting a time modifying constant G(t) and with the help of a scalar field (\u03a6)\n \\(G(t)\\)and with the help of a scalar field\n \\((\\Phi)\\)\\(G(t)\\)and with the help of a scalar field\n \\((\\Phi)\\)having interaction along with the geometry. Additionally, the well-known scalar field coupling constant or parameter ( \\(\\omega_{BD}\\)) of the BD theory is a constant that can be adjusted to get the desired outcomes in Jordan frame. It is assumed \\(\\Phi\\)is reciprocal of the dynamical gravitational constant, i.e.,\n \\(G(t)=\\frac{1}{\\Phi(t)}\\). The test particles travel along geodesics according to the BD theory, they consequently obey the weak equivalence principle, which states that the gravitational mass and inertial mass are equivalent. Mach principle, agreement with the weak equivalence principle, and Dirac\u2019s large number hypothesis are the main ingredients of the BD theory. This theory includes a metric tensor and a scalar field that describes gravity. \n\n\\(\\Phi\\)describes the fast expansion of the universe, is found by recent study in cosmology, including\n the redshift and distance-luminosity connection of type Ia Supernovae [59]. The evidence for various cosmic concerns, including the late behavior of the universe, cosmic acceleration, and the inflation issue, etc are also supported by the BD theory [60]. This theory has drawn interest in recent years due to its precision in describing early inflationary era and late time expansion of the cosmos. Several authors studied the Friedmann-Lema\u02c6 \u0131tre-Robertson-Walker model in the context of the BD theory [61\u201363]. \n\nThe main purpose of this work is to extend [64] in the BD theory. The paper is organized as follows. The appropriate BD theory for the GD formalism is discussed in Sec. II. In Sec. III, the MGD technique to a spherically symmetric geometry filled with two sources in the BD theory is introduced. In Sec. IV, junction conditions are established to match an outside Schwarzschild line element with the inside solution. In Sec. V, we studied mathematical and physical solutions to the modified field equations using the MGD method with constraints apply to matter density and radial pressure for anisotropy in the setting of the BD theory. In Sec. VI, the physical characteristics of an anisotropic stellar structure with the help of polytropic equation of state are provided. The main results are summarized in Sec. VII. ",
    "# Adaptive Low Rank Adaptation of Segment Anything to Salient Object Detection \n\nRuikai Cui, Siyuan He, and Shi Qiu \n\nAustralian National University {ruikai.cui, siyuan.he, shi.qiu}@anu.edu.au \n\n##### Abstract\nFoundation models, such as OpenAI\u2019s GPT-3 and GPT-4, Meta\u2019s LLaMA, and Google\u2019s PaLM2, have revolutionized the field of artificial intelligence. A notable paradigm shift has been the advent of the Segment Anything Model (SAM), which has exhibited a remarkable capability to segment real-world objects, trained on 1 billion masks and 11 million images. Although SAM excels in general object segmentation, it lacks the intrinsic ability to detect salient objects, resulting in suboptimal performance in this domain. To address this challenge, we present the Segment Salient Object Model (SSOM), an innovative approach that adaptively fine-tunes SAM for salient object detection by harnessing the low-rank structure inherent in deep learning. Comprehensive qualitative and quantitative evaluations across five challenging RGB benchmark datasets demonstrate the superior performance of our approach, surpassing state-of-the-art methods. \n\n##### Keywords:\n**Keywords:**  salient object detection \u00b7 large-scale pre-trained models \u00b7 parameter-efficient fine-tuning. \n\n## Introduction Foundation models [ 3 , 14 , 23 ] have received significant interests in recent years, owing to their exceptional performance across a multitude of diverse tasks These models typically consume billions of parameters, trained on expansive web-scaled datasets for fundamental tasks such as next token prediction [ 6 ] or masked region completion [ 7 ]. A particularly compelling instance of these models is the Segment-Anything Model (SAM) [ 14 ], which has been trained on an unprecedentedly vast dataset comprising 11 million images and 1 billion masks. \n\nDespite the Segment-Anything Model\u2019s (SAM) noteworthy proficiency in generating masks to segment real-world objects, it is deficient in the detection of salient objects. This shortcoming leads to suboptimal performance in isolating a single salient object from a given RGB image, a crucial aspect of computer vision that emphasizes the identification of the most visually striking or attention-demanding object within an image. \n\nTraditional approaches for harnessing the capabilities of foundation models for downstream tasks generally include fine-tuning the entire model [ 11 ] or integrating additional adapter layers [ 9 ]. However, most foundation models possess ",
    "steps can also require considerable amounts of time and compute resources, ranging from 5-12 days [73, 78, 81]. \n\nThe majority of task-specific publications provided access \n\nten publications were applied to more than one language: six publications considered two programming languages, one publication considered three languages, and three publications considered four languages. This results in an average of 1.33 programming languages considered per publication. \n\nIn addition to programming languages considered, we collect training details, such as hardware used and training time \n\nto the full trained models, some of which one needs to request access to [51, 76]. Moreover, there are approaches shared as online tools [44, 49, 86] or IDE extensions [47, 48, 83, 85]. There are also 12 out of 52 publications that did not share the full model, but trained embedding files, which are used by the model. These are marked in Table II with the \u2020 symbol. \n\n## V. T ASK -A GNOSTIC  C ODE  M ODELS \n\nThis section presents task-agnostic code models which share means of representing source code as embeddings, for a variety of downstream tasks. These models are able to transform code snippets to embeddings, which can be fine-tuned to SE tasks. For example, Lu et al. [108] provided fine-tuning details for the CodeXGLUE benchmark, with information for task-specific training and inference time for each task. 3 The fine-tuning time ranges from 2 GPU hours (defect detection) to 60 hours (text-to-code generation, documentation translation). \n\nIn total, we collected 27 task-agnostic models, as shown in \n\nfor each publication. However, those are not always provided. There are 22 out of 52 publications without hardware details (42%) and 26 out of 52 without training time (50%), 33% shared neither information (17 out of 52 publications). The training time of 26 publications with such details ranges from two hours or less [41, 55, 78, 79, 85] to hundreds of hours [47, 53]. While it is common to perform training on GPUs, there are four publications that did not use any GPU for their training procedure, published from 2015\u20132019 [41, 53, 77, 86]. Commonly, publications used a single GPU for training [39, 40, 43, 44, 49, 55, 63, 68, 75, 78\u201380, 87, 88], sometimes in combination with CPUs. The highest amount of GPUs have been used by Svyatkovskiy et al. [47]. They utilized 5 Lambda V100 boxes, with 16 V100 GPUs each, resulting in 80 GPUs. \n\nWhile we focus on the training procedure and the energy \n\nTable III. For each publication, we list the model name and the programming languages it was trained on. If available, we list details on hardware configuration and training times. Among the 27 publications, 52% did not provide training time details (14 out of 27) and 26% did not provide their hardware configurations (7 out of 27). For publications without hardware details, training time is not reported as well. \n\nAmong the publications that shared training time details, the shortest duration is found for code2vec [101], which was \n\nassociated with creating and sharing an ML model, we note the application of such models can vary highly for different SE tasks. Usually, the reported tested times are lower than the required training time (e.g., more than 100 times quicker than training [40, 75, 76]), but in particular, program repair experiments can require long testing times. For example, Chen et al. [55] applied Sequencer for 130 hours to find patches for 75 bugs. White et al. [56] applied their program repair tool DeepRepair for 2,616 days. Data extraction and preparation \n\nT RAINING DETAILS FOR TASK - AGNOSTIC LANGUAGE MODELS . F OR EACH MODEL ,  WE LIST HARDWARE DETAILS ,  TRAINING TIME IN \\(hours\\) AND ESTIMATED ENERGY CONSUMPTION IN \\(kWh\\),  IF THE INFORMATION IS AVAILABLE . \n\n\\begin{tabular}{c l c c r r}\n\\hline \\hline\nApproach & Year & Language & Hardware & Time in hours & kWh \\\\\n\\hline\nBLOOM [] & 2022 & Java, PHP, C++, Python, JavaScript, C\\#, Ruby, Lua, TypeScript, GO, C, Scala, Rust & server: 384 NVIDIA A100 GPUs, 80 GB & 1,082,990 & 433,196 \\\\\nProphetnet-x [] & 2021 & Go, Java, JS, Php, Python, Ruby & NVIDIA Tesla V100 GPUs & 30,000 & 15,330 \\\\\nCodeBERT [] & 2020 & Python, Java, JavaScript, PHP, Ruby, Go & server: 16 NVIDIA Tesla V100 GPUs, 32 GB & 1,320 & 10,610 \\\\\nDobf [] & 2021 & Java, Python & 32 NVIDIA V100 GPUs & 192 & 3,080 \\\\\nCodet5 [] & 2021 & Ruby, JavaScript, Go, Python, Java, Php, C, C\\# & server/cluster: 16 NVIDIA A100 GPUs, 40 GB & 288 & 1,930 \\\\\nPLBART [] & 2021 & Java, Python & 8 NVIDIA RTX 2080 Ti GPUs & 276 & 925 \\\\\nMastropaolo et al. [] & 2021 & Java & Google Cloud, Colab: 8 TPUs, 35.5 GB memory & 343 & 766 \\\\\nGraphcodebert [] & 2021 & Ruby, JS, Go, Python, Java, PHP & server: 32 NVIDIA Tesla V100 GPUs, 32 GB & 83 & 667 \\\\\nCodeTrans [] & 2021 & Python, Java, JavaScript, PHP, Ruby, Go, C\\#, SQL, LISP & 1 TPU v3-8 & 2,088 & 582 \\\\\nGREAT [] & 2022 & Python & 1 Tesla P100 GPU & 120 & 51 \\\\\nJavabert [] & 2021 & Java & 3 NVIDIA Titan X GPUs, 12 GB & 24 & 30 \\\\\ncode2vec [] & 2019 & Java & 1 NVIDIA Tesla K80 GPU & 36 & 18 \\\\\nOpenVocabCodeNLM [] & 2020 & Java, Python, C & GPUs & 336 & - \\\\\nGraphCode2Vec [] & 2022 & Java & server: 40 CPUs@2.20GHz, 256GB; 1 NVIDIA Tesla V100 GPU & - & - \\\\\nSpt-code [] & 2022 & Java, Python, JavaScript, PHP, GO, Ruby & 4 NIVDIA A100s9 GPUs & - & - \\\\\nStructCoder [] & 2022 & Java, Python, PHP, JavaScript & 4 RTX 8000 GPUs, 48GB & - & - \\\\\nCodex [] & 2021 & Python & Azure & - & - \\\\\nCotext [] & 2021 & Python, Java, JavaScript, PHP, Ruby, Go & 1 TPU v2-8 & - & - \\\\\nCuBERT [] & 2020 & Python & TPUs & - & - \\\\\nTSSA [] & 2020 & Java & 1 NVIDIA P100 GPU, 16 GB; 1 K80 GPU, 16GB memory & - & - \\\\\nCodeGPT [] & 2021 & Python, Java & - & - & - \\\\\nContraCode [] & 2021 & JavaScript & - & - & - \\\\\nCodeTransformer [] & 2021 & Python, JavaScript, Ruby, GO & - & - & - \\\\\nDAMP [] & 2020 & Java, C\\# & - & - & - \\\\\nObfuscated Code2Vec [] & 2020 & Java & - & - & - \\\\\ncode2seq [] & 2019 & Java, C\\# & - & - & - \\\\\nEfstathiou and Spinellis [] & 2019 & Java, Python, C++, C\\#, C, PHP & - & - & - \\\\ \\hline \\hline\n\\end{tabular}\n",
    "For the fourth property we need to find a value for \\(\\beta\\) such that \\(|Opt(G)-|I_{F}||\\leq\\beta|Opt(T_{G},T^{\\prime}_{G})-|F||\\)covered\n by 6\n We\n know\n . Let \\(\\ell=|I_{F}|\\) be the number of \\(A_{v}\\) in \\(F^{\\prime\\prime}\\)that are covered by 6 components. We know that \\(|F|\\geq|F^{\\prime}|\\geq|F^{\\prime\\prime}|=12n-\\ell\\). Observe: \n\n\\[|Opt(T_{G},T^{\\prime}_{G})-|F|| =|F|-Opt(T_{G},T^{\\prime}_{G})\\] \\[\\geq|F^{\\prime\\prime}|-Opt(T_{G},T^{\\prime}_{G})\\] \\[=12n-\\ell-Opt(T_{G},T^{\\prime}_{G})\\] \\[=12n-\\ell-(12n-k)\\] \\[=k-\\ell\\] \\[=|Opt(G)-|I_{F}||\\]  \n\nSo we pick \\(\\beta=1\\)and we are done.\n \n\n## A tight 7k kernel \n\nRecall the definitions of common subtrees and common chains from the preliminaries. It is well-known that the following two polynomial-time reduction rules do not alter the size of the uMAF [2]: \n\n**Subtree reduction.**  If \\(T\\) and \\(T^{\\prime}\\)have a maximal common pendant subtree \\(S\\) with at least two leaves, then reduce \\(T\\) and \\(T^{\\prime}\\)to \\(T_{r}\\) and \\(T^{\\prime}_{r}\\), respectively, by replacing \\(S\\) with a single leaf with a new label. \n\nChain\n  If \\(T\\) and \\(T^{\\prime}\\)have a maximal common \\(n\\)-chain \\(C=(\\ell_{1},\\ell_{2},\\ldots,\\ell_{n})\\)with\n \\(n\\geq 4\\), then reduce\n \\(T\\) and \\(T^{\\prime}\\)to \\(T_{r}=T|X\\setminus\\{\\ell_{4},\\ell_{5},\\ldots,\\ell_{n}\\}\\) and \\(T_{r}^{\\prime}=T^{\\prime}|X\\setminus\\{\\ell_{4},\\ell_{5},\\ldots,\\ell_{n}\\}\\), respectively. \n\nWhen applied to exhaustion on two unrooted binary trees, at which point we say the trees are _ fully reduced_ , these rules yield an instance with (ignoring additive terms) at most \\(15k\\) taxa [10], where \\(k\\) is the size of the uMAF 3 , and the analysis is tight. \n\nNote that applying the subtree or chain reduction to a caterpillar produces a new caterpillar. In this section we will show that, when applied to exhaustion on two caterpillars, a much smaller kernel is obtained than on general unrooted binary trees. \n\n**Theorem 4.** _ There is a 7k kernel for uMAF on caterpillars using only the common chain_ _and subtree reductions, and this is tight up to a constant additive term._ 3 The kernel bound given in [10] is in terms of TBR distance, rather than uMAF, but as noted earlier these quantities only differ by 1, so only additive terms are affected. ",
    "all \\(p_{i}\\)\u2019s are integers and \\(B=\\frac{4ac^{*}}{\\varepsilon}\\). We can compute\n \\(\\min(h_{{{\\mathcal{I}}}^{0}_{1}}(x),B)\\)exactly using standard\n time.\n \n\n.\n \n\ndynamic programming in \\(O(|{{\\mathcal{I}}}^{0}_{1}|\\cdot B)=\\widetilde{O}(\\frac{1}{\\varepsilon^{2}})\\)\n\nfunction\n \n\n\n\nThe complexity of the resulting function is \\(O(|{{\\mathcal{I}}}^{0}_{1}|)=\\widetilde{O}(\\frac{1}{\\varepsilon})\\)\n\nwith a\n In \\(\\widetilde{O}(n+\\frac{1}{\\varepsilon^{2}})\\)of\n \\(\\widetilde{O}(n+\\frac{1}{\\varepsilon^{2}})\\)time, we can compute a function\n \\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{3}}\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{3}}\\)that approximates\n \\(\\min(f_{{{\\mathcal{I}}}^{0}_{3}},\\frac{4c^{*}}{\\varepsilon^{3/2}})\\)as \\(a\\leqslant\\frac{1}{\\varepsilon^{1/2}}\\).\n factor of\n \\(1+\\widetilde{O}(\\varepsilon)\\)and\n via Lemma 7. The additive error caused by\n \\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{3}}\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{3}}\\)is at most \\(\\widetilde{O}(\\varepsilon\\cdot\\frac{4c^{*}}{\\varepsilon^{3/2}})\\leqslant \\widetilde{O}(\\frac{1}{a\\varepsilon})\\)\\(\\widetilde{O}(\\varepsilon\\cdot\\frac{4c^{*}}{\\varepsilon^{3/2}})\\leqslant \\widetilde{O}(\\frac{1}{a\\varepsilon})\\) , and the complexity of \\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{3}}\\)\n\ntwo\n \n\n\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{3}}\\)is \\(\\widetilde{O}(\\frac{1}{\\varepsilon})\\)\\(\\widetilde{O}(\\frac{1}{\\varepsilon})\\)\n\n_ and_ _, respectively. We can approximate_ \\(\\min(f_{{{\\mathcal{I}}}^{0}_{3}},\\frac{4c^{*}}{\\varepsilon^{3/2}})\\)Lemma\n _ Let_ \\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}\\)_and_ \\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{3}}\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{3}}\\)_be two functions that approximate_ \\(\\operatornamewithlimits{max}\\limits(f_{{{\\mathcal{I}}}^{0}_{1}},p({{\\mathcal{I }}}^{0}_{1})-\\frac{4c^{*}}{\\varepsilon^{3/2}})\\)_ time._ _ with additive error_ \\(\\widetilde{O}(\\frac{1}{a\\varepsilon})\\)\\(\\widetilde{O}(\\frac{1}{a\\varepsilon})\\)_ and complexity_ \\(\\widetilde{O}(\\frac{1}{\\varepsilon})\\)\\(\\widetilde{O}(\\frac{1}{\\varepsilon})\\)_ and complexity_ \n\n\\(\\widetilde{O}(\\frac{1}{\\varepsilon})\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}\\)\n\n\\(\\widetilde{O}(\\frac{1}{\\varepsilon})\\)_ in_ \\(\\widetilde{O}(\\frac{a^{2}}{\\varepsilon})\\)\n\na\n \n\n\\(\\widetilde{O}(\\frac{a^{2}}{\\varepsilon})\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}\\oplus\\widetilde{f}_{{{\\mathcal{I}}}^{0 }_{3}}\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}\\oplus\\widetilde{f}_{{{\\mathcal{I}}}^{0 }_{3}}\\)_with additive error_ \\(\\widetilde{O}(\\frac{1}{a\\varepsilon})\\)\\(\\widetilde{O}(\\frac{1}{a\\varepsilon})\\)\n\n_Proof._  Let \\(u=\\operatornamewithlimits{max}\\limits(0,p({{\\mathcal{I}}}^{0}_{1})-\\frac{4c^{* }}{\\varepsilon^{3/2}})\\). Since\n . Note that\n \\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}\\).\n \\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}\\)have a range contained in\n \\([u,p({{\\mathcal{I}}}^{0}_{1})]\\), so\n \\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}-u+1\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}-u+1\\)have a range contained in\n \\([1,\\frac{4c^{*}}{\\varepsilon^{3/2}}+1]\\)\\[\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}\\oplus\\widetilde{f}_{{{\\mathcal{I}}}^{0 }_{3}}=\\left((\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}-u+1)\\oplus\\widetilde{f}_ {{{\\mathcal{I}}}^{0}_{3}}\\right)+u-1.\\]  ,\n \\[\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}\\oplus\\widetilde{f}_{{{\\mathcal{I}}}^{0 }_{3}}=\\left((\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}-u+1)\\oplus\\widetilde{f}_ {{{\\mathcal{I}}}^{0}_{3}}\\right)+u-1.\\]  suffices\n , therefore,\n To approximate \\((\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}-u+1)\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}\\oplus\\widetilde{f}_{{{\\mathcal{I}}}^{0 }_{3}}\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}\\oplus\\widetilde{f}_{{{\\mathcal{I}}}^{0 }_{3}}\\), it suffices to approximate\n \\((\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}-u+1)\\oplus\\widetilde{f}_{{{\\mathcal{I }}}^{0}_{3}}\\)_ _ with an additive error . We can approximate the two\n . Both\n \\((\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}-u+1)\\)and\n allowed\n \\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{3}}\\)have ranges contained in \\(\\{0\\}\\cup[1,\\frac{4c^{*}}{\\varepsilon^{3/2}}+1]\\)of \\(\\widetilde{O}(\\frac{1}{a\\varepsilon})\\)\\(\\widetilde{O}(\\frac{1}{a\\varepsilon})\\)time. The complexity of the resulting function\n the approximation factor we are allowed to incur is\n \\(1+\\widetilde{O}(\\frac{\\varepsilon^{1/2}}{a})\\)  .\n functions via Lemma 4 using \\(\\widetilde{O}(\\frac{1}{\\varepsilon}+\\frac{a^{2}}{\\varepsilon})=\\widetilde{O}( \\frac{a^{2}}{\\varepsilon})\\)\\(\\widetilde{O}(\\frac{1}{\\varepsilon}+\\frac{a^{2}}{\\varepsilon})=\\widetilde{O}( \\frac{a^{2}}{\\varepsilon})\\)\n\n_ with_ \n\nis \\(\\widetilde{O}(\\frac{a}{\\varepsilon^{1/2}})\\leqslant\\widetilde{O}(\\frac{1}{ \\varepsilon})\\)\\(\\widetilde{O}(\\frac{a}{\\varepsilon^{1/2}})\\leqslant\\widetilde{O}(\\frac{1}{ \\varepsilon})\\)\n\n**Lemma 14.** _ Let_ \\(g\\)_ be a function that approximates_ \\(\\operatornamewithlimits{max}\\limits(f_{{{\\mathcal{I}}}^{0}_{1}},p({{\\mathcal{I }}}^{0}_{1})-\\frac{4c^{*}}{\\varepsilon^{3/2}})\\oplus\\min(f_{{{\\mathcal{I}}}^{0 }_{3}},\\frac{4c^{*}}{\\varepsilon^{3/2}})\\)_. We can approximate_ \\(g\\oplus f_{{{\\mathcal{I}}}^{0}_{2}}\\)_with additive error_ _ time._ _ and complexity_ \\(\\widetilde{O}(\\frac{1}{\\varepsilon})\\)\\(\\widetilde{O}(\\frac{1}{\\varepsilon})\\)_additive error_ \\(\\widetilde{O}(\\frac{1}{a\\varepsilon})\\)complexity\n \\(\\widetilde{O}(\\frac{1}{a\\varepsilon})\\)\\(\\widetilde{O}(\\frac{1}{a\\varepsilon})\\)\\(\\widetilde{O}(\\frac{1}{a\\varepsilon})\\)_ and complexity_ \n\n\\(\\widetilde{O}(\\frac{1}{\\varepsilon})\\)\n\n\\(\\widetilde{O}(\\frac{1}{\\varepsilon})\\)_ in_ \\(\\widetilde{O}(\\frac{1}{\\varepsilon^{2}})\\)\\(\\widetilde{O}(\\frac{1}{\\varepsilon^{2}})\\)\n\ndistinct profits. By dividing\n \\({{\\mathcal{I}}}^{0}_{2}\\)into groups by profits, and merging the functions for the groups via Lemma 5(ii), we can compute a function _Proof._  The items in \\({{\\mathcal{I}}}^{0}_{2}\\)have at most \\(O(\\delta)=\\widetilde{O}(\\frac{1}{\\varepsilon^{1/2}})\\)in time\n \\(O(|{{\\mathcal{I}}}_{2}|+\\frac{1}{\\varepsilon^{2}})\\leqslant O(n+\\frac{1}{ \\varepsilon^{2}})\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{2}}\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{2}}\\)that approximates \\(f_{{{\\mathcal{I}}}^{0}_{2}}\\)with factor\n \\(1+O(\\varepsilon)\\)and complexity\n \\(\\widetilde{O}(\\frac{1}{\\varepsilon})\\)\\(\\widetilde{O}(\\frac{1}{\\varepsilon})\\)time.\n time. The additive error of\n \\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{2}}\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{2}}\\)is at most \\(O(\\varepsilon)\\cdot f_{{{\\mathcal{I}}}^{0}_{2}}(t)\\leqslant O(\\frac{1}{a \\varepsilon})\\). Merging\n \\(g\\) and \\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{2}}\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{2}}\\)via Lemma 4(i) takes \n\n\n\n\\(\\widetilde{O}(\\frac{1}{\\varepsilon^{2}})\\)\\(\\widetilde{O}(\\frac{1}{\\varepsilon^{2}})\\)\n\n_ within the domain_ \\([b_{1},b_{0}]\\)_._ Lemma\n _ In_ \\(\\widetilde{O}(n+\\frac{1}{\\varepsilon^{2}})\\)\\(\\widetilde{O}(n+\\frac{1}{\\varepsilon^{2}})\\)_ time, we can compute a function with complexity_ \\(\\widetilde{O}(\\frac{1}{\\varepsilon})\\)\\(\\widetilde{O}(\\frac{1}{\\varepsilon})\\)\n\n\n\n_ that approx_ _imates_ \\(f_{{\\mathcal{I}}}\\)_ with additive error_ \\(\\widetilde{O}(\\frac{1}{a\\varepsilon})\\)\\(\\widetilde{O}(\\frac{1}{a\\varepsilon})\\)\n\ntime.\n _Proof._  Computing \\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{3}}\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{1}}\\)that approximates\n \\(\\operatornamewithlimits{max}\\limits(f_{{{\\mathcal{I}}}^{0}_{1}},p({{\\mathcal{I }}}^{0}_{1})-\\frac{4c^{*}}{\\varepsilon^{3/2}})\\)via Lemma\n takes\n \\(\\widetilde{O}(\\frac{1}{\\varepsilon^{2}})\\)\\(\\widetilde{O}(\\frac{1}{\\varepsilon^{2}})\\)time. Finally,\n time. Computing \\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{3}}\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{3}}\\)that approximates\n \\(\\min(f_{{{\\mathcal{I}}}^{0}_{3}},\\frac{4c^{*}}{\\varepsilon^{3/2}})\\)via Lemma\n takes\n \\(\\widetilde{O}(n+\\frac{1}{\\varepsilon^{2}})\\)\\(\\widetilde{O}(n+\\frac{1}{\\varepsilon^{2}})\\)time. The total additive error is bounded\n Computing a function \\(g\\) that approximates \\(\\widetilde{O}(\\frac{a(r_{0}-\\ell_{0})}{\\varepsilon})\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}_{1}}\\oplus\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{3}}\\)\\(\\widetilde{f}_{{{\\mathcal{I}}}_{1}}\\oplus\\widetilde{f}_{{{\\mathcal{I}}}^{0}_{3}}\\)takes\n \\(\\widetilde{O}(\\frac{a^{2}}{\\varepsilon})\\)additive\n \\(\\widetilde{O}(\\frac{a^{2}}{\\varepsilon})\\), and the total running time is\n approximating \\(g\\oplus f_{{{\\mathcal{I}}}^{0}_{2}}\\)takes\n \\(\\widetilde{O}(\\frac{a(r_{0}-\\ell_{0})}{\\varepsilon})\\)\\(\\widetilde{O}(\\frac{a(r_{0}-\\ell_{0})}{\\varepsilon})\\)by \\(\\widetilde{O}(\\frac{1}{a\\varepsilon})\\)\\(\\widetilde{O}(\\frac{1}{a\\varepsilon})\\)\\[\\widetilde{O}(n+\\frac{1}{\\varepsilon^{2}}+\\frac{a^{2}}{\\varepsilon})\\leqslant \\widetilde{O}(n+\\frac{1}{\\varepsilon^{2}}).\\]  \\[\\widetilde{O}(n+\\frac{1}{\\varepsilon^{2}}+\\frac{a^{2}}{\\varepsilon})\\leqslant \\widetilde{O}(n+\\frac{1}{\\varepsilon^{2}}).\\]  ",
    "Many of the earlier mathematical works on r csp s focused on determining their satisfiability thresholds and verifying the sharpness of  sat - unsat  transitions. For models that are known not to exhibit  rsb , such goals were established. These models include random 2- sat  [ CR92 , BBC + 01 ], random 1- in - \\(k\\)- sat  [ ACIM01 ], \\(k\\)- xor-sat  [ DM02 ,  DGM + 10 ,  PS16 ], and random linear equations [ ACOGM20 ]. On the other hand, for the models which are predicted to belong to 1 rsb  class, intensive studies have been conducted to estimate their satisfiability threshold, as shown in [ KKKS98 , AP04 , COP16 ] (random \\(k\\)- sat ), [ AM06 , COZ12 , COP12 ] (random \\(k\\)- nae-sat ), and [ AN05 , CO13 , COV13 , COEH16 ] (random graph coloring). \n\nMore recently, the satisfiability thresholds for r csp s that exhibits  rsb  have been rigorously determined for several models, namely the random regular \\(k\\)- nae-sat  [ DSS16b ], maximum independent set on \\(d\\)-regular graphs [ DSS16a ], random regular \\(k\\)- sat  [ COP16 ] and random \\(k\\)- sat  [ DSS22 ] for large \\(k\\) and \\(d\\). Although determining the location of \\(q\\)-colorability threshold for the sparse Erdos Renyi graph is left open, the \\(q\\)determining the location of q-colorability threshold for the sparse Erdos Renyi graph is left open, the condensation threshold \u03b1cond for random graph coloring, where the free energy becomes non-analytic, was settled\n \\(\\alpha_{\\sf cond}\\)for random graph coloring, where the free energy becomes non-analytic, was settled\n \\(\\alpha_{\\sf cond}\\) for random graph coloring, where the _ free energy_  becomes non-analytic, was settled in [ BCOH + 16 ]. They carried out a technically challenging analysis based on a clever \u201cplanting\u201d technique, where the results were further generalized to other models in [ COKPZ18 ]. Similarly, [ BCO16 ] identified the condensation threshold for random regular \\(k\\)- sat , where each variable appears \\(d/2\\)-times positive and\n \\(d/2\\)-times negative. Further, in the condensation regime\n \\(\\alpha\\in(\\alpha_{\\sf cond},\\alpha_{\\sf sat})\\), many quantities of interest was\n established for random regular \\(k\\)- nae-sat  with large enough \\(k\\), matching the statistical physics prediction. Namely, the number of solutions at exponential scale (free energy) [ SSZ22 ], the concentration of the _ overlap_  [ NSS20 ,  NSS21 ], and the local weak limit [ SS23 ] were established. Establishing the same quantities for other models in the condensation regime is left open. \n\nThe closest result to ours in the literature is by Ayre, Coja-Oghlan, and Greenhill [ ACOG22 ], where they lower bound the chromatic number (or equivalently, upper bound the colorability threshold) of the random regular graph of any degree, which is conjectured to be tight. [ ACOG22 ] also considers the sparse Erdos Renyi graph, which is more complicated since the conjectured chromatic number is defined in terms of a distributional (rather than real-valued) optimization due to the randomness of the local neighborhoods. In this work, we do not consider Erdos Renyi type problems, but we additionally address the question of the uniqueness of the  bp  fixed point for any \\(k\\geq 3\\)an\n (unique solution to the equation (\n 1.1 )). As in [ ACOG22 ], \\(k\\)gi\ny\n(\n-nae-sat model. It would be interesting to address the uniqueness of the bp fixed point\n \\(k\\)- nae-sat  model. It would be interesting to address the uniqueness of the  bp  fixed point for random \\(k\\)- nae-sat  and random \\(k\\)-sat for small \\(k\\geq 3\\). We refer to [\n ST03 , MRSY19 , YP22 , GP23 ] which addresses the uniqueness of  bp  fixed point for various models. \n\n### Proof methods We aim to rigorously establish the upper bound the satisfiability threshold predicted by the so-called \u20181 rsb  cavity method\u2019 from statistical physics [ DRZ08 ]. To do so, instead of using moment methods, we use a technique called \u2018interpolation method\u2019 from the theory of spin glasses developed by [ FL03 , Gue03 , PT04 ]. The interpolation method has been successful in upperbounding the satisfiability threshold for random \\(k\\)sat  [ DSS15 ] for large \\(k\\), the free energy for random regular \\(k\\)- nae-sat  [ SSZ16 ], and the colorability threshold for random graphs [ ACOG22 ]. \n\nWe first introduce the notations and mathematical framework that we use throughout the paper. For both the \\(d\\)-regular \\(k\\)-uniform hypergraphs and the \\(k\\)- nae-sat  formula, we can represent them as (labelled) \\((d,k)\\)-regular bipartite graph. Let\n \\(V=\\{v_{1},\\ldots,v_{n}\\}\\)formed\n  be the set of variables or nodes and \\(F=\\{a_{1},\\ldots,a_{m}\\}\\)or\n be the set of clauses or hyperedges. An edge is formed if the variable or node \\(v_{i}\\) is included in the clause or hyperedge \\(a_{j}\\). For an edge \\(e\\), we denote \\(v(e)\\)(resp.\n \\(a(e)\\)) by the variable (resp. clause) adjacent to it.\n \n\nDenote \\(G=(V,F,E)\\)by the resulting bipartite graph. We denote the neighborhood of\n \\(v\\in V\\) (resp. \\(a\\in F\\)) by \\(\\delta v:=\\{a\\in F:(av)\\in E\\}\\)formula,\n  (resp. \\(\\delta a:=\\{v\\in V:(av)\\in E\\}\\)extra\n ). Throughout, we denote \\(\\alpha\\equiv\\frac{m}{n}=\\frac{d}{k}\\). For the  nae-sat  formula, there is an extra label for each edge \\(e\\in E\\), namely the _ literal_ \\(\\texttt{L}_{e}\\in\\{0,1\\}\\), which specifies how the variable \\(v(e)\\)participates in the clause\n \\(a(e)\\). Then, the labelled graph\n \\(\\mathcal{G}=(V,F,E,\\underline{\\texttt{L}})\\equiv(V,F,E,(\\texttt{L}_{e})_{e\\in E})\\)represents a\n  nae-sat  instance. \n\nDefinition\n  Given a  nae-sat  instance \\(\\mathcal{G}=(V,F,E,\\underline{\\texttt{L}})\\),\n \\(\\underline{x}\\in\\{0,1\\}^{V}\\)is a ( nae-sat ) ** solution**  if \\[\\prod_{a\\in F}\\varphi((x_{v(e)}\\oplus\\texttt{L}_{e})_{e\\in\\delta a})=1\\,,\\]  ",
    "expanding box like model valid for both radially and temporally varying spherical flows. The generalisation of the expanding box model to radially varying flows was done in Tenerani & Velli  ( 2017 ). The generalisation to background flows which are also time dependant, motivated by the stellar formation problem, results in a model close to the accelerated expanding box (although our treatment of pressure will be closer to the distorted shearing box models of  Ogilvie & Latter  ( 2013 );  Ogilvie & Barker  ( 2014 )). We shall focus, in this paper, on the hydrodynamic case as it posses a number of important features that are worth understanding before generalising to MHD. \n\nIn Section  2  we present the derivation of our local model. Sections  2.4  and  2.5  derives symmetries and conservation laws of the local model. Section  3  presents some nonlinear solutions to the local model - and discuss how these relate to the global problem. In Section  4  we derive the linear theory of our local model. We discuss possible extension of our model in Section  5 . We present our conclusions in Section  6  and additional mathematical details (including alternative formulations which maybe more convenient for implementation in hydrocodes) are presented in the appendices. \n\n## DERIVATION \n\n### Global geometry \n\n\\[Du^{\\theta}+\\frac{2}{R}u^{R}u^{\\theta} =-R^{-2}\\left(\\partial_{\\theta}\\Phi+\\frac{1}{\\rho}\\partial_{ \\theta}p\\right),\\] (6) \\[Du^{\\phi}+\\frac{2}{R}u^{R}u^{\\phi} =-R^{-2}\\left(\\partial_{\\phi}\\Phi+\\frac{1}{\\rho}\\partial_{\\phi}p \\right),\\] (7) \\[Du^{R}-Ru^{\\phi}u^{\\phi}-Ru^{\\theta}u^{\\theta} =-\\left(\\partial_{R}\\Phi+\\frac{1}{\\rho}\\partial_{R}p\\right),\\] (8) \\[D\\rho =-\\rho R^{-2}\\partial_{i}(R^{2}u^{i}),\\] (9)  \n\n\\(o\\), located on the\n \\(o\\), located on the equator of a sphere of radius \\(R\\). The line element of the usual spherical polar coordinate system is \n\n\n\n\\[\\mathrm{d}s^{2}=\\mathrm{d}R^{2}+R^{2}(\\mathrm{d}\\theta^{2}+\\sin^{2}\\theta\\, \\mathrm{d}\\phi^{2}).\\] (1)  \n\nwhere the Lagrangian derivative is \n\nWe are interested in describing the local dynamics near to \\(p\\)occurring on a horizontal lengthscale \\(L_{\\rm H}\\ll R\\)(See Figure \n\n\\[D=\\partial_{t}+u^{i}\\partial_{i}.\\] (10)  \n\nNote, we have listed the \\(R\\)component of the momentum \n\n1 , which show the relationship between the global and local geometries). Without loss of generality, we can locate our local model on the equator of the sphere ( \\(\\theta=\\pi/2\\)) meaning\n we can approximate the line element by \n\nequation last as it will become the \\(z\\)momentum equation in the local coordinate system. To close this system of equations we must supplement them with an equation of state determining \\(p\\), which we assume is barotropic, \n\n\\[\\mathrm{d}s^{2}=\\mathrm{d}R^{2}+R^{2}(\\mathrm{d}\\theta^{2}+\\mathrm{d}\\phi^{2}) +\\mathcal{O}((L_{\\rm H}/R)^{2}d\\phi^{2}),\\] (2)  \n\nwhich results in metric tensor components, \n\n\\[p=p(\\rho).\\] (11)  \n\n\\[g_{RR}=1,\\quad g_{\\theta\\theta}=g_{\\phi\\phi}=R^{2},\\] (3)  \n\nand inverse metric tensor components \n\n### Spherical Collapse/Expansion \n\n\\[g^{RR}=1,\\quad g^{\\theta\\theta}=g^{\\phi\\phi}=R^{-2},\\] (4)  \n\nwith all other components zero. The Christoffel Symbols components, for this coordinate system, are \n\n\\[\\begin{split}\\Gamma_{\\theta\\theta}^{R}&=\\Gamma_{\\phi\\phi}^{R}=-R, \\\\ \\Gamma_{\\theta R}^{\\theta}=\\Gamma_{R\\theta}^{\\theta}&=\\Gamma_{\\phi R}^{\\phi}= \\Gamma_{R\\phi}^{\\phi}=R^{-1},\\end{split}\\] (5)  \n\n\\(\\Phi=\\Phi(t,R)\\). Con-\n \\(\\Phi=\\Phi(t,R)\\)\\(\\Phi=\\Phi(t,R)\\)tially time dependant) central potential \u03a6 = \u03a6(\ud835\udc61, \ud835\udc45). Consider a spherically symmetric fluid in this potential with\n density \\(\\rho_{0}=\\rho_{0}(R,t)\\) and purely radial velocity field \\(U^{i}=U(R,t)\\hat{e}_{R}^{i}\\). The density of the fluid then evolves according to the continuity equation, \n\n\n\nwith all others vanishing. The fluid equations in this coordinate system are \n\n\\[D_{0}\\rho_{0}=-\\rho_{0}R^{-2}\\partial_{R}(R^{2}U),\\] (12)  \n\n**Figure 1.**  Geometry of the domain. Globally (left) the domain is bounded by radial shells which can approach or recede from each other depending on the gradients in the background velocity. Points within the domain move in the radial direction due to the spherically symmetric background flow. The local model (right) is a rectangular domain where the horizontal coordinates are equivalent to the latitude/longitude on the sphere and the vertical direction moves between spherical shells comoving with the background flow. The aspect ratio of this local box changes as the distance between the spherical shells varies. ",
    "with unified pipeline design and multi-scale attention mechanism presents the best localization performance on all three subsets. \n\nIn [ 16 ], they use the Scale set to analyze the model\u2019s robustness against scale transformation. To further verify the effectiveness of the multi-scale attention mechanism. We also use Scale set to evaluate our models and the result as shown in Tab 5. In the Scale set, the spliced region is only processed with scale transformation of different degrees for ablation in [ 16 ]. It contains 9000 testing pairs and is equally divided into Difficult, Normal, Easy subsets. In the Difficult subset and Normal subset, there are more samples with larger scale degrees. On the contrary, in the Easy subset, the size of the spliced region between the two images tends to be more consistent. We can see that with the help of multi-scale attention mechanism, MSTAF achieves much better localization performance than TAF on the Normal and difficult subset. It demonstrates that MSTAF has an advantage in dealing with various scale transformation samples. After introducing the multi-scale attention mechanism, MSTAF is more robust against scale transformation. The visual comparison can refer to Fig. 6 and Fig. 7. \n\n## CONCLUSION In this work, we propose a Multi-scale Target-Aware Framework to simplify the pipeline of existing methods. It adopts self-attention for feature extraction and cross-attention for correlation match ing simultaneously. This unified design enables feature extraction and correlation matching to mutually promote each other, thereby enhancing the matching performance of the model. We further design a multi-scale attention mechanism to model the matching between image patches of different scales, which further improves the robustness against scale transformation. Experiment results demonstrate that our model is robust against scaling and outper forms state-of-the-art methods. \n\nWe design a unified pipeline implemented by Target-Aware Attention Framework (TAF), which is different from the separate pipeline used by existing methods. In order to evaluate the effec tiveness of the unified pipeline, we built a separate pipeline model for comparison. The TAF-separate model adopts the same architecture as TAF. It implements self-attention for both two heads of all Target-Aware Attention modules in the front, while the last Target-Aware Attention module only implements cross-attention for both two heads. We use the Synthetic dataset to conduct ablation study, the results are shown in Table 4. By comparing the TAF-separate model and the TAF model, we can see that the TAF with unified pipeline performs better than the separate pipeline. After introducing the multi-scale projection mechanism to achieve multi-scale attention, the MSTAF-separate and MSTAF models both showed improvements in localization performance. The MSTAF \n\nThis work was supported in part by the Natural Science Foundation of China under Grant 62001304; in part by the Guangdong Basic and Applied Basic Research Foundation under Grant 2022A1515010645; in part by the Foundation for Science and Technology Innovation of Shenzhen under Grant RCBS20210609103708014 and the Key \n\n**Table 4: Ablation study on the Synthetic set** \n\n\\begin{tabular}{c|c c c|c c c|c c c}\n\\hline\n\\multirow{2}{*}{Model} & \\multicolumn{3}{|c|}{Difficult} & \\multicolumn{3}{|c|}{Normal} & \\multicolumn{3}{|c}{Easy} \\\\\n\\cline{2-10}\n & IoU & MCC & NMM & IoU & MCC & NMM & IoU & MCC & NMM \\\\\n\\hline\nTAF-separate & 0.6239 & 0.7167 & 0.2963 & 0.8738 & 0.9143 & 0.7744 & 0.9490 & 0.9604 & 0.9164 \\\\\nMSTAF-separate & 0.7712 & 0.8432 & 0.5670 & 0.9210 & 0.9486 & 0.8583 & 0.9693 & 0.9764 & 0.9488 \\\\\n\\hline\nTAF & 0.8001 & 0.8586 & 0.6312 & 0.9379 & 0.9605 & 0.8937 & 0.9753 & 0.9811 & 0.9617 \\\\\nMSTAF & **0.8394** & **0.8918** & **0.7064** & **0.9510** & **0.9700** & **0.9151** & **0.9788** & **0.9838** & **0.9646** \\\\ \\hline\n\\end{tabular}\n\n\n**Table 5: Ablation study on the Scale set** \n\n\\begin{tabular}{c|c c c|c c c|c c c}\n\\hline\n\\multirow{2}{*}{Model} & \\multicolumn{3}{|c|}{Difficult} & \\multicolumn{3}{|c|}{Normal} & \\multicolumn{3}{|c}{Easy} \\\\\n\\cline{2-10}\n & IoU & MCC & NMM & IoU & MCC & NMM & IoU & MCC & NMM \\\\\n\\hline\nTAF & 0.7009 & 0.7644 & 0.4400 & 0.8789 & 0.9160 & 0.7807 & 0.9704 & 0.9769 & 0.9550 \\\\\nMSTAF & **0.7427** & **0.8022** & **0.5206** & **0.9105** & **0.9410** & **0.8406** & **0.9752** & **0.9808** & **0.9602** \\\\ \\hline\n\\end{tabular}\n\n\n**Figure 8: Visualization of attention maps. The blue point** **represents the token we selected to present attention maps.** **Stage i_j represents attention maps from the j Target-Aware** **Attention modules in stage i.** ",
    "the geometry of these regions is identical to the Einstein-Rosen bridge in a two-sided BTZ geometry with the same mass as the corresponding operator. We will take the interpretation that the details of what appears outside the domain of dependence of \\(\\mathcal{W}\\)of\n  is part of the \\(\\mathcal{W}\\)definition of the operator associated to that region. So in sum, the action of the Lorentzian\n cap is \n\n\\[I_{\\text{cap}}=\\frac{1}{4\\pi G_{\\textrm{\\tiny N}}}V_{\\mathcal{W}}+\\sum_{i= \\text{BH}}I_{i}=\\frac{\\pi}{4G_{\\textrm{\\tiny N}}}\\sum_{i}\\left(\\text{Re}(\\eta_ {i})-\\frac{1}{3}\\right)+\\sum_{i=\\text{BH}}I_{i}\\,.\\  \n\nHence we see that it is the sum of three contributions that each depend only on one of the three operators. Thus, we can absorb the corresponding phase generated by the action of the Lorentzian geometry into the definition of the operators, and we will arrive at a real result for the three-point function. \n\nHence we arrive at the total action for the single-sided geometry, \n\n\\[I_{\\text{single-sided}}=\\frac{1}{2}I_{\\text{wormhole}}+i\\sum_{i}f(i)\\,.\\  \n\nAgain, it is a nontrivial result that the imaginary term is given by the sum shown above since this allows us to absorb the corresponding phases into the definition of the operators. After eliminating these phases, we recover the three-point function from the single-sided bulk geometry, _ i.e.,_ \n\n\\[e^{-I}\\approx G_{L}(z_{1},z_{2},z_{3})\\,,\\  \n\nwhere \\(G_{L}(z_{1},z_{2},z_{3})\\)is the semiclassical Liouville three-point correlator in\n .\n \n\n# Discussion \n\nIn this paper we discussed three-dimensional asymptotically AdS \u2083 geometries that are sourced by the insertion of boundary operators whose scaling dimensions is heavy as the central charge of the holographic CFT \u2082. The presence of any such operators deforms the AdS geometry by inducing a non vanishing expectation value for the holographic stress tensor, close to the boundary. This is true perturbatively in general dimensions, but in three-dimensions there is an exact solution, due to Ba\u02dc nados [ 4 ], that describes such deformation. However, this metric does not describe the full bulk spacetime. When only two black hole operators are inserted, we showed that the full geometry is simply an infinite covering of the Euclidean BTZ black hole [ 1 ], but when three or more operators are inserted, we found that the completion of the Ba\u02dc nados metric into the bulk is a wormhole geometry involving multiple asymptotic boundaries. To understand this rather non trivial fact we rephrased the construction of the bulk geometry as a quotient of AdS \u2083 realized by domes and doors. The dome construction is a well know characterization of hyperbolic geometries with an asymptotically AdS \u2083 metric, and more familiar from the study of black hole thermodynamics, see _ e.g.,_ [ 38 ], but the addition of the doors is new as far as we can tell. \n\nAs in the description of a Euclidean two-point function geometry in section  2 , _ i.e.,_  as empty AdS \u2083 with identifications, the doors are needed to describe the insertion of boundary ",
    "3.1.3. \n\n#### The case of a general periodic force\n \n\ne.\n  Finally, we remark that in the general case of a \\(\\theta\\)-periodic force of the form \n\n\\[{\\mathcal{F}}(t/\\theta)=\\sum_{\\ell=1}^{+\\infty}F_{\\ell}\\cos(\\omega(\\ell)t), \\quad\\mbox{where }\\omega(\\ell):=\\frac{2\\pi\\ell}{\\theta}\\  \n\nFourier\n \n\n\n\n\n\n\n\nwhose real valued Fourier coefficients satisfy the\n \n\n\n\n, the work per formed by the force can be determined from the formula: \n\n\\[W(n)=\\sum_{\\ell=1}^{+\\infty}\\big{(}\\omega(\\ell)F_{\\ell}\\big{)}^{2}\\frac{N( \\omega(\\ell),n)}{D(\\omega(\\ell),n)}.\\  \n\ngets\n Therefore its behavior, as \\(n\\) gets large, can be determined from the term by term \n\n\n\nlarge,\n \n\n\n\nhand\n \n\n\n\ndetermined\nand side of\n \n\n\n\nanalysis of the series appearing on the right hand side of ( 3.21 ). \n\nin ( 2.17 ) and ( 2.16 ), respectively. 3.2. \n\n### Energy\n \n\n.\n  As in Section  3.1  we assume that the periodic force energy\n  is given by ( 3.3 ). The time average of the expectation of the total energy energy of the chain \\(E(\\omega,n)\\)and\n  breaks up into the sum of thermal component \\(E_{\\rm th}(\\omega,n)=\\sum_{x\\in{\\mathbb{I}}_{n}}\\langle\\langle e_{x}^{\\rm th}\\rangle\\rangle\\)of\n \\(e_{x}^{\\rm mech}\\)and the mechanical one \\(E_{\\rm mech}(\\omega,n)=\\sum_{x\\in{\\mathbb{I}}_{n}}\\langle\\langle e_{x}^{\\rm mech }\\rangle\\rangle\\)sum\n \n\nthermal\n \n\n, with \\(e_{x}^{\\rm th}\\)and \\(e_{x}^{\\rm mech}\\)defined \n\nConsidering the behavior of the thermal energy functional, defined in ( 2.15 ), it has been shown in [ 0 ], that in the case \\(\\omega_{0}=0\\)and\n and\n \\(\\gamma_{-}=\\gamma_{+}\\),\n  we have in\n \\(\\langle\\langle e_{x}^{\\rm th}\\rangle\\rangle=\\frac{1}{2}(T_{-}+T_{+})\\)(38)\n and\n  for all \\(x=1,\\ldots,n-1\\)in\n . If\n \\(\\omega_{0}>0\\)case\n and\n \\(\\gamma_{-}=\\gamma_{+}\\), then [ 0 , formulas (38) and (42)] give we\n ,\n As\n \\[\\langle\\langle e_{x}^{\\rm th}\\rangle\\rangle=\\frac{1}{2}(T_{-}+T_{+})(1+o_{x}), \\quad\\mbox{where }|o_{x}|\\leqslant\\frac{C}{g^{x\\wedge(n+1-x)}}\\]  constants\n \\(C>0\\)for some constants \\(C>0\\),\n \\(g>1\\)independent of\n \\(n\\). As a result we have \\(E^{\\rm th}(\\omega,n)\\sim n\\), as \\(n\\to+\\infty\\)\n\n#### Formula\n \n\n. \n\n3.2.1. \n\n#### 3.2.1. Formula for the total mechanical energy functional for a single mode oscillating force. In what follows we consider the behavior of the mechanical com-\n \n\ne. In what follows we consider the behavior of the mechanical com-\n \n\n#### cillating force\n \n\ncillating force. In what follows we consider the behavior of the mechanical component of the energy. Again, assume that the force is given by (3.3). It turns\n 3.3 ). It turns out, see Section  C  of the Appendix, that the time average over the period of the microscopic mechanical energy density equals \n\n\\[\\langle\\langle e_{x}^{\\rm mech}\\rangle\\rangle=\\frac{F^{2}}{2}\\cdot\\frac{M_{x}( \\omega,n)}{D(\\omega,n)},\\  \n\n(\n \n\n\n\nand\n \n\n\n\nwhere \\(D(\\omega,n)\\) is given by ( 3.5 ) and \\[M_{x}(\\omega,n)=G^{1}_{x}(\\omega,n)^{2}(\\omega^{2}+\\omega_{0}^{2})+(\\nabla^{ \\star}G^{1}_{x})(\\omega,n)^{2}+(2\\omega\\gamma_{-})^{2}\\Big{[}{\\mathcal{G}}_{x} (\\omega,n)^{2}+(\\nabla^{\\star}{\\mathcal{G}}_{x})(\\omega,n)^{2}\\Big{]},\\]  ",
    "### Study 1 Based on the pilot, we decided to proceed by fixing the reported bugs and replacing the usability scale with potential mediators to better assess which users would prefer the different bots. We conducted this study with n=71 participants (see Section 3). \n\n#### Measures In Study 1, we added 7-level bipolar rating scales for direct comparison (See Section 3.2). We were interested in how much control participants experienced; how natural they felt the chats to be; how well their intent was fulfilled in the chats; and how satisfied they were with them. See Table 2 for items and reliabilities of the constructs. \n\nTo account for potential mediation, we assessed interindividual difference variables, namely the most prominent personality measure, big 5, using a 15-item scale (BFI-2-XS) [ 39 ]. As insert expansions exist to smooth interaction by shaping expectations, we also assessed our participants need for cognitive closure (NFC-15) [40]. \n\n#### Procedure After a short demographic questionnaire, n=71 participants were given 3 scenarios (see Figure 2), rating each before turning to the next (see Figure 3.2). Having completed all scenarios and evaluations, feedback was elicited and interindividual variables were assessed. \n\n#### Feedback To quantify the feedback, we repeated the procedure described for the pilot. Feedback on the study was 69.01% positive (neutral opinions tend to be rated as negative as well, e.g. \"I have no opinion about the study.\"), on the interface only 52.11% (negatives include no feedback at all, neutral statements such as \"It was fast and responsive, just feel like the loading is too big and the lettering also\", but also some on bugs like \"It was fine, although sometimes my prompt would trigger a loading animation that the bot would never reply to, so I had to prompt again, which left the loading anim on the screen for one of the bots but not the other, not a big deal.\" or \"It was frusting when it could not listen or answer all \n\nFigure 2: Study 1 procedure. \n\n\\begin{tabular}{|l|l|c|}\n\\hline\n**Scale** & **Items** & **Reliability** \\\\\n\\hline\n\\multicolumn{3}{|c|}{Which of the two chats\u2026} \\\\\n\\hline\n\\multirow{3}{*}{Control} & enabled more personal direction? & \\multirow{3}{*}{_Study 1: \\(\\alpha=.77\\), \\(\\lambda=.79\\) (overall), for scenarios .77/.79, .84/.85, .91/.91 each; Study 2: \\(\\alpha=.81\\), \\(\\lambda=.84\\)_} \\\\\n & offered you more autonomy? & \\\\\n & let you steer the conversation more? & \\\\\n\\hline\n\\multirow{3}{*}{Naturalness} & seemed more authentic? & \\multirow{3}{*}{_Study 1: \\(\\alpha=.93\\), \\(\\lambda=.93\\) (overall), for scenarios .93/.93, .92/.91, .97/.97 each; Study 2: \\(\\alpha=.93\\), \\(\\lambda=.95\\)_} \\\\\n & had a more genuine feel? & \\\\\n & was more natural? & \\\\\n\\hline\n\\multirow{2}{*}{Intent-Effectiveness} & had more suitable responses? & \\multirow{2}{*}{_Study 1: \\(\\alpha=.93\\), \\(\\lambda=.93\\) (overall), for scenarios .93/.91, .95/.93, .96/.95 each; Study 2: \\(\\alpha=.95\\), \\(\\lambda=.96\\)_} \\\\\n & lived up to your expectations better? & \\\\\n\\hline\n\\multirow{2}{*}{Satisfaction} & was more to your liking? & \\multirow{2}{*}{_Study 1: \\(\\alpha=.95\\), \\(\\lambda=.95\\) (overall), for scenarios .95/.95, .92/.92, .97/.97 each; Study 2: \\(\\alpha=.98\\), \\(\\lambda=.97\\)_} \\\\\n & was more satisfactory? & \\\\ \\hline\n\\end{tabular}\n\n\nTable 2: Direct comparison bipolar rating scales with Crohnbach\u2019s \\(\\alpha\\) and Guttman\u2019s \\(\\lambda\\) 6. ",
    "## 1.  Introduction \n\nThe (logarithmic) Mahler measure of a non-zero rational function \\(P\\in\\mathbb{C}\\left(x_{1},\\dots,x_{n}\\right)^{*}\\)is defined by \n\n(1) \\[\\mathrm{m}\\left(P\\right)=\\mathrm{m}(P(x_{1},\\dots,x_{n})):=\\frac{1}{\\left(2\\pi i \\right)^{n}}\\int_{\\mathbb{T}^{n}}\\log|P\\left(x_{1},\\dots,x_{n}\\right)|\\frac{dx _{1}}{x_{1}}\\cdots\\frac{dx_{n}}{x_{n}},\\]  \n\nwhere \\(\\mathbb{T}^{n}=\\{\\left(x_{1},\\dots,x_{n}\\right)\\in\\mathbb{C}^{*}\\times\\mathbb{ C}^{*}\\times\\cdots\\times\\mathbb{C}^{*}:|x_{1}|=\\cdots=|x_{n}|=1\\}\\)\n\nthis\n \n\n\n\n(for\n \n\n. \n\nThe first appearance of this quantity (for one variable polynomials) can be traced back to Lehmer\u2019s work [1] on Mersenne numbers, and its several variable form first appeared in the work of Mahler [2] regarding a simpler proof of the Gel\u2019fond-Mahler inequality, and it was later named after him. \n\nIn the early \\(80\\)\u2019s, Smyth [3] discovered the following remarkable identities: \n\n\\[\\mathrm{m}(x+y+1)= \\frac{3\\sqrt{3}}{4\\pi}L(\\chi_{-3},2),\\] \\[\\mathrm{m}(1+x+y+z)= \\frac{7}{2\\pi^{2}}\\zeta(3),\\]  \n\nwhere \\(L(\\chi_{-3},2)\\) is the Dirichlet \\(L\\)-function of the quadratic character \\(\\chi_{-3}\\) of conductor \\(3,\\)and \\(\\zeta(s)\\) is the Riemann zeta function (for more details see [4]). These are two of the initial formulas for several variable cases. \n\nLater the work of Boyd [5], Deninger [6], Rodriguez-Villeags [7] and others provided us with interesting connections among Mahler measure, higher regulators, and Be\u02d8 \u0131linson\u2019s conjectures. The conjectural formulas to support their work, such as \n\n\\[\\mathrm{m}(P_{k}(x,y))\\stackrel{{?}}{{=}}r_{k}L^{\\prime}(E_{N(k)}, 0),\\quad\\quad r_{k}\\in\\mathbb{Q},\\]  \n\nwere eventually proved for certain polynomials, due to Rodriguez-Villegas [7], Rogers and Zudilin [8, 9] et al. Here \\(E_{N(k)}\\) is an elliptic curve of conductor \\(N(k)\\) associated to \\(P_{k},\\) and the question mark stands for a numerical formula that is true for at least 20 decimal places. (See the book of Brunault and Zudilin [10] for more details.) \n\nIn a different direction, Cassaigne and Maillot [11] generalized the formula found by Smyth to \\(\\mathrm{m}(a+bx+cy)\\) for arbitrary complex constants \\(a,b,\\ \\mbox{and}\\ c:\\)\n\n(2) \\[\\pi\\mathrm{m}(ax+by+c)=\\left\\{\\begin{array}[]{ll}\\alpha\\log|a|+\\beta\\log|b|+ \\gamma\\log|c|+D\\left(\\frac{|a|}{|b|}e^{i\\gamma}\\right)&\\mbox{if}\\ \\Delta\\ \\mbox{holds},\\\\ \\log\\max\\{|a|,|b|,|c|\\}&\\mbox{if}\\ \\Delta\\ \\mbox{does not hold},\\end{array}\\right.\\]  \n\nwhere \\(\\Delta\\)stands for the statement that \\(|a|,|b|,\\ \\mbox{and}\\ |c|\\)angles\n  are the lengths of the sides of a planar triangle, and in that case, \\(\\alpha,\\beta,\\ \\mbox{and}\\ \\gamma\\) are the angles opposite to the sides of the lengths \\(|a|,|b|\\)\n\nWe\n \n\n and \\(|c|\\)).\n \n\nWe also remark that the constant coefficient can be replaced by a variable without changing the Mahler measure, in the sense that \\(\\mathrm{m}(ax+by+c)=\\mathrm{m}(ax+by+cz).\\) Additionally, it is ",
    "where the initial \\(\\boldsymbol{u}_{AD}^{(0)}\\)is set as \\(\\overline{\\boldsymbol{u}}\\). By running the iteration (16) \\(N\\) times, we obtain \\(\\boldsymbol{u}_{AD}\\doteq\\boldsymbol{u}_{AD}^{(N)}\\)as the \\(N^{\\text{th}}\\) order van Cittert operator applied to \\(\\overline{\\boldsymbol{u}}\\). However, to make this iteration practical, we need to recall that each application of the filter \\(G\\) requires the inversion of a differential operator. Therefore, denoting by we\n \n\n\n\n\\(\\widetilde{\\boldsymbol{u}}^{(n+1)}\\)the quantity \\(\\widetilde{\\boldsymbol{u}}^{(n+1)}\\doteq G\\boldsymbol{u}_{AD}^{(n)}\\)\\(\\widetilde{\\boldsymbol{u}}^{(n+1)}\\doteq G\\boldsymbol{u}_{AD}^{(n)}\\), and substituting in our filter from (12), we observe that \\(\\widetilde{\\boldsymbol{u}}^{(n+1)}\\)\\(\\widetilde{\\boldsymbol{u}}^{(n+1)}\\)is found by solving \n\n\\[(I-\\delta^{2}\\Delta)^{-1}\\boldsymbol{u}_{AD}^{(n)}=\\widetilde{ \\boldsymbol{u}}^{(n+1)}\\Longleftrightarrow(I-\\delta^{2}\\Delta)\\widetilde{ \\boldsymbol{u}}^{(n+1)}=\\boldsymbol{u}_{AD}^{(n)}.\\] (17)  \n\norder\n \n\n\n\nEquation (17) requires to solve a linear system at each iteration \\(n=0,\\ldots,N-1\\). As discussed above, in order to employ the van Cittert AD in a ROM setting, by multiplying (17) by each test function in our ROM space and expanding our prospective solution as a linear combination of ROM basis functions, we obtain the linear system \n\nThus, the iterative process (16) amounts to setting \\(\\boldsymbol{c}_{AD}^{(0)}=\\overline{\\boldsymbol{c}}\\), updating the \n\n\\[\\left(\\boldsymbol{M}+\\delta^{2}\\boldsymbol{S}\\right)\\widetilde{\\boldsymbol{c}} ^{(n+1)}=\\boldsymbol{M}\\boldsymbol{c}_{AD}^{n}.\\] (18)  \n\nprocess\n \n\n\n\ncoefficients of the ROM AD velocity as \n\nand finally defining \\(\\boldsymbol{c}_{AD}\\doteq\\boldsymbol{c}_{AD}^{(N)}\\). \n\n\\[\\boldsymbol{c}_{AD}^{(n+1)}=\\boldsymbol{c}_{AD}^{(n)}+\\{\\overline {\\boldsymbol{c}}-\\widetilde{\\boldsymbol{c}}^{(n+1)}\\}\\qquad n=0,\\ldots,N-1,\\]  \n\n### 3.3. The Tikhonov AD The Tikhonov method of approximate deconvolution is defined as \n\n\\[\\boldsymbol{u}_{AD}=D_{\\mu}^{T}\\overline{\\boldsymbol{u}}=(G^{*}G+\\mu I)^{-1}G^ {*}\\overline{\\boldsymbol{u}},\\] (19)  \n\nwhere \\(G^{*}\\)denotes the adjoint of the operator \\(G\\), and \\(\\mu\\in\\mathbb{R}^{+}\\)\\(G^{*}\\)denotes the adjoint of the operator\n \\(G\\), and\n \\(\\mu\\in\\mathbb{R}^{+}\\)where G\u2217denotes the adjoint of the operator G, and \u00b5 \u2208R+ is a positive constant; we refer, e.g., to [39, section 3.3.1] for further details on the\n Tikhonov AD. When plugging in the specific filter from (12) and proceeding formally, we can write \n\n\\[[G^{*}G+\\mu I]\\boldsymbol{u}_{AD} =G^{*}\\overline{\\boldsymbol{u}},\\] \\[[(I-\\delta^{2}\\Delta)^{-*}(I-\\delta^{2}\\Delta)^{-1}+\\mu I] \\boldsymbol{u}_{AD}\\] =(I\u2212\u03b42\u0394)\u2212\u2217\ud835\udc96\u00af], \\[[(I-\\delta^{2}\\Delta)^{-1}+\\mu(I-\\delta^{2}\\Delta)^{*}] \\boldsymbol{u}_{AD} =\\overline{\\boldsymbol{u}},\\] \\[[I+\\mu(I-\\delta^{2}\\Delta)(I-\\delta^{2}\\Delta)^{*}]\\boldsymbol{u} _{AD} =(I-\\delta^{2}\\Delta)\\overline{\\boldsymbol{u}},\\] \\[[I+\\mu(I-\\delta^{2}\\Delta^{*}-\\delta^{2}\\Delta+\\delta^{2}\\Delta \\delta^{2}\\Delta^{*})]\\boldsymbol{u}_{AD} =(I-\\delta^{2}\\Delta)\\overline{\\boldsymbol{u}},\\] \\[\\left[I+\\mu(I-2\\delta^{2}\\Delta+\\delta^{4}\\Delta\\Delta)\\right] \\boldsymbol{u}_{AD} =(I-\\delta^{2}\\Delta)\\overline{\\boldsymbol{u}}.\\] (20)  ",
    "to accept a trigger of  40 ns  and an integration time of  325 ns  to collect photons on the sensor tile. The overvoltage of the silicon photomultipliers (SiPMs) is set to  3 V . As this is a digital tile it is possible to disable the SPADs which produce a high number of dark counts. This inhibit fraction is set to  10 % . The surface of each sensor tile is covered with a glass plate of  1 _._ 1 mm . The sensor tiles are connected to a singles processing unit (SPU) which manages their voltage supply and feeds their data to the data acquisition and processing server (DAPS). During the measurement, the tiles are cooled by a  15 _\u25e6_ C  liquid cooling system. \n\n#### 2.1.3. Masks \n\nWe perform measurements in one and two dimensions, i.e., we reconstruct an image along one axis or on a plane. For these two tasks, we use a one- and a two-dimensional versions of a MURA mask of rank 476, clipped to \\($31$\\times$31$\\)central pixels (see Fig. 2). The mask rank as well as the setup geometry\n have been optimised via Monte Carlo simulations before the experiment. To construct the physical masks we use tungsten rods of \\(($2.26$\\times$2.26$\\times$20$)\\,${\\mathrm{mm}}^{3}\\text{/}$\\)which are inserted into 3D printed rasters made from Pro Grey Resin. The\n rod manufacturing reaches a precision of  0 _._ 1 mm . The resulting masks have a dimension of \\(($73.6$\\times$73.6$)\\,${\\mathrm{mm}}^{2}\\text{/}$\\). The rasters have a total thickness of  13 mm  and the holes to insert the rods are\n  10 mm  deep. To prevent the rods from falling out, the assembled masks are wrapped in cling film. \n\n### 2.2. Radioactive sources \u00b2\u00b2Na source with an activity of 2.89 MBq.\nThe active material in\n \u00b2\u00b2Na source with an activity of  2 _._ 89 MBq . The active material in that source covers an area of \\($1\\text{\\,}\\mathrm{mm}\\text{/}$\\times$1\\text{\\,}\\mathrm{mm}\\text{/}$\\). As a \\(\\beta^{+}\\)-emitter, \u00b2\u00b2Na provides two photons of  511 keV emitted back-to-back, which can be used for electronic\n collimation. For calibration of the detectors we additionally used the  1275 keV gamma line of \u00b2\u00b2Na and two more radioactive sources: a \u00b9\u00b3\u2077Cs source with a gamma line at  662 keV  with an activity of  1 _._ 73 MBq  and a \u00b9\u00b3\u00b3Ba source with \n\nFigure 2: Coded masks for 1D measurement with the small-scale prototype (a) and for 2D measurement with the three-layered PET array (b). ",
    "Such that the overall problem can be set up with the following function: \n\n#### Runtime Analysis \n\nFor the runtime analysis, the idea is to \u00b4 run the sensor network localization problem with varying number of sensors both with a decentral and a central optimization step. To do so, firstly a vector with a number of sensors is needed and secondly a vector with variances. Then, the time needed for the decentral and the central optimization is measured and can be plotted. ",
    "**Definition 4.11.**  We say a spin system \\(\\mu\\)on \\(\\mathbb{Z}^{d}\\)satisfies the _ strong spatial mixing (SSM)_  condition if there exist constants \\(\\alpha,\\gamma,L>0\\)such that for every\n \\(d\\)-dimensional rectangle \\(\\Lambda\\subset\\mathbb{Z}^{d}\\)of side length between \\(L\\)and\n \\(2L\\)and every subset \\(B\\subset\\Lambda\\), with any pair \\((\\tau,\\tau^{\\prime})\\) of boundary configurations on \\(\\partial\\Lambda\\) that only differ at a vertex \\(u\\), we have \\[\\|\\mu_{B}^{\\tau}(\\cdot)-\\mu_{B}^{\\tau^{\\prime}}(\\cdot)\\|_{TV}\\leq\\gamma\\cdot \\exp(-\\alpha\\cdot dist(u,B)),\\]  where \\(dist(\\cdot,\\cdot)\\) denotes graph distance. \n\n\n\nmonotone\n \n\n on \\(\\mathbb{Z}^{2}\\). The definition above differs from other variants of SSM in the literature (e.g., [ DSVW04 , BCSV19 , MOS94 ]) in that \\(\\Lambda\\) has been restricted to \u201cregular enough\u201d rectangles. In particular, our variant of SSM is easier to satisfy than those in [ DSVW04 , MOS94 ] but more restricting than the one in [ BCSV19 ] (that only considers squares). Nevertheless, it follows from [ CP21 , MOS94 , Ale98 , BDC12 ] that for the ferromagnetic Ising model,\n this form of SSM holds up to a critical threshold temperature \\(\\beta<\\beta_{c}(2)=\\ln(1+\\sqrt{2})\\)\n\nCorollary  1.9  from the introduction states that for \\(b\\)-marginally bounded monotone spin system on \\(d\\)-dimensional cubes \\(V\\subseteq\\mathbb{Z}^{d}\\)result\n , SSM implies that the mixing time of any systematic scan \\(P_{\\phi}\\)is \\(O(\\log n)\\). As mentioned there, this result in turn implies that any systematic scan dynamics for the ferromagnetic Ising model is mixing in \\(O(\\log n)\\) steps on boxes of \\(\\mathbb{Z}^{2}\\)when \\(\\beta<\\beta_{c}(2)\\). Another interesting consequence of Corollary  1.9  is that we obtain \\(O(\\log n)\\)which\n  mixing time for any systematic scan dynamics \\(P_{\\phi}\\)for the hardcore model on \\(\\mathbb{Z}^{2}\\)when \\(\\lambda<2.538\\), which is the best known condition for ensuring SSM [\n SSSY17 , RST + 13 ]. \n\nOur proof of Corollary  1.9  relies on Lemma  4.12  that is restated below. Remarkably, Lemma  4.12  generalizes beyond monotone systems and may be of independent interests. \n\n**Lemma 4.12.** _ For a spin system on a_ \\(d\\)_-dimensional cube_ \\(V\\subseteq\\mathbb{Z}^{d}\\)_, SSM implies_ \\(\\eta\\)_-spectral independence,_ _where_ \\(\\eta=O(1)\\)_._ \n\n* \n\n_Proof of Corollary_ _ 1.9_ _._  Assume a monotone spin system satisfies SSM condition. Then the spin system satisfies \\(\\eta\\)-spectral independence, where \\(\\eta=O(1)\\) by Lemma  4.12 . By noting that \\(\\Delta=2^{d}\\)the corollary follows from Theorem  4.3 . \n\nLastly, we give a proof of Lemma  4.12 . For this, we recall the notion of a \\(\\kappa\\)-contractive coupling which is known to imply spectral independence. We say a distribution \\(\\mu\\)is \\(\\kappa\\)_-contractive_  with respect to a Markov chain \\(P\\)if for all \\(X_{0},Y_{0}\\in\\Omega\\), there exists a coupling of step of \\(P\\)so that \\[\\mathbb{E}[d(X_{1},Y_{1})\\mid X_{0},Y_{0}]\\leq\\kappa d(X_{0},Y_{0}),\\]  where \\(d(\\cdot,\\cdot)\\)that\n  denotes the Hamming distance of two configurations. The following lemma from [ BCC + 22 ] shows that spectral independence follows from the existence of a contractive coupling with respect to a heat-bath block dynamics. \n\n**Lemma 4.13**  ([ BCC + 22 ]) **.** _ If_ \\(\\mu\\)_is_ \\(\\kappa\\)_-contractive with respect to a block dynamics, then_ \\(\\mu\\)_is_ \\((\\frac{2DM}{1-\\kappa})\\)1\nvertex\n \ud835\udf05\nbeing\n _-spectrally_ _independent, where_ \\(M\\)_is the maximum block size and_ \\(D\\)_is the maximum probability of a vertex being selected_ _as part of a block in any step of the block dynamics._ \n\nWith this lemma on hand, we can now prove Lemma  4.12 . \n\n_Proof of Lemma_ _ 4.12_ _._  Let \\(L\\)be a sufficiently large constant so that the SSM condition is satisfied; we will choose \\(L\\)later. Let \\(V\\)be a \\(d\\)-dimensional cube of \\(\\mathbb{Z}^{d}\\). We define a heat-bath block dynamics \\(P_{\\mathcal{B}}\\) with respect to a collection \\(\\mathcal{B}\\) of \\(d\\)-dimensional rectangles in \\(V\\). Precisely, let \\(S_{v}:=\\{w\\in\\mathbb{Z}^{d}:d_{\\infty}(w,v)<L\\}\\)heat-bath\n , and let \\(\\mathcal{B}\\) be the set of blocks \\(\\{S_{v}\\cap V\\}_{v\\in V}\\)3\n . Given a configuration \\(X_{t}\\), the heat-bath block dynamics \\(P_{\\mathcal{B}}\\) obtains a configuration \\(X_{t+1}\\) in 3 steps as follows: ",
    "The initial conditions for the Taylor-Green vortex are \n\n\\begin{align*}     \\rho(x,y,z) &= 1\\\\     u(x,y,z) &= \\sin(x)\\cos(y)\\cos(z)\\\\     v(x,y,z) &= -\\cos(x)\\sin(y)\\cos(z)\\\\     w(x,y,z) &= 0\\\\     p(x,y,z) &= 10 + \\frac{(\\cos(2x) + \\cos(2y))(\\cos(2x)+2)-2}{16} \\end{align*}\n\nwith a pressure value corresponding to a Mach number $M \\approx 0.26$. The triperiodic domain has side length $2\\pi$ in all directions and is discretized using $32\\times32\\times32$ nodes. The chosen CFL value is sufficiently small that linear invariants are exactly conserved to machine precision for all schemes. The time evolution of the entropy integral for this test is shown in Fig. 2 and it is in agreement with the previous results. In this test, since the pressure is not constant, $A\\rho$- $H e$ is no longer equivalent to $A\\rho$- $A p$; in this case we have better performances from $A\\rho$- $H e$ and $G\\rho$- $G e$ when compared to $A\\rho$- $A p$ and $A\\rho$- $A e$ and this result is found for both fourth-order and six-order accurate fluxes. An improvement can be obtained using an additional term in the expansions and KEEP $^{(1)}$and AEP $^{(1)}$are the schemes which more closely achieve a constant value for the entropy integral. Information about the reliability of the scheme can be obtained thorough the study of the evolution of thermodynamic fluctuations in time. We checked that for all the schemes tested, the density and temperature fluctuations do not have an unbound growth (not shown). This is the desired behaviour, since for inviscid isotropic homogeneous turbulence they are reported to level off to a constant value [18, 2]. \n\n## Conclusions \n\nWe proposed a new class of asymptotically entropy-preserving fluxes for the discretization of the convective terms in the compressible Euler equations with interesting properties. It provides a consistent asymptotic approximation of an existing entropy-preserving scheme based on the logarithmic mean, and it consists of economical algebraic fluxes based on the harmonic mean. Moreover, at all orders of approximation, the numerical fluxes have the pressure-equilibrium preservation property. The theoretical predictions are confirmed on two test cases, verifying that the new schemes are able to numerically maintain pressure equilibrium and demonstrating good entropy-conservation property. It was also shown that the error on entropy can be reduced by using additional terms in the expansion of the AEC fluxes. \n\nThese results suggest that AEC fluxes could be good candidate for the discretization of compressible flow equations in high performance solvers. Due to the their algebraic form, they are less computationally expensive than the fluxes based on the logarithmic mean, while retaining many important properties. In fact, they guarantee the KEP and PEP properties, combined with arbitrarily small error on entropy preservation. \n\n## High-order extension  then an approximation of the derivative $\\partial f$ is The second-order accurate two-point fluxes presented in this article can be extended to higher-order formulations by using the approach proposed by Ranocha [ 7 ] in the context of Discontinuous Galerkin discretization of the Euler equations. The main result of interest for us is that contained in Theorem 3.1 of [ 7 ], which can be reformulated in FD terms as follows. We consider a numerical flux $\\mathcal{F}(\\vec{w_i},\\vec{w_{i+k}})$$i$ for a generic quantity $\\rho\\varphi$, which depends on the values of the variables vector $\\vec{w}$ in the nodal points $i$ and $i+k$. In our context $\\mathcal{F}$ can be any of the numerical fluxes specified in Eqs. \u2013 , (10)  or \u2013  and $\\vec{w}$ is the set of variables $\\left(\\rho,u,e\\right)$. We will assume that the numerical flux is smooth, symmetrical (i.e. $\\mathcal{F}(\\vec{w_i},\\vec{w_{i+k}}) = \\mathcal{F}(\\vec{w_{i+k},\\vec{w_i}})$) and consistent with the continuous flux $f$ so that $\\mathcal{F}(\\vec{w_i},\\vec{w_{i}}) = f(\\vec{w_i})$. Under these hypotheses, by following the steps of the proof to Theorem 3.1 in [ 7 ], we can show that given a numerical derivative formula of the type $\\partial\\varphi_i\\simeq\\sum_{k}a_{k}\\varphi_{i+k}$the\n \n\n\n\ngiven by \n\n\\begin{equation}\\label{eq:high_order_ranocha}     \\sum_{k} 2 a_{k} \\mathcal{F}(\\vec{w_i},\\vec{w_{i+k}}) \\end{equation}\n\nand it has the same order of accuracy as the original derivative formula with weights $a_{k}$. If one considers central derivative formulas, for which $a_{k} = -a_{-k}$, by using the symmetry of the flux $\\mathcal{F}$, Eq. (16) can be rewritten as \n\n\\begin{equation}\\label{eq:AppEq2}         \\sum_{k=1}^{L} 2 a_{k}     \\left(     \\mathcal{F}(\\vec{w_i},\\vec{w_{i+k}})- \\mathcal{F}(\\vec{w_{i-k}},\\vec{w_i})      \\right). \\end{equation}\\begin{equation}\\label{eq:AppEq2}         \\sum_{k=1}^{L} 2 a_{k}     \\left(     \\mathcal{F}(\\vec{w_i},\\vec{w_{i+k}})- \\mathcal{F}(\\vec{w_{i-k}},\\vec{w_i})      \\right). \\end{equation}",
    "## Empirical data \n\nWe observe the changes of activity over time of the empirical networks for the four data sets (Figure 11). The _ US school_  presents periodic patterns, varying from low contact periods when the students are in class to high contact periods when there is a recreational time. The _ US flight_  and _ Conference_ networks have circadian patterns as there are respectively less flights and less contacts at night. Finally, the _ Resistance game_  does not present any periodic change in its activity as every player of the game is looking at someone else at each time step. \n* References \n* [1] Petter Holme and Jari Saram\u00a8 aki. Temporal networks.  Physics reports , 519(3):97\u2013125, 2012. \n* [2] Petter Holme. Modern temporal network theory: a colloquium.  The European Physical Journal B , 88:1\u201330, 2015. \n* [3] Naoki Masuda and Renaud Lambiotte.  A guide to temporal networks . World Scientific, 2016. \n* [4] Alain Barrat and Ciro Cattuto. Temporal networks of face-to-face human interactions.  Temporal networks , pages 191\u2013216, 2013. \n* [5] Sune Lehmann. Fundamental structures in temporal communication networks.  Temporal Network Theory , pages 25\u201348, 2019. \n* [6] Mohammed Saqr and Sonsoles L\u00b4 opez-Pernas. The why, the what and the how to model a dynamic relational learning process with temporal networks. In  Proceedings of the NetSciLA22 workshop , 2022. \n\n**Figure 11:**  Number of events as a function of time for the four data sets: the _ US school_  (panel a), the _US flight_  (panel b), the _ Conference_  (panel c) and the _ Resistance game_  (panel d). The _ US school_  network contains high activity periods during recreational moments of the students\u2019 day, while the _ US flight_  and the _ Conference_  networks present circadian patterns. The Resistance game network does not have particular periodic activity changes. ",
    "\\[\\gamma_{2}(0) =\\sum_{x\\in\\mathbb{Z}}\\beta_{k_{j}}^{*q}(x)\\theta(-x)\\] \\[=\\sum_{|x|\\leq(n-1)N_{k_{j}-1}}\\beta_{k_{j}}^{*q}(x)\\theta(-x)\\] \\[\\leq\\sum_{|x|\\leq(n-1)N_{k_{j}-1}}\\beta_{k_{j}}^{*q}(x)\\] \\[=\\beta_{k_{j}}^{*q}\\left(\\left[-(n-1)N_{k_{j}-1},(n-1)N_{k_{j}-1} \\right]\\right)\\] \\[\\leq\\varepsilon_{n},\\]  \n\nwhere we used the fact that \\(\\beta_{k_{j}}\\) satisfies Equation ( 2 ), with \\(k_{j}\\geq p_{n}\\). \n\nWe conclude that \\(\\nu^{*n}(0)=\\gamma_{1}(0)+\\gamma_{2}(0)\\leq 2\\varepsilon_{n},\\) which finishes the proof. \n\nIf we weaken the hypothesis \\(\\mathbb{E}\\left(|\\mathrm{supp}(\\sigma_{1})|\\right)<\\infty\\)Indeed,\n from Lemma  4.10  it is possible that the permutation coordinate never stabilizes. Indeed, with ideas similar to an example of [ Kai83 ], we obtain the following. \n\n**Proposition 4.14.** _ The group_ \\({\\mathsf{Shuffler}}(\\mathbb{Z})\\)_ admits probability measures_ \\(\\mu\\)\\({\\mathsf{Shuffler}}(\\mathbb{Z})\\)admits probability measures\n \\(\\mu\\)Proposition 4.14. The group Shuffler(Z) admits probability measures \u00b5 with an infinite first moment and a finite (1 \u2212\u03b5)-moment, for every 0 < \u03b5 < 1, that induce a\n \\((1-\\varepsilon)\\)-moment, for every\n \\(0<\\varepsilon<1\\), that induce\n \\((1-\\varepsilon)\\)for\n _-moment, for every_ \\(0<\\varepsilon<1\\)_, that induce a_ _transient random walk on_ \\(\\mathbb{Z}\\)_ and for which the permutation coordinate of the_ \\(\\mu\\)_-random_ _walk does not stabilize. Such measures can be chosen to satisfy_ \\(\\mathbb{E}(|\\mathrm{supp}(\\sigma_{1})|)=\\infty\\)_and_ \\(\\mathbb{E}(|\\mathrm{supp}(\\sigma_{1})|^{1-\\varepsilon})<\\infty\\)_for every_ \\(0<\\varepsilon<1\\)_._ \n\n_Proof._  For each \\(n\\geq 1\\), denote by\n \\(r_{n}:\\mathbb{Z}\\to\\mathbb{Z}\\) the permutation \n\nrn(x)={x+1, if \u20620\u2264x<n\u22121,0, if \u2062x=n\u22121, andx, otherwise.  \n\nWe define the measure \\(\\mu\\) on \\({\\mathsf{Shuffler}}(\\mathbb{Z})\\)as follows. Let\n \n\n\\[\\mu((\\mathsf{id},1))=1/8,\\ \\mu((\\mathsf{id},-1))=3/8,\\]  \n\nand \n\n\\[\\mu((r_{n},0))=\\frac{1}{2n(n+1)},\\ \\text{ for }n\\geq 1.\\]  \n\n, so that\n \\(\\mu\\) is indeed a probability measure. Also note that Note that \\(\\sum_{n\\geq 1}\\frac{1}{n(n+1)}=1\\)\\(|\\mathrm{supp}(r_{n})|=n\\). From this, the fact that the harmonic series \\(\\sum_{n\\geq 1}\\frac{1}{n}\\)diverges implies that is \\(\\mathbb{E}(|\\mathrm{supp}(\\sigma_{1})|)\\)is infinite. Moreover, since\n \\(\\|(r_{n},0)\\|_{S_{\\mathrm{std}}}\\geq|\\mathrm{supp}(r_{n})|\\)every\n , we also have that \\(\\mu\\)has an infinite first moment. On the other hand, for every \\(\\varepsilon>0\\)the series\n \\(\\sum_{n\\geq 1}\\frac{n^{1-\\varepsilon}}{n(n+1)}\\)convergent and thus \\(\\mathbb{E}(|\\mathrm{supp}(\\sigma_{1})|^{1-\\varepsilon})\\)expressed\n is finite. The element\n \\(r_{n}\\) has word length at most \\(3n\\) (since it can be expressed as the product of at most \\(n\\)transpositions together with\n \\(2n\\)movements in the \\(\\mathbb{Z}\\) coordinate), and hence \n\n\\[\\sum_{n\\geq 1}\\frac{\\|(r_{n},0)\\|_{S_{\\mathrm{std}}}^{1-\\varepsilon}}{n(n+1)} \\leq 3^{1-\\varepsilon}\\sum_{n\\geq 1}\\frac{n^{1-\\varepsilon}}{n(n+1)},\\]  \n\nwhich is finite. Hence, \\(\\mu\\)has a finite\n \\((1-\\varepsilon)\\)\n\n\n\n-moment.\n \n\nLet us show that the value \\(F_{n}(0)\\),\n \\(n\\geq 1\\)\\(\\mu\\), almost surely changes infinitely often. By\n definition of the group operation and the \\(\\mu\\)-random walk, we can write \\(F_{n}=F_{n-1}\\circ(S_{n}\\cdot\\sigma_{n})\\).\n Hence, \\(F_{n}(0)\\neq F_{n-1}(0)\\)if and only if\n \\(S_{n}\\cdot\\sigma_{n}(0)\\neq 0\\)action\n , which can be rewritten as\n \\(\\sigma_{n}(-S_{n})\\neq-S_{n}\\), by using the definition of the action of \\(\\mathbb{Z}\\)on\n \\(\\mathrm{FSym}(\\mathbb{Z})\\)(here we use an additive\n notation for the group operation on \\(\\mathbb{Z}\\)). \n\nThe induced random walk on \\(\\mathbb{Z}\\) is drifted to the negative numbers, and hence almost surely \\(S_{n}\\xrightarrow[n\\to\\infty]{}-\\infty\\). Also, at time \\(n\\) the projection to \\(\\mathbb{Z}\\) satisfies \\(S_{n}\\geq-n\\), since the ",
    "### 2.3 Metrics \n\nThree metrics were widely used across the papers: accuracy, specificity, and sensitivity. The equations for these four metrics can be seen below. \n\n\\[\\text{Accuracy}=\\frac{\\text{Correctly classified speech}}{\\text{Total speech samples}}\\] (1)  \n\n\\[\\text{Specificity}=\\frac{\\text{Correctly classified healthy speech}}{\\text{ Total healthy speech}}\\] (2)  \n\n\\[\\text{Sensitivity}=\\frac{\\text{Correctly classified pathological speech}}{ \\text{Total pathological speech}}\\] (3)  \n\nAnother metric was often used in the papers using multi-class classification - unweighted average recall (UAR). This metric is calculated by averaging the recall value for each of the specific pathologies included in the dataset. Equation 4 shows how it is calculated, where N is the number of pathologies in the dataset and \\(R_{i}\\) is the recall of the ith pathology in the dataset. \n\n\\[\\text{UAR}=\\frac{\\sum_{i=1}^{N}{R_{i}}}{N}\\] (4)  \n\n### 2.4 Binary Classification Literature \n\n**?**  (2020) investigate the classification of cancer patients from healthy controls using six machine learning algorithms. The dataset used includes recordings of the prolonged vowel /ah/ from 50 male laryngeal \n\n**(a)**  Signal of a person saying a short phrase. \n\n**(b)**  MFCC generated from the above speech signal. \n\n**Figure 6.**  MFCCs generated from a short audio signal. ",
    "for this paper, since a majority of features in keystroke sounds are within the lower frequencies [15, 3, 4] and would therefore be less distinguishable on a linear scale. Meanwhile, MFCC involves performing the discrete cosine transform on a mel-spectrogram, producing a compressed representation that prioritises the frequencies used in human speech. Since, for this paper, human speech is not the target, and the removal of frequencies could risk the loss of relevant data, MFCC was decided to be less suitable than mel-spectrograms. \n\n**Data augmentation:**  Prior to feature extraction, signals were time-shifted \\(40\\%\\)in either direction. This time shifting is an instance of\n data augmentation, in which the amount of data input to a DL model is artificially increased by slightly adjusting existing inputs [28]. The mel-spectrograms were then generated using 64 mel bands, a window length of 1024 samples and hop length of 500 (255 for the MacBook keystrokes, given their shorter length), resulting in 64x64 images. Using the spectrograms, a second method of data augmentation was implemented called masking. This method involves taking a \\(10\\%\\)of both the time and frequency axis and setting all values within\n those ranges to the mean of the spectrogram, essentially \u2018blocking out\u2019 a portion of the image. Using time warping and spectrogram masking combined is called SpecAugment and was found to encourage the model to generalise and avoid overfitting the training data [25, 10]. \n\nHaving converted keystrokes from each data set into a more visual medium, more direct comparisons could be made. MacBook keystrokes (similar to the keystrokes examined in the literature [4, 39, 6]) have only 2 visible peaks: the \u2018push\u2019 and \u2018release\u2019 peaks respectively. The 2 peak structures shown in Fig. 2 are similar to each other, implying that such a structure is native to the MacBook keyboard regardless of recording method, a noticeable difference however is the large range of frequencies present in the zoom recording. The Zoom peaks extend much higher than that of the phone-based recordings, indicating significant data in multiple frequencies that were not present when recorded via phone. \n\nThe overall data preparation procedure for our data was inspired by the structure presented in [10] and is shown in Fig. 3. \n\n### Model Selection and Implementation \n\nFigure 2: Waveform and corresponding mel-spectrogram of Left: Phone recording, and Right: Zoom recording. ",
    "CNPq through grant 308900/2019-7. R. Clemente acknowledges partial support from CNPq through grant 304454/2022-2. \n* 99 \n* Abreu, E.,  \u00b4 O, J. & Medeiros, E. Properties of positive harmonic functions on the half-space with a nonlinear boundary condition.  J. Differential Equations .  248 , 617-637 (2010), \n* Adams, R. & Fournier, J. Sobolev spaces. (Elsevier/Academic Press, Amsterdam,2003) \n* Aleksandrov, A. Uniqueness theorems for surfaces in the large. I.  Amer. Math. Soc. Transl. (2) .  21  pp. 341-354 (1962),  https://doi.org/10.1090/trans2/021/09 \n* Alexandrov, A. A characteristic property of spheres.  Ann. Mat. Pura Appl. (4) .  58  pp. 303-315 (1962),  https://doi.org/10.1007/BF02413056 \n* Allegretto, W. & Huang, Y. A Picone\u2019s identity for the p-Laplacian and applications. Nonlinear Anal. .  32 , 819-830 (1998),  https://doi.org/10.1016/S0362-546X(97)00530-0 \n* Bonder, J. & Rossi, J. Existence results for the p-Laplacian with nonlinear boundary conditions.  J. Math. Anal. Appl. .  263 , 195-223 (2001), \n* Chipot, M., Chleb\u0131\u00b4 \u0131k, M., Fila, M. & Shafrir, I. Existence of positive solutions of a semilinear elliptic equation in  R n + with a nonlinear boundary condition.  J. Math. Anal. Appl. .  223 , 429-471 (1998),  https://doi.org/10.1006/jmaa.1998.5958 \n* Cuesta, M. & Tak\u00b4 a\u02c7 c, P. A strong comparison principle for positive solutions of degenerate elliptic equations.  Differential Integral Equations .  13 , 721-746 (2000) \n* Damascelli, L. & Pacella, F. Monotonicity and symmetry of solutions of p-Laplace equations, 1  < p <  2, via the moving plane method.  Ann. Scuola Norm. Sup. Pisa Cl. Sci. (4) .  26 , 689-707 (1998),  http://www.numdam.org/item?id=ASNSP 1998 4 26 4 689 0 \n* Damascelli, L. & Sciunzi, B. Regularity, monotonicity and symmetry of positive solutions of m-Laplace equations.  J. Differential Equations .  206 , 483-515 (2004), \n* Degiovanni, M., Musesti, A. & Squassina, M. On the regularity of solutions in the Pucci-Serrin identity.  Calc. Var. Partial Differential Equations .  18 , 317-334 (2003), \n* \u00b4 O, J. & Medeiros, E. Remarks on least energy solutions for quasilinear elliptic problems in R N .  Electron. J. Differential Equations . pp. No. 83, 14 (2003) \n* Escobar, J. Sharp constant in a Sobolev trace inequality.  Indiana Univ. Math. J. .  37 , 687-698 (1988),  https://doi.org/10.1512/iumj.1988.37.37033 \n* Farina, A., Montoro, L. & Sciunzi, B. Monotonicity and one-dimensional symmetry for solutions of  \u2212 \u2206 p u  =  f ( u ) in half-spaces.  Calc. Var. Partial Differential Equations .  43 , 123-145 (2012),  https://doi.org/10.1007/s00526-011-0405-z \n* Farina, A., Montoro, L. & Sciunzi, B. Monotonicity of solutions of quasilinear degenerate elliptic equation in half-spaces.  Math. Ann. .  357 , 855-893 (2013), ",
    "to $Ax=b$from Theore\nRemark 1.\n has full support. By Proposition  4 , columns of $A$are integrally independent. It follows from Theorem  6  that inequality ( 5 ) holds. \n\n**Remark 1.** _ We demonstrate how to modify the proof of Theorem_ _ 6_ _ to obtain the bound_  ( 7 ) _ given in_ _[_ _AADLO22_ _]. We use the same notation as in the proof of Theorem_ _ 6_ _. For any_ the\n $m\\times m$_submatrix of_ in\n $A$_whose columns are indexed by_ \n\n$J$\\begin{equation*} \\begin{aligned}     |\\operatorname{det}(A_{[m]\\times J})|     = & |\\operatorname{det}(D)|\\cdot |\\operatorname{det}((U^{-1})_{[m]\\times J})|\\\\     = & \\gcd(A) \\cdot |\\operatorname{det}((U^{-1})_{[m]\\times J})| \\\\     = & \\gcd(A) \\cdot |\\operatorname{det}(U_{[n]\\backslash J ~\\times~ [m+1:n]})|. \\end{aligned} \\end{equation*}\n\n_where_ as in\n $|J|=m$_, we have_ \n\n_We also know that_ \n\nby\n \n\n$J$\\begin{equation*} \\begin{aligned}     |\\operatorname{det}(A_{[m]\\times J})|     = & |\\operatorname{det}(D)|\\cdot |\\operatorname{det}((U^{-1})_{[m]\\times J})|\\\\     = & \\gcd(A) \\cdot |\\operatorname{det}((U^{-1})_{[m]\\times J})| \\\\     = & \\gcd(A) \\cdot |\\operatorname{det}(U_{[n]\\backslash J ~\\times~ [m+1:n]})|. \\end{aligned} \\end{equation*}\n\n, we have\n \n\n\n\n\n\n\n\n_and thus_ \n\n\\begin{equation*}     \\prod_{i\\in [n]\\backslash J}q_i~ \\Big|~|\\operatorname{det}(U_{[n]\\backslash J ~\\times~ [m+1:n]})|, \\end{equation*}\\begin{equation*}     \\prod_{i\\in [n]\\backslash J}q_i~ \\Big|~|\\operatorname{det}(U_{[n]\\backslash J ~\\times~ [m+1:n]})|, \\end{equation*}\n\nand\n and\n \n\n\n\nthe\n \n\n\n\ne same\nthe pr\n \n\n\n\nprime\n obtain\n _._ _where_ $q_i, i\\in [n]\\backslash J$.\n Recall\n $s_1,...,s_k\\in\\mathbb{Z}_{>0}$since the\n _are primes numbers and with the same prime repeating at most_ $m$_times in_ $\\{q_i\\mid i\\in  [n]\\backslash J\\}$mul-\n tiplicities \ud835\udc60\nMoreover,\n _. Recall notation_ $\\Omega_m(z)=\\sum_{i=1}^{k}\\min\\{s_i,m\\}$.\n multiplicity\n numbers\n Clearly, w\nplicity of\n when\nf each\n   $x\\mid y$$q_i$in\n with\n $\\Omega_m(x)\\ensuremath{\\leqslant} \\Omega_m(y)$$\\prod_{i\\in [n]\\backslash J}q_i$_ for the prime factorization of_ most\n $z=r_1^{s_1}\\cdots r_k^{s_k}$$m$$m$times\n _with mul_ _tiplicities_ $s_1,...,s_k\\in\\mathbb{Z}_{>0}$since\n $n-m\\ensuremath{\\leqslant} \\Omega_m\\mathopen{}\\mathclose\\bgroup\\originalleft(\\frac{|\\operatorname{det}(A_{[m]\\times J})|}{\\gcd(A)}\\aftergroup\\egroup\\originalright)$notation\n _. Clearly, when_ $x\\mid y$$q_i$in\n $J$is\n _,_ $\\Omega_m(x)\\ensuremath{\\leqslant} \\Omega_m(y)$$\\prod_{i\\in [n]\\backslash J}q_i$an\n for\n is\n at\n subset\nt most \ud835\udc5a\n _. Thus,_ factorization\n $\\Omega_m\\mathopen{}\\mathclose\\bgroup\\originalleft(\\prod_{i\\in [n]\\backslash J}q_i\\aftergroup\\egroup\\originalright)\\ensuremath{\\leqslant} \\Omega_m\\mathopen{}\\mathclose\\bgroup\\originalleft(\\frac{|\\operatorname{det}(A_{[m]\\times J})|}{\\gcd(A)}\\aftergroup\\egroup\\originalright)$we\n $[n]$have \u03a9\n] with\n $\\Omega_m\\mathopen{}\\mathclose\\bgroup\\originalleft(\\prod_{i\\in [n]\\backslash J}q_i\\aftergroup\\egroup\\originalright)=|[n]\\backslash J|=n-m$cardinality\n $m$,\n with\n _Moreover, since the multiplicity of each_ $x\\mid y$$q_i$_in_ $\\Omega_m(x)\\ensuremath{\\leqslant} \\Omega_m(y)$$\\prod_{i\\in [n]\\backslash J}q_i$Applying\n\ud835\udc3dis an arb\n arbitrary\n _is at most_ Thus,\n $m$_, we have_ $\\Omega_m\\mathopen{}\\mathclose\\bgroup\\originalleft(\\prod_{i\\in [n]\\backslash J}q_i\\aftergroup\\egroup\\originalright)=|[n]\\backslash J|=n-m$in\n cardinality\nn the proof\n $m$.\n , we obtain\n Theorem 2\n _._ _Therefore,_ $n-m\\ensuremath{\\leqslant} \\Omega_m\\mathopen{}\\mathclose\\bgroup\\originalleft(\\frac{|\\operatorname{det}(A_{[m]\\times J})|}{\\gcd(A)}\\aftergroup\\egroup\\originalright)$obtain\n $f(A)\\ensuremath{\\leqslant} m+\\min_{\\tau\\in\\binom{[n]}{m}, \\operatorname{det}(A_\\tau)\\neq 0}\\Omega_m\\Big(\\frac{|\\operatorname{det}(A_\\tau)|}{\\gcd(A)}\\Big)$multiplicity\n _. Since_ $J$.\n _is an arbitrary subset of_ we\n $[n]$_ with cardinality_ $m$of\n _, we obtain_ $n\\ensuremath{\\leqslant} m+\\min_{\\tau\\in\\binom{[n]}{m}, \\operatorname{det}(A_\\tau)\\neq 0}\\Omega_m\\Big(\\frac{|\\operatorname{det}(A_\\tau)|}{\\gcd(A)}\\Big)$$n-m\\ensuremath{\\leqslant} \\Omega_m\\mathopen{}\\mathclose\\bgroup\\originalleft(\\frac{|\\operatorname{det}(A_{[m]\\times J})|}{\\gcd(A)}\\aftergroup\\egroup\\originalright)$we obtain\n $f(A)\\ensuremath{\\leqslant} m+\\min_{\\tau\\in\\binom{[n]}{m}, \\operatorname{det}(A_\\tau)\\neq 0}\\Omega_m\\Big(\\frac{|\\operatorname{det}(A_\\tau)|}{\\gcd(A)}\\Big)$.\n Since\n Since\n _. Applying the same argument as in the proof of Theorem_ _ 2_ _above, we obtain_ $f(A)\\ensuremath{\\leqslant} m+\\min_{\\tau\\in\\binom{[n]}{m}, \\operatorname{det}(A_\\tau)\\neq 0}\\Omega_m\\Big(\\frac{|\\operatorname{det}(A_\\tau)|}{\\gcd(A)}\\Big)$\n\n### bound\n \n\n\n\n### on\n $h(m,t)$\n\nthe\n _._ \n\n### Upper bound on $h(m,t)$\n\nmum, taken\nsize of an\n Recall $h(m,t)$\ud835\udc61, of the smallest\ndefined in (3)). U\nsubdeterminant, w\n  is the maximum, taken over all integer matrices $A$entry\n with $m$upper\n rows and largest entry $t$, of the smallest support size of an integer solution to $A$$Ax=b$est entry\nobtain a\nwhich gi\n for some $b\\in \\mathcal{L}(A)$bound f\nn upper\n d the siz\nr bound\nfor \u210e(\ud835\udc5a\n  (formally defined in ( 3 )). Using a relation between the size of largest entry of a matrix and the size of its subdeterminant, we want to use results in Section  3.2  to obtain an upper bound for $h(m,t)$bound on\n . We will use the well-known Hadamard inequality [ Had93 ], which gives us an upper bound on the determinant of a matrix, i.e. for any matrix $B\\in \\mathbb{R}^{m\\times m}$the\n Had93\n , Applying this to inequality ( 5 ), we obtain the following corollary. $B\\in \\mathbb{R}^{m\\times m}$$$|\\operatorname{det}(B)|\\ensuremath{\\leqslant} (\\sqrt{m}\\mathopen{}\\mathclose\\bgroup\\originalleft\\lVert B\\aftergroup\\egroup\\originalright\\rVert_\\infty)^m.$$obtain the\n following\n **Corollary 9.** to\n \n\n$h(m,t)$_ satisfies_ \n\n\\begin{equation}     \\label{eq:integer:equation:bound2}         (\\sqrt{m}~t)^m\\ensuremath{\\geqslant} p_2^m p_3^m\\cdots p_{\\mathopen{}\\mathclose\\bgroup\\originalleft\\lfloor\\frac{h(m,t)}{m}\\aftergroup\\egroup\\originalright\\rfloor}^{m}p_{\\mathopen{}\\mathclose\\bgroup\\originalleft\\lceil\\frac{h(m,t)}{m}\\aftergroup\\egroup\\originalright\\rceil}^{h(m,t)-m\\mathopen{}\\mathclose\\bgroup\\originalleft\\lfloor\\frac{h(m,t)}{m}\\aftergroup\\egroup\\originalright\\rfloor}.     \\end{equation}",
    "### Comparative Analysis of Smaller Dataset (65 Images) and Larger Dataset (2700 Images) using Principal Component Analysis We conducted an experiment using Principal Component Analysis (PCA) for image reconstruction with both smaller (65 images) and larger (2700 images) datasets, utilizing 50 principal components for representation. The explained variance for the smaller dataset was approximately \\(98.19\\%\\), while for the larger one it was roughly \\(98.35\\%\\) (Figure 18). \n\nHowever, visual inspections revealed a marked degradation in quality between the two datasets(Figure 18). In the 65 image dataset, the reconstructions showed anomalies like purplish lines in the background and bluish color distortions. For the 2700-image dataset, the performance was even worse, with greenish horizontal lines appearing in the foreground and failure in capturing essential details. Several factors may contribute to this unexpected result. The increased complexity and variability within the larger dataset might have overwhelmed PCA\u2019s ability to represent finer details. Since PCA relies on linear assumptions, it might have failed to handle the nonlinear structures and dependencies that become more pronounced with the increase in data complexity. The \\(1.5\\%-2\\%\\) unexplained variance might contain critical information affecting the visual quality, especially in a larger, more intricate dataset. Moreover, the choice of 50 components might have been insufficient for capturing nuanced variations in the larger dataset, despite sufficing for the smaller one. These observations highlight PCA\u2019s limitations in handling highly complex image data and emphasize that capturing a high percentage of variance does not guarantee accurate or visually pleasing reconstruction. \n\nFigure 15: ** Smaller Network** , Original Images (First Four), Reconstructed Images (Last Four) ** (a) Row 1** : codebook size=8192, latent dimension size = 256, 65 images, without positional encoding. ** (b) Row 2** : codebook size=8192, latent dimension size = 256, 65 images, with positional encoding. (Figure 16(b)) \n\nFigure 16: ** (a) Column 1** : codebook sizes = [1024, 8192, 1024], Latent dimensions = 256, image sizes \\(=[2700,185,2700]\\), with, with and without positional encoding respectively. (refer Figure 12 & Figure 8) [2700, 185, 2700], with, with and without positional encoding respectively. (refer Figure 12 & Figure 8) (b) Column 2: Smaller network, codebook size = 8192, latent dimension size = 256, image size = 65, without and with\n : ** Smaller network** , codebook size = 8192, latent dimension size = 256, image size = 65, without and with positional encoding. (refer Figure 15) ",
    "that, for the same projection point, the higher height indicates that the transmission link is more likely to be LoS, which means the signal strength from the interfering UAV becomes stronger. Hence, when the misalignment for the beamforming is non-negligible, the lower deployment of UAVs is preferred for both schemes. Under the case of perfect beam alignment, from Fig. 6(b), it can be seen that the outage probability of MAPAS is smaller for the lower height of UAVs. The explanation is the same as before. However, in terms of the performance of CDAS, it seems that the outage probability for the higher altitude of UAVs can be better. This is mainly because of the fact the UE is associated with the closest UAV and their link can be either LoS or NLoS. As mentioned before, for the same projection point, the link from UAV at the lower height is much more likely to be NLoS, which reduces the desired signal strength at the UE whereby degrading the outage performance. \n\n### D. Effect of UAV Density \n\nFig. 7 plots the outage probability versus the number of \n\nbeam alignment case, an excessive number of antennas is adverse to the network coverage probability. As for the perfect beam alignment case, Fig. 6(b) shows that, as the number of antennas becomes large, the outage probability decreases, and the trend of decreasing gradually slows down. This figure implies that from the perspective such as hardware cost, it is not necessary to equip the UAV with too many antennas since the performance gain is very small. \n\n### C. Effect of UAV Deployment Height With regards to the effect of UAV deployment height, \n\nantennas for UAV under different UAV densities for both imperfect and perfect alignment cases. Under the imperfect beam alignment scenario, as expected, the outage probability drops at first and then rises with the increase in the number of antennas. Moreover, since more interfering UAVs are involved in the system, the higher UAV density leads to worse outage probability performance. Besides that, Fig. 7(a) shows that the optimal number of UAV antennas increases as the UAV density rises, e.g., for MAPAS, the optimal number antennas is 4 for \\(\\lambda_{k}=0.5\\times 10^{-5}\\ \\rm{m}^{-2}\\)while it goes to 16 for \\(\\lambda_{k}=5\\times 10^{-5}\\ \\rm{m}^{-2}\\). The reason is as follows. When the UAV density is very sparse, the number of interfering UAVs falling into the region covered by the main-lobe beam of the UE is very small. In other words, the interference is not that severe. Then the serving UAV needs to ensure that the typical UE is covered by its main-lobe beam; hence, a larger mainlobe beamwidth (equivalently, a smaller number of antennas) is preferred. However, when the interfering UAVs are very dense, the interference becomes very severe. One way to reduce the interference is to reduce the density of interfering UAVs with main-lobe beam pointed to the typical UE. From our analysis, this can be achieved by narrowing the main-lobe beamwidth. Note that it cannot be too narrow, because this can degrade the signal strength from the serving UAV due to the beam misalignment. Hence, a relatively larger number of antennas is preferred for the case of denser UAVs. Under the perfect beam scenario, for the MAPAS, sparse UAVs lead to a lower outage probability as expected. However, this is not the case for the CDAS. Fig. 7(b) shows that the denser UAVs can even result in a better outage probability, especially when the number of antennas is large. The reason is as follows. When the UAV density is very sparse, the closest UAV (i.e., the serving UAV) can be very far away, which consequently leads to a very weak signal strength from the serving UAV. Increasing the density of UAVs somehow improves the signal strength from the serving \n\nFig. 6(a) shows that the higher deployment of UAVs will lead to a larger outage probability under the imperfect alignment case. The reason is as follows. The higher height implies the larger coverage area of the main-lobe beam on certain tiers, which introduces more interference from more UAVs to the typical UE with the main-lobe pointed. When the beam is mispointed, this kind of effect on SINR becomes worse. Besides \n\nFig. 6. Outage probability versus the number of antennas for UAV \\(N_{v}\\) under different UAV heights for both imperfect and perfect alignment cases. ",
    "This iteration was introduced by Nadel in [31] where he also proved that periodic points of order two or three must be K\u00a8 ahler-Einstein metrics. This was generalized [20, 33] to periodic points \\(\\omega\\)of any order, that is, those satisfying \\(\\rho^{k}_{\\omega}=\\lambda\\omega\\) for any \\(k\\in\\mathbb{N}\\)if\n . The iteration (3) can be regarded as a discretization of the K\u00a8 ahler\u2013Ricci flow. Observe that, if the manifold \\(M\\) is compact, by Calabi\u2019s conjecture one does not need positivity assumptions to reverse the construction above and define the _ inverse Ricci\u2013K\u00a8_ _ahler iterations_ \\(\\rho^{-k}_{\\omega}\\). Both of this discrete dynamical systems have been studied in the literature, see for instance [5, 13]. \n\nHere we focus on the following generalized Monge-Amp` ere equation on a complex manifold \\(M\\)\n\n(4) \\[\\rho^{k}_{\\omega}=\\lambda\\Omega\\]  \n\nwhere \\(\\Omega\\)is again a K\u00a8 \\(\\Omega\\)where \u2126is again a K\u00a8\nahler form. In particular we study equation (4) for a special class of wellbehaved K\u00a8\nahler metrics. Our second result is the following theorem dealing with K\u00a8\nahler metrics\n ahler metrics. Our second result is the following theorem dealing with K\u00a8 ahler metrics induced by the flat metric (which are well-behaved by Example 4 below). \n\n**Theorem 2.** _ Let_ \\(M\\)_ be a complex manifold with two metrics_ \\(g\\)_ and_ \\(G\\)_ induced by the flat metric. If_ _the corresponding K\u00a8_ _ahler forms_ \\(\\omega,\\Omega\\)_satisfy_ \\(\\rho_{\\omega}^{k}=\\lambda\\Omega\\)_for some_ \\(k\\geqslant 1\\)_ and_ \\(\\lambda\\in\\mathbb{R}\\)_, then_ \\((M,g)\\)_ is a_ _totally geodesic submanifold of the flat ambient space._ \n\nObserve that this result can be seen as a generalization of [40, Theorem 2.1]. Namely, when \\(k=1\\) and \\(g=G\\), Theorem 2 shows that a K\u00a8 ahler\u2013Einstein submanifolds of \\(\\mathbb{C}^{n}\\)with the flat metric is necessarily Ricci-flat, hence a totally geodesic submanifold. It is worth pointing out that the metric \\(g\\) is assumed to be induced by a flat one for simplicity, but the hypothesis on \\(g\\) can be sensibly relaxed, cf. Remark 11 below. \n\nOur third and last result deals with K\u00a8 ahler\u2013Ricci solitons (KRS). Recall that a K\u00a8 ahler metric \\(G\\)is a KRS if there exists a holomorphic vector field \\(X\\) (the solitonic vector field) such that \\(\\mathrm{Ric}(G)=\\mu G+L_{X}G\\) where \\(\\mathrm{Ric}(G)\\) denotes the Ricci tensor of \\(G\\) and \\(L_{X}\\) the Lie derivative in the direction of \\(X\\). K\u00a8 ahler\u2013Ricci solitons are important generalizations of K\u00a8 ahler\u2013Einstein metrics which arise in the study of the K\u00a8 ahler\u2013Ricci flow. Our next result show that KRS cannot arise as K\u00a8 ahler\u2013Ricci iterations of metrics induced by complex space forms. \n\n**Theorem 3.** _ Let_ \\(M\\)_ be a complex manifold with two real analytic K\u00a8_ _ahler metrics_ \\(g\\)_ and_ \\(G\\)_. Assume_ _that_ \\(g\\)_ is induced by a complex space form and_ \\(G\\)_ is a KRS. If the corresponding K\u00a8_ _ahler forms_ \\(\\omega,\\Omega\\)_satisfy_ \\(\\rho_{\\omega}^{k}=\\lambda\\Omega\\)_for some_ \\(\\lambda\\neq 0\\)_ and_ \\(k\\geqslant 0\\)_, then_ \\(G\\)is trivial, i.e. K\n hler\u2013Einstein.\n \n\nObserve that, when \\(\\lambda=0\\), one cannot draw any conclusion. Take for instance \\(g\\) to be the flat metric on \\(\\mathbb{C}\\) and \\(G\\) to be Hamilton\u2019s cigar KRS [17]. It is worth mentioning that we do not know of any K\u00a8 ahler\u2013Einstein metric \\(G\\) and K\u00a8 ahler metric \\(g\\) induced by a complex space form which satisfy \\(\\rho_{\\omega}^{k}=\\lambda\\Omega\\)for \\(\\lambda<0\\) unless \\(g=G\\) and \\(k=1\\). In that case \\(M\\) is forced to be a totally geodesic submanifold in \\(\\mathbb{C}\\mathrm{H}^{n}\\)[40]. On the other hand, such examples for \\(\\lambda>0\\) are discussed in Section 3, see in particular Proposition 2. \n\nAlso in this case we generalize some recent results on KRS induced by complex space forms which indeed served as partial motivation for this paper. In particular, if we assume \\(k=0\\) (and \\(\\lambda>0\\)) in Theorem 3, we recover [25, Theorem 1.1]. If we restrict to compact complex manifolds, then this result can be rephrased in terms of the inverse K\u00a8 \\(\\rho^{-k}_{\\omega}\\)of a non-trivial KRS\n \\((g,X)\\)on\n ahler\u2013Ricci iterations \\(\\rho^{-k}_{\\omega}\\)of a non-trivial KRS \\((g,X)\\) on a compact complex manifold \\(M\\) can be induced by a complex space form. ",
    "Finally, let us simplify Term 1: \n\n\\[{\\rm Term1}\\] =exp({)\u2212i\u03b11(s)E}exp({)\u2212i\u03b12(s)P}exp({)\u2212i\u03b13(s)Q}(exp({)\u2212i\u03b14(s)H}\u03b14\u2032(s)H) =\u03b14\u2032(s)exp({)\u2212i\u03b11(s)E}exp({)\u2212i\u03b12(s)P}(exp({)\u2212i\u03b13(s)Q}H)exp({)\u2212i\u03b14(s)H} =\u03b14\u2032(s)e\u2212i\u2062\u03b11\u2062(s)\u2062Ee\u2212i\u2062\u03b12\u2062(s)\u2062P(exp({)\u2212i\u03b13(s)Q}H)ei\u2062\u03b13\u2062(s)\u2062Q\u2062e\u2212i\u2062\u03b13\u2062(s)\u2062Q\u23dfIdentity operator inserted exp({)\u2212i\u03b14(s)H} =\u03b14\u2032(s)exp({)\u2212i\u03b11(s)E}exp({)\u2212i\u03b12(s)P}(exp({)\u2212i\u03b13(s)Q}Hexp({)i\u03b13(s)Q}\u23dfApply Baker-Campbell Hausdorff formula) exp({)\u2212i\u03b13(s)Q}exp({)\u2212i\u03b14(s)H} =\u03b14\u2032(s)exp({)\u2212i\u03b11(s)E}exp({)\u2212i\u03b12(s)P}(H+\u03b13(s)P+\u03b13\u2062(s)22E) exp({)\u2212i\u03b13(s)Q}exp({)\u2212i\u03b14(s)H} =\u03b14\u2032(s)exp({)\u2212i\u03b11(s)E}exp({)\u2212i\u03b12(s)P}Hexp({)\u2212i\u03b13(s)Q}exp({)\u2212i\u03b14(s)H} +\u03b14\u2032(s)exp({)\u2212i\u03b11(s)E}exp({)\u2212i\u03b12(s)P}\u03b13(s)Pexp({)\u2212i\u03b13(s)Q}exp({)\u2212i\u03b14(s)H} +\u03b14\u2032(s)exp({)\u2212i\u03b11(s)E}exp({)\u2212i\u03b12(s)P}\u03b13\u2062(s)22Eexp({)\u2212i\u03b13(s)Q}exp({)\u2212i\u03b14(s)H} =\u03b14\u2032(s)exp({)\u2212i\u03b11(s)E}(H\u2212\u03b12(s)Q+\u03b12\u2062(s)22E) exp({)\u2212i\u03b12(s)P}exp({)\u2212i\u03b13(s)Q}exp({)\u2212i\u03b14(s)H} \\[~{}~{}+\\alpha_{4}^{\\prime}(s)\\alpha_{3}(s)PU(s)+\\alpha_{4}^{ \\prime}(s)\\frac{\\alpha_{3}(s)^{2}}{2}EU(s)\\] \\[=\\alpha_{4}^{\\prime}(s)HU(s)-\\alpha_{4}^{\\prime}(s)\\alpha_{2}(s) QU(s)+\\frac{1}{2}\\alpha_{4}^{\\prime}(s)\\alpha_{2}(s)^{2}EU(s)\\] \\[~{}~{}~{}~{}~{}~{}~{}+\\alpha_{4}^{\\prime}(s)\\alpha_{3}(s)PU(s)+ \\frac{1}{2}\\alpha_{4}^{\\prime}(s)\\alpha_{3}(s)^{2}EU(s)\\] =(\u03b14\u2032(s)H\u2212\u03b14\u2032(s)\u03b12(s)Q+12\u03b14\u2032(s)\u03b12(s)2E +\u03b14\u2032(s)\u03b13(s)P+12\u03b14\u2032(s)\u03b13(s)2E)U(s). (292)  \n\nThe above form of \\(dU(s)/ds\\) is exactly what was required. Now we one simply match the coefficients of the corresponding generators on both sides and arrive at the following ",
    "KYUNGKEUN KANG AND CHANHONG MIN \n\nThe first integral of ( 5.21 ) can be estimated as follows: for any \\(\\epsilon>0\\), \n\n\\[\\int_{\\frac{1}{4}}^{\\frac{1}{2}}\\int_{|y^{\\prime}|\\leq 1} \\frac{1}{(t-s)^{\\frac{1}{2}}(|x-y^{\\prime}|^{2}+(t-s))^{\\frac{n-1 }{2}}}\\left|\\partial_{s}g_{k}^{\\mathcal{T}}(s)\\right|dy^{\\prime}ds\\] \\[\\lesssim\\int_{\\frac{1}{4}}^{\\frac{1}{2}}\\frac{1}{(t-s)^{\\frac{1}{ 2}}}\\frac{\\log\\left(2+\\frac{1}{\\sqrt{t-s}}\\right)}{(|x|+1+\\sqrt{t-s})^{n-1}}ds\\] \\[\\lesssim\\frac{1}{\\left<x\\right>^{n-1}}\\int_{\\sqrt{t-\\frac{1}{2}}} ^{\\sqrt{t-\\frac{1}{4}}}\\log\\left(2+\\frac{1}{u}\\right)du\\lesssim\\frac{1}{\\left< x\\right>^{n-1}}\\int_{\\sqrt{t-\\frac{1}{2}}}^{\\sqrt{t-\\frac{1}{4}}}\\frac{1}{v^{ \\epsilon}}dv\\] \\[\\lesssim\\frac{(t-\\frac{1}{2})^{\\frac{1-\\epsilon}{2}}}{\\left<x \\right>^{n-1}}.\\]  \n\nThe second integral of ( 5.21 ) can be estimated as follows: \n\n\\[\\int_{\\frac{1}{2}}^{1}\\int_{|y^{\\prime}|\\leq 1} \\frac{1}{(t-s)^{\\frac{1}{2}}(|x-y^{\\prime}|^{2}+(t-s))^{\\frac{n-1 }{2}}}\\left|\\partial_{s}g_{k}^{\\mathcal{T}}(s)\\right|dy^{\\prime}ds\\] \\[\\lesssim\\int_{\\frac{1}{2}}^{1}\\int_{|y^{\\prime}|\\leq 1}\\frac{1}{( t-s)^{\\frac{1}{2}}(|x-y^{\\prime}|^{2}+(t-s))^{\\frac{n-1}{2}}(1-s)^{1-a}}dy^{ \\prime}ds\\] \\[\\lesssim\\int_{\\frac{1}{2}}^{1}\\frac{1}{(t-s)^{\\frac{1}{2}}}\\frac{ \\log\\left(2+\\frac{1}{\\sqrt{t-s}}\\right)}{(|x|+\\sqrt{t-s}+1)^{n-1}}\\frac{1}{(1- s)^{1-a}}ds\\mathbbm{1}_{|x|<2}+\\int_{\\frac{1}{2}}^{1}\\frac{1}{(t-s)^{\\frac{1}{ 2}}(1-s)^{1-a}}ds\\frac{1}{|x|^{n-1}}\\mathbbm{1}_{|x|>2}\\] \\[\\lesssim\\int_{\\sqrt{t-1}}^{\\sqrt{t-\\frac{1}{2}}}\\frac{\\log\\left(2 +\\frac{1}{u}\\right)}{(1-t+u^{2})^{1-a}}du\\mathbbm{1}_{|x|<2}+\\frac{\\textup{LN} ^{*}}{|x|^{n-1}}\\mathbbm{1}_{|x|>2}\\] \\[\\lesssim\\int_{\\sqrt{t-1}}^{\\sqrt{t-\\frac{1}{2}}}\\frac{(1+\\frac{1} {u})^{\\epsilon}}{(1-t+u^{2})^{1-a}}du\\mathbbm{1}_{|x|<2}+\\frac{\\textup{LN}^{*} }{|x|^{n-1}}\\mathbbm{1}_{|x|>2}\\] \\[\\lesssim\\int_{\\sqrt{t-1}}^{\\sqrt{t-\\frac{1}{2}}}\\frac{1}{u^{ \\epsilon}(1-t+u^{2})^{1-a}}du\\mathbbm{1}_{|x|<2}+\\frac{\\textup{LN}^{*}}{|x|^{n -1}}\\mathbbm{1}_{|x|>2}\\] \\[\\lesssim\\frac{1}{(t-1)^{\\frac{\\epsilon}{2}}}\\int_{0}^{\\frac{1}{2} }\\frac{dv}{v^{1-a}(t-1+v)^{\\frac{1}{2}}}\\mathbbm{1}_{|x|<2}+\\frac{\\textup{LN}^ {*}}{|x|^{n-1}}\\mathbbm{1}_{|x|>2}\\] \\[\\lesssim\\frac{\\textup{LN}^{*}}{(t-1)^{\\frac{\\epsilon}{2}}} \\mathbbm{1}_{|x|<2}+\\frac{\\textup{LN}^{*}}{|x|^{n-1}}\\mathbbm{1}_{|x|>2}.\\]  \n\nThus we conclude that \n\n(707.1) \\[|I_{2}|\\lesssim\\frac{\\left(t-\\frac{1}{4}\\right)^{\\frac{1-\\epsilon}{2}}}{\\left< x\\right>^{n-1}}+\\mathbbm{1}_{|x|<2}\\frac{\\textup{LN}^{*}}{(t-1)^{\\frac{ \\epsilon}{2}}}+\\mathbbm{1}_{|x|>2}\\frac{\\textup{LN}^{*}}{|x|^{n-1}}.\\]  \n\nHence ( 5.17 ), ( 5.19 ) and ( 5.22 ) give \n\n\\[|I_{2}| \\lesssim\\mathbbm{1}_{|x|<2}\\left(\\mathbbm{1}_{t\\leq\\frac{1}{2}} \\left(t-\\frac{1}{4}\\right)^{\\frac{1-\\epsilon}{2}}+\\mathbbm{1}_{\\frac{1}{2}\\leq t <1}\\left(1+\\frac{1}{(1-t)^{\\frac{1+\\epsilon}{2}-a}}\\right)+\\mathbbm{1}_{t>1} \\frac{\\textup{LN}^{*}}{(t-1)^{\\frac{\\epsilon}{2}}}\\right)\\] \\[+\\mathbbm{1}_{|x|>2}\\left(\\mathbbm{1}_{t\\leq\\frac{1}{2}}\\frac{1}{ |x|^{n-1}}+\\left(\\mathbbm{1}_{\\frac{1}{2}\\leq t<1}+\\mathbbm{1}_{t>1}\\right) \\left(\\frac{1}{|x|^{n-1}}+\\frac{\\textup{LN}^{*}}{|x|^{n-1}}\\right)\\right).\\]  \n\nFor the estimates of the higher spatial derivatives, the similar argument as above gives the result, and this proves the pressure estimate.  \u25a1 ",
    "corresponding statistical estimators. In this case, we also use the LP / B03 / ExD model from the spec- \\(z\\) as reference to check the impact of the GaZNet redshift in terms of accuracy and scatter. Basically, the results show that, for the same correlations seen in Fig.  3 , the relative bias of the di ff erent configurations is not worsened, meaning that the accuracy of the mass estimates is not a ff ected by the use of the morphoto- \\(z\\). This is eventually a consequence of the good accuracy of these latter as seen in Fig.  2 . On the other hand, we register an evident increase of the NMAD as a consequence of the morphoto- \\(z\\) intrinsic statistical errors and outlier fractions, which is also mirrored by the scatter of the residual, at the bottom of the 1-to-1 relations, which is now of the order of 0.23 dex, for\n \\(\\log M_{*}/M_{\\odot}>9\\), and 0.49 dex for\n \\(\\log M_{*}/M_{\\odot}<9\\), on average. These large scatter at low stellar masses\n are mainly caused by the trend we see that below\n \\(\\log M_{*}/M_{\\odot}=8.5\\), where stellar masses are systematically overestimated\n compared to those obtained with the spec- \\(z\\). This is not an e ff ect that comes from the particular set-up of the fitting procedure, as shown by the comparison of the LP / B03 / ExD / morphoto- \\(z\\) against the same set-up with spec- \\(z\\) (bottom / left plot in Fig.  4 ). Even in this latter case, we see that below\n \\(\\log M_{*}/M_{\\odot}=8.5\\)the positive bias is similar to the ones of all other configurations.\n We track the motivation of this systematics to some bias of the GaZNet redshifts for a group of objects at very low redshifts ( \\(z<0.05\\)see Fig.\n  2 ), which turn-out to have also low masses. This can be due to some residual contamination from stars, not picked in the spectra classification, or just a failure of the GaZNet predictions at very low- \\(z\\), which clearly impact the mass predictions. We will come back to this on Sect.  4 . However, still looking at the LP / B03 / ExD / morphoto- \\(z\\) vs. spec- \\(z\\), above \\(\\log M_{*}/M_{\\odot}=8.5\\), the bias is almost absent and the only relevant ef\n ff ect is the GaZNet redshift scatter that, from the NMAD, is quantified in 0.09. This is confirmed by noticing that the general increase of the NMAD from the spectroscopic sample to the morphoto-metric sample, in Table  2 , is compatible with the sum in quadrature of the NMAD of the former with\n \\(0.09\\)coming\n from the latter, consistently with some pseudo-Gaussian distributions. This is consistent with a log-normal distribution of the uncertainties of the stellar masses, which are confirmed by the outlier fractions that are all of the order of 5-6% above 2 \\(\\sigma\\) of the \n\nStellar mass estimates as for Fig.  3  but using the GaZNet morphoto-metric redshifts. ",
    "# Improving Generalization in Visual Reinforcement Learning via Conflict-aware Gradient Agreement Augmentation \n\nSiao Liu Zhaoyu Chen Yang Liu Yuzheng Wang Dingkang Yang Zhile Zhao Ziqing Zhou Xie Yi Wei Li Wenqiang Zhang Zhongxue Gan Academy for Engineering & Technology, Fudan University _{_ saliu20, zhaoyuchen20, yang liu20, yzwang20, dkyang20, fd liwei, wqzhang, ganzhongxue _}_ @fudan.edu.cn \n\n_{_ zhilezhao21, ziqingzhou21, yixie22 _}_ @m.fudan.edu.cn \n\n##### Abstract\n_Learning a policy with great generalization to unseen_ \n\nof a pretrained RL agent to perform well in unseen environments. Due to the dynamic nature of the real world, even minor perturbations in the environment can result in significant semantic shifts in the visual observations, which makes visual RL generalization challenging. \n\n##### Abstract\n_environments remains challenging but critical in visual reinforcement learning._ _Despite the success of augmentation combination in the supervised learning generalization,_ \n\nTo improve generalization performance, data augmentation [29] is a widely adopted technique in reinforcement \n\n##### Abstract\n_naively applying it to visual RL algorithms may damage_ _the training efficiency, suffering from serve performance_ _degradation._ _In this paper, we first conduct qualitative_ \n\nlearning. Numerous studies [22, 13] utilize data augmentation methods to generate synthetic data and diversify the training environments, yielding considerable performance improvements. However, recent methods [14, 3, 44] mostly select a single augmentation technique to improve the generalization capability, resulting in a poor performance in the environments with observations varying far from the augmented images. For instance, ColorJitter [23] is the preferred choice for addressing color variations, but agents trained with such augmentation still hard to cope with intricate texture patterns. In other words, the generalization ability heavily relies on the selection of specific data augmentation technique, which is so-called generalization bias. \n\nCompared to single data augmentation, Augmentation \n\n##### Abstract\n_analysis and illuminate the main causes: (i) high-variance_ _gradient magnitudes and (ii) gradient conflicts existed in_ _various augmentation methods. To alleviate these issues,_ _we propose a general policy gradient optimization framework, named Conflict-aware Gradient Agreement Augmentation (CG2A), and better integrate augmentation combination into visual RL algorithms to address the generalization_ _bias. In particular, CG2A develops a Gradient Agreement_ _Solver to adaptively balance the varying gradient magnitudes, and introduces a Soft Gradient Surgery strategy to alleviate the gradient conflicts. Extensive experiments demonstrate that CG2A significantly improves the generalization_ _performance and sample efficiency of visual RL algorithms._ \n\n## 1. Introduction \n\nWith the development of deep learning in various \n\nCombination (AC) [16] integrates multiple data augmentation methods to enhance the diversity of augmentations and alleviate the generalization bias, which is a more promising pre-processing solution. Unfortunately, there is a dilemma in incorporating AC into visual RL. Although data augmentation combination can effectively improve generalization capability in the supervised visual tasks, RL algorithms are quite sensitive to excessive variations, resulting in performance degradation and training sample inefficiency. Therefore, it is necessary to rethink why visual RL algorithms cannot benefit from AC as much as supervised learning. \n\nFrom the perspective of gradient optimization, we conduct numerous qualitative analysis to illustrate the causes \n\ntasks [28, 26, 25, 27, 7, 6, 38, 40, 39, 24], visual Reinforcement Learning (RL) has achieved impressive success in various fields such as robotic control [11], autonomous driving [17], and game-playing [35]. Previous works usually formulate it as a Partially Observable Markov Decision Process (POMDP) [33], and the agent receives highdimensional image observations as inputs. As depicted \n\nof performance degradation and training collapse that occur when employing augmentation combinations during train- \n\nin [15, 14], visual RL generalization refers to the ability ",
    "Lemma\n _ Let_ \\(x=\\Delta^{k}\\)_for some nonzero integer_ \\(k\\)_. We have_ \\(\\operatorname{SSS}(\\Delta^{k})=\\{\\Delta^{k}\\}\\)and\n _. The_ _centralizer of_ \\(\\Delta^{k}\\)_in_ \\(G(m,\\ell)\\)_ is either_ \\(G(m,\\ell)\\)_ if_ \\(k\\ell\\)_is a multiple of_ \\(m\\)_, or cyclic and generated_ _by_ \\(\\Delta\\)_otherwise._ \n\n_Proof._  We have that \\(y\\in G(m,\\ell)\\)is\n lies in\n \\(\\operatorname{SSS}(\\Delta^{k})\\)only if\n \\(\\inf(y)=k=\\sup(y)\\). The only\n element satisfying this is\n \\(\\Delta^{k}\\), which is conjugate to itself. Thus we have\n \\(\\operatorname{SSS}(\\Delta^{k})=\\{\\Delta^{k}\\}\\). Now, let \\(s(j,q)\\)be a simple element in\n \\(M(m,\\ell)\\). Since both\n \\(1\\)and\n \\(\\Delta\\)conjugate\n \\(\\Delta^{k}\\)to itself, we can assume that \\(q\\in\\overline{Q}_{n}(u){1,m-1}\\)e hav\n \n\n\\[s(j,q)^{-1}\\Delta^{k}s(j,q) =\\bar{\\bar{s(j,q)}}\\Delta^{k-1}s(j,q)\\] \\[=s(j+q,\\ell-q)\\Delta^{k-1}s(j,q)\\] \\[=\\Delta^{k-1}s(j+q+(k-1)\\ell,\\ell-q)s(j,q).\\]  \n\nIn order for this element to lie in\n \\(\\operatorname{SSS}(\\Delta^{k})\\), the word\n \\(s(j+q+(k-1)\\ell,\\ell-q)s(j,q)\\)ultiple of\n must\n not be greedy. This is equivalent to _ j_ \\(j+k\\ell\\equiv j[m]\\)I\n _ k\u2113_ \\(k\\ell\\)a multiple of\n _ m_ \\(m\\)his is true for\n all _ \u2208_ \\(j\\in\\overline{Q}_{n}(u){0,m-1}\\)e obtain\n _j, q_ \\(s(j,q)^{-1}\\Delta^{k}s(j,q)=\\Delta^{k}\\)rows from \u2206\n \\(\\Delta^{k}\\)in\n CG(\u2206 _k_ \\(\\operatorname{CG}(\\Delta^{k})\\)n by all the simple elements. Otherw\n  + true for\n _ \u2208_ 1, m\n \\(j\\in\\overline{Q}_{n}(u){1,m-1}\\)arrows from\n \\(\\Delta^{k}\\)G(\n \\(\\operatorname{CG}(\\Delta^{k})\\)1 and \u2206.\n \u25a1 \n\n_We have_ ) = \\(x=\\Delta^{k}s(i,p)\\)n \u2208\n [ [0 _ \u2212_ }. The cen\n \\(M(m,\\ell)\\) \u2206 \\(p\\in\\overline{Q}_{n}(u){1,m-1}\\)s\n cyclic an\n \\(\\operatorname{SSS}(x)=\\{\\Delta^{k}s(n,p)~{}|~{}n\\in\\overline{Q}_{n}(u){0,m-1}\\}\\)\n\n_j, q_ be a simple element i\n \\(x\\)_ M_ _m, \u2113_ ). We have _j,q_ _k_ \n\n\n\nSince + p \u22610\n _m_ \\(\\operatorname{SSS}(x)\\)ns are equivalent. If th\n \\(j+k\\ell\\equiv i[m]\\)d,\n \\(i+p\\equiv j[m]\\)e\n \n\n(17) \\[x^{s(j,q)}=\\Delta^{k}s(j+q-p,p)=\\Delta^{k}s(i+q,p).\\]  \n\n_, m_ \\(s(p,n)\\)r \u2206ks\n _n, p_ SSS( ), the simples \\(\\Delta^{k}s(0,p)\\)(\u2206\n \\(\\Delta^{k}s(n,p)\\)\u2208SS\n \\(n\\in\\overline{Q}_{n}(u){0,m-1}\\)e\n ( \\(\\Delta^{k}s(n,p)\\in\\operatorname{SSS}(x)\\)ph of\n \\(s\\)given by\n \n\n\n\n(19) \\(\\Delta^{k}s(0,p)\\)+\n  1) \n\n\n\n( + m \u22121 1\n \n\n\n\n 1) = \n\n_m_ Garside automorphism , corresponding to conjugacy by \u2206on the right, sends a simple element ) to \\(\\phi\\), \n _ m_ _ \u2113_ \\(\\Delta\\)t trivial power of \u03d5\n  is and \u2206 \\(s(i,p)\\)e s\n \\(s(i+\\ell,p)\\)ntra\n \\(m\\neq 1\\neq\\ell\\)\u2206in G\n _m, \u2113_ \n\n_ m, \u2113_ _be two positive integers. If_  = 1 _m_ \\(m,\\ell\\)= 2 _, then_ _ G_  Z \\(m=1\\)Ot\n \\(\\ell=1\\)e\n ( \\(G(m,\\ell)\\simeq\\mathbb{Z}\\)ite cyclic and\n \\(m=\\ell=2\\)y\n _m_ ",
    "\n* Merloni A., et al., 2000, Monthly Notices of the Royal Astronomical Society, 313, 193 \n\nture during a significant decrease in disk contribution, as well as the study of timing characteristics in that state. \n\n## 6 ACKNOWLEDGEMENTS \n* Miller J., et al., 2008, The Astrophysical Journal, 680, 1359 Mineshige S., et al., 1994, The Astrophysical Journal, 426, 308 Mitsuda K., et al., 1984, Publications of the Astronomical Society of Japan, 36, 741 \n\nWe would like to thank the anonymous referee for their valuable \n* Morningstar W. R., Miller J. M., 2014, The Astrophysical Journal Letters, 793, L33 \n* Mudambi S. P., et al., 2022, Monthly Notices of the Royal Astronomical Society, 517, 4489 \n* Negoro H., et al., 2021a, The Astronomer\u2019s Telegram, 14701, 1 Negoro H., et al., 2021b, The Astronomer\u2019s Telegram, 14708, 1 Negoro H., et al., 2022, The Astronomer\u2019s Telegram, 15715, 1 Orosz J., et al., 2002, in American Astronomical Society Meeting Abstracts. pp 15\u201311 \n\nsuggestions, which improved the quality of this work. This work has utilized data from _ AstroSat_  mission which is archived at Indian Space Science Data Centre (ISSDC). We are grateful to the SXT and LAXPC POC teams for providing the data and requisite softwares to perform data analysis. NH acknowledges the financial support provided by Department of Science and Technology (DST) under the INSPIRE fellowship scheme. AG, RM and SS acknowledges the financial support provided by Department of Space, Govt of India \\(\\_\\)2B-13012(2)/\n / 2 / 2022-Sec.2). \n* Orosz J., et al., 2003, in Proceedings of IAU Symposium. Park S. Q., et al., 2004, The Astrophysical Journal, 610, 378 Ponti G., et al., 2012, Monthly Notices of the Royal Astronomical Society: Letters, 422, L11 \n\n## 7 DATA AVAILABILITY The data used in the publication is publicly available \n* Prabhakar G., et al., 2023, Monthly Notices of the Royal Astronomical Society Rawat D., et al., 2022, Monthly Notices of the Royal Astronomical Society, 511, 1841 \n* Reeves J., et al., 2008, Monthly Notices of the Royal Astronomical Society: Letters, 385, L108 \n\nfor download at  https://astrobrowse.issdc.gov.in/astro_ archive/archive/Home.jsp  using the observation IDs mentioned in Tab  1 . \n* Remillard R. A., McClintock J. E., 2006, Annu. Rev. Astron. Astrophys., 44, 49 \n* REFERENCES \n* Agrawal P., et al., 2017, Journal of Astrophysics and Astronomy, 38, 30 Antia H., et al., 2017, The Astrophysical Journal Supplement Series, 231, 10 Asplund M., et al., 2009, Annual review of astronomy and astrophysics, 47, 481 \n* Shafee R., et al., 2005, The Astrophysical Journal, 636, L113 Shakura N. I., Sunyaev R. A., 1973, Astronomy and Astrophysics, 24, 337 Shimura T., Takahara F., 1995, The Astrophysical Journal, 445, 780 Singh K. P., et al., 2016, in Space Telescopes and Instrumentation 2016: Ultraviolet to Gamma Ray. pp 389\u2013398 Singh K., et al., 2017, Journal of Astrophysics and Astronomy, 38, 1 Steiner J. F., et al., 2010, The Astrophysical Journal Letters, 718, L117 Takahashi H., Makishima K., 2006, Proceedings of the The X-ray Universe 2005 (ESA SP-604). 26-30 September 2005, El Escorial, Madrid, Spain. Editor: A. Wilson, p. 309, 604, 309 \n* Belloni T. M., et al., 2011, arXiv preprint arXiv:1109.3388 Bhargava Y., et al., 2022, Monthly Notices of the Royal Astronomical Society, 512, 6067 Capitanio F., et al., 2009, Monthly Notices of the Royal Astronomical Society, 398, 1194 Chevalier C., Ilovaisky S., 1992, International Astronomical Union Circular, 5520, 1 \n* Trigo M. D., et al., 2007, Astronomy & Astrophysics, 462, 657 Verner D., Ferland G. J., Korista K., Yakovlev D., 1996, arXiv preprint astroph / 9601009 Wang J., et al., 2022, The Astronomer\u2019s Telegram, 15253, 1 Watarai K.-y., et al., 2000, Publications of the Astronomical Society of Japan, 52, 133 \n* Connors R., et al., 2021, The Astronomer\u2019s Telegram, 14725, 1 Dauser T., et al., 2014, Monthly Notices of the Royal Astronomical Society: Letters, 444, L100 \n* Wilms J., et al., 2000, The Astrophysical Journal, 542, 914 Zhang X., et al., 2022, The Astronomer\u2019s Telegram, 15157, 1 Zimmerman E., et al., 2005, The Astrophysical Journal, 618, 832 \n* Davis S. W., et al., 2005, The Astrophysical Journal, 621, 372 Done C., et al., 2007, The Astronomy and Astrophysics Review, 15, 1 Draghis P. A., et al., 2022, arXiv preprint arXiv:2210.02479, DR22 Ebisawa K., et al., 1993, Astrophysical Journal, Part 1 (ISSN 0004-637X), vol. 403, no. 2, p. 684-689., 403, 684 \n* Ebisawa K., et al., 2003, The Astrophysical Journal, 597, 780 Garcia J., Kallman T. R., 2010, The Astrophysical Journal, 718, 695 Garg A., et al., 2022, Monthly Notices of the Royal Astronomical Society Gierli\u00b4 nski M., Done C., 2004, Monthly Notices of the Royal Astronomical Society, 347, 885 \n* Gierli\u00b4 nski M., et al., 1999, Monthly Notices of the Royal Astronomical Society, 309, 496 \n* Harmon B., et al., 1992, International Astronomical Union Circular, 5510, 2 Husain N., et al., 2022, Monthly Notices of the Royal Astronomical Society, 510, 4040 \n* Kallman T., Bautista M., 2001, The Astrophysical Journal Supplement Series, 133, 221 Kitamoto S., et al., 1984, Publications of the Astronomical Society of Japan, 36, 799 \n* Kubota A., et al., 2007, Publications of the Astronomical Society of Japan, 59, S185 \n* Li L.-X., et al., 2005, The Astrophysical Journal Supplement Series, 157, 335 Matilsky T., et al., 1972, The Astrophysical Journal, 174, L53 McClintock J. E., et al., 2006, The Astrophysical Journal, 652, 518 ",
    "the presynaptic and postsynaptic neuron activities have low correlation their connection are likely to be removed. The latter process is called synaptic pruning and it is considered essential for optimizing activity propagation and memory capacity(Chklovskii, Mel, and Svoboda, 2004; Knoblauch _ et al._ , 2014; Knoblauch and Sommer, 2016). Furthermore, it is commonly believed that synaptic pruning and rewiring dysfunction are one of the neural correlate of developmental disorders such as autism or schizophrenia (Bourgeron, 2009;\nMoyer, Shelton, and Sweet,\n \n\n2015), leading to, respectively, an higher or lower synaptic density with respect to neurotypical subjects(Hutsler and Zhang, 2010; Pagani _ et al._ , 2021; Glantz and Lewis, 2000). In the last decades computational neuroscience has investigated brain dynamics at different scales, from cellular (Markram _ et al._ , 2015) to mesoscopic and macroscopic through mean-field approaches (Wilson and Cowan, 1972; Amit and Brunel, 1997; Hopfield, 1984; Renart, Brunel, \n\n2020). Regarding synaptic plasticity, computational models were mostly focused on plasticity mechanisms that involve strengthening or weakening of existing synapses, like short-term plasticity (STP) (Tsodyks, Pawelzik, and Markram, 1998) or spike timing-dependent plasticity (STDP) (G\u00a8 utig _ et al._ , 2003) and on their role in short-term, long-term, working memory and learning \n\nqiang Bi and ming Poo, 2001; Golosio _ et al._ , 2021; Capone _ et al._ , 2022). Only in recent times computational models of structural plasticity and connectivity rearrangements during learning were developed, showing intriguing results. Knoblauch _ et al._  (2014) and Knoblauch and Sommer (2016) describe a model of structural plasticity based on \u201deffectual connectivity\u201d, defined in these works as the fraction of synapses able to represent a memory stored in a network. By structural plasticity, effectual connectivity is improved, since synapses that do not code for the memory are moved in order to optimize network\u2019s connectivity. Their model defines synapses using a Markov model of three states: potential (i.e. not instantiated), instantiated but silent or instantiated and consolidated. Structural plasticity is thus related to the passage of the synapses from a potential state to an instantiated state (and vice versa), whereas changes only related to the synaptic weight are described by the consolidation of the instantiated synapses. With such a model, it is possible to show that networks with structural plasticity have higher or comparable memory capacity to networks with dense connectivity and it is possible to explain some cognitive mechanism such as the spacing effect (Knoblauch _ et al._ , 2014). Spiess _ et al._  (2016) simulated a spiking neural network with structural plasticity and STDP, showing that structural plasticity reduces the amount of noise of the network after a learning process, thus making the network able to have a clearer output. Furthermore, such a network with structural plasticity shows higher learning speed than the same network with only STDP implemented. Some new insights about the importance of synaptic pruning are also shown in Navlakha, Barth, and Bar-Joseph (2015), in which different pruning rates were studied suggesting that a slowly decreasing rate of pruning over time leads to more efficient network architectures. As discussed above, the biochemical and biophysical mechanisms underlying structural plasticity are extremely complex and only partially understood to date. For this reason, rather than attempting to build a biologically detailed model, this work exploits a relatively simple phenomenological model, including both the activity-driven and the homeostatic contributions; despite the lower complexity, this model accounts for the effects of structural plasticity in terms of the consolidation of synaptic connections between neurons with a high activity correlation as well as those of pruning and rewiring the connections for which this correlation is lower. This approach is also justified by the requirement for a simple and effective computational model suitable for simulating networks with a relatively large number of neurons and connections and for representing learning processes with sizable numbers of training and validation patterns. This model will then serve as the foundation for the creation of a mean-field-based theoretical framework for learning through synaptic plasticity capable of accounting for a variety of biological network properties. This framework will be used in a training and validation procedure to characterize learning and memory capacity of plastic neuronal networks as the number of training patterns and other model parameters vary. The results will then be compared with those obtained through simulations based on firing-rate-based neuronal networks. The model consid- ",
    "[width=85mm]figure2.pdf \n\nlength \\(\\xi_{L}\\) which is given by \n\n\\[\\xi^{2}_{L}\\equiv\\frac{1}{4\\sin^{2}(k/2)}{\\left(\\frac{\\langle q^{2}\\rangle}{ \\langle\\mid q(\\vec{k})\\mid^{2}\\rangle}-1\\right)}\\;,\\] (11)  \n\n\n\nwhere \\(q(\\vec{k})\\) is \n\n\n\n[width=82mm]figure3.pdf \n\n\\[q({\\vec{k}})\\equiv\\frac{1}{N}\\sum_{j}s^{(1)}_{j}s^{(2)}_{j}e^{{\\rm i}\\vec{k} \\cdot\\vec{r}_{j}}\\;,\\] (12)  \n\nErrors in the measurements of these quantities have \n\nwith \\(\\vec{r}_{j}\\)\\(\\vec{r}_{j}\\) the position of the \\(j\\)-th NP, \\(\\vec{k}=(2\\pi/L,0,0)\\)\\(\\vec{k}=(2\\pi/L,0,0)\\) and \n\n\\(k=\\|\\vec{k}\\|=2\\pi/L\\)\n\nErrors\n \n\n\n\nthe\n \n\n. . \n\nbeen calculated as the mean squared deviations of the sample-to-sample fluctuations. \n\n## RESULTS \n\n### Phase diagram for isotropic HS-like configurations \n\nIn this section we investigate the magnetic order as \n\n\\(N\\). An extrapolation of the positions of the maxima of those peaks vs\n \\(1/N\\) provides a value for the transition temperature, \\(T_{c}(\\Phi=0.4)\\simeq 1.9(1)\\)\\(1/N\\)provides\n \\(\\chi_{m}\\)the\n not\n , in agreement with the estimated \\(T_{c}\\) obtained from the analysis of Fig. 1(a). For \\(T<T_{c}\\) we find that \\(\\chi_{m}\\) does not diverge with \\(N\\), a fact that validates the above conclusions on FM order. All that is in contrast to the results obtained for\n \\(\\Phi=0.1\\),\n shown in Fig. 2(c) where we see how the values of \\(\\chi_{m}\\)increase with \\(N\\) for low \\(T\\). Data are consistent with a trend \\(\\chi_{m}\\sim N^{p}\\)for \\(p\\approx 0.45\\)and\n \\(T\\lesssim 0.2\\). This behavior\n suggests the existence of a SG phase. \n\n\\(\\Phi\\)at which\n \n\n\\(\\Phi\\)a function of the volume fraction \u03a6 for frozen configurations obtained from equilibrium states of hard sphere\n fluids in the range\n \\(0<\\Phi\\lesssim 0.49\\).\n \\(\\Phi\\)measures the degree\n of spatial disorder on such configurations. We will show \\(\\Phi\\)(which means increasing disorder)\n SG order replaces the FM order. \n\nA first overview can be grasped from Figs. 1-2. \n\nThe plots in Fig. 3 show that the FM order persists at \n\nthe FM order disappears. Mean-field calculations predict that FM order persists for\n \\(\\Phi\\geq\\Phi_{c}=\\pi/20\\sim 0.157\\).\n 20 \n\nFig. 1(a) displays plots of the specific heat \\(c\\) vs \\(T\\) for \\(\\Phi=0.4\\). The curves exhibit a marked lambda-shaped\n peak. Their evident dependence on the number of NP indicates the presence of a singular point in the curve that corresponds to \\(N\\to\\infty\\)at \\(T_{c}\\approx 1.9\\). That singular\n behavior is expected in PM-FM second order transitions. Data are consistent with a logarithmic divergence of \\(c\\)with \\(N\\). Fig. 1(b) shows the plots obtained for\n \\(\\Phi=0.1\\).\n In contrast to the previous ones, these plots are smooth and depend little on the sample size. So, there is no sign of any singular behavior. This is expected in PM-SG \n\n\\(\\Phi=0.18\\). The curves of\n \\(m_{1}\\) vs \\(T\\) in panel (a) indicate an increase in magnetization with \\(N\\) at low \\(T\\), although they also exhibit relevant finite size effects. The Binder parameter of panel (b) allows to determine the transition \\(N\\rightarrow\\infty\\)in FM phases, while from\n \\(N\\rightarrow\\infty\\)in FM phases, while from the law of large numbers it follows that in PM phases \\(B_{m}\\to 0\\)as\n \\(N\\) increases. On the other hand, since \\(B_{m}\\) is dimensionless, it must be independent of \\(N\\)\\(N\\)dimensionless, it must be independent of N at the critical point.\nAs a consequence, curves of Bm vs T for\n \\(B_{m}\\)vs\n \\(T\\)for\n As a consequence, curves of \\(B_{m}\\) vs \\(T\\) for \n\ntransitions with strong structural disorder. \n\n\\(m\\). Fig.\n (a) displays\n \\(m_{1}\\)vs\n \\(T\\)for\n \\(\\Phi=0.4\\)at\n \\(m\\)(a) displays\n \\(m_{1}\\) vs \\(T\\)for\n \\(\\Phi=0.4\\)at\n several \\(N\\). They show that \\(m_{1}\\)\\(N\\). They show that\n \\(m_{1}\\)several N. They show that m1 tends to non-zero values for N \u2192\u221eand low T, revealing the existence of\n \\(N\\to\\infty\\)and low\n \\(T\\), revealing the existence of\n \\(N\\to\\infty\\)and low \\(T\\), revealing the existence of strong FM order. The curves plotted in Fig. 2(b) for the magnetic susceptibility \\(\\chi_{m}\\) vs \\(T\\)\\(\\chi_{m}\\)vs\n \\(T\\)the magnetic susceptibility \u03c7m vs T confirm this conclusion as they show peaks that become sharper for large\n \n\ndifferent values of \\(N\\) cross at \\(T_{c}\\)\\(N\\)cross at\n \\(T_{c}\\)different values of N cross at Tc for second order transitions. Instead, in presence of an intermediate marginal\n phase of quasi-long-range FM order, the curves do not cross but join. Plots of \\(B_{m}\\) vs \\(T\\) for several \\(N\\) are shown in Fig. 3(b) for\n \\(\\Phi=0.18\\). Those curves cross at a well\n defined critical temperature for \\(N\\geq 512\\).\n 38 \\(N\\geq 512\\)( )\ndefined critical temperature for N \u2265512.38 With similar results obtained for \u03a6 \u22650.17, we can draw a line of\n \\(\\Phi\\geq 0.17\\), we can draw a line of\n , we can draw a line of\n transition between PM and FM phases. \n\nThe corresponding plots for\n \\(\\Phi=0.14\\)are shown in\n \n\n[width=85mm]figure1.pdf \n\nFig. 4. The qualitatively different results illustrate the \\(\\Phi\\).\n The plots of the magnetization in panel (a) show that \\(m_{1}\\) gradually decreases as \\(N\\) increases for all \\(T\\). The data of \\(m_{1}\\)for\n low temperature agree with an algebraic decay \\(m_{1}\\sim N^{p}\\)\n\nfor \\(p<1/2\\)temperature\n \\(p<1/2\\)for p < 1/2, hence a marginal order is a priori not excluded. However, the plots of Bm vs T from panel (b)\n \\(B_{m}\\)vs\n \\(T\\)from panel (b)\n \\(B_{m}\\) vs \\(T\\) from panel (b) \n\nFIG. 2. (a) Plots of the magnetization \\(m_{1}\\) versus \\(T\\)\\(m_{1}\\)versus\n \\(T\\)FIG. 2. (a) Plots of the magnetization m1 versus T for volume fraction \u03a6 = 0.4. Symbols \u25bf, \u25b5, \u22c4, \u25ab, and \u2022 stand for\n \\(\\Phi=0.4\\). Symbols\n \\(\\smalltriangledown\\),\n \\(\\smalltriangleup\\),\n \\(\\smalldiamond\\),\n \\(\\smallsquare\\), and\n \\(\\smallblackcircle\\)stand for\n . Symbols\n \\(\\smalltriangledown\\), \\(\\smalltriangleup\\), \\(\\smalldiamond\\), \\(\\smallsquare\\), and \\(\\smallblackcircle\\) stand for \\(N=125,216,512,1000\\)and\n \\(1728\\)respectively.\n b)  Plots of \n\nthe magnetic susceptibility \\(\\chi_{m}\\) versus \\(T\\) for volume fraction \\(\\Phi=0.4\\). Same symbols as in (a). (\n c ) Same as in (b) but for volume fraction\n \\(\\Phi=0.1\\).\n \n\nFIG. 3. (a) Plots of the magnetization \\(m_{1}\\) vs \\(T\\)for\n \\(\\Phi=0.18\\).\n Symbols \\(\\smalltriangleup\\), \\(\\smalldiamond\\), \\(\\smallsquare\\), and \\(\\smallcircle\\)stand for \\(N=216,512,1000\\)and\n \\(1728\\)respectively. (b) Plots of the Binder cumulant of the\n magnetization \\(B_{m}\\) vs \\(T\\)for\n \\(\\Phi=0.18\\). Same symbols as in (a).\n \n\nFIG. 1. (a) Plots of the specific heat \\(c\\) versus \\(T\\) for volume fraction\n \\(\\Phi=0.4\\). Symbols\n \\(\\smalltriangledown\\), \\(\\smalltriangleup\\), \\(\\smalldiamond\\), \\(\\smallsquare\\), and \\(\\smallblackcircle\\) stand for \\(N=125,216,512,1000\\)and\n \\(1728\\)respectively. (b) Same as in (a)\n for volume fraction\n \\(\\Phi=0.1\\).\n ",
    "# WHEN DOES THE CHAOS IN THE CURIE-WEISS MODEL STOP TO PROPAGATE? \n\nLet us now informally discuss the case when \\(\\alpha>0\\). For simplicity, we consider (13). The limit on\n the right-hand side is non-zero, which suggests that there is a residual dependence between the \\(k(N)\\) spins under the Gibbs measure. The reason for the non-zero limit is the fact that the distribution of \\(\\mathcal{P}_{k(N)}\\) and the corresponding binomial distribution satisfy central limit theorems with different variances, the variance of \\(\\mathcal{P}_{k(N)}\\) being strictly larger, which comes from the fact that the spins are positively correlated under the Gibbs measure. The distance between these normal distributions appears on the right-hand side of (13). In Theorem 3.5, we shall determine a _ mixed_  binomial distribution which approximates the distribution of \\(\\mathcal{P}_{k(N)}\\) under \\(\\mu_{N}\\). In some sense, this describes the residual dependence between the spins under the Gibbs measure. \n\n_Remark_  1.2 _._  The exchangeability of the measure \\(\\mu_{N}\\) has been used to investigate the Curie-Weiss model for example, in [17, Section 5.2] and [2]. In particular, an explicit representation of \\(\\mu_{N}\\) as a mixture of Bernoulli measures (valid for each fixed \\(N\\)) can be found in [17, Theorem 5.6]. A general propagation of chaos principle stating that the distribution of \\(k\\) entries in a finite exchangeable vector of length \\(n\\) can be approximated by a mixture of i.i.d. distributions can found in [7]. \n\nThe paper is organized as follows. Our proof relies on local limit theorems for the magnetization \\(m_{N}\\) and also for the total number of positive spins \\(\\mathcal{P}_{N}\\) under \\(\\mu_{N}\\). In some regimes those are known. We collect the corresponding results in Section 2 below. The proofs of these local limit theorems, which we have not been able to locate in the literature, are given in Section 4. The proof of Theorem 1.1 is given in Section 3, including the statement of residual dependence. Two auxiliary technical results related to calculations of the total variation distance are presented in Section 5. \n\n## 2. L OCAL LIMIT THEOREM FOR THE MAGNETIZATION \n\nDenote by \\(\\mathcal{N}({\\tt m},{\\tt v}^{2})\\) a Gaussian distribution with mean \\({\\tt m}\\) and variance \\({\\tt v}^{2}\\), so \\[\\mathcal{N}({\\tt m},{\\tt v}^{2})(A)=\\int_{A}\\varphi(t;{\\tt m},{\\tt v}^{2}){\\rm d }t,\\quad A\\in\\mathcal{B}(\\mathbb{R}).\\]  Put \\(\\delta_{N}:=(1-(-1)^{N})/2\\). This correction term appears below in the local limit theorems for\n \\(m_{N}\\), since \\(Nm_{N}\\) always has the same parity as \\(N\\). \n\n**Proposition 2.1.** Assume that\n \\(h\\neq 0\\)_ or_ \\(0<\\beta<1\\)_. Then_ \\[\\mu_{N}\\left(\\sqrt{N}(m_{N}-{\\tt m}(\\beta,h))\\in\\cdot\\right)~{}\\Longrightarrow ~{}\\mathcal{N}\\left(0,{\\tt v}^{2}_{\\beta,h}\\right),\\quad N\\longrightarrow\\infty,\\]  _and the following local limit theorem holds true:_ \n\n\\[\\lim_{N\\longrightarrow\\infty}\\sqrt{N}\\sup_{\\ell\\in\\mathbb{Z}}\\left|\\mu_{N} \\left(\\frac{Nm_{N}+\\delta_{N}}{2}=\\ell\\right)-\\varphi\\left(\\ell;\\frac{N{\\tt m} (\\beta,h)}{2},\\frac{N{\\tt v}^{2}_{\\beta,h}}{4}\\right)\\right|=0.\\] (16)  ",
    "# Mitigating Task Interference in Multi-Task Learning via Explicit Task Routing with Non-Learnable Primitives \n\nChuntao Ding \u00b9Zhichao Lu \u00b2Shangguang Wang \u00b3Ran Cheng \u2074Vishnu N. Boddeti \u2075\u00b9 Beijing Jiaotong University \u00b2 Sun Yat-sen University \u00b3 Beijing University of Posts and Telecommunications \u2074 Southern University of Science and Technology \u2075 Michigan State University chuntaoding@163.com _{_ luzhichaocn, ranchengcn _}_ @gmail.com sgwang@bupt.edu.cn vishnu@msu.edu \n\n##### Abstract\n_Multi-task learning (MTL) seeks to learn a single model_ \n\n##### Abstract\n_to accomplish multiple tasks by leveraging shared information among the tasks. Existing MTL models, however,_ _have been known to suffer from negative interference among_ _tasks. Efforts to mitigate task interference have focused on_ _either loss/gradient balancing or implicit parameter partitioning with partial overlaps among the tasks._ _In this_ _paper, we propose ETR-NLP to mitigate task interference_ _through a synergistic combination of non-learnable primitives (NLPs) and explicit task routing ()._ _Our key idea_ \n\nFor instance, consider the learning progression of an \n\n##### Abstract\n_is to employ non-learnable primitives to extract a diverse_ _set of task-agnostic features and recombine them into a_ _shared branch common to all tasks and explicit task-specific_ _branches reserved for each task. The non-learnable primitives and the explicit decoupling of learnable parameters into shared and task-specific ones afford the flexibility_ _needed for minimizing task interference. We evaluate the_ _efficacy of ETR-NLP networks for both image-level classification and pixel-level dense prediction MTL problems._ _Experimental results indicate that ETR-NLP significantly_ _outperforms state-of-the-art baselines with fewer learnable_ _parameters and similar FLOPs across all datasets. Code is_ _available at this_ _ URL_ _._ \n\nMTN with a standard learnable convolutional layer in Figure  1a  (blue curve). Observe that the model learns rapidly, we posit, by exploiting all the shared information between the tasks, i.e., gradients pointing in similar directions. However, the performance starts degrading on further training since the model needs to exploit dissimilar information between the tasks for further improvement, i.e., gradients point in different directions. The latter can be verified by observing the similarity (centered kernel alignment [ 19 ]), or the lack thereof, between the gradients for each pair of tasks in Figure  1b . \n\n## 1. Introduction \n\nMulti-task learning (MTL) is commonly employed to \n\nSeveral approaches were proposed for mitigating task interference in MTNs, including loss/gradient balancing [ 17 , \n\nimprove learning efficiency and performance of multiple tasks by using supervised signals from other related tasks [ 6 ,  33 ,  49 ]. These models have led to impressive results across numerous tasks. However, there is well-documented evidence [ 18 , 28 , 41 , 53 ] that these models are suffering from _task interference_  [ 53 ], thereby limiting multi-task networks (MTNs) from realizing their full potential. \n\n* _Work done as a visiting scholar at Michigan State University._ \u2020 _Corresponding author_ \n\n21 , 22 , 34 , 52 ], parameter partitioning [ 2 , 28 , 30 , 37 ] and architectural design [ 8 , 18 , 29 ]. Despite the diversity of these approaches, they share two common characteristics, (i) all parameters are learned, either for a pre-trained task or for the multiple tasks at hand, (ii) the learned parameters are either fully shared across all tasks or are shared across a partial set of tasks through implicit partitioning, i.e., with no direct control over which parameters are shared across which tasks. Both of these features limit the flexibility of existing \n\n(a)  ResNet18 \n\n(b)  Layer 1, 4, and 8 of ResNet18 (from left to right) \n\nFigure 1. (a) Learning progression of multi-task networks (MTNs) on CelebA for eight tasks. Hard-sharing models with fully learnable parameters ( gray ) learn rapidly and then suffer from performance degradation due to conflicting gradients from task interference. Networks with non-learnable primitives (NLPs;  blue ) do not suffer from task interference by design, while explicit task routing (ETR; green), and ETR with NLPs ( red ) do not eliminate but suffer less from task interference. (b) Gradient correlations measured via CKA [ 19 ] across all pairs of tasks for different layers of a standard MTN at the end of training. Observe the acute lack of correlation between tasks (low off-diagonal magnitude). ",
    "W. BARRERA, A. CANO, J.P. NAVARRETE, AND J. SEADE \n\n1.5. The control group\n .\n The control group\n 1.5. The control group. We refer to [8] for a discussion about this section. Consider \u0393 \u2282PSL(3, C) a (discrete or not) subgroup which acts on P2\nC with a point p\n \\(\\Gamma\\subset{\\rm PSL}(3,\\mathbb{C})\\)a (discrete or not) subgroup which acts on\n \\({\\mathbb{P}}_{\\mathbb{C}}^{2}\\)with a point\n is\n a (discrete or not) subgroup which acts on\n \\({\\mathbb{P}}_{\\mathbb{C}}^{2}\\)with a point \\(p\\)\\(\\Gamma\\). Choose an arbitrary line\n \\(\\ell\\)in \\({\\mathbb{P}}_{\\mathbb{C}}^{2}\\setminus\\{p\\}\\), and notice we have a canonical projection: \\[\\pi=\\pi_{p,\\ell}:\\mathbb{P}^{2}_{\\mathbb{C}}\\setminus\\{p\\}\\longrightarrow\\ell\\,,\\]  given by \\(\\pi(x)=\\overleftrightarrow{x,p}\\cap\\ell\\). It is clear that this map is holomorphic and it allows us to define a group homomorphism: \\[\\Pi=\\Pi_{p,\\ell}:\\Gamma\\longrightarrow Bihol(\\ell)\\cong{\\rm PSL}(2,\\mathbb{C})\\,,\\]  by\n \\(\\Pi(g)(x)=\\pi(g(x))\\).\n If we choose another line, say \\(\\ell^{\\prime}\\), one gets similarly a projection \\(\\pi^{\\prime}=\\pi_{p,\\ell^{\\prime}}:\\mathbb{P}^{2}_{\\mathbb{C}}\\setminus\\{p\\} \\to\\ell^{\\prime}\\,,\\)to see\n and a group homomorphism\n \\(\\Pi^{\\prime}=\\Pi_{p,\\ell^{\\prime}}:\\Gamma\\to{\\rm PSL}(2,\\mathbb{C})\\)that\n . It is an exercise to see that\n \\(\\Pi\\)and\n \\(\\Pi^{\\prime}\\)are equivalent in the sense that there is a biholomorphism \\(h:\\ell\\to\\ell^{\\prime}\\)inducing an automorphism \\(H\\)of\n \\({\\rm PSL}(2,\\mathbb{C})\\)such that \\(H\\circ\\Pi=\\Pi^{\\prime}\\). As before, the line \\(\\ell\\)is called _ the horizon_ . \n\nThis leads to the following definition: \n\n**Definition 1.7.** Let\n \\(\\Gamma\\subset{\\rm PSL}(3,\\mathbb{C})\\)(or\n be a discrete group as above. We call\n \\(\\Pi=\\Pi_{p,\\ell}\\)the control morphism (or map) and its image\n \\(\\Pi(\\Gamma)\\subset{\\rm PSL}(2,\\mathbb{C})\\)\\(\\ell\\)up\n , is the\n _ control_ _group_ . These are well-defined and independent of \\(\\ell\\)up to an automorphism of \\({\\rm PSL}(2,\\mathbb{C})\\).\n \n\nThe control map and the control group allow us to get information about the dynamics of\n \\(\\Gamma\\)by looking at a subgroup of\n \\({\\rm PSL}(2,\\mathbb{C})\\), which is far easier to handle.\n The prize we pay is that the control group in\n \\({\\rm PSL}(2,\\mathbb{C})\\)may not be discrete.\n \n\n## 2.  Purely parabolic groups \n\nWe now follow [5] and look at the discrete subgroups in\n \\({\\rm PSL}(3,\\mathbb{C})\\)that, besides\n the identity, have only parabolic elements. These are called purely parabolic and there are five families of such groups; three of them split into various subfamilies according to their limit set (and their control group, see [8]). All of these are elementary. \n\nThe simplest purely parabolic groups are cyclic, generated by a parabolic element. As described above, there are three types of such elements in PSL(3, C),\n \\({\\rm PSL}(3,\\mathbb{C})\\),\n described by the Jordan normal form of their lifts to\n \\(\\textrm{SL}(3,\\mathbb{C})\\)\\(\\textrm{SL}(3,\\mathbb{C})\\)described by the Jordan normal form of their lifts to SL(3, C). Each of these belongs to a different type of the families we describe below. The first type generates\n torus groups (see definitions below), the second generates Abelian Kodaira groups and the ellipto-parabolic elements generate elliptic groups. \n\n(i) Elliptic groups. These are the only purely parabolic groups that are not conjugate to subgroups of the Heisenberg group\n \\({\\rm Heis}(3,\\mathbb{C})\\)and they are\n subgroups of fundamental groups of elliptic surfaces. These have limit set a single line. Up to conjugation these groups are of the form: \\[{{\\rm Ell}}(W,\\mu)=\\left\\{\\left[\\begin{array}[]{lll}\\mu(w)&\\mu(w)w&0\\\\ 0&\\mu(w)&0\\\\ 0&0&\\mu(w)^{-2}\\\\ \\end{array}\\right]:w\\in W\\right\\},\\]  an\n where \\(W\\subset\\mathbb{C}\\) is an additive discrete subgroup and \\(\\mu:W\\rightarrow\\mathbb{S}^{1}\\)is a group morphism. ",
    "# Topportunities at the LHC: Rare Top Decays with Light Singlets Henning Bahl \u2217 , Seth Koren \u2020 , and Lian-Tao Wang \u2021 \n\n_Department of Physics and Enrico Fermi Institute, University of Chicago,_ _5720 South Ellis Avenue, Chicago, IL 60637 USA_ \n\n##### Abstract\nThe discovery of the top quark, the most massive elementary particle yet known, has given us a distinct window into investigating the physics of the Standard Model and Beyond. With a plethora of top quarks to be produced in the High Luminosity era of the LHC, the exploration of its rare decays holds great promise in revealing potential new physics phenomena. We consider higher-dimensional operators contributing to top decays in the SMEFT and its extension by a light singlet species of spin 0, 1/2, or 1, and exhibit that the HL-LHC may observe many exotic top decays in a variety of channels. Light singlets which primarily talk to the SM through such a top interaction may also lead to distinctive long-lived particle signals. Searching for such long-lived particles in top-quark decays has the additional advantage that the SM decay of the other top quark in the same event provides a natural trigger. ",
    "### Computational Performance of the Optimization Proxies \n\nThis section presents numerical experiments used to assess the performance of the proposed optimization proxies (Proxies) against the optimization models (GDO) and the greedy heuristic (GH). \n\n**Optimality Gap:** \n\nTable 3 presents the optimality gaps of various approaches, including the results of Model  (1)  under various time constraints. In the table, the columns under \u201cGap of Model  (1) \u201d denote the optimality gaps of the model under various time limits. Similarly, columns _ Gap_  for GH and Proxies denote optimality gaps for GH and the optimization proxies. In addition, columns _ Time(s)_  denote the solving times for GH and Proxies. \n\nRecall that Model  (1)  produces solutions that exhibit considerable variability when the total commodity volume is perturbed as detailed in Table 4 and 5. As such, it is unlikely to be practical in scenarios with planners in the loop. Hence, the table compares the optimization proxies and the heuristics GH with an \u201cidealized\u201d benchmark. With this caveat in place, observe the performance of the optimization proxies under tight time constraints. Proxies generate solutions with low optimality gaps and may be up to 10 to 50 times faster than GH, and around 10 times faster than Model  (1)  solved with Gurobi. Second, although Model  (1)  efficiently produces solutions with low optimality gaps, closing the optimizality gap proves to be a significant challenge due to the poor LP relaxation. The performance of GH is also impeded by the inefficiencies of the LP relaxation, as it solves the LP relaxations over many iterations; it takes the GH \\(30\\)iterations for terminal M,\n \\(200\\)iterations for terminal L, and more than\n \\(1000\\)iterations for terminal\n XL to generate a feasible solution. \n\n**Consistency:** \n\nTables 4 and 5 report the consistency of solutions obtained from different models in terms of the normalized distance to the reference load plan and the total variation of the generated solutions. As GDO requires running Model  (1)  and Model  (2)  sequentially, these experiments set the same time limits for the two stages. For example, if a time limit of 30 seconds is set, GDO runs Model  (1)  for 30 seconds and subsequently runs Model (2) using the best upper bound obtained from Model (1) for another 30 seconds. \n\n_The high-level result is that proxies are ideally suited to produce consistent plans._  Table 4 shows that the proxies accurately predict, in a few seconds, the results produced by GDO after an hour. Furthermore, Table 5 \n\n**Table 3:** _ Optimality Gap (%) with respect to the Total Trailer Cost_ \n\n\\begin{tabular}{l|r r r r r r r r r r}\n\\hline \\hline\n\\multicolumn{1}{l}{\\multirow{2}{*}{Instance}} & \\multicolumn{6}{c}{Model (1)} & \\multicolumn{2}{c}{GH} & \\multicolumn{2}{c}{Proxies} \\\\\n\\cline{2-11}\n\\multicolumn{1}{l}{} & \\multicolumn{1}{c}{1s} & \\multicolumn{1}{c}{5s} & \\multicolumn{1}{c}{10s} & \\multicolumn{1}{c}{30s} & \\multicolumn{1}{c}{60s} & \\multicolumn{1}{c}{1800s} & \\multicolumn{1}{c}{Gap} & \\multicolumn{1}{c}{Time (s)} & \\multicolumn{1}{c}{Gap} & \\multicolumn{1}{c}{Time (s)} \\\\\n\\hline\nM & 2.59 & 0.55 & 0.48 & 0.48 & 0.48 & 0.48 & 3.84 & 3.12 & 1.14 & 0.33 \\\\\nL & 51.15 & 5.22 & 2.18 & 1.71 & 1.41 & 1.39 & 12.85 & 13.28 & 3.80 & 1.10 \\\\\nXL & 77.35 & 14.02 & 10.41 & 2.93 & 2.07 & 0.93 & 17.01 & 121.55 & 5.21 & 2.49 \\\\ \\hline \\hline\n\\end{tabular}\n",
    "**Notes:**  In all panels, the national minimum wage increases by 20 log points from the first period to the second. In Panels A and B, regions differ only in the location parameter \\(\\mu_{r,t}\\), assumed to be constant over time. In Panels C and D, regions are identical in period one, but differ in \\(\\mu_{r,t}\\) in period two. Each panel displays average results for 5,000 simulations, each with 50 regions. For each outcome, the numbers correspond to the mean true ATE across simulations, the mean estimates of causal effects based on the regressions listed on the left, and the average standard error associated with the estimates (in parentheses, clustered at the region level). \n\n**Table 2:**  Normal-markdown model: ideal cases \n\n\\begin{tabular}{l c c c c c}\n\\hline \\hline\n & \\multicolumn{5}{c}{Outcome} \\\\\n & Emp. & p10 & p25 & p50 & p90 \\\\\n\\hline\n\\multicolumn{6}{l}{_Panel A: Regions differ in location parameter, initial min. wage is small_} \\\\\n Mean causal effect & -0.011 & 0.026 & 0.013 & 0.007 & 0.003 \\\\\n Fraction affected & -0.013 & 0.028 & 0.014 & 0.008 & 0.004 \\\\\n & (0.000) & (0.001) & (0.000) & (0.000) & (0.000) \\\\\n Gap measure & -0.010 & 0.021 & 0.011 & 0.006 & 0.003 \\\\\n & (0.000) & (0.001) & (0.000) & (0.000) & (0.000) \\\\\n\\multicolumn{6}{l}{_Panel B: Regions differ in location parameter, initial min. wage is large_} \\\\\n Mean causal effect & -0.076 & 0.155 & 0.079 & 0.049 & 0.025 \\\\\n Fraction affected & -0.079 & 0.112 & 0.081 & 0.054 & 0.031 \\\\\n & (0.002) & (0.014) & (0.003) & (0.000) & (0.001) \\\\\n Gap measure & -0.055 & 0.074 & 0.058 & 0.038 & 0.022 \\\\\n & (0.003) & (0.012) & (0.002) & (0.001) & (0.000) \\\\\n\\multicolumn{6}{l}{_Panel C: Identical regions receive different location shocks, initial min. wage is small_} \\\\\n Mean causal effect & -0.006 & 0.015 & 0.007 & 0.004 & 0.002 \\\\\n Effective min. wage & -0.006 & 0.011 & 0.003 & 0.000 & -0.002 \\\\\n & (0.001) & (0.001) & (0.000) & (0.000) & (0.000) \\\\\n Effective min. wage, p90 & -0.006 & 0.013 & 0.005 & 0.002 & 0.000 \\\\\n & (0.001) & (0.001) & (0.001) & (0.000) & (0.000) \\\\\n\\multicolumn{6}{l}{_Panel D: Identical regions receive different location shocks, initial min. wage is large_} \\\\\n Mean causal effect & -0.058 & 0.129 & 0.062 & 0.037 & 0.018 \\\\\n Effective min. wage & -0.059 & 0.092 & 0.024 & 0.000 & -0.019 \\\\\n & (0.002) & (0.001) & (0.001) & (0.000) & (0.001) \\\\\n Effective min. wage, p90 & -0.059 & 0.112 & 0.043 & 0.019 & 0.000 \\\\\n & (0.001) & (0.002) & (0.001) & (0.000) & (0.000) \\\\ \\hline \\hline\n\\end{tabular}\n",
    "**Lemma 3.4.** _ Under the hypothesis of Theorem 3.1, for every_ \\(p_{0}>2\\)_ there exists a constant_ \\(C_{1}\\)_ such that for all_ \\(p\\geqslant p_{0}\\)_ and_ \\(\\zeta\\in C_{0}^{\\infty}(\\mathbb{R}^{n};\\,\\mathbb{R}_{\\geqslant 0})\\)\n\n\\[\\|\\nabla(\\zeta|\\psi|^{p/2})\\|_{2}\\leqslant C_{1}\\,p^{\\alpha}\\|(| \\nabla\\zeta|+\\zeta)|\\psi|^{p/2}\\|_{2},\\] (29)  \n\n_where_ \\(\\alpha=(\\mu+1)/2\\)_._ \n\n_Proof._  The proof of this lemma is based on (22) and it follows the proof of (Theorem 5.1 in [0]). Note that (22) becomes useless for \\(p=2\\). Agmon works with the stronger inequality\n (19), which doesn\u2019t degenerate at \\(p=2\\). By fixing a number\n \\(p_{0}>2\\)and looking at numbers\n \\(p\\geqslant p_{0}\\) we can reuse Agmon\u2019s proof. From (22) and H\u00a8 older\u2019s inequality it follows that \n\n\\[(p-2)\\int dx\\,\\zeta^{2}|\\psi|^{p-2}|\\nabla|\\psi||^{2}\\leqslant 2 \\left(\\int dx\\,\\zeta^{2}|\\psi|^{p-2}|\\nabla|\\psi||^{2}\\right)^{1/2} \\left(\\int dx\\,|\\nabla\\zeta|^{2}|\\psi|^{p}\\right)^{1/2}\\] \\[+ \\int dx\\,\\zeta^{2}q_{-}|\\psi|^{p}\\]  \n\nUsing (26) this can be rewritten as \n\n\\[(p-2)\\dfrac{4}{p^{2}}\\underbrace{\\int dx\\,\\zeta^{2}|\\nabla|\\psi|^ {p/2}|^{2}}_{=A^{2}}\\leqslant 2\\dfrac{2}{p}\\underbrace{\\left(\\int dx\\,\\zeta^{2 }|\\nabla|\\psi|^{p/2}|^{2}\\right)^{1/2}}_{=A} \\underbrace{\\left(\\int dx\\,|\\nabla\\zeta|^{2}(|\\psi|^{p/2})^{2} \\right)^{1/2}}_{=B}\\] \\[+ \\underbrace{\\int dx\\,\\zeta^{2}q_{-}(|\\psi|^{p/2})^{2}}_{=C}.\\]  \n\nNote that by Lemma 3.3 and assumption (13) all integrals are finite. The above inequality is equivalent to \n\n\\[A^{2}\\leqslant\\dfrac{p}{p-2}AB+\\dfrac{p^{2}}{4(p-2)}C.\\]  \n\nNext, we use that \\(p/(p-2)\\leqslant p_{0}/(p_{0}-2)\\eqqcolon D_{0}\\) for \\(p\\geqslant p_{0}\\) and \\(AB\\leqslant\\delta A^{2}+B^{2}/\\delta\\) for all \\(\\delta>0\\):\n \n\n\\[A^{2} \\leqslant D_{0}\\left(\\delta A^{2}+\\dfrac{B^{2}}{\\delta}\\right)+ \\dfrac{p}{4}D_{0}C\\] \\[\\iff(1-D_{0}\\delta)A^{2} \\leqslant D_{0}\\dfrac{B^{2}}{\\delta}+\\dfrac{p}{4}D_{0}C.\\]  \n\nWe choose \\(\\delta=\\dfrac{1}{2D_{0}}\\), so that \n\n\\[\\dfrac{1}{2}A^{2}\\leqslant 2D_{0}^{2}B^{2}+\\dfrac{p}{4}D_{0}C.\\]  \n\n\\(\\sqrt{a+b}\\leqslant\\sqrt{a}+\\sqrt{b}\\)Using  it follows that \n\n\\[A\\leqslant 2D_{0}B+\\sqrt{\\dfrac{D_{0}}{2}}\\sqrt{p}\\,\\sqrt{C}\\]  ",
    "### 4 language pairs A single encoder-decoder model is trained on 4 language pairs. We run experiments with 3 types of language pair combinations: \n\n\n* ** Model 1** : 2 unique language pairs in forward and reverse direction: kn \\(\\leftrightarrow\\)ml,te \\(\\leftrightarrow\\)ta. Results documented in Table 3 \n* ** Model 2** : 4 unique language pairs: kn \\(\\rightarrow\\)ml, ml \\(\\rightarrow\\)te, te \\(\\rightarrow\\)ta, ta \\(\\rightarrow\\)kn. Results documented in Table 4 \n* ** Model 3** : 4 unique language pairs with VOLT: kn \\(\\rightarrow\\)ml, ml \\(\\rightarrow\\)te, te \\(\\rightarrow\\)ta, ta \\(\\rightarrow\\)kn. Results documented in Table 5 \n\nBoth techniques expose the model to 1/3 of the total translation directions during training but the first technique is built to test model performance in very low resource conditions; when there are only 2 sources of parallel corpora available. In comparison, the second model is exposed to 1/3 of the total translation directions with each source-target language combination being unique. We ensure that in every model, both the encoder and decoder see each language atleast once during training. We observe that BLEU score for zero-shot translation lags by 5.03 on average compared to the performance of trained language pairs when we train on both directions of 2 language pairs only. In comparison, the zero-shot translation BLEU score lags by 5.98 BLEU on average for the model trained on 4 unique language pairs. The BLEU score for trained translation directions is always in the 6-8 BLEU range. The 4 language pair model trained with VOLT outperforms both the 32000 vocabulary models in zero-shot translation performance with zero shot scores lagging by 3.53 on average from the trained directions. \n\n### 6 language pairs 2 additional language pairs are added to the 4 unique language pairs of model 2 and a transformer model is trained on all 6 language pairs. The model now sees 1/2 of all possible translation directions during training. Table 6 shows the results obtained from the 6 language pair model. We observe that zero-shot translation performance increases drastically. Zero-shot directions now lag by 1.76 BLEU to the trained translation directions. \n\nTable 3: BLEU score for 4 language pair model 1. The rows are the source language and the columns are the target language. Cells in bold represent the translation directions used in training \n\n\\begin{tabular}{c|c c c c}\n\\hline\n & kn & ml & te & ta \\\\\n\\hline\nkn & - & **7.7** & 1.0 & 0.8 \\\\\nml & **8.9** & - & 5.7 & 0.6 \\\\\nte & 0.5 & 3.2 & - & **7.4** \\\\\nta & 5.8 & 4.9 & **7.4** & - \\\\ \\hline\n\\end{tabular}\n\n\nTable 4: BLEU score for 4 language pair model 2. The rows are the source language and the columns are the target language. Cells in bold represent the translation directions used in training \n\n\\begin{tabular}{c|c c c c}\n\\hline\n & kn & ml & te & ta \\\\\n\\hline\nkn & - & **7.4** & 0.4 & 0.5 \\\\\nml & 1.0 & - & **7.0** & 0.4 \\\\\nte & 0.8 & 4.7 & - & **7.1** \\\\\nta & **8.9** & 4.5 & 0.6 & - \\\\ \\hline\n\\end{tabular}\n\n\nTable 5: BLEU score for 4 language pair model 3. The rows are the source language and the columns are the target language. Cells in bold represent the translation directions used in training \n\n\\begin{tabular}{c|c c c c}\n\\hline\n & kn & ml & te & ta \\\\\n\\hline\nkn & - & **6.5** & 4.5 & 0.8 \\\\\nml & 6.8 & - & **6.4** & 5.5 \\\\\nte & 0.7 & 2.4 & - & **6.6** \\\\\nta & **8.1** & 1.7 & 4.5 & - \\\\ \\hline\n\\end{tabular}\n",
    "\\(\\left|0\\right\\rangle\\)after the SFQ operation. Therefore,\n \\(\\left|0\\right\\rangle\\)is\n after the SFQ operation. Therefore, when the \\(\\pi\\)\\(\\pi\\)when the \u03c0 pulse is applied to the qubit immediately after the SFQ operation, the qubit cannot be completely\n excited to the \\(\\left|1\\right\\rangle\\)state. As the recovery time prolongs, the population of \\(\\left|1\\right\\rangle\\)after the \\(\\pi\\)\\(\\left|1\\right\\rangle\\)after the\n \\(\\pi\\)the population of |1\u27e9after the \u03c0 pulse also gradually increases to 1.\n \n\n## Appendix C: Extraction of Quasiparticle Density \n\n## Near Qubit \n\n## Appendix D: Diffusion of Quasiparticles in Superconducting Quantum-Classical Hybrid Circuits \n\nMost QPs propagate diffusively when the local QP density is relatively low. The local QP density is \\(x_{\\mathrm{QP}}=n_{\\mathrm{QP}}/n_{\\mathrm{CP}}\\), where \\(n_{\\mathrm{QP}}\\) is the QP density and \\(n_{\\mathrm{CP}}\\)the Cooper pair density. As the local QP density increases, QPs have a greater probability of recombination, \n\nThe \\(x_{\\mathrm{QP,qubit}}\\) extracted using \\(x_{\\mathrm{QP,qubit}}=(\\Gamma(t)-\\Gamma_{0})/{C}\\)\\(T_{1}\\) is a kind of average QP density during the \\(T_{1}\\)\\(t_{\\mathrm{avg}}\\)(\n \\(\\sim\\,T_{1}\\)) after\n \\(t_{\\mathrm{R}}\\). To\n \\(t_{\\mathrm{avg}}\\) ( \\(\\sim\\,T_{1}\\)the\n ) after \\(t_{\\mathrm{R}}\\). To intuitively illustrate the validity of the \\(x_{\\mathrm{QP,qubit}}\\)\\(x_{\\mathrm{QP,qubit}}\\)intuitively illustrate the validity of the xQP,qubit evolution extracted in this way to analyze the QP propagation\n mechanism, we compare (i) the \\(x_{\\mathrm{QP,qubit}}\\) extracted with a very short measurement time ( \\(t_{\\mathrm{avg}}\\,=\\,0\\)\\(t_{\\mathrm{avg}}\\,=\\,0\\)very short measurement time (tavg = 0) in an ideal measurement, and (ii) the xQP,qubit extracted with several\n \\(x_{\\mathrm{QP,qubit}}\\)extracted with several\n \\(x_{\\mathrm{QP,qubit}}\\) extracted with several microsecond measurement times ( \\(t_{\\mathrm{avg}}=3,\\ 6,\\ 12,\\ 18\\ \\mu s\\)) in a real experiment. We assume that the gray curve \n\nand phonon-mediated propagation becomes the leading mechanism. We calculated the diffusion equation by finite element simulation, thereby estimating the contribution of QP diffusion to the QP propagation in the device described in the paper. We set a boundary of \n\n( \\(t_{\\mathrm{avg}}\\,=0\\)) in the Fig. 9 below, which is similar to the\n trend of the extracted \\(x_{\\mathrm{QP,qubit}}\\)\\(x_{\\mathrm{QP,qubit}}\\)trend of the extracted xQP,qubit evolution in the maintext, is the real QP density evolution. The trends and\n timescales ( \\(\\sim\\)over\n several microseconds) of \\(x_{\\mathrm{QP,qubit}}\\) evolution vary little over all values of \\(t_{\\mathrm{avg}}\\) listed. \n\n**(a)**  Pulse sequence applied to measure qubits state after an SFQ pulse train. The transmission of the readout resonator is measured at \\(f_{\\mathrm{r}}\\). ** (b)**  Qubit readout resonator spectroscopy vs. DC/SFQ converter drive pulse duration \\(t_{\\mathrm{SFQ}}\\). ** (c)** Pulse sequence applied to measure qubits state with variable delay \\(t_{\\mathrm{dalay}}\\) after a 25 \\(\\mu\\mathrm{s}\\)SFQ pulse train. The transmission of the\n readout resonator is measured at \\(f_{\\mathrm{r}}\\). ** (d)**  Qubit readout resonator spectroscopy vs. delay between SFQ circuit operation and readout pulse \\(t_{\\mathrm{dalay}}\\). The frequencies corresponding to the readout resonator when the state of qubit is \\(\\left|0\\right\\rangle\\), \\(\\left|1\\right\\rangle\\), and punch out have been marked. \n\nFIG. 9. Effect of measurement time on the extracted \\(x_{\\mathrm{QP,qubit}}\\)evolution ",
    "the other cliques, ensuring a fully connected graph. All nodes and edges are associated with information through embeddings, described below. \n\n**GNN stage**  The second stage employs a generalized message-passing GNN following [5] to perform several prediction tasks on this graph simultaneously: \n\n\n1.** keypoint association prediction:**  we model association between body \\(k\\)-NN graph.\n \\(k\\)-NN graph. \n2.** body keypoint level prediction:**  for body keypoints, we model the spine level prediction as multi-class node classification. \n3.** keypoint legitimacy prediction:**  to filter out false-positive keypoints, we additionally compute an binary legitimacy prediction for each node. \n\nTo perform these task, our message-passing GNN maintains edge and node embeddings which are updated in each layer. A message-passing layer performs a node update and edge update operation. Denoting the feature vector of a node \\(v\\) by \\(x_{v}\\), and the feature vector of a directed edge \\((u,v)\\) by \\(x_{uv}\\), the node and edge features are updated as follows: \n\n\\[\\underbrace{x_{u}^{\\prime}=\\bigoplus_{v\\in\\mathcal{N}_{u}\\cup\\{u\\}}\\psi_{ \\mathrm{node}}(x_{u},x_{v},x_{uv})}_{\\text{Node update}},\\qquad\\underbrace{x_{ uv}^{\\prime}=\\vphantom{\\bigoplus_{v\\in\\mathcal{N}_{u}\\cup\\{u\\}}}\\psi_{\\mathrm{ edge}}(x_{u},x_{v},x_{uv})}_{\\text{Edge update}}\\] (1)  \n\noperation\n \n\n\n\nour\n \n\n\n\nHere \\(\\bigoplus\\)two\n denotes a symmetric pooling operation (in our case max pooling) over the neighborhood \\(\\mathcal{N}_{u}\\). \\(\\psi_{\\text{node}}\\) and \\({}_{\\text{edge}}\\) are trainable parametric functions: in our case, two distinct two-layer MLPs with ReLU nonlinearities. After \\(N\\) such message-passing layers we obtain an embedding vector for each node and edge. Each node/edge embedding is passed through a linear layer (distinct for nodes and edges) to obtain a vector of node class logits or a single edge prediction logit, respectively. The last entry in the node prediction vector is interpreted as a node legitimacy prediction score: nodes predicted as illegitimate are discarded for the output. \n\nThe node input features \\(x_{u}\\in\\mathbb{R}^{7}\\)consist of the one-hot encoded keypoint \\([0,1]\\)for each of the four spine segments of belonging to that\n \\([0,1]\\) for each of the four spine segments of belonging to that segment, computed by applying a sigmoid to the heatmap network\u2019s output channels which represent the different spine segments). The edge input features \\(x_{uv}\\in\\mathbb{R}^{4}\\)between\n consist of the normalized direction vector of the edge and the distance between the two endpoints. \n\nThe output of the GNN contains finer spine-level classification (i.e. C1-C7, T1-T13, L1-L6, S1-S2), keypoint-level legitimacy (legitimate vs. false-positive detection) and body-pedicle association via edge prediction, implicitly defining the orientation of each vertebra. Prediction scores of corresponding directed edges \\((u,v)\\) and \\((v,u)\\) are symmetrized by taking the mean. \n\nIn our experiments we consider variations to our architecture: weight sharing between consecutive GNN layers, multiple heads with a shared backbone (jointly trained) and dedicated networks (separately trained) for edge/node prediction. ",
    "The integral over \\(y\\) can be calculated in terms of the complete elliptical integral of the first kind \\(K(x)\\) using the identity (3.131.5) from [20] \n\n\n\ntaking \\(\\Omega\\rightarrow\\Omega+\\imath 0^{+}\\), where we add infinitesimally small imaginary part as it is required in the retarded Green\u2019s function. Then \\(a=(\\Omega+\\imath 0^{+})^{2}+...\\) gets small imaginary part \\(2\\imath\\Omega 0^{+}\\)defining the value of \\(\\operatorname{csgn}\\). Taking the limit of infinitisimal \\(0^{+}\\)we arrive at the following expression for the trace of the Green\u2019s function \n\n\\[\\int_{u_{2}}^{u_{3}}\\frac{dy}{\\sqrt{(u_{3}-y)(y-u_{2})(y-u_{1})}}\\] \\[=\\frac{2}{\\sqrt{u_{3}-u_{1}}}K\\left[\\sqrt{\\frac{(u_{3}-u_{2})}{(u _{3}-u_{1})}}\\right],\\] (16)  \n\n\\[\\text{Tr}\\mathbf{G}(\\Omega)=\\frac{2\\Omega}{\\pi}\\int_{0}^{\\pi}dk_{y}\\begin{ cases}\\frac{\\operatorname{sgn}{a}}{\\sqrt{a^{2}-b^{2}}}&\\text{for}\\;\\;a^{2}>b^{ 2},\\\\ \\imath\\frac{\\operatorname{sgn}{\\Omega}}{\\sqrt{b^{2}-a^{2}}}&\\text{for}\\;\\;a^{2 }\\leqslant b^{2},\\end{cases}\\] (13)  \n\n\n\n\n\n\n\n\n\nwhere \\(u_{3}>u_{2}>u_{1}\\). In Eq. (15) these parameters are \n\nwhere we used the fact that the integrand is an even \n\n\\(\\sqrt{2}K\\left[\\sqrt{(1-y_{0})/2}\\right]\\)\n\nfunction of \\(k_{y}\\). Here the values \\(a\\) and \\(b\\)\\(k_{y}\\).\nHere the values\n \\(a\\)and\n \\(b\\)function of ky.\nHere the values a and b are the functions of the variables ky and \u2126and the parameter m as\n \\(k_{y}\\)and\n \\(\\Omega\\)and the parameter\n \\(m\\)as\n \\(k_{y}\\) and \\(\\Omega\\)and the parameter \\(m\\) as \n\n\\(u_{1}=-1\\), \\(u_{2}=y_{0}\\), \\(u_{3}=1\\) and the result of integration is equal to . Then the DOS for \\(|m|=1\\)\n\ndetermined by Eqs. (10). \n\nis and\n \n\nThe DOS is proportional to the imaginary part of \n\n\n\n\\(\\text{Tr}G(\\Omega)\\), therefore it is nonzero only in the region of \\(\\Omega\\)where \n\n\\[\\rho_{|m|=1}(\\Omega)=\\begin{cases}\\frac{\\sqrt{2}}{\\pi^{2}}\\frac{|\\Omega|}{ \\sqrt{\\Omega^{2}-1}}K\\left[\\sqrt{\\frac{9-\\Omega^{2}}{8}}\\right],\\;\\;\\;\\;\\text{ if}\\;\\;1\\leqslant\\Omega^{2}\\leqslant 9,\\\\ 0,\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\text{otherwise}.\\end{cases}\\] (17)  \n\n\\[a^{2}-b^{2}\\leqslant 0.\\] (14)  \n\n\n\nOutside the region (14)\n \\(\\text{Tr}G\\) is real and the DOS is equal \n\nFor convenience, in the Appendix A we provide the definitions of the elliptic integrals. \n\nto zero, i.e., \\(\\rho(\\Omega)=0\\). \n\nThe next step in evaluation of Eq. (13) is to perform \n\n#### Case \\(|m|>1\\)\n\n\\(m\\)we need first to analyze the function in de-\n \\(m\\)\\(m\\)rameter m we need first to analyze the function in denominator of Eq. (13).\nFor |m| \u0338= 1 we can write\n \\(|m|\\neq 1\\)we can write\n For \\(|m|\\neq 1\\) we can write \\(a^{2}-b^{2}=4(m^{2}-1)(y-y_{1})(y-y_{2})\\)zeros\n function\n are\n denoted\n . Here the left and right zeros of the function are denoted as \\(y_{1}=\\min(\\tilde{y}_{1},\\tilde{y}_{2})\\) and \n\nintegration over \\(k_{y}\\). It is convenient to replace \\(y=\\cos k_{y}\\)and \\(dk_{y}=-dy(1-y^{2})^{-1/2}\\)are\n \\(dk_{y}=-dy(1-y^{2})^{-1/2}\\)and dky = \u2212dy(1 \u2212y2)\u22121/2. The boundaries of the integration are \u22121 \u2a7dy \u2a7d1, where changing the order of\n \\(-1\\leqslant y\\leqslant 1\\), where changing the order of\n \\(-1\\leqslant y\\leqslant 1\\), where changing the order of the integration boundaries results an additional minus sign. The integration over \\(y\\)\\(y\\)sign. The integration over y is performed differently depending on the value of the parameter m. Therefore, in\n \\(m\\). Therefore, in\n \\(m\\). Therefore, in what follows we are considering three cases with \\(|m|=1\\), \\(|m|>1\\), and \\(|m|<1\\), separately. \n\n\\(y_{2}=\\max(\\tilde{y}_{1},\\tilde{y}_{2})\\), respectively, where \n\n\\[\\tilde{y}_{1}=\\frac{\\Omega^{2}-1-(m+1)^{2}}{2(m+1)},\\] \\[\\tilde{y}_{2}=\\frac{\\Omega^{2}-1-(m-1)^{2}}{2(m-1)}.\\] (18)  \\[\\tilde{y}_{1}=\\frac{\\Omega^{2}-1-(m+1)^{2}}{2(m+1)},\\] \\[\\tilde{y}_{2}=\\frac{\\Omega^{2}-1-(m-1)^{2}}{2(m-1)}.\\] (18)  \n\n#### Case \\(|m|=1\\)\n\n\n\nCalculations are simpler in the special case of \\(|m|=1\\)(\n . \n\n\n\nSo we have to set \\(y_{1}=\\tilde{y}_{1}\\), \\(y_{2}=\\tilde{y}_{2}\\) if the the following condition is met \n\nThe function in the denominator of the integral (13) can be written explicitly as \\(a^{2}-b^{2}=(\\Omega^{2}-1)(\\Omega^{2}-5-4my)\\). It is linear in \\(y\\) and changes the sign only once at the point \\(y=y_{0}\\operatorname{sgn}{m}\\), where \\(y_{0}=(\\Omega^{2}-5)/4\\)and\n . Solving \n\n\\[\\frac{\\Omega^{2}+m^{2}-2}{m^{2}-1}>0,\\] (19)  \n\nthe condition (14) with respect to \\(\\Omega\\)and using the fact that \\(|y|\\leq 1\\) we obtain that DOS is nonzero only for \\(1\\leq|\\Omega|\\leq 3\\)\n\nThe\n \n\n. \n\nand to set \\(y_{1}=\\tilde{y}_{2}\\), \\(y_{2}=\\tilde{y}_{1}\\), otherwise. \n\nThe condition (14) considered with respect to \\(y\\)\\(y\\)The condition (14) considered with respect to y determines the boundaries of integration in Eq. (13). For\n \n\nLets consider the case \\(|m|>1\\)(\n )\n , then factor \\(m^{2}-1\\)\\(y\\) is positive. Rewriting Eq. (13) in terms of variable \\(y\\) and substituting it in Eq. (7), we obtain the nonzero DOS in the implicit form \n\n\\(m=1\\) it is satisfied for \\(y_{0}\\leq y\\leq 1\\)of\n variable\n .Then the imaginary part of Eq. (13) in terms of variable \\(y\\) gives the DOS in the implicit form \n\n\\[\\rho(\\Omega)=\\frac{|\\Omega|}{\\pi^{2}\\sqrt{m^{2}-1}}\\int\\frac{dy}{ \\sqrt{(1-y^{2})(y_{1}-y)(y-y_{2})}}.\\] (20)  \n\n\\[\\rho(\\Omega)=\\frac{|\\Omega|}{\\pi^{2}\\sqrt{\\Omega^{2}-1}}\\int_{y_{ 0}}^{1}\\frac{dy}{\\sqrt{(1-y^{2})(y-y_{0})}},\\] (15)  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere the boundaries of integration are determined by \n\n\n\nused.\n where the definition (7) is used. The similar expression \n\n), which reads\n \\(y_{1}\\geq y\\geq y_{2}\\)which\n , implying \\(|y|\\leqslant 1\\). There are two cases, in which these conditions can be satisfied by the integration variable \\(y\\): \n\nwill appears for \\(m=-1\\)and\n : the boundaries of integration are \\(-1\\leq y\\leq-y_{0}\\)\\(\\sqrt{(1-y^{2})(-y-y_{0})}\\) and denominator in the integrand is into\n . The corresponding DOS can be \\(\\sqrt{(1-y^{2})(-y-y_{0})}\\)tegration\n \n\n\\[|y_{1}|\\leqslant 1,|y_{2}|>1,\\] \\[|y_{1}|>1,|y_{2}|\\leqslant 1.\\] (21)  \n\n\\(y\\rightarrow-y\\). So Eq. (15) is valid for both\n \\(y\\rightarrow-y\\). So Eq. (15) is valid for both cases \\(m=\\pm 1\\). ",
    "\n* [9] Sun, Y., Wang, Z. J., and Liu, Y., \u201cSpectral (Finite) Volume Method for Conservation Laws on Unstructured Grids VI: Extension to Viscous Flow,\u201d  Journal of Computational Physics , Vol. 215, No. 1, 2006, pp. 41\u201358. \n* [10] Huynh, H. T., \u201cA Flux Reconstruction Approach to High-Order Schemes Including Discontinuous Galerkin Methods,\u201d AIAA Paper No. 2007-4079,  18th AIAA Computational Fluid Dynamics Conference , Miami, FL, USA, June 2007. \n* [11] Huynh, H. T., \u201cA Reconstruction Approach to High-Order Schemes Including Discontinuous Galerkin for Diffusion,\u201d AIAA Paper No. 2009-403,  47th AIAA Aerospace Sciences Meeting Including The New Horizons Forum and Aerospace Exposition , Orlando, FL, USA, Jan. 2009. \n* [12] Roe, P. L., \u201cCharacteristic-based schemes for the Euler Equations,\u201d  Annual Review of Fluid Mechanics , Vol. 18, 1986, pp. 337\u2013365. \n* [13] Kopriva, D. A. and Kolias, J. H., \u201cA Conservative Staggered-Grid Chebyshev Multidomain Method for Compressible Flows,\u201d  Journal of Computational Physics , Vol. 125, 1996, pp. 244\u2013261. \n* [14] Lomax, H., Pulliam, T. H., and Zingg, D. W.,  Fundamentals of Computational Fluid Dynamics , Springer-Verlag, Heidelberg, 1st ed., 2001, p. 249. \n* [15] Romero, J., Asthana, K., and Jameson, A., \u201cA Simplified Formulation of the Flux Reconstruction Method,\u201d  Journal of Scientific Computing , Vol. 67, 2016, pp. 351\u2013374. \n* [16] Hirsch, C.,  Numerical Computation of Internal and External Flows - Volume 1: Fundamentals of Numerical Discretization , John Wiley & Sons, Chichester, 1st ed., 1988, p. 515. \n* [17] Roe, P., \u201cA Simple Explanation of Superconvergence for Discontinuous Galerkin Solutions to  u t  + u x  = 0,\u201d  Communications in Computational Physics , Vol. 21, No. 4, 2017, pp. 905\u2013912. \n\n## RESPONSIBILITY NOTICE \n\nThe authors are solely responsible for the printed material included in this paper. ",
    "further, the time scales becomes sequenced as \n\nfor \\(|z|\\gg 1\\)and\n \n\n\\[t_{c}-\\hat{t}<t_{i}<t_{f}<t_{c}+\\hat{t},\\] (54)  \n\nwhere the system enters into the S regime. The scenario \n\n\\[D_{m}(z)=\\frac{2^{m/2}\\sqrt{\\pi}}{\\Gamma(\\frac{1}{2}-\\frac{m}{2} )}-\\frac{2^{\\frac{1}{2}+\\frac{m}{2}}\\sqrt{\\pi}z}{\\Gamma(-\\frac{m}{2})}+O(z^{2}),\\] (59)  \n\nof the adiabatic-impulse approximation is illustrated in Fig.  7 . \n\n## ACKNOWLEDGMENTS \n\nfor \\(|z|\\to 0\\).\n \n\nFurthermore, in numerical simulations, the timedependent parameter should start at a finite value. We \n\nWe thank Yan He for useful discussion. This work is supported by NSFC under Grants No. 11074177. \n\nchoose a sufficiently large but finite initial transverse field, so the initial conditions of Eqs. ( A1 ) and ( A2 ) can be expanded into a powers of\n \\(1/g_{i}\\), \n\n## Appendix A: Solution of TDBdG equations \n\nWe can solve the TDBdG equations given by Eq. ( 6 ) \n\n\\[u_{q}(t_{i})^{2} =1-\\frac{\\sin^{2}q}{4g_{i}^{2}}+O(\\frac{1}{g_{i}^{3}}),\\] (60) \\[v_{q}(t_{i})^{2} =1-u_{q}(t_{i})^{2}.\\] (61)  \n\nexactly by mapping them to the Landau-Zener problem. Then, the time-dependent Bogoliubov coefficients can be given by \n\n\n\nBased on this approximation, the two constants, \\(C_{1}\\) and \\(C_{2}\\), can be expressed as \n\n\\[v_{q}(z)= C_{1}D_{-s_{q}-1}(iz)+C_{2}D_{-s_{q}-1}(-iz),\\] (55) \\[u_{q}(z)= \\frac{e^{i\\pi/4}}{\\sqrt{\\tau_{Q}}\\sin q}\\left(i\\frac{\\mathrm{d}}{ \\mathrm{d}z}+\\frac{iz}{2}\\right)v_{q}(z),\\] (56)  \n\n\\[|C_{1}|^{2} =u_{q}(t_{i})^{2}~{}e^{-\\frac{\\pi}{2}\\tau_{Q}\\sin^{2}q}\\tau_{Q} \\sin^{2}q\\] (62) \\[|C_{2}|^{2} =0,\\] (63)  \n\nwith free complex parameters \\(C_{1}\\) and \\(C_{2}\\). Here, \\(D_{m}(z)\\)is the complex parabolic cylinder function,\n \\(z=2\\sqrt{\\tau_{Q}}\\left(\\frac{t}{\\tau_{Q}}+\\cos q\\right)e^{i\\pi/4}\\)\n\n\n\nthe\n\u0010\n complex\n , and \\(s_{q}=-i\\tau_{Q}\\sin^{2}q\\). , and\n \\(s_{q}=-i\\tau_{Q}\\sin^{2}q\\)2\u221a\u03c4Q\n\u0010\nt\n\u03c4Q + cos q\n\u0011\nei\u03c0/4, and sq = \u2212i\u03c4Q sin2 q.\nTo reduce the above rigorous solution, we need to apply the\n \n\nfor \\(|z_{i}|\\gg 1\\), and\n \n\nasymptotes of \\(D_{m}(z)\\)that are given by [\n 89 ] \n\n\\[D_{m}(z)=e^{-z^{2}/4}z^{m},~{}\\forall|\\arg(z)|<3\\pi/4,\\] (57)  \n\n\\[C_{1}= \\frac{v_{q}(t_{i})}{\\sqrt{2\\pi}}-\\frac{(-1)^{3/4}u_{q}(t_{i}) \\sqrt{\\tau_{Q}}\\sin q}{2}+O(\\tau_{Q},\\tau_{Q}^{2})\\] (64) \\[C_{2}= \\frac{v_{q}(t_{i})}{\\sqrt{2\\pi}}+\\frac{(-1)^{3/4}u_{q}(t_{i}) \\sqrt{\\tau_{Q}}\\sin q}{2}+O(\\tau_{Q},\\tau_{Q}^{2}),\\] (65)  \\[C_{1}= \\frac{v_{q}(t_{i})}{\\sqrt{2\\pi}}-\\frac{(-1)^{3/4}u_{q}(t_{i}) \\sqrt{\\tau_{Q}}\\sin q}{2}+O(\\tau_{Q},\\tau_{Q}^{2})\\] (64) \\[C_{2}= \\frac{v_{q}(t_{i})}{\\sqrt{2\\pi}}+\\frac{(-1)^{3/4}u_{q}(t_{i}) \\sqrt{\\tau_{Q}}\\sin q}{2}+O(\\tau_{Q},\\tau_{Q}^{2}),\\] (65)  \n\n\\[D_{m}(z)= e^{-z^{2}/4}z^{m}-\\frac{\\sqrt{2\\pi}}{\\Gamma(-m)}e^{-im\\pi}e^{z^{ 2}/4}z^{-m-1},\\] \\[~{}\\forall-5\\pi/4<\\arg(z)<-\\pi/4,\\] (58)  \n\nfor \\(|z_{i}|\\ll 1\\), where\n \\(z_{i}\\) is defined by Eq. ( 9 ). \n* [1] T. W. B. Kibble,  Journal of Physics A: Mathematical and General  9 , 1387 (1976) . \n* [10] R. Monaco, J. Mygind, and R. J. Rivers,  Phys. Rev. Lett. 89 , 080603 (2002) . \n* [11] A. Maniv, E. Polturak, and G. Koren,  Phys. Rev. Lett. 91 , 197001 (2003) . \n* [12] L. E.Sadler, J. M.Higbie, S. R.Leslie, M.Vengalattore, and D. M.Stamper-Kurn,  Nature  443 , 312 (2006) . \n* [2] T. W. B. Kibble,  Physics Reports  67 , 183 (1980) . [3] W. H. Zurek,  Nature  317 , 505 (1985) . [4] W. H. Zurek,  Acta physica polonica. B  24 , 1301 (1993) . [5] W. Zurek,  Physics Reports  276 , 177 (1996) . [6] I. Chuang, R. Durrer, N. Turok, and B. Yurke,  Science 251 , 1336 (1991) . \n* [13] C. N.Weiler, T. W.Neely, D. R.Scherer, A. S.Bradley, M. J.Davis, and B. P.Anderson,  Nature  455 , 948 (2008) . \n* [14] D. Golubchik, E. Polturak, and G. Koren,  Phys. Rev. Lett.  104 , 247002 (2010) . \n* [15] G. D. Chiara, A. del Campo, G. Morigi, M. B. Plenio, and A. Retzker,  New Journal of Physics  12 , 115003 (2010) . \n* [7] M. J. Bowick, L. Chandar, E. A. Schiff, and A. M. Srivastava,  Science  263 , 943 (1994) . [8] V. M. H. Ruutu, V. B. Eltsov, A. J. Gill, T. W. B. Kibble, M.Krusius, Y. G.Makhlin, B.Pla\u00b8 cais, G. E. Volovik, and W. Xu,  Nature  382 , 334 (1996) . \n* [9] C.B\u00a8 auerle, Y. M.Bunkov, S. N.Fisher, H.Godfrin, and G. R.Pickett,  Nature  382 , 332 (1996) . \n* [16] S. M. Griffin, M. Lilienblum, K. T. Delaney, Y. Kumagai, M. Fiebig, and N. A. Spaldin,  Phys. Rev. X  2 , 041022 (2012) . ",
    "\n\n_length_ _._ **Proposition 2.** _ Given integers_ _ and_ _ where_ _, the shortest negative cycle of_ _ is of_ \n\n_Proof._ We first present two natural choices for a negative cycle, one of length\n \\(2k\\)and another of length\n \\(2l\\). The first is a negative cycle on the first two layers. Take a positive edge and connect its two ends with one of the two paths using only the negative edges that connect the two layers. This would result in a negative cycle of length\n \\(2k\\). The second negative cycle we consider is by taking a positive edge and connecting each of its ends to the vertex \\(u\\) by a shortest path (all edges negative). One of these paths will be of length \\(l\\)and the other would be of length \\(l-1\\). Together with the first chosen edge itself then, they form a negative\n cycle of length\n \\(2l\\). \n\nIt remains to show that the shortest of these two types of cycles gives us the negative girth. To that end, we will first show that a shortest negative cycle can only use one positive edge of \\(\\widehat{BQ}(\\ell,2k-1)\\)e aim\ncome\n \\(\\widehat{BQ}(\\ell,2k-1)\\)present\n . Towards\n a contradiction, let \\(C\\) be a negative cycle with more than two positive edges. We aim to present a negative cycle \\(C^{\\prime}\\)whose length is at most \\(|C|-2\\). We take two positive edges of\n \\(C\\) that come consecutively on the cyclic order. Assume \\(xy\\) and \\(x^{\\prime}y^{\\prime}\\)are these two edges and that \\(x^{\\prime}\\)is followed by \\(y\\) in the cyclic order of \\(C\\)(that is to say, there is no positive edge in the \\(x^{\\prime}-y\\)but\n  path in \\(C\\)). We remove the two positive edges \\(xy\\)and \\(x^{\\prime}y^{\\prime}\\)and the \\(x^{\\prime}y\\) path connecting them in \\(C\\), but then we add a \\(xy^{\\prime}\\)copy of this path (which also has no positive edge). The result is a closed walk whose sign is the same as that of \\(C\\), and whose length is \\(|C|-2\\)a\n . But then this closed walk must contain a negative cycle, whose length then is also at most\n \\(|C|-2\\),\n a contradiction. \n\nFigure 3: Construction of \\(\\widehat{BQ}(\\ell,2k-1)\\)\\(\\widehat{BQ}(\\ell,2k-1)\\).\n \\(\\widehat{BQ}(2,3)\\)\\(\\widehat{BQ}(2,3)\\), presented two different ways.\n \\(\\min\\{2l,2k\\}\\)\\(l\\)\\(k\\)\\(l,k\\geq 2\\)\\(\\widehat{BQ}(\\ell,2k-1)\\)\\(\\widehat{BQ}(\\ell,2k-1)\\)",
    "For a set \\(E\\), \\(\\overset{\\circ}{E}\\) denotes its interior and \\(\\overline{E}\\) its closure. \n\nFor \\(E\\subseteq\\mathbb{R}^{d}\\)the\n , \\({\\cal C}_{\\overline{E}}[0,\\infty)\\)cadlag\n denotes the set of continuous functions from\n \\([0,\\infty)\\)to\n \\(\\overline{E}\\) and \\({\\cal D}_{\\overline{E}}[0,\\infty)\\)denotes the set of cadlag functions from\n \\([0,\\infty)\\)\n\nprobability\n \n\nto\n \\(\\overline{E}\\). \n\nFor \\(E\\subseteq\\mathbb{R}^{d}\\)denotes\n , \\({\\cal P}(\\overline{E})\\)the\n denotes the set of probability measures on\n \\(\\overline{E}\\). For a stochastic process \\(Z\\), \\(\\{{\\cal F}^{Z}_{t}\\}\\) denotes the filtration generated by \\(Z\\), i.e. \\({\\cal F}^{Z}_{t}:=\\sigma\\{Z(s),\\,s\\leq t\\}\\). \n\n## Formulation of the problem and preliminaries \n\nLet \\({\\cal W}\\subseteq\\mathbb{R}^{d}\\) be a piecewise smooth cone with vertex at the origin i.e. \n\n\\[{\\cal W}:=\\bigcap_{j=1}^{m}{\\cal W}_{j},\\quad{\\cal W}_{j}:=\\{x=rz,\\,z\\in{\\cal S }_{j},\\,r>0\\},\\] (1)  \n\nwhere \\({\\cal S}_{j}\\) is a nonempty domain in the unit sphere \\(S^{d-1}\\)with \\({\\cal C}^{2}\\)boundary. Clearly \n\n\\[{\\cal W}=\\{x=rz,\\,z\\in{\\cal S},\\,r>0\\},\\;\\;\\;\\mbox{\\normalshape where }{\\cal S }:=\\bigcap_{j=1}^{m}{\\cal S}_{j}.\\] (2)  \n\nIt is supposed that \\[\\overline{{\\cal S}}=\\bigcap_{j=1}^{m}\\overline{{\\cal S}_{j}}.\\]  The object of this work is the semimartingale obliquely reflecting Brownian motion (ORBM) in \\(\\overline{{\\cal W}}\\)i.e.\n  with drift \\(b\\), dispersion matrix \\(\\sigma\\) and radially constant direction of reflection \\(g^{j}\\)on each face, i.e. for \\(x\\in\\partial{\\cal W}_{j}-\\{0\\},\\)\\(x=rz,\\,z\\in\\partial{\\cal S}_{j}\\), \n\n\\[g^{j}(x)=g^{j}(z),\\] (3)  \n\nfor some unit vector field \\(g^{j}\\)defined on \\(\\partial{\\cal S}_{j}\\)with\n . This process can be defined as the solution of the following stochastic differential equation with reflection: \n\n\\[X(t)=X(0)+b\\,t+\\sigma\\,W(t)+\\int_{0}^{t}\\gamma(s)\\,d\\lambda(s), \\quad t\\geq 0, \\non\\] (4) \u03b3(t)\u2208G(X(t)),|\u03b3(t)|=1,d\u03bb\u2212a.e.,t\u22650, (5) \\[X(t)\\in\\overline{{\\cal W}},\\quad\\lambda(t)=\\int_{0}^{t}{\\bf 1}_{ \\partial{\\cal W}}(X(s))d\\lambda(s),\\quad t\\geq 0, \\non\\] (6)  \n\n\\[X(t)=X(0)+b\\,t+\\sigma\\,W(t)+\\int_{0}^{t}\\gamma(s)\\,d\\lambda(s), \\quad t\\geq 0, \\non\\] (4) \u03b3(t)\u2208G(X(t)),|\u03b3(t)|=1,d\u03bb\u2212a.e.,t\u22650, (5) \\[X(t)\\in\\overline{{\\cal W}},\\quad\\lambda(t)=\\int_{0}^{t}{\\bf 1}_{ \\partial{\\cal W}}(X(s))d\\lambda(s),\\quad t\\geq 0, \\non\\] (6)  \n\nwhere \n\n\\[G(x):=\\{g:\\,g=\\sum_{j\\in{\\cal J}(x)}u_{j}g^{j}(x),\\;u_{j}\\geq 0 \\},\\quad{\\cal J}(x):=\\{j:\\,x\\in\\partial{\\cal W}_{j}\\},\\quad x\\in\\partial{\\cal W }-0,\\non\\] (7) (8) G(0):=the closed convex cone generated by {gj(x),x\u2208(\u2202\ud835\udcb2j\u2229\ud835\udcb2\u00af)\u2212{0},j=1,\u22ef,m}. (9)  \n\n\\[G(x):=\\{g:\\,g=\\sum_{j\\in{\\cal J}(x)}u_{j}g^{j}(x),\\;u_{j}\\geq 0 \\},\\quad{\\cal J}(x):=\\{j:\\,x\\in\\partial{\\cal W}_{j}\\},\\quad x\\in\\partial{\\cal W }-0,\\non\\] (7) (8) G(0):=the closed convex cone generated by {gj(x),x\u2208(\u2202\ud835\udcb2j\u2229\ud835\udcb2\u00af)\u2212{0},j=1,\u22ef,m}. (9)  ",
    "**Lemma 1.1.** _ [_ _0_ _] If_ \\(G\\)_ is a graph such that for_ \\(u,v\\in V(G)\\)_,_ \\(uv\\notin E(G)\\)_, then_ \\(\\rho(G)<\\rho(G+uv)\\)_._ \n\nLet \\(A\\) be a real symmetric matrix whose rows and columns are indexed by \\(V=\\{1,2,\\cdots,n\\}\\). Let \\(\\{V_{1},V_{2},\\cdots,V_{k}\\}\\)\\(\\{V_{1},V_{2},\\cdots,V_{k}\\}\\) be a partition of \\(V\\) such that the block partition of the matrix \\(A\\) according to \\(\\{V_{1},V_{2},\\cdots,V_{k}\\}\\) can be expressed as \n\n\\[A=\\begin{bmatrix}A_{11}&A_{12}&\\dots&A_{1k}\\\\ A_{21}&A_{22}&\\dots&A_{2k}\\\\ \\vdots&\\vdots&\\ddots&\\vdots\\\\ A_{k1}&A_{k2}&\\dots&A_{kk}\\end{bmatrix},\\]  \n\nwhere \\(A_{ij}\\) denotes the block formed by intersection of the rows in \\(V_{i}\\) and the columns in \\(V_{j}\\). Let \\(q_{ij}(A)\\)denote the average row sum of\n \\(A_{ij}\\). Then, the quotient matrix of \\(A\\) with respect to the partition \\(\\{V_{1},V_{2},\\cdots,V_{k}\\}\\) is given by \\[Q(A)=[q_{ij}(A)].\\]  Moreover, if the row sum of each block \\(A_{ij}\\) is constant then we say that the partition is equitable and \\(Q(A)\\)is called an equitable quotient matrix of\n \\(A\\). There is a nice relation between the spectrum of \\(A\\) and that of \\(Q(A)\\), which is stated now as a theorem.\n \n\n**Theorem 1.2.** _ [_ _0_ _] Let_ \\(A\\)_ be a real symmetric matrix such that it has an equitable quotient matrix_ \\(Q(A)\\)_, then,_ \\(\\sigma(Q(A))\\subset\\sigma(Q(A))\\)_. Moreover, if_ \\(A\\)_ is nonnegative, then_ \\(\\rho(A)=\\rho(Q(A))\\)_, i.e., the_ _spectral radius of_ \\(Q(A)\\)_ is actually the spectral radius of_ \\(A\\)_._ \n\nA vertex \\(v\\) of a connected graph \\(G\\) is a cut vertex of \\(G\\) if \\(G-v\\)no\n  is disconnected. A block of the graph \\(G\\) is a maximal connected subgraph of G that has no cut-vertex. Given two blocks \\(F\\) and \\(H\\) of graph \\(G\\) are said to be adjacent if they are connected via a cut-vertex. We denote \\(F\\circledcirc H\\), to represent the induced subgraph on the vertex set of two adjacent blocks \\(F\\) and \\(H\\). \n\nA complete graph is a graph where each vertex is adjacent to every other vertex. A complete graph on \\(n\\) vertices is denoted by \\(K_{n}\\). A connected graph is called a clique tree if each of its blocks is a clique. Let \\(G\\) be a clique tree with \\(d_{1}\\) blocks of \\(K_{n_{1}}\\), \\(d_{2}\\) blocks of \\(K_{n_{2}}\\), so on up to \\(d_{b}\\) blocks of \\(K_{n_{b}}\\), then we write \\(G\\) with blocks \\(K_{n_{1}}^{(d_{1})}-K_{n_{2}}^{(d_{2})}-\\cdots-K_{n_{b}}^{(d_{b})}\\)the blocks\n (for example see Figure  1 ). Here the above notation only gives information about the blocks of \\(G\\), but not about the structure of the graph. But for a special case, if \\(G\\) has a central cut vertex, then all the blocks are adjacent via the central cut vertex and we denote it by \\[G=K_{n_{1}}^{(d_{1})}\\circledcirc K_{n_{2}}^{(d_{2})}\\circledcirc\\cdots \\circledcirc K_{n_{b}}^{(d_{b})}.\\]  \n\nA block \\(H\\) of a clique tree \\(G\\) is a pendent block of \\(G\\) if \\(H\\) has exactly one cut-vertex of \\(G\\). Let \\(v\\) be a cut-vertex of \\(G\\). If \\(G-v\\) consists of two disjoint graphs \\(W_{1}\\) and \\(W_{2}\\) and let \\(G_{i}(i=1,2)\\)be the subgraph of \\(G\\) induced by \\(\\{v\\}\\cup V(W_{i})\\)by\n \\(G=G_{1}\\oplus_{v}G_{2}\\), then\n \\(G\\) is called the vertex-sum at \\(v\\) of the two graphs \\(G_{1}\\) and \\(G_{2}\\), and denoted by \\(G=G_{1}\\oplus_{v}G_{2}\\). For a vertex \\(v\\) in a graph \\(G\\), the block index of \\(v\\) is the number of blocks which share the vertex \\(v\\) and is denoted by \\(bi_{G}(v)\\).\n \n\nThe spectral radius of a graph has been extensively studied subject to various graph theoretic constraints. In spectral graph theory, the maximization and minimization of the spectral radius of a given class of a graph and the problem of determining the extremal graphs find a particular interest among researchers. One such result due to Brualdi and Solheid in [ 0 ] is an important motivation for our study. In this article, the authors obtained the graphs that maximize the ",
    "where \\(\\rho_{w}\\) is the density of water and \\(C\\) the ocean function that equals one where water is present and zero otherwise. In the case of ice loading, the direct term is given by \n\n\\[\\zeta=\\rho_{i}(1-C)\\Delta I,\\] (12)  \n\nwhere \\(\\rho_{i}\\) is the density of ice, and \\(\\Delta I\\) the change in ice thickness. The factor, \\(1-C\\), within this expression accounts for the possibility of floating ice (e.g. Crawford et al. 2018, equations 31\u201334). \n\nConsider again a pair of solutions \\((\\mathbf{u},\\phi)\\) and \\((\\mathbf{u}^{\\dagger},\\phi^{\\dagger})\\) of the loading problem associated, respectively, to with loads \\(\\sigma\\) and \\(\\sigma^{\\dagger}\\). Here, however, we assume that these loads are decomposed as in eq.(2.11) into water and direct terms that share a common ocean function. From the above expression for sea level change we can write \n\n\\[\\mathbf{u}\\cdot\\nabla\\Phi+\\phi=-g\\,\\Delta SL+\\Phi_{g},\\quad\\mathbf{u}^{\\dagger }\\cdot\\nabla\\Phi+\\phi^{\\dagger}=-g\\,\\Delta SL^{\\dagger}+\\Phi_{g}^{\\dagger},\\] (13)  \n\nand hence eq.(2.8) becomes \n\n\n\n\\[\\int_{\\partial M}(-g\\,\\Delta SL^{\\dagger}+\\Phi^{\\dagger}_{g})\\,\\sigma\\,\\mathrm {d}S=\\int_{\\partial M}(-g\\,\\Delta SL+\\Phi_{g})\\,\\sigma^{\\dagger}\\,\\mathrm{d}S.\\] (14)  \n\nThe terms involving the constants \\(\\Phi_{g}\\) and \\(\\Phi_{g}^{\\dagger}\\)vanish due to conservation of mass, and so the identity simplifies to \n\n\n\n\\[\\int_{\\partial M}\\Delta SL^{\\dagger}\\,\\sigma\\,\\mathrm{d}S=\\int_{\\partial M} \\Delta SL\\,\\sigma^{\\dagger}\\,\\mathrm{d}S.\\] (15)  \n\nIf we now substitute into the equality the decompositions of the loads, \\(\\sigma\\) and \\(\\sigma^{\\dagger}\\), we find \n\n\n\n\\[\\int_{\\partial M}\\Delta SL^{\\dagger}(\\rho_{w}C\\,\\Delta SL+\\zeta)\\,\\,\\mathrm{d} S=\\int_{\\partial M}\\Delta SL\\,(\\rho_{w}C\\,\\Delta SL^{\\dagger}+\\zeta^{\\dagger}) \\,\\mathrm{d}S,\\] (16)  \n\nand cancelling the terms symmetric in \\(\\Delta SL\\) and \\(\\Delta SL^{\\dagger}\\)we arrive at \n\n\n\n\\[\\int_{\\partial M}\\Delta SL^{\\dagger}\\,\\zeta\\,\\,\\mathrm{d}S=\\int_{\\partial M} \\Delta SL\\,\\zeta^{\\dagger}\\,\\mathrm{d}S.\\] (17)  \n\nAgain, this is a known result, being implied as a special case by the adjoint theory of Crawford et al. (2018) for sea level change in a viscoelastic earth model. What is new is the explicit statement as a reciprocity theorem along with the more elementary derivation that has been facilitated by restricting attention to the elastic fingerprint problem. \n\n### Symmetry of the Green\u2019s function \n\nBecause the fingerprint problem is linear, its solution must take the form \n\n\n\n\\[\\Delta SL(\\mathbf{x})=\\int_{\\partial M}G(\\mathbf{x},\\mathbf{x}^{\\prime})\\zeta( \\mathbf{x}^{\\prime})\\,\\mathrm{d}S_{\\mathbf{x}^{\\prime}},\\] (18)  \n\nfor an appropriate Green\u2019s function, where we have added a subscript to the surface element to make clear which variable it is defined with respect to. Suppose that, within eq.(2.17), we take ",
    "decline in activity on Stack Overflow. \n\nWe report the estimated effect of our difference-in-differences model in Table  1  and visualize the weekly estimates of the relative change in the Stack Overflow activity in Figure  2 . Table  1  indicates that ChatGPT decreased posting activity on Stack Overflow by 15.6% ( \\(1-e^{-0.17}\\)). These results are robust to changes in the controls and starting point of the data time series. We also tested for heterogeneity in subsets of the data: considering only questions (rather than counting both questions and answers) and posts on weekdays. In both subsets our estimates did not deviate significantly from the main result: we estimate a 12% relative decrease in questions and 14% relative decrease in posts on weekdays. \n\nFigure  2  shows that the impact of ChatGPT is increasing over time and is by the end of our study greater in magnitude than the average post-ChatGPT effect estimated in Table  1 . By the end of April 2023, the estimated effect stabilizes at around 25%. Interestingly, ChatGPT use, in general, peaked around this time. 3 \n\n\\begin{tabular}{l c c c}\n\\hline\n & (1) & (2) & (3) \\\\\n & Number of posts & Number of questions & Weekday posts \\\\\n\\hline\nStack Overflow \\(\\times\\) Post-GPT & -0.170** & -0.112+ & -0.149* \\\\\n & (0.0607) & (0.0619) & (0.0636) \\\\\nObservations & 1,150 & 1,150 & 1,150 \\\\\nR-squared & 0.995 & 0.994 & 0.993 \\\\\nR-squared within & 0.290 & 0.315 & 0.232 \\\\\nOutcome mean & 16363 & 7273 & 13191 \\\\\nOutcome std. dev. & 29088 & 12661 & 23685 \\\\ \\hline\n\\end{tabular}\n\n\nTable 1: Results of a difference-in-differences model, estimating the change in activity observed weekly on Stack Overflow following the release of ChatGPT, relative to activity on four other platforms less likely to have been impacted. All regressions comprise platform fixed effects, week fixed effects, and platform-specific linear time-trends. The standard-error of the estimate clustered on month is reported in parentheses. Significance codes: ***: \\(p<0.001\\), **: \\(p<0.01\\), *: \\(p<0.05\\), +: \\(p<0.1\\). ",
    "# : stellar occultation events by (307261) 2002 MS \u2084\n\ndent points at the sky plane to fit the five ellipse parameters. The global elliptical limb is determined by minimizing the classical \\(\\chi^{2}\\)function. The quality of the result is given by the \\(\\chi^{2}\\)per degree of freedom \\(\\chi^{2}_{\\rm pdf}=\\chi^{2}/(N-M)\\approx 1\\)for satisfactory fits, where\n \\(N\\)is the number of points and \\(M\\) is the number of fitted parameters ( Gomes-J\u00fanior et al. 2022 ). A set of empirical tests 9 assuming topography values between 0 and 10 km were performed and revealed a good fit ( \\(\\chi^{2}_{\\rm pdf}=0.92\\)) when features of 7 km were\n considered. This result agrees with the theoretical approach proposed by  Johnson and McGetchin  ( 1973 ), which gives a lower limit of 6 to 7 km for topography on MS4 (see Sect.  3.4 ). \n\ncause the GPS was connected to the computer and it presented a large o ff set with respect to all close-by chords; 5) Artemis because its length does not match the length of Catania\u2019s chord (at 1 \\(\\sigma\\) level), which probed exactly the same object\u2019s profile but is a bit larger. 6) Finally, Caussols, Ariana, and Kuban have larger uncertainties than other chords that probed the same region. In addition to the eight GPS data sets, we selected another five positive chords acquired from M\u00e9o station, M\u00e1traszentistv\u00e1n, Hvar, Agerola, and La Palma. The main criteria for selecting the mentioned NTP chords were: data acquired with professional telescopes, low dispersion in the light curves, and the smallest uncertainties of the probed limb. \n\nAmong the elliptical solutions inside the\n \\(3\\sigma\\)\\(3\\sigma\\)Among the elliptical solutions inside the 3\u03c3 region, we excluded those that crossed or approached the negative grazing\n \n\nFigure  2  presents the 13 selected positive chords (blue) overplotted to the other positives (gray segments). Solid lines represent GPS chords, while dashed lines show NTP data. The selected data are ordered from north to south, as follows: M\u00e9o \n\nchords within the tolerance level of 7 km (radial direction). Therefore, although the solutions cross the negative chord as seen from Montsec (Fig.  2 ), they are inside the 7 km assumed \\(R_{\\rm equiv}=a^{\\prime}\\sqrt{1-\\epsilon^{\\prime}}\\). Finally, the limb solution in Table\n \\(R_{\\rm equiv}=a^{\\prime}\\sqrt{1-\\epsilon^{\\prime}}\\). Finally, the limb solution in Table  4 9  See Eq. 11 in  Gomes-J\u00fanior et al.  ( 2022 ) for details about the function that considers topography in the limb fitting. station (FRA), Valbonne (FRA), M\u00e1traszentistv\u00e1n (HUN), Catalonia (ESP), Massa (ITA), Rome (ITA), Hvar (HRV), Sassari (ITA), Odesa (UKR), Agerola (ITA), Algiers (DZA), La Palma (ESP), and \u00c7anakkale (TUR). They provide N  =  26 indepen- \n\nTable 2: Target stars designation and geocentric coordinates at closest approach instant (UT) sorted by occultation date (day-monthyear). \n\n\\begin{tabular}{c c c c c c c c c c}\n\\hline\n**Date** & \\begin{tabular}{c} **Gaia DR3** \\\\ **Designation** \\\\ \\end{tabular} & \\begin{tabular}{c} **Propagated** \\\\ **right ascension** \\\\ **(hh mm ss.sssss)** \\\\ \\end{tabular} & \\begin{tabular}{c} **Error** \\\\ **(mas)** \\\\ \\end{tabular} & \\begin{tabular}{c} **Propagated** \\\\ **declination** \\\\ **(\u00ba '\u2006 '')** \\\\ \\end{tabular} & \\begin{tabular}{c} **Error** \\\\ **(mas)** \\\\ \\end{tabular} & \\begin{tabular}{c} **V**a \\\\ **(mag)** \\\\ \\end{tabular} & \\begin{tabular}{c} **K**a \\\\ **(mag)** \\\\ \\end{tabular} & \\begin{tabular}{c} **S**Diamb \\\\ **(km)** \\\\ \\end{tabular} & \\begin{tabular}{c} \\(\\Delta_{MS4}\\)c \\\\ **(au)** \\\\ \\end{tabular} \\\\\n\\hline\n09-07-2019 & 4253196402592965504 & 18 45 19.24565 & 0.15 & -06 24 13.0031 & 0.12 & 15.00 & 14.15 & 0.19 & 45.62 \\\\\n\\hline\n\\multirow{2}{*}{26-07-2019} & 4253186506987951104 & 18 44 07.57274 & 0.54 & -06 26 40.1240 & 0.46 & 17.78 & 16.27 & 0.08 & 45.67 \\\\\n\\cline{2-10}\n & 4253186477047835648 & 18 44 06.31756 & 0.13 & -06 26 43.8948 & 0.11 & 15.45 & 11.66 & 0.98 & 45.68 \\\\\n\\hline\n19-08-2019 & 4253181804071259648 & 18 42 43.51905 & 0.24 & -06 32 34.0868 & 0.19 & 16.51 & 16.59 & 0.05 & 45.88 \\\\\n\\hline\n26-07-2020 & 4253244201379441792 & 18 48 18.07372 & 0.12 & -06 13 31.6134 & 0.12 & 14.76 & 12.61 & 0.47 & 45.60 \\\\\n\\hline\n08-08-2020 & 4253248324549054464 & 18 47 29.96384 & 0.12 & -06 16 31.4727 & 0.10 & 14.62 & 11.13 & 1.19 & 45.70 \\\\\n\\hline\n24-02-2021 & 4253709191700784896 & 18 56 35.98731 & 0.25 & -06 30 23.1569 & 0.23 & 16.51 & 12.96 & 0.53 & 47.05 \\\\\n\\hline\n14-10-2021 & 4252495635735083264 & 18 50 30.76176 & 0.31 & -06 24 13.3375 & 0.27 & 15.83 & 13.44 & 0.34 & 46.52 \\\\\n\\hline\n10-06-2022 & 4253907305577009664 & 19 00 15.44628 & 0.23 & -05 42 42.9960 & 0.21 & 15.1 & 13.00 & 0.39 & 45.48 \\\\ \\hline\n\\end{tabular}\n\n[FOOTNOTE:a][ENDFOOTNOTE]\n\n[FOOTNOTE:a][ENDFOOTNOTE]\n\n[FOOTNOTE:b][ENDFOOTNOTE]\n\n[FOOTNOTE:c][ENDFOOTNOTE]\n\n\n\nFig. 1: Chords measured during the 8 August 2020 event show the detection of MS4\u2019s limb in blue with 1 \\(\\sigma\\)\\(\\sigma\\)the detection of MS4\u2019s limb in blue with 1\u03c3 error bars (red segments). Six positive chords with large error bars were suppressed\n from this plot for better visualization: TAROT, Lleida, Khmelnytskyi, Fuensanta de Martos, Kharkiv T36, and Marbella. The green lines represent positions compatible with the total target\u2019s flux within the noise (i.e., no secondary occultation). The order of positive chords, from north to south, is the same as in Table  3 . \n\nFig. 2: Thirteen selected chords (blue), where GPS data are presented in solid lines and NTP by dashed lines. Gray segments show the other positive chords not used in limb-fitting. The black \\(3\\sigma\\). The orange segments represent each image\n . The orange segments represent each image acquired from the Montsec station and the light green segments show other negative chords. ",
    "time-scale of slow spike dynamics for the Proposition  5.1  characterizes the slow dynamics of an \\(N\\)-spike quasi-equilibrium solution on the long \\({\\mathcal{O}}\\left(\\epsilon^{-3}\\right)\\)GM and Gray-Scott models ([ 23 ], [ 8 ], [ 12 ]), where there are no chemotactic e ff ects. time-scale. We remark that this time-scale is longer than the \\({\\mathcal{O}}\\left(\\epsilon^{-2}\\right)\\)no\n \n\nIn Appendix  H , we show that \\(\\beta_{j}\\), as given in ( 5.17 ), can be calculated asymptotically by retaining only the contribution from the sub-inner solution. In particular, in Appendix  H  we provide the leading order estimate \n\n\\[\\beta_{j}\\sim\\frac{2}{v_{\\max j}}\\,,\\qquad\\mbox{for}\\,\\,\\,v_{\\max j }\\gg 1\\,.\\  \n\nMoreover, in Appendix  H  we show at the steady-state spike locations that \\(\\beta_{j}=\\beta_{0}\\)\\(\\forall j\\)\n\nDAE\n \n\n, with \\(\\beta_{0}\\) given in ( 4.28 ). \n\nTo illustrate our results, we now compare the dynamics computed from the DAE system ( 5.24 ) with corresponding numerical results computed from the full PDE system ( 1.2 ) using FLEXPDE7 [ 14 ]. In our comparison, we computed the integrals defining \\(\\beta_{j}\\) numerically from ( 5.17 ). The results for a one- and two-spike dynamics are shown in Figure  8  for the parameter values in the figure caption. In Figure  8a , where we chose the initial condition \\(x_{1}(0)=-0.1\\), the asymptotic and numerical spike trajectories are favorably compared for a one-spike\n quasi-equilibrium pattern. In Figure  8b \\(x_{1}(0)=-0.6\\)and\n \\(x_{2}(0)=0.6\\).\n \\(x_{1}(0)=-0.6\\)and\n \\(x_{2}(0)=0.6\\).\n \n\n### Computation of Jacobian Matrix for Balancing Conditions \n\nIn this subsection, and as remarked in \u00a7 4 , we show that when \\(d_{1}\\in{\\mathcal{T}}_{e}\\)the\n  the matrix \\({\\mathcal{M}}\\)spike\n  in ( 4.29 ) arises from the linearization of the DAE dynamics ( 5.24 ) in Proposition  5.1  about the steady-state spike locations. Our approach below is inspired by a related analysis for the GM model in [ 58 ]. \n\nTo this end, we use the Green\u2019s function in ( 2.24 ) together with its decomposition in ( 5.20 ) to define \n\n\\[\\partial_{x_{j}}G(x_{j};x_{k}):=\\left\\{\\begin{array}[]{ll}\\frac{ \\partial R}{\\partial x}(x;x_{j})|_{x=x_{j}}\\,,&j=k\\,,\\\\ \\frac{\\partial G}{\\partial x}(x;x_{k})|_{x=x_{j}}\\,,&j\\not=k\\,,\\end{array} \\right.\\qquad\\partial_{x_{j}}\\partial_{x_{k}}G(x_{j};x_{k})=\\left\\{\\begin{ array}[]{ll}\\frac{\\partial}{\\partial x}|_{x=x_{j}}\\frac{\\partial}{\\partial y}| _{y=x_{k}}R(x;y)\\,,&j=k\\,,\\\\ \\partial_{x_{j}}\\partial_{x_{k}}G(x_{j};x_{k})\\,,&j\\not=k\\,.\\end{array}\\right.\\  \n\n(a) one-spike slow dynamics \n\n(b) two-spike slow dynamics ",
    "where \\(S_{n}(u)=\\,e^{-B_{S}}\\psi_{s_{n}}(u)\\). To get the normalization constant we first consider the asymptotic expansion of the normalizable solution, \\(S_{n}(u)\\), close to the boundary, \\(S_{n}(u)=N_{s_{n}}u^{3}+\\cdots\\) , where \\(N_{s_{n}}\\) is the normalization constant, which is obtained by plugging \\(S_{n}(u)\\)in ( 4.3 ). Then decay constants of the scalar mesons are given by the following dictionary \n\n\\[F_{s_{n}}=\\zeta\\,u\\,e^{3A_{s}-\\Phi}\\partial_{u}S_{n}\\bigg{|}_{u=\\epsilon}=3 \\frac{\\sqrt{N_{c}}}{2\\pi}\\,N_{s_{n}}.\\] (57)  \n\nWe first investigate the behavior of the scalar meson decay constants as a function of the parameter \\(a_{0}\\) in the chiral limit with the other parameters fixed as in model A. Our numerical results are displayed on the left panel of Fig.  14 . As can be seen from the plot, the results show a smooth behavior of the decay constants in the region of interest, i.e., \\(a_{0}<a_{0}^{c}\\), where \\(a_{0}^{c}\\approx 0.0974\\). However, the behavior of the decay constant increases close to \\(a_{0}^{c}\\)for the ground state while it decreases for the scalar resonances. \n\nIn addition, we calculate the scalar meson decay constants as a function of the quark mass. Our numerical results are displayed on the right panel of Fig.  14 . As can be seen from the plot, the decay constant increases in the region of small quark mass until it reaches some maximum value and then decreases when the quark mass grows. Finally, we calculate the decay constant using the final set of parameters for models A and B displayed in Table  1 . \n\n\\begin{tabular}{l|c|c|l}\n\\hline \\hline\n & Models A and B & SW [] & Experimental [] \\\\\n\\hline\n\\(F_{{V_{0}}}^{{1/2}}\\) & 276 & 261 & \\(346.2\\pm 1.4\\) \\\\\n\\(F_{{V_{1}}}^{{1/2}}\\) & 341 & & \\(433\\pm 13\\) \\\\\n\\(F_{{V_{2}}}^{{1/2}}\\) & 384 & & \\\\ \\hline \\hline\n\\end{tabular}\n\\begin{tabular}{l|c|c|l}\n\\hline \\hline\n & Models A and B & SW [] & Experimental [] \\\\\n\\hline\n\\(F_{{V_{0}}}^{{1/2}}\\) & 276 & 261 & \\(346.2\\pm 1.4\\) \\\\\n\\(F_{{V_{1}}}^{{1/2}}\\) & 341 & & \\(433\\pm 13\\) \\\\\n\\(F_{{V_{2}}}^{{1/2}}\\) & 384 & & \\\\ \\hline \\hline\n\\end{tabular}\n\\begin{tabular}{l|c|c|l}\n\\hline \\hline\n & Models A and B & SW [] & Experimental [] \\\\\n\\hline\n\\(F_{{V_{0}}}^{{1/2}}\\) & 276 & 261 & \\(346.2\\pm 1.4\\) \\\\\n\\(F_{{V_{1}}}^{{1/2}}\\) & 341 & & \\(433\\pm 13\\) \\\\\n\\(F_{{V_{2}}}^{{1/2}}\\) & 384 & & \\\\ \\hline \\hline\n\\end{tabular}\n\n\nThe decay constants of the vector mesons (in MeV) obtained in our work (same result for models A and B), compared against the result obtained using the soft wall model (SW) [ 13 ]. In order to compare with experimental results of [ 78 ], we need to identify \\(F_{V}\\) with \\(g_{\\rho}\\). \n\nLeft panel: The decay constants of the scalar mesons as a function of \\(a_{0}\\) in the chiral limit. Right panel: The decay constants of the scalar mesons as a function of the quark mass for \\(\\lambda=27\\), \\(b_{0}=1.7\\) and \\(a_{0}=0.02\\). ",
    "Hui Miao, Yuanfang Guo, and Yunhong Wang \n\n\n*  We analyze the frequency spectrum of the real and generated fingerprint images and construct a simple yet effective gen eration artifact stream, _ i.e._ , a shallow convolutional neural network, to extract frequency-domain inconsistencies. \n*  Comprehensive experiments demonstrate that our method is effective, efficient, and robust to the anti-forensic method [11]. \n\n## RELATED WORK \n\n### Fingerprint Image Synthesis \n\ndetection methods [  29 ] only focus on coping with presen tation attacks, which construct artificial fingers [ 34 ] to circumvent the fingerprint recognition system. To model the physiological dif ferences between the artificial and real fingers, existing liveness detection methods usually rely on collecting the pulse rate, skin odor, finger elasticity, _ etc._ , from the sensor of the fingerprint recog nition system. Unfortunately, the replacement attack, _ i.e._ , replacing the real fingerprint images with the GAN-generated fingerprint images, usually happens after the fingerprint collection step and the fake fingerprint images are generated without the defects of artificial fingers. Besides, the GAN-generated fingerprint images also exist some generation artifacts, which are induced by specific processing operations in GANs and does not exist in the captured impressions. Under such circumstance, the existing fingerprint live ness detection methods can hardly be directly applied to detect the GAN-generated fingerprint images. \n\nTo efficiently and effectively identify the GAN-generated fin gerprint images with decent robustness against the existing anti forensic method [ 11 ], in this paper, we propose a ** R** obust deep \n\nSeveral recent methods have been proposed for generating realistic fingerprint images automatically [  17 ]. [ 3 and [ 35 ] combine a convolution autoencoder (CAE) and a GAN based method ( _e.g._ , DCGAN [ 38 ], WGAN [ 18 ]) directly. [ 4 ] presents a GAN-based pipeline followed by a stochastic search algorithm over the latent variable space, to search for suitable latent variable and generate DeepMasterPrints which are synthetic fingerprints and can be matched against a large number of fingerprints. These techniques can be considered as single-staged architectures, whose input is a random vector and output is a generated image. \n\nTo make the synthetic results more realistic and obtain multiple impressions for a virtual identity, many multi-staged methods [  39 ] firstly synthesize a binary masterprint which defines a ridge structure and represents a new identity. After non linear distortion and cropping, which simulate various pressures and different contact regions between the finger and the fingerprint sensor, the distorted masterprint is fed into another generative neural network to generate a realistic fingerprint image. The differences between these multi-staged methods lie in the way of the master print generation scheme, the distortion simulation method, and the final impression (fingerprint) generation approach. [ 12 ] utilizes the GAN-based methods ( _e.g._ , BigGAN [ 5 ]) in these three steps. [ 17 attempts to employ conventional rotation instead of the deep learning method in the distortion module. [ 39 ] adopts StyleGAN2 [ 22 ] to synthesize the fingerprint skeletons and CycleGAN [ 46 ] to generate photorealistic fingerprint images. [ 44 ] also proposes a CycleGAN based L3 synthetic fingerprint generation (L3-SF) approach, which firstly uses traditional methods ( _e.g._ , Anguli [ 1 ], Gabor filter) to generate masterprints with pores and scratch. Besides, [ 44 ] releases a synthetic fingerprint database. \n\n**F** orgery ** D** etection method ** for**  GAN-generated ** Fin** gerprint images (RFDforFin). To take full advantage of the fingerprint characteris tics and the generation artifacts of the fake fingerprint images, we construct a lightweight yet robust two-stream neural network, by exploiting the unique features of the fingerprint images and gen eration artifacts in frequency domain. Considering the impact of sweat on grayscale variations along the ridges of fingerprints [ 10 ], we construct a special ridge stream which utilizes this unique fin gerprint characteristic. In the generation artifact stream, inspired by [ 13 ], which discovers the obvious generation artifacts in the Discrete Cosine Transform (DCT) frequency domain, we transform the input fingerprint image into different frequency domains, an alyze the generation artifacts in these spectrum, and construct a simple yet effective convolutional neural network to learn more robust generation artifacts between the generated and real images from the FFT frequency spectrum. To simultaneously utilize the features extracted from the ridges and generation artifacts in the fi nal prediction, we build a simple yet effective fusion module. Since typical CNNs can learn certain frequency information from the input image or its frequency transformed spectrum, by utilizing the unique 1D ridge features jointly with the 2D generation artifact features, our method can avoid overfitting to certain frequency information, which can improve the robustness of our method. \n\nOur main contributions are summarized as follows: \n\n### Deep Forgery Detection \n\n\n*  We propose the first deep forgery detection method for GAN-generated fingerprint images, by jointly exploiting the unique 1D ridge features and 2D generation artifact features via a lightweight two-stream neural network to ensure the robustness and efficiency of the proposed work. \n*  We propose to exploit fingerprint-related characteristic and construct a ridge stream, which exploits the grayscale varia tions along the ridges. With this ridge stream, our method can avoid overfitting to certain frequency information, which can be easily interfered by existing anti-forensic method [ 11 and thus improves the overall robustness. \n\nResearchers have proposed a series of deep forgery detection approaches to detect the generated images [ 2  7  13  23  26  31 ]. [ 31 ] reveals that the texture statistics is an important detection clue and global texture features can improve the robustness of face forgery detection. [ 13 ] observes that GAN generated images contain distinguishable artifacts in the frequency domain due to the upsampling operations in the generator of GAN architectures, and these artifacts can be utilized for forgery detec tion. [ 28 ] attempts to explore the discrepancies in Learned Noise Patterns (LNP) to detect forgery. [ 30 ] concatenates spatial images and phase spectrums to emphasize the artifacts and proposes a Spatial-Phase Shallow Learning method. [ 26 ] captures frequency aware features and merge them with the extracted spatial domain ",
    "RANA BADREDDINE \n\n(1)  It should be noted that for any potential \\(u\\), the eigenvalues\n \\((\\nu_{n})\\)of\n \\(L_{u}\\) cannot be all simple. For instance, take \\(u(x)=\\operatorname{e}^{ix}\\), one can easily check that for \\(L_{u}=D-T_{u}T_{\\overline{u}}\\,,\\)\\[L_{u}1=L_{u}e^{ix}=0\\,.\\]  (2)  Inequality  ( \n2.7)  implies that as \\(n>\\!>0\\), the lower bound of the distance\n between two consecutive eigenvalues \\(\\nu_{n}\\)\\(1\\,\\).\n \n\n_Proof._  All the presented inequalities are a direct consequence of the max\u2013min principle \n\n\\[\\lambda_{n}=\\max_{\\underset{\\dim F\\leq n}{F\\subseteq L^{2}_{+}}} \\,\\min\\left\\{\\left\\langle\\tilde{L}_{u}h\\,|\\,h\\right\\rangle\\,;\\,h\\in F^{\\perp} \\cap H^{\\frac{1}{2}}_{+}(\\mathbb{T})\\,,\\ \\|h\\|_{L^{2}}=1\\right\\}\\,.\\] \\[\\nu_{n}=\\max_{\\underset{\\dim F\\leq n}{F\\subseteq L^{2}_{+}}}\\, \\min\\left\\{\\left\\langle L_{u}h\\,|\\,h\\right\\rangle\\,;\\,h\\in F^{\\perp}\\cap H^{ \\frac{1}{2}}_{+}(\\mathbb{T})\\,,\\ \\|h\\|_{L^{2}}=1\\right\\}\\,.\\]  \n\n**Spectrum of** \\(\\tilde{L}_{u}\\,\\)\\(\\tilde{L}_{u}\\,\\)** .**  Let \\(F\\) be any subspace of \\(L^{2}_{+}(\\mathbb{T})\\)of dimension\n \\(n\\,,\\) and consider \\(E:=\\mathbb{C}1\\oplus S(F)\\,,\\) where \\(S\\) is the shift operator, then \\[\\lambda_{n+1}\\geq\\min\\{\\langle\\tilde{L}_{u}h\\mid h\\rangle\\ ;\\|h\\|_{L^{2}}=1,\\, h\\in E^{\\bot}\\cap H^{\\frac{1}{2}}_{+}\\}\\]  , thus by ( 2.2 ) , Observe that \\(E^{\\perp}=S\\left(F^{\\perp}\\right)\\,\\)\n\n\\[\\lambda_{n+1}\\geq \\,\\min\\left\\{\\langle\\tilde{L}_{u}g\\mid g\\rangle+1+\\lvert\\left \\langle Sg\\,|\\,u\\right\\rangle\\rvert^{2}\\ ;\\ \\|g\\|_{L^{2}}=1,\\ g\\in F^{\\bot} \\cap H^{\\frac{1}{2}}_{+}\\right\\}\\,.\\]  \\(\\lvert\\left\\langle Sg\\,|\\,u\\right\\rangle\\rvert^{2}\\geq 0\\)\n\nIn addition, since \\(\\lvert\\left\\langle Sg\\,|\\,u\\right\\rangle\\rvert^{2}\\geq 0\\), we infer for all\n \\(n\\in\\mathbb{N}_{\\geq 0}\\,,\\)\\[\\lambda_{n+1}\\geq\\lambda_{n}+1\\,.\\]  **Spectrum of** \\(L_{u}\\,\\)** \u2013Inequality**  ( 2.6 ) **.**  let \\(F\\) be any subspace of \\(L^{2}_{+}(\\mathbb{T})\\)of dimension\n \\(n\\), and take \\(G:=\\mathbb{C}1\\oplus S(F)+~{}\\mathbb{C}u\\) . Then, \\[\\nu_{n+2}(u)\\geq\\min\\{\\langle L_{u}h\\mid h\\rangle\\ ;\\|h\\|_{L^{2}}=1,\\ h\\in G^{ \\bot}\\cap H^{\\frac{1}{2}}_{+}\\}\\,.\\]  , then Since \\(G^{\\perp}=S\\left(F^{\\perp}\\cap(S^{*}u)^{\\perp}\\right)\\)\\[\\nu_{n+2}\\geq\\min\\left\\{\\langle L_{u}Sg\\mid Sg\\rangle\\ ;\\ \\|g\\|_{L^{2}}=1,\\ g \\in F^{\\bot}\\cap(S^{*}u)^{\\bot}\\cap H^{\\frac{1}{2}}_{+}(\\mathbb{T})\\right\\}\\,.\\]  ,\n Note that \\(g\\perp S^{*}u\\), then by ( 2.2 ), \n\n\\[\\nu_{n+2}\\geq \\,\\min\\left\\{\\langle L_{u}g\\mid g\\rangle+1;\\ \\|g\\|_{L^{2}}=1,\\ g \\in F^{\\bot}\\cap(S^{*}u)^{\\bot}\\cap H^{\\frac{1}{2}}_{+}(\\mathbb{T})\\right\\}\\,,\\]  \n\nleading to \\[\\nu_{n+2}\\geq\\nu_{n}+1\\,.\\]  ",
    "From embedding \\(L^{\\frac{2n}{n-2}}(\\Omega)\\hookrightarrow L^{\\frac{2n\\gamma}{n-2(1-\\sigma)}}(\\Omega)\\)and\n \\(D(A^{\\frac{1-\\sigma}{2}})\\hookrightarrow L^{\\frac{2n}{n-2(1+\\sigma)}}(\\Omega)\\), (\n ) and the Young inequality, we conclude \n\n\\[\\left(f_{1}\\left(v_{1}(t)\\right),A^{\\sigma}v_{2}(t)\\right) \\leqslant C\\int_{\\Omega}\\left(1+\\left|v_{1}(t)\\right|^{\\gamma} \\right)\\left|A^{\\sigma}v_{2}(t)\\right|dx\\] \\[\\leqslant C\\left(1+\\left\\|v_{1}(t)\\right\\|^{\\gamma}_{L^{\\frac{2n \\gamma}{n+2-2\\sigma}}(\\Omega)}\\right)\\|A^{\\sigma}v_{2}(t)\\|_{L^{\\frac{2n}{n-2+ 2\\sigma}}(\\Omega)}\\] \\[\\leqslant C\\left(1+\\left\\|v_{1}(t)\\right\\|^{\\gamma}_{L^{\\frac{2n} {n-2}}(\\Omega)}\\right)\\left\\|A^{\\sigma}v_{2}(t)\\right\\|_{L^{\\frac{2n}{n-2+2 \\sigma}}(\\Omega)}\\] \\[\\leqslant C\\left(1+\\left\\|v_{1}(t)\\right\\|^{\\gamma}_{L^{\\frac{2n} {n-2}}(\\Omega)}\\right)\\|A^{\\frac{1+\\sigma}{2}}v_{2}(t)\\|\\] \\[\\leqslant C\\left(1+\\left\\|v_{1}(t)\\right\\|_{L^{\\frac{2n}{n-2}}( \\Omega)}^{2\\gamma}\\right)+\\frac{1}{16}\\|A^{\\frac{1+\\sigma}{2}}v_{2}(t)\\|^{2}.\\  \n\nUsing ( 1.7 ), we derive \n\n\\[|(f(u(t))-f\\left(v_{1}(t)),A^{\\sigma}v_{2}(t))|\\right. \\leqslant C\\int_{\\Omega}\\left|(f^{\\prime}\\left((1-\\mu)u(t))+\\mu v _{1}(t)\\right)\\right||u(t)-v_{1}(t)|\\,|A^{\\sigma}v_{2}(t)|dx\\ \\[\\leqslant C\\int_{\\Omega}\\left(1+|u(t)|^{\\frac{4}{n-2}}+\\left|v_{1 }(t)\\right|^{\\frac{4}{n-2}}\\right)\\left|v_{2}(t)\\right|\\left|A^{\\sigma}v_{2}(t )\\right|dx,\\]  \n\nwhere\n \\(0<\\mu<1\\).\n \n\nNoticing \\(u(t)=v_{1}(t)+v_{2}(t)\\), it follows that\n \n\n\\[\\int_{\\Omega}|u(t)|^{\\frac{4}{n-2}}\\left|v_{2}(t)\\right||A^{\\sigma}v_{2}(t)|dx \\leqslant C\\int_{\\Omega}\\left(\\left|v_{1}(t)\\right|^{\\frac{4}{n-2}}+\\left|v_{2 }(t)\\right|^{\\frac{4}{n-2}}\\right)\\left|v_{2}(t)\\right|\\left|A^{\\sigma}v_{2}(t )\\right|dx.\\  \n\nHence, from Lemma  2.11 , the Cauchy and Young inequalities, we obtain there exists positive constants \\(\\widetilde{C}_{4}\\)\\(\\widetilde{C}_{4}\\) and \\(\\widetilde{C}_{5}\\)\\(\\widetilde{C}_{5}\\) such that \n\n\\[\\int_{\\Omega}\\left|v_{2}(t)\\right|\\left|A^{\\sigma}v_{2}(t)\\right|dx\\leqslant \\widetilde{C}_{4}+\\widetilde{C}_{5}\\|A^{\\frac{1+{\\sigma}}{2}}v_{2}(t)\\|^{2}.\\  \n\nConducting similar calculations to ( 4.72 ), then by Corollary  4.8 , we deduce \n\n\\[\\int_{\\Omega}|v_{1}(t)|^{\\frac{4}{n-2}}|v_{2}(t)||A^{\\sigma}v_{2} (t)|dx \\leqslant C\\left\\|v_{1}(t)\\right\\|_{L^{\\frac{2n}{n-2}}(\\Omega)}^{ \\frac{4}{n-2}}\\left\\|v_{2}(t)\\right\\|_{L^{\\frac{2n}{n-2(1+\\sigma)}}(\\Omega)} \\left\\|A^{\\sigma}v_{2}(t)\\right\\|_{L^{\\frac{2n}{n-2(1-\\sigma)}}(\\Omega)}\\] \\[\\leqslant C\\|A^{\\frac{1}{2}}v_{1}(t)\\|^{\\frac{4}{n-2}}\\|A^{\\frac{ 1+\\sigma}{2}}v_{2}(t)\\|^{2}\\] \\[\\leqslant\\frac{1}{16}\\|A^{\\frac{1+\\sigma}{2}}v_{2}(t)\\|^{2}+C \\widetilde{C}_{3}\\left\\|\\nabla v_{1}(t)\\right\\|^{2}\\|A^{\\frac{1+\\sigma}{2}}v_{ 2}(t)\\|^{2}.\\  ",
    "## 4. TinySiamese Network The proposed TinySiamese neural network takes on a new look and a new way of working which is different from the standard Siamese network. The difference first appears in the input processing of the network. Instead of having images as input, the input was the output feature vector of a pretrained CNN model. In other words, all input images would be transformed into feature vectors using a feature extractor (such as a pre-trained CNN model) as illustrated in Fig. 3. Then, the Tiny-Siamese encoded the features in a small set of layers and finally calculated the distance between two encoded feature vectors and generated similarity score. Using this score, the model was trained from scratch with the Adam optimization algorithm and binary cross-entropy loss function. \n\n### 4.1. Architecture Unlike the standard Siamese, the input of the TinySiamese was the encoded image as a feature vector. The backbone layers first aimed to extract relevant features using a linear fully-connected layer and a ReLU layer and then amplify them using another linear fully-connected layer and Sigmoid layer. The output size of the first linear layer had the half size of the input (n, n/2) and was followed by a non-linear ReLU layer. The second linear layer took n/2 features in input and came back to the same first input size in output (n/2, n). This layer was followed by a non-linear Sigmoid layer. The outputs of the TinySiamese sub-networks were encoded into an n-dimensional vector using inputs of a size equal to n. Siamese networks are usually trained \n\nFigure 3: The Proposed Architecture Based on TinySiamese Network for Verification. ",
    "# Natural Language is All a Graph Needs **Ruosong Ye** **Caiqi Zhang** **Runhui Wang** Rutgers University University of Cambridge Rutgers University \n\nruosong.ye@rutgers.edu cz391@cam.ac.uk runhui.wang@rutgers.edu \n\n**Shuyuan Xu** **Yongfeng Zhang** Rutgers University Rutgers University \n\nshuyuan.xu@rutgers.edu yongfeng.zhang@rutgers.edu \n\n##### Abstract\nThe emergence of large-scale pre-trained language models, such as ChatGPT, has revolutionized various research fields in artificial intelligence. Transformers based large language models (LLMs) have gradually replaced CNNs and RNNs to unify fields of computer vision and natural language processing. Compared with the data that exists relatively independently such as images, videos or texts, graph is a type of data that contains rich structural and relational information. Meanwhile, natural language, as one of the most expressive mediums, excels in describing complex structures. However, existing work on incorporating graph learning problems into the generative language modeling framework remains very limited. As the importance of large language models continues to grow, it becomes essential to explore whether LLMs can also replace GNNs as the foundation model for graphs. In this paper, we propose ** InstructGLM** ( **Instruct** ion-finetuned ** G** raph ** L** anguage ** M** odel), systematically design highly scalable prompts based on natural language instructions, and use natural language to describe the geometric structure and node features of the graph for instruction tuning an LLM to perform learning and inference on graphs in a generative manner. Our method exceeds all competitive GNN baselines on ogbn-arxiv, Cora and PubMed datasets, which demonstrates the effectiveness of our method and sheds light on generative large language models as the foundation model for graph machine learning. \n\n## Introduction Before the advent of Transformers [ 1 ], various artificial intelligence domains with different inductive biases had diverse foundational model architectures. For instance, CNNs [ 2 ,  3 ] were designed with considerations for spatial invariance in images, leading to superior performance in computer vision tasks [ 4 ,  5 ]. Memory-enhanced models like RNNs [ 6 ] and LSTM [ 7 ,  8 ] were widely used for handling sequential data such as natural language [ 9 ] and audio [ 10 ]. Graph Neural Networks (GNNs) excel in capturing topological information by employing message passing and aggregation mechanisms, making them a preferred choice in the field of graph learning for a long time [ 11 \u2013 13 ]. \n\nIn recent years, the AI community has witnessed the emergence of numerous powerful pre-trained Large Language Models (LLMs) [ 14 \u2013 18 ], which are driving huge advancements and lead to the pursuit of possible Artificial General Intelligence (AGI) [ 19 ]. Under this background, there is a trend towards unification in model architectures across different domains. Specifically, pre-trained Transformers have demonstrated remarkable performance on various modalities, such as images [ 20 ] and videos [ 21 ] in computer vision, text in natural language processing [ 22 ], structured data in graph machine learning [ 23 ], decision sequences in reinforcement learning [ 24 ], and visual-text pairs in multimodal tasks [ 25 ]. There has even been Transformers capable of handling twelve modalities [ 26 ]. \n\nBesides model architecture, the unification of processing method in handling multimodal data is also a significant trend worth attention. T5 [ 15 ] established a text-to-text framework, unifying all NLP ",
    "each root subgroup may be expressed in terms of commutators of other root subgroups. If some commutative unital ring \\(K\\) acts on the root subgroups in a natural way, then the resulting odd form ring\n \\((R,\\Delta)\\)is an augmented odd form\n \\(K\\)-algebra and in the last claim of the theorem the maps of the root subgroups are isomorphisms. \n\nThe Chevalley commutator formula is \\[[G_{\\alpha},G_{\\beta}]\\leq\\prod_{\\begin{subarray}{c}i\\alpha+j\\beta\\in\\Phi\\\\ i,j\\in\\{1,2,\\ldots\\}\\end{subarray}}G_{i\\alpha+j\\beta},\\]  we also assume that \\(G_{2\\alpha}\\leq G_{\\alpha}\\)is\n \\(2\\)-step nilpotent filtrations for any ultrashort\n root \\(\\alpha\\). In other words, \\(G\\) is a group with \\(\\mathsf{BC}_{\\ell}\\)-commutator relations in the sense of [8]. Alternatively, we may assume only that \\(G\\) contains groups indexed by a root system of type \\(\\mathsf{B}_{\\ell}\\)and \\[[G_{\\alpha},G_{\\beta}]\\leq\\prod_{\\begin{subarray}{c}i\\alpha+j\\beta\\in\\Phi\\\\ i,j\\in\\mathbb{R}_{+}\\end{subarray}}G_{i\\alpha+j\\beta}.\\]  These formulas turn out to be equivalent (modulo other natural conditions) up to a choice of the nilpotent filtrations \\(G_{2\\alpha}\\leq G_{\\alpha}\\). \n\n\\(2\\)we recall the definitions of\n \\(3\\)and\n \\(4\\)we list the\n precise conditions on \\(G\\) and its subgroups. Namely, the conditions are (C1)\u2013(C5) without using a commutative unital ring \\(K\\) or (C1)\u2013(C8) involving \\(K\\). In section \\(4\\)we also discuss the case\n \\(\\ell=3\\): under additional \u201cassociativity conditions\u201d\n (A1)\u2013(A4) the main results still hold, otherwise there are counterexamples (e.g. Chevalley groups of types \\(\\mathsf{E}_{6}\\) and \\(\\mathsf{E}_{7}\\)). These associativity conditions always hold for \\(\\ell\\geq 4\\)by theorem 1. Sections\n \\(5\\)and\n \\(6\\)contain the proof of the main theorem\n \\(7\\)we prove theorem 3 for\n groups satisfying only (C1)\u2013(C5). \n\n## Odd form groups and odd form rings \n\n\\(2\\)-step nilpotent groups with various operations,\n so it is useful to develop some technique to simplify such constructions. The \\(2\\)-step nilpotent groups is usually denoted by\n \\(\\dotplus\\). All lemmas in this section may be checked directly or using the machinery of polyquadratic maps [14,  \u00a7 1.3]. \n\nWe say that\n \\((M,H)\\)is a\n _ hermitian group_  if \\(M\\) and \\(H\\) are abelian groups, there is an automorphism \\(\\par\\!\\;\\overline{\\!\\!\\:(-)\\vphantom{!}\\!\\!\\:}\\;\\!\\colon H\\to H\\)such\n \\(2\\), and there is a biadditive pairing\n \\(\\langle{-},{=}\\rangle\\colon M\\times M\\to H\\)\\(\\par\\!\\;\\overline{\\!\\!\\:\\langle m,m^{\\prime}\\rangle\\vphantom{!}\\!\\!\\:}\\;\\!\\par =\\langle m^{\\prime},m\\rangle\\) such that \\(\\par\\!\\;\\overline{\\!\\!\\:\\langle m,m^{\\prime}\\rangle\\vphantom{!}\\!\\!\\:}\\;\\!\\par =\\langle m^{\\prime},m\\rangle\\)for all \\(m,m^{\\prime}\\in M\\). ",
    "ones where there are only a few particles, we opt to first bin the data points by _ X_ max . In each bin we calculate the mean value of the spectral parameter and the corresponding standard deviation. If a bin contains less than two data points, which can occur because not all showers might contain particles in that slice, we do not consider it for the parabolic fit. All the other bins are then fed to a least-squares fitting routine. We end up with a spectral function describing the spectral parameter value as function of the shower _ X_ max  in a given slice, for a particular antenna, \n\n\\[a(r_{\\text{ant}},X_{\\text{slice}},\\;X_{\\text{max}})=p_{0}^{a}+p_ {1}^{a}\\cdot\\;X_{\\text{max}}+p_{2}^{a}\\cdot\\;X_{\\text{max}}^{2}\\] \\[b(r_{\\text{ant}},X_{\\text{slice}},\\;X_{\\text{max}})=p_{0}^{b}+p_ {1}^{b}\\cdot\\;X_{\\text{max}}+p_{2}^{b}\\cdot\\;X_{\\text{max}}^{2}\\] \\[c(r_{\\text{ant}},X_{\\text{slice}},\\;X_{\\text{max}})=p_{0}^{c}+p_ {1}^{c}\\cdot\\;X_{\\text{max}}+p_{2}^{c}\\cdot\\;X_{\\text{max}}^{2}\\;.\\]  \n\nIn Figure 3 we present a schematic overview of how we extract the spectral functions. These need to be determined only once for the air shower geometry under consideration. Generalising them to arbitrary geometries will be the subject of future work. \n\n### Construction of the template \n\nThe final ingredient of template synthesis, is the _ template_  itself. With this object and the spectral functions, we have all the necessary information to synthesise the emission from an air shower with arbitrary longitudinal profile. \n\nIn order to construct our template, we use a single microscopic simulation called the _ origin_  shower. The origin \n\nthe spectral coefficients. We can fit this dependency of the coefficients in order to obtain the _ spectral functions_ \n\nis a microscopic simulation, sliced using the same procedure as the simulation set that was used to extract the spectral functions. From the origin shower we calculate the amplitude frequency spectrum \\(A_{\\text{origin}}\\)\\(A_{\\text{origin}}\\)the amplitude frequency spectrum Aorigin and phase frequency spectrum \u03d5origin in each antenna and every slice,\n \\(\\phi_{\\text{origin}}\\)in each antenna and every slice,\n \\(\\phi_{\\text{origin}}\\) in each antenna and every slice, as shown in Figure 4. Using the spectral functions with the _ X_ max  of the origin shower, we can normalise these to obtain the spectra of the template, \n\n\\[A_{\\text{template}}(r_{\\text{ant}},f,X_{\\text{slice}}) =A_{\\text{origin}}(r_{\\text{ant}},f,X_{\\text{slice}})\\] \\[\\qquad\\cdot\\left[\\tilde{A}(r_{\\text{ant}},f,X_{\\text{slice}}\\;X_{ \\text{max}}^{\\text{origin}})\\right]^{-1}\\] \\[\\phi_{\\text{template}}(r_{ant},f,X_{\\text{slice}}) =\\phi_{\\text{origin}}(r_{\\text{ant}},f,X_{\\text{slice}})\\;.\\]  \n\n\\[a(r_{\\text{ant}},X_{\\text{slice}},\\;X_{\\text{max}})\\;,\\] \\[b(r_{\\text{ant}},X_{\\text{slice}},\\;X_{\\text{max}})\\;,\\] \\[c(r_{\\text{ant}},X_{\\text{slice}},\\;X_{\\text{max}})\\;,\\]  \n\nin every slice. This procedure is applied to each antenna \n\n\n\nIn this equation the parameterised amplitude frequency spectrum  \\(\\tilde{A}(f)\\)\\(\\tilde{A}(f)\\)also depends on\n _ X_ max \\(\\tilde{A}(f)\\)spectrum A(f) also depends on Xmax through the spectral coefficients, which are calculated using the fitted\n \\(f\\)is restricted to the range used to fit the spectral\n \\(f\\) is restricted to the range used to fit the spectral functions. \n\nindependently, indicated by the explicit dependency on the antenna distance. Therefore in the current version of template synthesis \\(r_{\\text{ant}}\\), as well as \\(X_{\\text{slice}}\\), can only take values on a fixed grid. We note here that while we write the functions as both a function of \\(X_{\\text{slice}}\\) and _ X_ max , a more accurate description should probably take some combination of the two that could serve as a proxy for shower age in the slice. We come back to this in Section VI. \n\nThe template thus contains a normalised version of the \n\nWe fit the spectral parameters as a function of _ X_ max \n\norigin shower. It acquires its phase frequency spectrum as is, but the origin amplitude frequency spectrum is corrected for the longitudinal evolution (particle number in \n\nusing a parabola. In order to better deal with the large scatter for some slices, especially the very early and late \n\nFIG. 3. Schematic overview of how we extract the spectral functions from our simulation set. In every antenna, we decompose the emission from every slice in the geomagnetic (GEO) and charge-excess (CE) components. These are then fitted using Equations (4) and (5) respectively. Finally, we fit a parabola to each spectral parameter as a function of _ X_ max . The result of this are the spectral functions. ",
    "### Effectiveness of different features in the physical world \n\n#### Color transfer and texture blurring \n\nIn physical-world deployments, attack patches are often affected by color transfer due to lighting conditions or blurring caused by camera focus or smudging. To analyze if these changes will affect the performance of the attack patches, we compare the performance of an original patch, a color-adjusted patch, and a local texture adjusted patch. The color-adjusted patch is applied by adding a value ( \\(\\delta\\)) to all values in RGB channels and making sure \\(\\delta\\) will not lead to an overflow. This color transfer will not change the texture information of the patch. The local texture adjustment is applied by using a 3x3 Gaussian blur. Figure 4 demonstrates the two types of feature adjustments applying to a patch with brightness range=0.24. \n\nThe performances of different patches are shown in Table 1. Regardless of the lightness restriction, the color transfer patch achieves almost the same success rate as the original patch. This performance shows that the patch does not need to maintain a specific color to deceive the target network. On the other hand, the blurred patch exhibits a significant decrease in success rate, suggesting that local texture is the key feature in deceiving target networks. Using these findings, we can apply the proposed hue mapping method to adjust the color of the patch and enhance its integration with the target environment, resulting in further reduced visibility. This process does not require any learning and can be quickly applied when deploying the patch in the physical world. \n\n#### Random color variations When printing an attack patch, it is important to consider that normal printers are not able to produce a patch with precisely the same color as the digital version. Therefore, the patch\u2019s robustness to random color variations must be evaluated. \n\nTo replicate the color drift that commonly occurs during printing, we generate random noise within a restricted range that corresponds to a percentage of the original value. This approach allows us to simulate different levels of drift, and the results are shown in Table 2. \n\nFigure 4: Patch with different feature changes. (left: original patch; middle: color transfer patch; right: texture blurring patch) \n\nTable 1: Performance with color transfer and Gaussian blur \n\n\\begin{tabular}{c c c c}\n\\hline \\hline\nBrightness range & Original & Color transfer & Gaussian blur \\\\\n\\hline\n\\(1\\) (AdvPatch) & 89.4\\% & 90.8\\% & 47.8\\% \\\\\n\\(0.35\\) & 89.5\\% & 87.9\\% & 22.7\\% \\\\\n\\(0.24\\) & 74.2\\% & 75.3\\% & 10.1\\% \\\\ \\hline \\hline\n\\end{tabular}\n\n\nTable 2: Performance with different color drift \n\n\\begin{tabular}{c c c c c}\n\\hline \\hline\nBrightness range & Original & 10\\% drift & 15\\% drift & 20\\% drift \\\\\n\\hline\n\\(1\\) (AdvPatch) & 89.4\\% & 87.6\\% & 85.9\\% & 83.3\\% \\\\\n\\(0.35\\) & 89.5\\% & 84.2\\% & 77.6\\% & 67.2\\% \\\\\n\\(0.24\\) & 74.2\\% & 68.6\\% & 43.2\\% & 27.3\\% \\\\ \\hline \\hline\n\\end{tabular}\n",
    "power of \\(\\mathcal{M}_{A}\\). While of potential interest, this is unfortunately not demonstrable from the present analysis. \n\n### 6.2 Impact of magnetic fields on the energetics of sub-structures \n\nWe are also interested in assessing the energetic relevance of magnetic fields over different length scales in the MCs, especially with respect to potentially star-forming structures. For this purpose, we compute the volume term of the magnetic energy and compare it with the kinetic and potential energies. Similar work for the same simulations has been performed by  Ganguly et al.  ( 2022 ), who assess the virial balance of the cloud sub-structures. Here, we extend the range of our analysis to include the dynamics of lower-density gas (between 10 _-24_and 10 _-22_g cm _-3_; _ low-den_  dendrogram analysis, see Table  2 ). The magnetic energy of a given structure is computed as \n\nThe cyan dashed line represents the linear least-squares best fit \n\n\\[E_{\\rm B}=\\int_{V}\\frac{1}{8\\pi}|\\mathbf{B}|^{2}\\mathrm{d}^{3}r,\\] (21)  \n\nwhere the integration is computed over the entire volume \\(V\\)of the structure. The kinetic energy is computed using the following relation: \n\nperformed on the logarithm of the points for high densities ( \\(\\rho_{\\rm thr}>1.1\\times 10^{-21}\\)g cm _-3_). The best fit of \\(\\kappa=0.47\\pm 0.03\\)is consistent\n with the strong-field limit of \\(B\\propto\\rho^{0.5}\\). We have already shown in the previous section (Section  5 ) that our structures are on average highly elongated, and magnetic fields clearly help to deform the shape of the forming structures. It is therefore not unexpected that we find a shallower scaling compared to the weak field limit ( \\(\\kappa=0.67\\)).\n \n\n\\[E_{\\mathrm{KE}}=\\frac{1}{2}\\int_{V}\\rho(\\mathbf{v}-\\mathbf{v}_{0})^{2}\\mathrm{ d}^{3}r.\\] (22)  \n\nWe see that, while there is no clear transition from the sub- to the \n\n\n\nHere, \\(\\mathbf{v}_{0}\\) is the centre of mass velocity computed from Eq.  17 . The self-gravitating potential energy of a given structure is obtained using the following relation: \n\n\\[E_{\\rm PE}=-\\frac{1}{2}G\\int_{V}\\int_{V}\\frac{\\rho(\\mathbf{r})\\rho(\\mathbf{r^{ \\prime}})}{|\\mathbf{r}-\\mathbf{r^{\\prime}}|}\\mathrm{d}^{3}r\\mathrm{d}^{3}r^{ \\prime},\\] (23)  \n\nsuper-Alfv\u00e9nic regime, there is clearly a trend that higher Alfv\u00e9nic Mach numbers are preferentially obtained at the higher density end. This is confirmed by a Kolmogorov-Smirnov (KS) two-sample test, which compares if two distributions belong to the same population. In this case, we compare the \\(\\rho_{\\rm thr}\\)-distributions of structures with \\(\\mathcal{M}_{A}>1\\)\\(6\\times 10^{-4}\\)and\n \\(\\mathcal{M}_{A}\\leq 1\\)Myr\n . We find the\n \\(p\\)-values 3 to be very low: \\(6\\times 10^{-4}\\)at 2 Myr and\n \\(5.2\\times 10^{-15}\\)found\n at 3.5 Myr (see Table ). \n\nwhere \\(G\\)is the gravitational constant. We compute the self-gravity \n\nCrutcher et al.  ( 2010 ) found that the observed magnetic field distribution is rather flat at low density, in agreement with the idea that \n\nof each dendrogram structure using a KD-tree algorithm ( Bentley 1975 ) instead of an \\(\\mathcal{O}(N^{2})\\)relative\n  direct computation. We show the relative importance of magnetic fields with respect \n\ndenser clouds are swept up along the magnetic field lines on large scales, while at higher density there is a power-law increase of the magnetic field strength. If spherical clouds start to collapse and the magnetic field is not strong enough to stop the collapse, one expects a power-law slope of \\(\\kappa=0.5-0.67\\)wei\n (see above).\n In the case of our clouds, we find that the high-density end is well consistent with \\(\\kappa=0.5\\), and the lower-density end clearly shows a\n much shallower slope. Nonetheless, there does not seem to be a clear single density at which there is a sharp change in slope. Simulations by  Li et al.  ( 2015 ),  Mocz et al.  ( 2017 ),  Girichidis et al.  ( 2018 ),  Zhang et al.  ( 2019 ) find similarly the lack of a sharp transition density.  Auddy et al.  ( 2022 ) predict that the transition density depends on the fourth 3  If the \\(p\\)-value is larger than a certain value (typically 0.05), this means that we cannot reject the null hypothesis that the sub-Alfv\u00e9nic and super-Alfv\u00e9nic structures have the same underlying density distribution. \n\nto potential and kinetic energy in the left and right panel of Fig.  7 , respectively, for all MHD cloud structures at \\(t_{\\rm evol}=3.5\\)Myr. For\n both plots, the \\(x\\)-axis represents the density threshold \\(\\rho_{\\rm thr}\\), and the \\(y\\)-axis represents \\(E_{\\rm B}/|E_{\\rm PE}|\\)points\n  (left) and \\(E_{\\rm B}/|E_{\\rm KE}|\\) (right), respectively. The colours of the points represent their morphologies. Here, for the purpose of understanding the dynamics of low-density gas, we also include the \"unclassified\" structures (i.e. structures with >5% of their surface cells touching the edge of the analysis box, see Section  3 ). The side panels to the right and top of each plot show the marginal distributions of \\(N_{x}/N_{\\rm tot}\\) for each morphology. Note that, since the definition of \\(N_{\\rm tot}\\) (Eq.  14 ) does not contain unclassified structures, the fractions in the two side panels add up to greater than unity. The filled symbols are molecular structures, while the open symbols are atomic. \n\nTypically, for low-density structures, which mostly consist of atomic gas, the magnetic energy is either comparable to or much larger than the potential energy (left panel of Fig.  7 ). The magnetic energy is \n\n\\begin{tabular}{c|c|c|c}\n\\hline\nvariable 1 & variable 2 & time [Myr] & p-value \\\\\n\\hline\n\\(\\rho_{\\rm thr}(\\mathcal{M}_{A}>1)\\) & \\(\\rho_{\\rm thr}(\\mathcal{M}_{A}\\leq 1)\\) & 2 & \\(6\\times 10^{-4}\\) \\\\\n & & 3.5 & \\(5.2\\times 10^{-15}\\) \\\\ \\hline\n\\end{tabular}\n\n\n**Table 6.**  The \\(p\\)-values of the 2-sample KS test for the density distribution of sub-Alfvenic and super-Alfv\u00e9nic structures. We can see that the \\(p\\)-value is low for both 2 and 3.5 Myr, suggesting that sub-Alfv\u00e9nic and super-Alfv\u00e9nic structures (corresponding to bluish and reddish points in Fig.  6 , respectively) have statistically significant differences in their density distributions. \n\n**Figure 6.**  Relation between the root-mean-square magnetic field and \\(\\rho_{\\rm thr}\\)for all MHD clouds at \\(t_{\\rm evol}\\)=3.5 Myr. The colour bar shows the Alfv\u00e9nic Mach number \\(\\mathcal{M}_{\\rm A}\\)(\n . The dash-dotted line represents the B \\(-\\rho\\)\\(B\\propto\\rho^{0.5}\\)relation from Crutcher et al.  ( 2010 ), while the dotted line represents a \\(B\\propto\\rho^{0.5}\\)all\n power law. The cyan dashed line represents the best fit power law for all points with \\(\\rho_{\\rm thr}>1.1\\times 10^{-21}\\)g cm _-3_. ",
    "feedback topic. Figure  4  presents an overview of the two different presentations of this taxonomy, and the mapping between them. \n\nWe motivate this taxonomy to finely categorize \n\ninstructions given in the prompt. Past research has shown the importance of stating the actions a model can take, such as outputting \u201cI don\u2019t know.\u201d ( Zhou et al. ,  2023 ). Similarly, how strongly the prompt encourages a model to incorporate feedback can favor overoptimization. \n\n**Introducing Errors** Finally, effective feedback \n\ncurrent approaches to textual feedback that implic itly formulate feedback solely for _ utility_  (i.e.,how useful is the feedback for guiding a model toward a suitable response). However, they do not cate gorize its content, leaving a conceptual gap about _what_  makes feedback useful. Our taxonomy strati fies the feedback space, allowing a deliberate and systematic study of feedback content. \n\n### General Taxonomy We break down feedback content along ten dimen sions that influence how feedback is formulated: \n\nmay communicate information on where the learner is failing, requiring an understanding of the possible error modes for a given task, and which ones the learner is likely in. For example, guessing and committing systematic reasoning mistakes are reflections of differing understandings. Exploring the error space and identifying the mistakes made by a learner is an important extension to the base framework directly derived from pedagogical and psychology of education research. \n\n\n1._ length_ , an indication of how much feedback feedback is given, possibly measured \n\n### Feedback Integration \n\nby counting its number of tokens, \n2._ granularity_ , a measure of the level of detail with which the feedback addresses the original answer \u2014 it is not a measure of how much of the answer is being considered, but rather of the level of detail with which it is being considered, 8 \n3._ applicability of instructions_ , expressing both whether the feedback contains instructions, as well as how applicable those instructions are for the learner and their current understanding and approach to solving the task, \n4._ answer coverage_ , which registers how much \n\nThe method used to transmit the feedback to the model influences how it is subsequently processed. Fernandes et al.  ( 2023 ) identify three common feed back integration mechanisms: feedback-based imi tation learning, joint-feedback modeling, and rein forcement learning. In addition to this, we also con sider feedback use in in-context learning ( Brown et al. ,  2020 ). The training objective will necessarily influence how the model is processing and incorpo rating feedback. Typically, the training relies upon either scalar feedback (a single number encoding how much the model should be rewarded for its out put) or a ranking (how well a given output did in relation to other candidate answers). However, this is simple information, and does not leverage the rich and complex information encoded in natural language feedback. Section  5  therefore comprehen sively explores the different types of information that can be encoded in feedback. \n\nof the learner\u2019s answer is considered to gen erate the given feedback. The feedback could be independent of the answer, or only relate to parts of the answer (e.g.,, focusing on a par ticular mistake), or the feedback might take the complete answer into consideration, \n5._ criteria_ , denoting which criteria the answer is \n\n## Feedback Content Taxonomy \n\nbeing evaluated on: global evaluation, specific dimensions (e.g., fluency, engagement, etc.), or, alternatively, no dimensions (the answer is not being evaluated), \n6._ information novelty_ , indicating the degree to which learner already had access to the information provided in the feedback, ranging from all information being previously known 8 For an open-answer example task, feedback might range from global learning meta-feedback, to global but task specific, to paragraph-level, to sentence-level, to word-level, to token-level feedback. \n\nIn Section  4 , we presented an overview of the com plex ecosystem of feedback, including an expansion specifically for LLMs (i.e., FELT) that con nects various background elements (e.g.,the learner, the task, the error types) to the actual feedback that must be given. In this section, we expand on our analysis of the _ content_  dimension of feedback in FELT. Specifically, we present a taxonomy of feed back content under two different forms: a set of 10 broad axes along which feedback can vary, and a more concrete set of nine emergent categories for ",
    "individual escape fractions, we select a subsample of galaxies not used for the fitting in order to avoid problems due to over-fitting. As a measure for this accuracy we use the average relative deviation \n\n\\[r=\\frac{1}{N_{\\mathrm{test}}}\\sum_{i=1}^{N_{\\mathrm{test}}}\\frac{\\lvert f_{ \\mathrm{esc,pred},i}-f_{\\mathrm{{esc},i}}\\rvert}{f_{\\mathrm{esc},i}},\\] (15)  \n\nwith \\(f_{\\mathrm{esc,pred},i}\\)and \\(f_{\\mathrm{esc},i}\\)being the predicted and modelled escape fraction of the \\(i\\)-th galaxy respectively, and \\(N_{\\mathrm{test}}\\) the number of test galaxies. We only used galaxies with \\(f_{\\mathrm{esc}}>0.01\\), as this measure\n is not useful for \\(f_{\\mathrm{esc}}\\) approaching 0. We find a value of \\(r\\approx 1.2\\)2,\n ,\n i.e. the average estimation error is of the order of a factor of 2, and as such the accuracy of predicting the escape fraction of a single halo is limited. However, for large scale studies where the statistical distribution of the escape fraction is more important, this model performs significantly better. Indeed, the average escape fraction obtained with the fitting formula is\n \\(\\bar{f}_{\\mathrm{esc,pred},i}=0.121\\pm 0.086\\), with\n the modelled escape fraction being\n \\(\\bar{f}_{\\mathrm{esc},i}=0.117\\pm 0.1334\\).\n \n\nIn fig.  9  we show how well the fitting formula is able to reproduce the behaviour of the escape fraction in relation to the stellar mass and redshift that we examined in fig.  2 . We see that the evolution of the escape fraction with redshift is successfully reproduced. However, the large gradients in \\(\\langle f_{\\mathrm{esc}}\\rangle\\)that are seen in fig.  8  are smoothed out. The reason for this likely lies in the optimization process used to find the fitting formula, as the mean squared error was used for optimization, and thus large gradients in the fitting function were disfavored because they led to large errors for the outer mass ranges. \n\nFig.  10  shows that the fitting formula is able to successfully predict the bimodality in the escape fraction, as seen in fig.  4 . However the boundary between the two modes is less pronounced. This is likely caused by the smoothing effect of the optimization process of the fitting function discussed above. \n\nFinally, by comparing fig.  11  to fig.  3 , we see that the fitting formula is able to reproduce all important trends, namely, the decrease in peak escape fraction with redshift and the approximate locations and values of the peaks. We also reproduce both the minima and maxima in the dependence of \\(f_{\\mathrm{esc}}\\) on \\(M_{\\mathrm{gas}}\\). \n\nAs mentioned earlier, it is important to emphasize that our modeling aims to capture the overall trends of LyC escape with galactic properties. Considering the inherent limitations in resolution and simplifications involved in estimating the LyC flux, it is crucial to scale the absolute value predicted by the fitting formula using a free parameter, which should be determined based on the specific ionizing photon budget required for reionization. We intend to investigate the large scale implication of these results and to determine scaling parameters in subsequent work. \n\n## 5 DISCUSSION AND CONCLUSIONS \n\nare likely to be inaccurate. Indeed, the unconstrained estimate\n \\(\\tilde{f}_{\\mathrm{esc}}\\)\n\nTo gain a better understanding of the correlation of LyC escape with galactic properties, we have applied the physically motivated model for the LyC escape fraction developed in F23 to \\(\\approx\\)Nelson et al. 2019\n 600,000 galaxies extracted from the TNG50 simulation ( Nelson et al. 2019 ;  Pillepich et al. 2019 ) in the range\n \\(5.2<z<20\\).\n \n\npredicts high escape fraction values in the high stellar mass range and hence does not match our findings in fig.  4 . We therefore artificially set the \\(f_{\\mathrm{esc}}\\) value to 0 for galaxies with \\(x_{\\star}>8.5\\), obtaining:\n \n\nGiven the large uncertainties in the subgrid modeling of LyC escape, attempting a quantitative comparison of our results to those of \n\n\\[f_{\\mathrm{esc}}=\\begin{cases}0\\hskip 28.45274pt&\\text{$\\tilde{f}_{\\mathrm{esc }}<0$ or $M_{\\star,\\mathrm{log}}<8.5$}\\\\ 1&\\text{ $\\tilde{f}_{\\mathrm{esc}}>1$}\\\\ \\tilde{f}_{\\mathrm{esc}}&\\text{otherwise}.\\end{cases}\\] (14)  \n\nprevious studies would be impractical. Therefore, we focus our discussion on qualitative results. Numerous previous numerical studies, such as the First Billion Year project ( Paardekooper et al. 2015 ), CODA-II ( Lewis et al. 2020 ), FIRE-II ( Ma et al. 2020 ), THESAN ( Yeh et al. 2022 ), SPHINX ( Rosdahl et al. 2022 ) and TNG50 \n\nIn order to determine the accuracy of the model in predicting \n\n\n\n**Figure 6.**  Galaxies with disk scale heights \\(H>10^{21.3}\\mathrm{cm}\\)selected for their\n high and low SFR, i.e.\n \\(\\log(\\mathrm{SFR}/\\mathrm{M}_{\\odot}\\mathrm{yr}^{-1})=0.14,0.20\\)and\n \\(0.40\\)(top) and\n \\(\\log(\\mathrm{SFR}/\\mathrm{M}_{\\odot}\\mathrm{yr}^{-1})=-4.34,-4.05\\)bottom,\n figure\n and\n \\(-4.08\\)to\n (bottom figure). From top to\n bottom, the panels in each figure refer to the cell escape fraction, \\(f_{\\rm esc,cell}\\), optical depth of dust, \\(\\tau_{\\mathrm{d}}\\), and of gas, \\(\\tau_{\\mathrm{HI}}\\). ",
    "(image, scene knowledge, query) triples to perform accu rate reasoning. We propose two approaches to perform this new task: Knowledge-embedded Vision-Language Interac tion and Linguistic-enhanced Vision-Language Matching. Experimental results confirm the validity of the proposed approaches but also show that there is still substantial room for improvement, e.g., reasoning and interpretability. \n\nlevel accuracy, we can obtain the message that LeViLM is not capable of performing complicated (multi-hop) reasoning over the scene knowledge and producing accurate predictions. Besides, the prediction process is black-box and can not be explainable, which can be further studied in the future. The answer is that (i) The current baselines can only achieve strong results on easy or medium tasks and are un able to perform well on the hard task; (ii) The interpretability of the baselines is poor. \n\n## Acknowledgement \n\n### 4.5. Case Study \n\nThis work was supported in part by the Chinese Key-Area Research and Development Program \n\nTo further investigate the effects of knowledge, we per form qualitative analysis on four cases in the SK-VG dataset. \n\nof Guangdong Province (2020B0101350001), in part by the Guangdong Basic and Applied Basic Research Foundation (NO. 2020B1515020048), in part by the National Natural Science Foundation of China (NO. 61976250), in part by the Shenzhen Science and Technology Program (NO. JCYJ20220530141211024, NO. JCYJ20220818103001002), in part by the Fundamental Research Funds for the Central Universities under Grant 22lgqb25 and in part by the Guangdong Provincial Key Lab oratory of Big Data Computing, The Chinese University of Hong Kong, Shenzhen. This work was also sponsored by Tencent CCF Open Fund (NO. RBFR2022009). \n\nFigure  5  shows the grounding results of four baselines on four referring expressions. It is observed that in the first case, all the baselines can ground the \u201c _cane_ \u201d in the image even without the knowledge since there is only one cane presented. In the second case, the finetuned LeViLM can detect the target object even without knowledge, while it can not detect the \u201c _Brandon\u2019s servant_ \u201d without knowledge in the third case. In the last case, all the baselines can not ground the referred object correctly, and the last three baselines all treat the \u201c _Spider-Man_ \u201d as the \u201c _enemy_ \u201d. This shows that the baseline models can not perform accurate reasoning in some complicated cases, demonstrating the challenges. \n\n## 5. Concluding Remarks The visual grounding field has emerged as a prominent attractive research direction, where the models are required to reason over vision and language to ground the target ob jects. Yet, the language part of the existing VG benchmarks is only simple description texts, which can not evaluate the reasoning capability of the models comprehensively. To take a step in this direction, we propose a new benchmark dataset called SK-VG, which requires models to reason over the \n\nFigure 5. The illustration of samples from the proposed SK-VG dataset, where a scene story and its four referring expressions are shown with the grounding results from four baseline methods. ",
    "# Unique continuation for an elliptic interface problem using unfitted isoparametric finite elements \n\n##### Abstract\nWe study unique continuation over an interface using a stabilized unfitted finite element method tailored to the conditional stability of the problem. The interface is approximated using an isoparametric transformation of the background mesh and the corresponding geometrical error is included in our error analysis. To counter possible destabilizing effects caused by non-conformity of the discretization and cope with the interface conditions, we introduce adapted regularization terms. This allows to derive error estimates based on conditional stability. Numerical experiments suggest that the presence of an interface seems to be of minor importance for the continuation of the solution beyond the data domain. On the other hand, certain convexity properties of the geometry are crucial as has already been observed for many other problems without interfaces. \n\n##### Keywords:\n**Keywords:**  unfitted finite element method, unique continuation, interface problems, isoparametric finite element method, geometry errors, conditional H\u00a8 older stability \n\n## 1 Introduction \n\n### 1.1 Motivation "
  ]
}